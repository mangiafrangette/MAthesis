Previous work in using artificial neural networks for computational stylistics has concentrated on using large, arbitrary network structures. This paper examines the use of the Cascade-Correlation algorithm for the construction of minimal networks. We find that a number of problems in computational stylistics with a large number of variables but a limited number of training examples may be solved successfully without resorting to large networks. The issue of redundancy in the data is also considered.