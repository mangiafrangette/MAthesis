<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
	"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head><meta http-equiv="content-type" content="text/html; charset=UTF-8"/><meta name="generator" content="ABBYY FineReader 14"/><title>Microsoft Word - 664. Dombrowski-High Performance Computing for Photogrammetry and OCR Made Easy-664.docx</title><link rel="stylesheet" href="664_files/664.css" type="text/css"/>
</head>
<body>
<p><span class="font2" style="font-weight:bold;">High Performance Computing for&nbsp;Photogrammetry and OCR&nbsp;Made Easy</span></p><h3><a name="caption1"></a><a name="bookmark0"></a><span class="font1" style="font-weight:bold;">Quinn Dombrowski</span></h3>
<p><span class="font1"><a href="mailto:quinnd@berkeley.edu">quinnd@berkeley.edu</a></span></p>
<p><span class="font1">UC Berkeley, United States of America</span></p><h3><a name="bookmark1"></a><span class="font1" style="font-weight:bold;">Tassie Gniady</span></h3>
<p><span class="font1"><a href="mailto:ctgniady@iu.edu">ctgniady@iu.edu</a></span></p>
<p><span class="font1">Indiana University, United States of America</span></p><h3><a name="bookmark2"></a><span class="font1" style="font-weight:bold;">Megan Meredith-Lobay</span></h3>
<p><span class="font1"><a href="mailto:megan.lobay@ubc.ca">megan.lobay@ubc.ca</a></span></p>
<p><span class="font1">University of British Columbia, Canada</span></p><h3><a name="bookmark3"></a><span class="font1" style="font-weight:bold;">John Simpson</span></h3>
<p><span class="font1"><a href="mailto:john.simpson@computecanada.ca">john.simpson@computecanada.ca</a> University of Alberta, Canada</span></p>
<p><span class="font1">Computationally-intensive research methods have seen increasing adoption among digital humanities&nbsp;scholars, but for scholars outside R1 institutions with&nbsp;robust computing environments, techniques like pho-togrammetry or text recognition within images can&nbsp;easily monopolize desktop computers for days at a&nbsp;time. Even at institutions with a research computing&nbsp;program, systems are configured for scientific applications, and IT staff may be unaccustomed to working&nbsp;with humanities scholars, particularly those who are&nbsp;not already proficient at using the command line. National compute infrastructures in North America&nbsp;(Compute Canada and XSEDE) are a compelling alternative, providing no-cost compute allocations for researchers and offering support from technical staff interested in and familiar with humanities computing&nbsp;needs. This workshop will start by introducing participants to Compute Canada and XSEDE, cover how to&nbsp;obtain a compute allocation (including for researchers&nbsp;outside of the US and Canada), and proceed through&nbsp;two hands-on tutorials on research methods that benefit from the additional compute power provided by&nbsp;these infrastructures: 1) photogrammetry using PhotoScan and 2) using OCR via Tesseract to extract&nbsp;metadata from images.</span></p><h1><a name="caption2"></a><a name="bookmark4"></a><span class="font0" style="font-weight:bold;">Photogrammetry</span></h1>
<p><span class="font1">Photogrammetry (generating 3D models from a series of partially-overlapping 2D images) is quickly gaining favor as an efficient way to develop models of&nbsp;everything from small artifacts that fit in a light box to&nbsp;large archaeological sites, using drone photography.&nbsp;Stitching photographs together, generating point&nbsp;clouds, and generating the dense mesh that underlies&nbsp;a final model are all computationally-intensive processes that can take up to tens of hours for a small object to weeks for a landscape to be stitched on a high-powered desktop. Using a high-performance compute&nbsp;cluster can reduce the computation time to about ten&nbsp;hours for human-sized statues and twenty-four hours&nbsp;for small landscapes. Generating a dense cloud, in particular, sees a significant performance when run on&nbsp;GPU nodes, which are increasingly common in institutional HPC clusters and available through Compute&nbsp;Canada and XSEDE.</span></p>
<p><span class="font1">One disadvantage of doing photogrammetry on an HPC cluster is that it requires use of the command line&nbsp;and Photoscan's Python API. Since it is not reasonable&nbsp;to expect that all, or even most, scholars who would&nbsp;benefit from photogrammetry are proficient with Python, UC Berkeley has developed a Jupyter notebook&nbsp;that walks through the steps of the photogrammetry&nbsp;process, with opportunities for users to configure the&nbsp;settings along the way. Jupyter notebooks embed documentation along with code, and can serve both as a&nbsp;resource tool for researchers who are learning Python,&nbsp;and as a stand-alone utility for those who want to&nbsp;simply run the code, rather than write it. Indiana University, on the other hand, has developed a workflow&nbsp;using a remote desktop interface so that all the GUI capabilities and workflows of PhotoScan are still available. A python script is still needed so that the user may&nbsp;avail herself of the compute nodes, but the rest of the&nbsp;workflow is very similar traditional PhotoScan usage.&nbsp;Finally, both methods offload the processing the HPC&nbsp;cluster, allowing users to continue to work on a computer that might normally be tied up by the processing&nbsp;demands of photogrammetry.</span></p>
<p><span class="font1">The workshop will give participants hands-on experience creating a 3D model using two different approaches: first, by accessing the Photoscan graphical user interface on a virtual desktop running on XSEDE's&nbsp;Jetstream cloud resource; and second, by using a Jupy-ter notebook running on an HPC cluster.</span></p><h1><a name="bookmark5"></a><span class="font0" style="font-weight:bold;">OCR</span></h1>
<p><span class="font1">Optical Character Recognition (OCR) is a tool used for extracting text from images and is perhaps most&nbsp;well known as a core technology behind the creation&nbsp;of the Google Books and HathiTrust corpora. OCR continues to open historical texts for analysis at large&nbsp;scale, fuelling a significant portion of research work</span></p>
<p><span class="font1">within the digital humanities to the point that it would</span></p>
<p><span class="font1">be difficult to think of the “</span><span class="font1" style="text-decoration:underline;">million books problem</span><span class="font1">” existing without this technology. While there are many OCR tools available the most popular tool that is also&nbsp;free and open source is </span><span class="font1" style="text-decoration:underline;">Tesseract</span><span class="font1">.</span></p>
<p><span class="font1">This portion of the workshop will also make use of Jupyter Notebooks to provide templates for learning&nbsp;the development process and that can then be taken&nbsp;away to speed development of future code. We will&nbsp;feature two projects for participants to practice with.&nbsp;A “traditional” OCR task that will have workshop participants processing images from the London Times in&nbsp;a demonstration of the improvements in OCR over the&nbsp;past few years and a task focusing on processing historical photographs to find text that can be added to&nbsp;the associated metadata to improve the searchability&nbsp;of an index.</span></p><h1><a name="bookmark6"></a><span class="font0" style="font-weight:bold;">Target Audience</span></h1>
<p><span class="font1">We anticipate that this workshop will appeal particularly to scholars who work with cultural heritage materials (a field where photogrammetry is an increasingly common method for generating digital surrogates), as well as those who work with archival photographs, and scholars with large corpora of photographs. It will also be relevant for scholars who already engage in computational analysis of primary&nbsp;sources, who wish to increase the efficiency of their&nbsp;analysis by leveraging high-performance compute environments. No previous experience with HPC environments is necessary. This workshop can accommodate 25 participants.</span></p><h1><a name="bookmark7"></a><span class="font0" style="font-weight:bold;">Instructors</span></h1><h2><a name="bookmark8"></a><span class="font0" style="font-style:italic;">Quinn Dombrowski</span></h2>
<p><span class="font1">Quinn is the Humanities Domain Expert at Berkeley Research Computing. At UC Berkeley, Quinn works&nbsp;with humanities researchers and research computing&nbsp;staff at Research IT to bridge the gap between humanities research questions and campus-provided resources for computation and research data management. She was previously a member of the program&nbsp;team for the Mellon-funded cyberinfrastructure initiative Project Bamboo, has led the DiRT tool directory&nbsp;and served as the technical editor of DHCommons.&nbsp;Quinn has an MLIS from the University of Illinois, and&nbsp;a BA and MA in Slavic linguistics from the University of&nbsp;Chicago.</span></p><h2><a name="bookmark9"></a><span class="font0" style="font-style:italic;">Tassie Gniady</span></h2>
<p><span class="font1">Tassie manages the Cyberinfrastructure for Digital Humanities group at Indiana University. She has a PhD&nbsp;in Early Modern English Literature from the University of California-Santa Barbara where she began her&nbsp;digital humanities journey in 2002 under the wing of&nbsp;Patricia Fumerton. She coded the first version of the&nbsp;NEH-funded English Broadside Ballad Archive, making&nbsp;many mistakes and learning much along the way. She&nbsp;now has an MIS from Indiana University, teaches a digital humanities course in the Department of Information and Library Science at IU, and holds regular&nbsp;workshops on text analysis with R and photogramme-try.</span></p><h2><a name="bookmark10"></a><span class="font0" style="font-style:italic;">Megan Meredith-Lobay</span></h2>
<p><span class="font1">Megan Meredith-Lobay is the digital humanities and social sciences analyst, as well as the Vice President, for Advanced Research Computing at the University of Briitsh Columbia. She holds a PhD from the University of Cambridge in medieval archaeology where&nbsp;she used a variety of computing resources to investigate ritual landscapes in early medieval Scotland Scotland. Megan has worked at the University of Alberta&nbsp;where she supported research computing for the Faculty of Arts, and at the University of Oxford where she&nbsp;was the programme coordinator for Digital Social Research, an Economic and Social Research Council project to promote advanced ICT in Social Science research.</span></p><h2><a name="bookmark11"></a><span class="font0" style="font-style:italic;">John Simpson</span></h2>
<p><span class="font1">John Simpson joined Compute Canada in January 2015 as a Digital Humanities Specialist and bringing a&nbsp;diverse background in Philosophy and Computing.&nbsp;Prior to Compute Canada, he was involved in a research-intensive postdoctoral fellowship focusing on&nbsp;developing semantic web expertise and prototyping&nbsp;tools capable of assisting academics in consuming and&nbsp;curating the new data made available by digital environments. He has a PhD in Philosophy from the University of Alberta, and an MA in Philosophy and BA in&nbsp;Philosophy &amp; Economics from the University of Waterloo. In addition to his role at WestGrid, John is also a&nbsp;Member-at-Large of the Canadian Society for Digital&nbsp;Humanities (CSDH-SCHN), a Programming Instructor</span></p>
<p><span class="font1">with the Digital Humanities Summer Institute (DHSI), and the national coordinator for Software</span></p>
</body>
</html>