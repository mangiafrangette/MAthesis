<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
	"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head><meta http-equiv="content-type" content="text/html; charset=UTF-8"/><meta name="generator" content="ABBYY FineReader 14"/><title>Microsoft Word - 526. Piasecki-Literary Exploration Machine New Tool for Distant Readers-526.docx</title><link rel="stylesheet" href="526_files/526.css" type="text/css"/>
</head>
<body><h1><a name="caption1"></a><a name="bookmark0"></a><span class="font4" style="font-weight:bold;">Literary Exploration Machine: A New Tool for Distant&nbsp;Readers of Polish Literature</span></h1>
<p><span class="font7" style="font-weight:bold;">Maciej Piasecki</span></p>
<p><span class="font7"><a href="mailto:maciej.piasecki@pwr.edu.pl">maciej.piasecki@pwr.edu.pl</a></span></p>
<p><span class="font7">Wroclaw University of Science and Technology Poland</span></p>
<p><span class="font7" style="font-weight:bold;">Tomasz Walkowiak</span></p>
<p><span class="font7"><a href="mailto:tomasz.walkowiak@pwr.edu.pl">tomasz.walkowiak@pwr.edu.pl</a></span></p>
<p><span class="font7">Wroclaw University of Science and Technology Poland</span></p>
<p><span class="font7" style="font-weight:bold;">Maciej Maryl</span></p>
<p><span class="font7"><a href="mailto:maciej.maryl@ibl.waw.pl">maciej.maryl@ibl.waw.pl</a></span></p>
<p><span class="font7">Polish Academy of Sciences, Poland</span></p><h2><a name="bookmark1"></a><span class="font3" style="font-weight:bold;">Brief Summary</span></h2>
<p><span class="font7">This paper presents an initial prototype of a web-based application for textual scholars. The goal of this project is to create a complex and stable research environment allowing scholars to upload the texts they&nbsp;are analysing and either explore with a suite of dedicated tools or transform them into another format&nbsp;(text, table, list). This latter functionality is especially&nbsp;important for research into Polish texts, because it allows for further processing with the tools built for the&nbsp;English language.</span></p>
<p><span class="font7">This application brings together the existing applications developed by CLARIN-PL and supplements them with new functionalities. The project is based on&nbsp;a close cooperation between IT professionals, linguists&nbsp;and literary scholars, which ensures that the tools will&nbsp;suit actual researchers' needs.</span></p>
<p><span class="font7">The main features of LEM include: lemmatization, part-of-speech tagging, text clustering, semantic text&nbsp;classification based on machine learning, and visualisation of its output, generating custom wordlists and&nbsp;lemmatized texts.</span></p><h2><a name="bookmark2"></a><span class="font3" style="font-weight:bold;">Challenge</span></h2>
<p><span class="font7">Digital literary studies seem to be one of the most vividly developing strand of digital humanities. Different analytical systems were proposed, e.g. </span><span class="font7" style="text-decoration:underline;">Mallet</span><span class="font7">, </span><span class="font7" style="text-decoration:underline;">Phil-</span><span class="font7">oLogic3 plus PhiloMine, but focused on selected techniques and mostly on English texts. Their languageprocessing capabilities are limited only to lemmatiza-tion and morphosyntactic tagging and they usually require from their users certain programming skills.</span></p>
<p><span class="font7">In order to address those challenges we have developed a prototype of a web-based system, called </span><span class="font7" style="font-style:italic;">Literary Exploration Machine</span><span class="font7"> </span><span class="font7" style="text-decoration:underline;">(LEM</span><span class="font7">), which does not require installation and programming skills. LEM has a component-based architecture, remains open for expanding components, implements natural language&nbsp;processing on different levels and is planned to support several different paradigms of the text analysis.</span></p><h2><a name="bookmark3"></a><span class="font3" style="font-weight:bold;">Scheme of the system</span></h2>
<p><span class="font3">Components</span></p>
<p><span class="font7">Word frequencies can be simply computed for English, but not for highly inflected languages such as Polish, which has more than 100 possible word forms&nbsp;of an adjective (however, almost-full sets of distinct&nbsp;forms exist only for some lemmas). In such languages,&nbsp;morphological forms have to be first mapped to </span><span class="font7" style="font-style:italic;">lemmas</span><span class="font7"> by a morpho-syntactic tagger, e.g. WCRFT2 for&nbsp;Polish (Radziszewski, 2013). By applying different language tools, we can enrich texts with metadata revealing linguistic structures.</span></p>
<p><span class="font7">LEM expands </span><span class="font7" style="text-decoration:underline;">WebSty</span><span class="font7"> - an open stylometric system, adopting the following features for text description:&nbsp;segmentation-based (lengths of documents, paragraphs and sentences), morphological (words, punctuations, pseudo-suffixes and lemmas), grammatical&nbsp;classes and categories (e.g. from the Polish National&nbsp;Corpus -see Przepiorkowski et al, 2012- tagset, Broda&nbsp;and Piasecki, 2013) and their n-grams.</span></p>
<p><span class="font7">This set has been additionally expanded in LEM with the following features, allowing for semantic analysis:</span></p>
<p><span class="font2">• &nbsp;&nbsp;&nbsp;</span><span class="font7">semantic </span><span class="font7" style="font-style:italic;">Proper Name classes</span><span class="font7"> - recognised&nbsp;by a Named Entity Recogniser Liner2&nbsp;(Marcinczuk et al, 2013),</span></p>
<p><span class="font2">• &nbsp;&nbsp;&nbsp;</span><span class="font7">temporal, spatial relation (Kocon and&nbsp;Marcinczuk, 2015), and selected semantic&nbsp;binary relations (e.g. </span><span class="font7" style="font-style:italic;">owner of</span><span class="font7">) ,</span></p>
<p><span class="font2">• &nbsp;&nbsp;&nbsp;</span><span class="font7" style="font-style:italic;">lexical meanings</span><span class="font7"> - synsets in plWordNet (the&nbsp;Polish wordnet); assigned to words and selected multiword expressions by Word&nbsp;Sense Disambiguation tool WoSeDon&nbsp;(K^dzia et al, 2015),</span></p>
<p><span class="font2">• &nbsp;&nbsp;&nbsp;</span><span class="font7">generalised lexical meanings - meanings&nbsp;mapped to more general synsets, e.g. </span><span class="font7" style="font-style:italic;">an animal</span><span class="font7"> instead of </span><span class="font7" style="font-style:italic;">a cheetah</span><span class="font7">,</span></p>
<p><span class="font2">• &nbsp;&nbsp;&nbsp;</span><span class="font7">lexicographic domains from Wordnet.</span></p>
<p><span class="font7">Rich text description is a good basis for several processing paradigms that LEM is going to support, namely:</span></p>
<p><span class="font2">• </span><span class="font7" style="font-style:italic;">linguistic text preprocessing</span><span class="font7"> - extraction of language data for further statistical analysis,&nbsp;i.e. computing frequencies as the initial feature values, e.g., of lemmas, tags, word&nbsp;senses, etc.,</span></p>
<p><span class="font2">• </span><span class="font7" style="font-style:italic;">topic modelling</span><span class="font7">,</span></p>
<p><span class="font2">• </span><span class="font7">unsupervised </span><span class="font7" style="font-style:italic;">semantic text clustering</span><span class="font7"> and analysis of characteristic features for clusters,</span></p>
<p><span class="font2">• </span><span class="font7">supervised </span><span class="font7" style="font-style:italic;">semantic text classification</span><span class="font7"> -trained on the manually annotated texts,</span></p>
<p><span class="font2">• </span><span class="font7">stylometric analysis - performed with the</span></p>
<p><span class="font7">help of the WebSty system.</span></p>
<p><span class="font3">Processing scheme</span></p>
<p><span class="font7">The processing paradigms share the following workflow:</span></p>
<p><span class="font2">• </span><span class="font7">Uploading a corpus of documents together with metadata in CMDI format (Broeder et al,&nbsp;2012) from the CLARIN infrastructure.</span></p>
<p><span class="font2">• </span><span class="font7">Text extraction and cleaning.</span></p>
<p><span class="font2">• </span><span class="font7">Choosing the features for the description of</span></p>
<p><span class="font7">documents by users (see Fig. 1).</span></p>
<p><span class="font2">• </span><span class="font7">Setting up the parameters for processing (users).</span></p>
<p><span class="font2">• </span><span class="font7">Pre-processing texts with language tools.</span></p>
<p><span class="font2">• </span><span class="font7">Calculating feature values for the pre-pro</span></p>
<p><span class="font7">cessed texts.</span></p>
<p><span class="font2">• </span><span class="font7">Filtering and/or transforming the original feature values.</span></p>
<p><span class="font2">• </span><span class="font7">Data mining.</span></p>
<p><span class="font2">• </span><span class="font7">Presenting the results: visualisation or export of data.</span></p>
<p><span class="font7">To facilitate the upload, users are encouraged to</span></p>
<p><span class="font7">deposit large text collections in the </span><span class="font7" style="text-decoration:underline;">CLARI-PL dSpace repository</span><span class="font7">. Users are advised to use public licences,&nbsp;but private research corpora can be also uploaded.</span></p>
<p><span class="font7">OCR-ed documents usually contain many language errors that should be corrected to some extent in the&nbsp;step 2. Moreover, metadata elements (e.g. page numbers, headers and footers) have to be separated during&nbsp;from the content and stored in a standalone annotation.</span></p>
<p><span class="font7">Users are not expected to have advanced knowledge of Natural Language Engineering or Data&nbsp;Mining. Thus, in Step 4, default settings of parameters&nbsp;will be provided. More advanced users will be able to&nbsp;tune the tool to their needs (see Fig. 1)</span></p><img src="526_files/526-1.jpg" style="width:247pt;height:141pt;"/>
<p><span class="font1">Figure 1. Web interface - a panel with a list of features</span></p>
<p><span class="font7">In Step 5 language tools are run. Each text is analysed by a part-of-speech tagger (e.g. WCRFT2) and next piped to a name entity recognizer (e.g. Liner2,&nbsp;Marcinczuk et al, 2013), temporal expression recognition, word sense recognition (WoSeDon, see K^dzia et&nbsp;al, 2015), etc.</span></p>
<p><span class="font7">Extraction of features encompasses counting frequencies, but also annotations matching patterns for every position in a document. In the case of wordnet-based features, meaning generalisation is done by iterating via wordnet structure.</span></p>
<p><span class="font7">A dedicated feature extraction module was built that is similar to Fextor (Broda et al, 2013) but much&nbsp;more efficient by supporting parallel processing. As a&nbsp;result of Step 6 every document is represented as vector of feature values and/or a sequence of language elements.</span></p>
<p><span class="font7">Filtering and transformation functions comes from the clustering packages or dedicated systems, e.g. SuperMatrix system (Broda and Piasecki, 2013).</span></p>
<p><span class="font7">Step 8 differentiates between the processing paradigms. Topic modelling, e.g. by Mallet, takes documents represented as lemma sequences. They can be also processed by corpus tools, e.g. for concordances&nbsp;and frequencies. Documents as feature vectors can be&nbsp;processed by clustering systems e.g. Cluto, or used in&nbsp;machine learning, e.g. Weka system.</span></p>
<p><span class="font7">Different processing paradigms provide varied perspectives on the data, e.g. topic modelling represents a document in terms of stochastic processes generating word occurrences from topic-related subsets&nbsp;in the text. Clustering reveals groups of documents&nbsp;based on content similarity. It is difficult to find a system that supports all paradigms.</span></p>
<p><span class="font7">In LEM, clustering is expanded with the extraction of features characteristic for the individual clusters.&nbsp;Several functions (from Weka, scikit-learn and SciPy&nbsp;packages), based on mathematical statistics, information theory and machine learning, are offered. The&nbsp;rankings of features are presented on the screen for&nbsp;interactive browsing and can be downloaded.</span></p>
<p><span class="font7">WebSty, based on elements of the same framework, can be applied to stylometric analysis.</span></p>
<p><span class="font7">Step 9, visualisation of clustering results (see Fig. 4), is based on Spectral Embedding (also known as Laplacian Eigenmaps). The 3D representation of the data&nbsp;(represented by similarity matrix) is calculated using&nbsp;a spectral decomposition of the graph Laplacian. Texts&nbsp;similar to each other are mapped close to each other&nbsp;in the low dimensional space, preserving local distances.</span></p><h2><a name="bookmark4"></a><span class="font3" style="font-weight:bold;">Use Case</span></h2>
<p><span class="font7">The LEM prototype was developed by the team</span></p>
<p><span class="font7">working with a particular textual corpus of 2553</span></p>
<p><span class="font7">Polish texts, published in </span><span class="font7" style="font-style:italic;">Teksty Drugie,</span><span class="font7"> an academic journal dedicated to literary studies. The corpus consisted two parts: OCRd scans (1990-1998) and digital&nbsp;files (1999-2014). Given the aim of this paper (software presentation) and the shortage of space, we will&nbsp;treat the results only as examples of the method, without getting into too much detail.</span></p>
<p><span class="font7">The work on the prototype was divided into stages, conceived as a feedback loop for the developing team:&nbsp;on every stage a new service was added to application&nbsp;and the test run was performed. After the analysis of&nbsp;the result, the step was repeated or the team moved to&nbsp;the next phase.</span></p>
<p><span class="font7" style="font-weight:bold;">Phase 1. </span><span class="font7">Cleaning. The OCR-ed corpus has been cleaned (e.g. wordbreaks and headers were removed)</span></p>
<p><span class="font7" style="font-weight:bold;">Phase 2. </span><span class="font7">The corpus was lemmatized and parts of speech were tagged. Frequency lists were created&nbsp;what enabled the search for patterns in the textual&nbsp;output. For instance, Figure 2 shows the pattern of interest in particular Polish poets throughout 25 years,&nbsp;based on lemmatized mentions.</span></p>
<p><span class="font5">Polish writers discussed in </span><span class="font5" style="font-style:italic;">Teksty Drugie</span></p>
<p><span class="font0" style="font-weight:bold;">1200</span></p><img src="526_files/526-2.jpg" style="width:218pt;height:106pt;"/>
<p><span class="font0" style="font-weight:bold;">.Czestaw Mrtosz^—Witold Gombrcwicz^—Zbigniew Herbert^— TadeuszRàzewicz &nbsp;&nbsp;&nbsp;Miron Biatoszews</span></p>
<p><span class="font1">Figure 2. Pattern of interest in particular Polish writers in </span><span class="font1" style="font-style:italic;">Teksty Drugie</span><span class="font1"> (1990-2014).</span></p>
<p><span class="font7" style="font-weight:bold;">Phase 3. </span><span class="font7">The analysis of the word frequencies revealed some problems with the word list, especially with numbers, years and city names, which were preserved in bibliographic references. A functionality of&nbsp;adopting a custom stopword list was employed. The&nbsp;exclusion of corpus-specific problematic words and</span></p>
<p><span class="font7">general meaningless words (e.g. a, this, that, if) allowed for visualisation of the most frequent words in </span><span class="font7" style="font-style:italic;">Teksty Drugie</span><span class="font7"> (Fig. 3)</span></p><img src="526_files/526-3.jpg" style="width:244pt;height:86pt;"/>
<p><span class="font1">Figure 3. 300 most frequent words from </span><span class="font1" style="font-style:italic;">Teksty Drugie </span><span class="font1">(1990-2014) (meaningless words excluded) visualised with&nbsp;wordle.</span></p>
<p><span class="font7" style="font-weight:bold;">Phase 4. </span><span class="font7">The texts were then grouped into clusters of 20, 50 and 100 in a series of experiments. Each grouping revealed a bit different level of generalization&nbsp;about the texts. LEM, thanks to visualisation features&nbsp;(Fig. 4), allows for real-time exploration of deeper relationships between the texts.</span></p><img src="526_files/526-4.jpg" style="width:119pt;height:158pt;"/>
<p><span class="font1">Figure 4. Visualisation of clustering results (weighting: MI-simple, similarity metric: ratio, number of clusters: 20, clustering method: agglomerative, visualization: the&nbsp;similarity matrix converted to distances and mapped to 3D&nbsp;by a spectral decomposition of the graph Laplacian -spectral embedding method).</span></p>
<p><span class="font7">By choosing the level of granularity (20, 50 or 100 clusters) we may analyse diverse patterns of discursive similarities between texts. Table 1 shows the differences in clustering of the same sample. The first option (20) shows the similarity between texts on a rather general level, that could be described as stylistic&nbsp;or genre similarity (e.g. formal vocabulary). Other options allow for more detailed exploration of general research approach (50) or particular topics analyzed in</span></p>
<p><span class="font7">articles (100). Semantics of clusters is described by the identified characteristic features.</span></p><img src="526_files/526-5.jpg" style="width:242pt;height:96pt;"/>
<p><span class="font1">Table 1. Differences between the clustering options (numbers reflect the quantity of texts assigned to particular&nbsp;cluster)</span></p>
<p><span class="font7">Researchers may explore all options and analyse the vocabulary responsible for classifying particular&nbsp;texts into a certain group by a virtue of being over- or&nbsp;under-represented in comparison to the entire sample.</span></p>
<p><span class="font7">The LEM is not a real time system. However, processing of the exemplar corpus (2553 documents from “Teksty Drugie”) takes less than 20 minutes. This is&nbsp;due to the use of a private cloud and proprietary message-oriented engine for processing texts. We plan to&nbsp;speed up the process, by running larger number of instances of language tools and by compressing results&nbsp;at each stage. Moreover, the user is able to start processing from any stage, so the processing time is&nbsp;shorter when the user plays with different settings.</span></p><h2><a name="bookmark5"></a><span class="font3" style="font-weight:bold;">Further Development</span></h2>
<p><span class="font7">Currently LEM's GUI is developed in cooperation with potential users, literary scholars working on various types of texts (fiction, journal articles, blog posts).&nbsp;That is also why we call this software “literary”, because further development will address the issues pertinent for literary theory, exceeding a purely linguistic&nbsp;perspective. Some literary-specific issues and functions will be expanded on the later stage of development, e.g. with adding language tools for Word Sense&nbsp;Disambiguation and partial analysis of the text structure, like anaphor resolution and discourse structure&nbsp;recognition. LEM's architecture is open for such extensions. With that said, in this paper we have focused on&nbsp;the current stage of development.</span></p>
<p><span class="font7">LEM will be fully implemented and made available as a web application to the scholarly audience working&nbsp;on Polish. Next, it will be extended with with tools for&nbsp;other languages (e.g. English and German). As LEM&nbsp;has a modular architecture, it would require mostly&nbsp;linking new processing Web Services and adding converters. LEM has an open licences and we will be&nbsp;happy to share our tools, code and </span><span class="font7" style="font-style:italic;">know-how</span><span class="font7"> with&nbsp;teams interested in doing so. Options for exporting to&nbsp;other formats will be added, so that researchers can&nbsp;easily create the output in a particular format (list,&nbsp;text, table) and upload it to other applications (e.g.&nbsp;Mallet) for further processing.</span></p><h2><a name="bookmark6"></a><span class="font3" style="font-weight:bold;">Bibliography</span></h2>
<p><span class="font6" style="font-weight:bold;">Broda, B., Kçdzia, P., Marcinczuk, M., Radziszewski, A., Ramocki, R. and Wardynski, A. </span><span class="font6">(2013). Fextor: A feature extraction framework for natural language processing: A case study in word sense disambiguation, relation recognition and anaphora resolution. </span><span class="font6" style="font-style:italic;">Studies in&nbsp;Computational Intelligence</span><span class="font6">. Berlin: Springer, vol. 458, pp.&nbsp;41-62.</span></p>
<p><span class="font6" style="font-weight:bold;">Broda, B. and Piasecki, M. </span><span class="font6">(2013). Parallel, Massive Processing in SuperMatrix - a General Tool for Distributional Semantic Analysis of Corpora. </span><span class="font6" style="font-style:italic;">International Journal of Data Mining, Modelling and Management</span><span class="font6">, </span><span class="font6" style="font-weight:bold;">5</span><span class="font6">(1):1-</span></p>
<p><span class="font6">19.</span></p>
<p><span class="font6" style="font-weight:bold;">Broeder, D., Van Uytvanck, D., Gavrilidou, M., Trippel, T., and Windhouwer, M. </span><span class="font6">(2012). Standardizing a component metadata infrastructure. In: N. Calzolari (ed.), </span><span class="font6" style="font-style:italic;">Proceedings of LREC 2012: 8th International Conference on&nbsp;Language Resources and Evaluation</span><span class="font6">. European Language&nbsp;Resources Association (ELRA), pp. 1387-1390.</span></p>
<p><span class="font6" style="font-weight:bold;">Eder, M., Kestemont, M. and Rybicki, J. </span><span class="font6">(2013). Stylometry</span></p>
<p><span class="font6">with R: a suite of tools. In: </span><span class="font6" style="font-style:italic;">Digital Humanities 2013: Conference Abstracts</span><span class="font6">. University of Nebraska-Lincoln, NE, pp. 487-489.</span></p>
<p><span class="font6" style="font-weight:bold;">Kçdzia, P., Piasecki, M. and Orlinska, M. J. </span><span class="font6">(2015). Word Sense Disambiguation Based on Large Scale Polish&nbsp;CLARIN Heterogeneous Lexical Resources. </span><span class="font6" style="font-style:italic;">Cognitive&nbsp;Studies | Études cognitives</span><span class="font6">, (15), 269-292.</span></p>
<p><span class="font6" style="font-weight:bold;">Kocon, J. &amp; Marcinczuk, M </span><span class="font6">(2015). Recognition of Polish Temporal Expressions. In Mitkov, R., Angelova, G. &amp;&nbsp;Boncheva, K. (editors), </span><span class="font6" style="font-style:italic;">Proceedings of the International</span></p>
<p><span class="font6" style="font-style:italic;">Conference Recent Advances in Natural Language Processing</span><span class="font6">, pages 282-290. INCOMA Ltd. Shoumen</span></p>
<p><span class="font6" style="font-style:italic;">Knowledge Discovery</span><span class="font6">, </span><span class="font6" style="font-weight:bold;">10</span><span class="font6">(2): 141-168.</span></p>
<p><span class="font6" style="font-weight:bold;">Mallet </span><span class="font6">(n.d.) </span><span class="font6" style="text-decoration:underline;"><a href="http://mallet.cs.umass.edu/">http://mallet.cs.umass.edu/</a></span></p>
<p><span class="font6" style="font-weight:bold;">Marcinczuk, M., Kocon, J. and Janicki, M. </span><span class="font6">(2013). Liner2 -A Customizable Framework for Proper Names Recognition for Polish. </span><span class="font6" style="font-style:italic;">Studies in Computational Intelligence</span><span class="font6">. Berlin: Springer, vol. 467, pp. 231-253.</span></p>
<p><span class="font6" style="font-weight:bold;">Marcinczuk, M. &amp; Radziszewski, A </span><span class="font6">(2013). WCCL Match -A Language for Text Annotation. In Klopotek, A., M., Ko-ronacki, Jacek, Marciniak, Malgorzata et al (editors), </span><span class="font6" style="font-style:italic;">Language Processing and Intelligent Information Systems</span><span class="font6">,</span></p>
<p><span class="font6">pages 131-144. Springer Berlin Heidelberg.</span></p>
<p><span class="font6" style="font-weight:bold;">PhiloLogi3 </span><span class="font6">(n.d.) </span><span class="font6" style="text-decoration:underline;"><a href="https://sites.google.com/site_/philo-logic3/home">https://sites.google.com/site /philo-logic3/home</a></span></p>
<p><span class="font6" style="font-weight:bold;">Piasecki, M.; Szpakowicz, S.; Maziarz, M. &amp; Rudnicka, E.</span></p>
<p><span class="font6">(2016) plWordNet 3.0 -- Almost There. In Mititelu, V. B.; Forascu, C.; Fellbaum, C. &amp; Vossen, P. </span><span class="font6" style="font-style:italic;">(Eds.)</span><span class="font6"> Proceedings&nbsp;of the 8th Global Wordnet Conference, Bucharest, 27-30&nbsp;January 2016, Global Wordnet Association, pp. 290-299.</span></p>
<p><span class="font6" style="font-weight:bold;">Piasecki, M., Szpakowicz, S. &amp; Broda, B. </span><span class="font6">(2009). </span><span class="font6" style="font-style:italic;">A Wordnet from the Ground Up</span><span class="font6">. Wroclaw : Oficyna Wydawnicza&nbsp;Politechniki Wroclawskiej.</span></p>
<p><span class="font6" style="font-weight:bold;">Przepiorkowski, A., Banko, M., Gorski, R. L. and Lewan-</span></p>
<p><span class="font6" style="font-weight:bold;">dowska-Tomaszczyk, B. </span><span class="font6">(eds) (2012). </span><span class="font6" style="font-style:italic;">Narodowy Korpus Jqzyka Polskiego.</span><span class="font6"> Warszawa: PWN.</span></p>
<p><span class="font6" style="font-weight:bold;">Radziszewski, A</span><span class="font6">. (2013). A tiered CRF tagger for Polish, Intelligent Tools for Building a Scientific Information Platform. </span><span class="font6" style="font-style:italic;">Studies in Computational Intelligence</span><span class="font6">. Berlin: Springer, vol. 467, pp. 215-230.</span></p>
<p><span class="font6" style="font-weight:bold;">Rygl, J. </span><span class="font6">(2014) Automatic Adaptation of Author's Stylo-metric Features to Document Types. In Sojka, P., Horak, A., Kopecek, I. and Pala, K. (eds), </span><span class="font6" style="font-style:italic;">Proceedings of 17th International Conference TSD 2014</span><span class="font6">. Brno, Czech Republic,&nbsp;LNCS 8655, Springer.</span></p>
<p><span class="font6" style="font-weight:bold;">Szatkiewicz, t. and Przepiorkowski, A. </span><span class="font6">(2012). Anotacja morfoskladniowa. In Przepiorkowski, A., Banko, M., Gorski, R. L. and Lewandowska-Tomaszczyk, B. (eds)&nbsp;(2012). </span><span class="font6" style="font-style:italic;">Narodowy Korpus Jqzyka Polskiego.</span><span class="font6"> Warszawa:&nbsp;PWN., pp. 59-96.</span></p>
<p><span class="font6" style="font-weight:bold;">Walkowiak, T. </span><span class="font6">(2015). Web based engine for processing and clustering of Polish texts. </span><span class="font6" style="font-style:italic;">Proceedings of the Tenth&nbsp;International Conference on Dependability and Complex&nbsp;Systems DepCoS-RELCOMEX</span><span class="font6">. Brunow, Poland. Springer,&nbsp;pp. 515-522.</span></p>
<p><span class="font6" style="font-weight:bold;">WebSty </span><span class="font6">(n.d.) </span><span class="font6" style="text-decoration:underline;"><a href="http://websty.clarin-pl.eu/">http://websty.clarin-pl.eu/</a></span></p>
<p><span class="font6" style="font-weight:bold;">Zhao, Y. and Karypis, G. </span><span class="font6">(2005). Hierarchical Clustering Algorithms for Document Datasets. </span><span class="font6" style="font-style:italic;">Data Mining and</span></p>
</body>
</html>