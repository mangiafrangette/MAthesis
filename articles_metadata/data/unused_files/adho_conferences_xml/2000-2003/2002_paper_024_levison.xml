<?xml version="1.0" encoding="UTF-8"?>
<?oxygen RNGSchema="file:/Users/saraschmidt/Desktop/teiConferenceAbstracts.rng" type="xml"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" rend="paper">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title level="a" type="main">Jigsaw Puzzles: Problem B</title>
                <author>
                    <name>
                        <forename type="first">Michael</forename>
                        <surname>Levison</surname>
                        <affiliation>
                            <name type="org">Queen's University</name>, Ontario
                                <email>levison@cs.queensu.ca</email>
                        </affiliation>
                    </name>
                </author>
                <author>
                    <name>
                        <forename type="first">Craig</forename>
                        <surname>Thomas</surname>
                        <affiliation>
                            <name type="org">Queen's University</name>, Ontario
                                <email>thomas@cs.queensu.ca</email>
                        </affiliation>
                    </name>
                </author>
            </titleStmt>
            <publicationStmt>
                <date when="2002">2002</date>
                <publisher>
                    <name>University of Tübingen</name>
                </publisher>
                <pubPlace>Tübingen</pubPlace>
            </publicationStmt>
            <seriesStmt>
                <title level="m">ALLC/ACH 2002</title>
                <respStmt>
                    <resp>editor</resp>
                    <name>
                        <forename type="first">Harald</forename>
                        <surname>Fuchs</surname>
                    </name>
                    <name>
                        <forename type="first"/>
                        <forename type="middle"/>
                        <surname/>
                    </name>
                    <name>
                        <forename type="first"/>
                        <surname/>
                    </name>
                </respStmt>
                <respStmt>
                    <resp>encoder</resp>
                    <name>
                        <forename type="first">Sara</forename>
                        <forename type="middle">A.</forename>
                        <surname>Schmidt</surname>
                    </name>
                </respStmt>
            </seriesStmt>
            <sourceDesc>
                <p/>
            </sourceDesc>
        </fileDesc>
        <profileDesc>
            <textClass>
                <keywords scheme="http://hcmc.uvic.ca/teiJournal/topicKeywords/">
                    <list>
                        <item> </item>
                        <item> </item>
                        <item> </item>
                    </list>
                </keywords>
            </textClass>
        </profileDesc>
    </teiHeader>
    <text>
        <body>
            <div>
                <div>
                    <p>A jigsaw puzzle problem arises whenever an archaeologist finds an old
                        manuscript broken into fragments and wishes to reconstruct it. The best
                        known examples are the Dead Sea Scrolls, reconstructed by hand during the
                        middle of the 20th century.</p>
                    <p>In fact, there are two different types of problem, each requiring a different
                        strategy. If the fragments come from a familiar text, the manuscript can be
                        reconstructed by locating each fragment in an existing copy without
                        reference to other pieces of the puzzle. If the text is unfamiliar, we must
                        compare the shapes of fragments to one another to discover good matches with
                        reasonable letter sequences formed across the boundaries. We haved called
                        the former Jigsaw Problem A, the latter Problem B.</p>
                    <p>The purpose is to find computer techniques which substantially reduce the
                        human work involved in reconstruction.</p>
                </div>
                <div>
                    <head>Previous Work</head>
                    <p>Very little has been published on this topic since it was brought to the
                        first author's attention 35 years ago. A previous paper ( Levison and Wu,
                        1999) reported on some experiments involving artificial fragments derived
                        from a paragraph of <title level="m">Alice in Wonderland</title>. This work
                        essentially provided a computer solution for Problem A, predicting whether a
                        single site is likely for a given fragment based on letter-sequence
                        frequencies and, for our fragments, finding such a unique location in Alice
                        whenever it was predicted.</p>
                    <p>Experiments on problem B proved less successful. A program matched each of
                        the 53 fragments to each of the others with all possible vertical shifts,
                        computing a score for each juxtaposition. The "best" matches were listed for
                        each fragment, different scoring formulae being tried without materially
                        affecting the outcome. The correct match often occurred among the best five,
                        but only a few times in top or second place. In effect, two or three of 52
                        competitors often scored better than the correct one by chance alone.
                        Extrapolation suggests that, given a set of a few thousand fragments, a
                        human might have to examine a few hundred matches per fragment to determine
                        the correct one -- a ten-fold improvement over a human-only approach, but
                        still very time-consuming. For a satisfactory outcome, we want to narrow the
                        field, allowing a human researcher to inspect only a few matches per
                        fragment.</p>
                    <p>Incidentally, these experiments did suggest that letter-sequences play only a
                        secondary role in the scoring, shape being the most important feature. This
                        is perhaps not surprising since letter-sequences can be assessed only on
                        lines which fit together.</p>
                </div>
                <div>
                    <head>Refinement</head>
                    <p>In Levison and Wu (1999), the left- and right-profiles of each fragment are
                        represented by a sequence of measurements from an arbitrary vertical datum
                        line. At first sight, it is the step-like nature of the edges which causes
                        the problem, allowing too many good fits between unrelated fragments. In
                        fact, however, any shape represented by a finite sequence of measurements
                        can be viewed as step-like. The true problem is the granularity of the
                        measurements: a single measure per line of text, with a (fixed) character
                        width, about 2.5 mm, as the horizontal unit.</p>
                    <p>In new experiments, a further paragraph of <title level="m">Alice</title> was
                        fragmented and three measurements were made for each line of text to the
                        nearest 0.5 mm. Once again each fragment was compared with every other in
                        all different vertical positions. The scoring algorithm measured the total
                        gap between lines when two fragments were "just touching". This initial
                        measure was adjusted according to the number of lines which contributed to
                        it, and the final score biased to reward juxtapositions where several lines
                        fitted closely but not exactly. In the set of 61 new fragments from the
                        paragraph, 41 correct matches occurred in first place, with five each in
                        second and third, a major improvement on the earlier results.</p>
                </div>
                <div>
                    <head>Tear and Wear</head>
                    <p>Do these improvements persist if the number of fragments is much higher? With
                        many correct fits now occurring in first place, the rough extrapolation used
                        earlier no longer applies. Although few good shape matches may appear by
                        chance among 61 fragments, they may well arise among thousands. To answer
                        the question we need to experiment with much larger sets. Unfortunately no
                        such sets are available, while tearing and measuring thousands of artificial
                        fragments is not an enticing prospect. We have therefore created sets of
                        "virtual fragments".</p>
                    <p>The comparison process uses only the left- and right-profiles of each
                        fragment. We therefore generate vertical "tears" which form the right-
                        profiles of one group of fragments and the left-profiles of an adjacent one.
                        A tear is simply a sequence of measurements, each randomly displaced from
                        the one above. The displacements are chosen from a non- uniform
                        distribution, small changes being common, larger ones less frequent. In
                        fact, the actual distribution determines how rough or smooth the edges of
                        the virtual fragments are.</p>
                    <p>In practice, the shapes of these virtual fragments may be too perfect. Since
                        the right-profile of a fragment and the left-profile of its neighbour come
                        from the same tear, the correct match will involve no gap at all, helping to
                        ensure that it is always the best. We therefore submit the virtual fragments
                        to a process of "wear". Each profile measurement is altered by a random
                        amount to reduce the quality of the fit between correctly matching
                    profiles.</p>
                </div>
                <div>
                    <head>Results</head>
                    <p>Many sets of fragments ranging from about 60 to 5400 in number were simulated
                        and compared using the matching process. Typical results are shown in Table
                        1. For sets of around 60 fragments, the average number of correct matches
                        occurring in the first three places is around 88%, very close to the results
                        obtained for the paragraph from Alice. As expected, this percentage
                        diminishes as the size of the set increases. For 3600 fragments, it is still
                        about 66%. In other words, if we have a set of 3600 fragments whose profiles
                        do not deviate substantially from our virtual sets, we expect to find the
                        correct match among our three top choices about two-thirds of the time. This
                        meets the objective set earlier.</p>
                    <p>In fact, we can expect even better results if we apply the process in both
                        directions, and use it interactively, so that the human scholar confirms
                        some matches and thereby eliminates some profiles from later comparisons.</p>
                    <p>The comparison program is written in C, and was run on a 500Mhz PC. Table 2
                        shows the time taken to carry out the comparisons for sets of different
                        sizes. In principle, the time should be proportional to the square of the
                        number of fragments, and this is closely borne out by the last three
                        observations. (The processing portion of the two smaller cases is swamped by
                        the initialization and output portions of the program.) Even for very large
                        sets the process is feasible on current computers.</p>
                    <table rows="17" cols="4">
                        <head>Table 1. Typical results of the comparison process.</head>
                        <row>
                            <cell/>
                            <cell role="label">number of<lb/>fragments</cell>
                            <cell role="label">number of<lb/>correct matches<lb/>among top three</cell>
                            <cell role="label">percentage</cell>
                        </row>
                        <row>
                            <cell/>
                            <cell>62</cell>
                            <cell>50</cell>
                            <cell>80.7%</cell>
                        </row>
                        <row>
                            <cell/>
                            <cell>62</cell>
                            <cell>56</cell>
                            <cell>90.3%</cell>
                        </row>
                        <row>
                            <cell/>
                            <cell>58</cell>
                            <cell>54</cell>
                            <cell>93.1%</cell>
                        </row>
                        <row>
                            <cell role="label">average</cell>
                            <cell/>
                            <cell/>
                            <cell>87.9%</cell>
                        </row>
                        <row>
                            <cell/>
                            <cell>199</cell>
                            <cell>152</cell>
                            <cell>76.4%</cell>
                        </row>
                        <row>
                            <cell/>
                            <cell>181</cell>
                            <cell>157</cell>
                            <cell>86.7%</cell>
                        </row>
                        <row>
                            <cell/>
                            <cell>193</cell>
                            <cell>146</cell>
                            <cell>75.6%</cell>
                        </row>
                        <row>
                            <cell role="label">average</cell>
                            <cell/>
                            <cell/>
                            <cell>79.4%</cell>
                        </row>
                        <row>
                            <cell/>
                            <cell>406</cell>
                            <cell>303</cell>
                            <cell>74.6%</cell>
                        </row>
                        <row>
                            <cell/>
                            <cell>407</cell>
                            <cell>284</cell>
                            <cell>69.8%</cell>
                        </row>
                        <row>
                            <cell/>
                            <cell>383</cell>
                            <cell>297</cell>
                            <cell>77.5%</cell>
                        </row>
                        <row>
                            <cell role="label">average</cell>
                            <cell/>
                            <cell/>
                            <cell>73.9%</cell>
                        </row>
                        <row>
                            <cell/>
                            <cell>3636</cell>
                            <cell>2443</cell>
                            <cell>67.2%</cell>
                        </row>
                        <row>
                            <cell/>
                            <cell>3667</cell>
                            <cell>2448</cell>
                            <cell>66.8%</cell>
                        </row>
                        <row>
                            <cell/>
                            <cell>3627</cell>
                            <cell>2412</cell>
                            <cell>66.5%</cell>
                        </row>
                        <row>
                            <cell role="label">average</cell>
                            <cell/>
                            <cell/>
                            <cell>66.8%</cell>
                        </row>
                    </table>
                    <table rows="6" cols="2">
                        <head> Table 2. Timings for sets of different sizes</head>
                        <row>
                            <cell role="label">fragments</cell>
                            <cell role="label">time (seconds)</cell>
                        </row>
                        <row>
                            <cell>60</cell>
                            <cell>1</cell>
                        </row>
                        <row>
                            <cell>111</cell>
                            <cell>1.5</cell>
                        </row>
                        <row>
                            <cell>272</cell>
                            <cell>4</cell>
                        </row>
                        <row>
                            <cell>1084</cell>
                            <cell>48</cell>
                        </row>
                        <row>
                            <cell>5381</cell>
                            <cell>1100 (= 18 minutes 20 seconds)</cell>
                        </row>
                    </table>
                </div>
                <div>
                    <head>Further Stages</head>
                    <p>The comparison process is the central component of the reconstruction task.
                        It permits many of the fragments to be combined into pairs and, by
                        extension, into horizontal bands, from which scholars can easily complete
                        the reconstruction. A complete program suite might go further, making use of
                        digital photographs to display best fits for human judgement, applying the
                        comparison process in the vertical direction to the horizontal bands, and so
                        on. One time-consuming activity remains -- that of accurately measuring
                        fragments to obtain their profiles. We have therefore investigated the
                        possibility of deriving measurements directly from digital photographs.</p>
                    <p>Some of our artificial fragments were photographed horizontally against a
                        bright red ground using a digital camera. For this discussion we assume that
                        the text is black on white. Our purpose is simply to distinguish three kinds
                        of pixel: text, "paper" and background. If the text is faded or the material
                        dirty, there are well-known digital processes for "cleaning" the image.</p>
                    <p>The horizontal rows of pixels are scanned, and the numbers of black pixels in
                        each row are counted. In principle, the numbers will be near zero for the
                        inter-line gaps, higher for the bodies of text lines, and intermediate for
                        rows corresponding to risers and descenders if any. This lets us locate the
                        pixel rows which delimit the body of each text line; after which, scanning
                        the top, middle and bottom rows of each line to find where red pixels stop
                        and start again allows us to compute the desired measurements. Experiments
                        confirm that this holds true in practice.</p>
                    <p>In essence, then, the processes described here provide a computer solution to
                        Problem B.</p>
                </div>
            </div>
        </body>
        <back>
            <div type="bibliography">
                <head>References</head>
                <listBibl>
                    <biblStruct type="journalArticle">
                        <analytic>
                            <author>
                                <name>
                                    <forename type="first">M.</forename>
                                    <surname>Levison</surname>
                                </name>
                            </author>
                            <title level="a">The Siting of Fragments</title>
                        </analytic>
                        <monogr>
                            <title level="j">Computer Journal</title>
                            <imprint>
                                <biblScope type="vol">7</biblScope>
                                <biblScope type="issue"/>
                                <biblScope type="pp">275-277</biblScope>
                                <date when="1965">1965</date>
                            </imprint>
                        </monogr>
                    </biblStruct>
                    <biblStruct type="bookChapter">
                        <analytic>
                            <author>
                                <name>
                                    <forename type="first">M.</forename>
                                    <surname>Levison</surname>
                                </name>
                            </author>
                            <title level="a">The Computer in Literary Studies</title>
                        </analytic>
                        <monogr>
                            <editor>
                                <name>
                                    <forename type="first">A.</forename>
                                    <forename type="middle">D.</forename>
                                    <surname>Booth</surname>
                                </name>
                            </editor>
                            <title level="m">Machine Translation</title>
                            <imprint>
                                <pubPlace>Amsterdam</pubPlace>
                                <publisher>North-Holland Publishing Company</publisher>
                                <date when="1967">1967</date>
                                <biblScope type="pp">173-194</biblScope>
                            </imprint>
                        </monogr>
                    </biblStruct>
                    <biblStruct>
                        <analytic>
                            <author>
                                <name>
                                    <forename type="first">M.</forename>
                                    <surname>Levison</surname>
                                </name>
                            </author>
                            <author>
                                <name>
                                    <forename type="first">J.</forename>
                                    <surname>Wu</surname>
                                </name>
                            </author>
                            <title level="a">The Jigsaw Puzzle Problem Revisited</title>
                        </analytic>
                        <monogr>
                            <title level="m">ACH-ALLC 1999, Charlottesville</title>
                            <imprint>
                                <pubPlace/>
                                <publisher/>
                                <date when="1999">1999</date>
                            </imprint>
                        </monogr>
                        <note>(Conference abstracts, pp 106-111.)</note>
                    </biblStruct>
                    <biblStruct>
                        <analytic>
                            <author>
                                <name>
                                    <forename type="first">J.</forename>
                                    <forename type="middle">A.</forename>
                                    <surname>Ogden</surname>
                                </name>
                            </author>
                            <title level="a">The siting of papyrus fragments: an experimental
                                application of digital computers</title>
                        </analytic>
                        <monogr>
                            <edition>PhD Thesis 2195</edition>
                            <imprint>
                                <publisher>University of Glasgow</publisher>
                                <date when="1969">1969</date>
                            </imprint>
                        </monogr>
                    </biblStruct>
                </listBibl>
            </div>
        </back>
    </text>
</TEI>
