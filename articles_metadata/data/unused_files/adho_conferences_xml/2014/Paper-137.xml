<?xml version="1.0" encoding="utf-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:x="http://www.w3.org/1999/xhtml" xmlns:exsl="http://exslt.org/common" xml:id="Paper-137">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>Does <hi rend="italic">colour</hi> mean <hi rend="italic">color</hi>?: Disambiguating word sense and ideology in British and American orthographic variants</title>
        <author>
          <name>
            <surname>Grue</surname>, <forename>Dustin</forename>
          </name>
          <affiliation>University of British Columbia</affiliation>
          <email>dustin.grue@gmail.com</email>
        </author>
      </titleStmt>
      <publicationStmt>
        <authority/>
        <publisher>EPFL, Switzerland</publisher>
        <distributor>
          <name>EPFL Digital Humanities Laboratory</name>
          <address>
            <addrLine>GC D2 386</addrLine>
            <addrLine>Station 18</addrLine>
            <addrLine>CH-1015 Lausanne</addrLine>
            <addrLine>frederic.kaplan@epfl.ch</addrLine>
          </address>
        </distributor>
        <pubPlace>Lausanne, Switzerland</pubPlace>
        <address>
          <addrLine>EPFL</addrLine>
          <addrLine>CH-1015 Lausanne</addrLine>
        </address>
        <availability>
          <p/>
        </availability>
      </publicationStmt>
      <notesStmt>
        <note type="abstract">Using unsupervised and supervised Naïve Bayes classification to examine 16 orthographic variables in ~50 million words from the archive of the University of British Columbia's student newspaper, I find that multiple variants occur in predictable contexts. That is, in this Canadian medium where editorial oversight on orthographic convention is minimal, color prefers different contexts than colour to the extent that we can predict the variant given its surrounding words with surprising accuracy. While this would seem to critique language external motivations for variant selection -- specifically the orthography/identity connection advocated by Heffernan et al. (2010) who argue for a connection between ideology and orthography in the Canadian context -- these contexts are themselves ideologically motivated as they tend to take the form of differentially oriented advertisements, or, as I term them, 'solicitations'. Combining computational with more traditional sociolinguistic techniques, this paper proposes the identity/orthography connection in more proximal, more interactional terms.</note>
      </notesStmt>
      <sourceDesc>
        <p>No source: created in electronic format.</p>
        <p>
          <date when="20140711"/>
          <time when="09:00:00"/>
        </p>
		<p n="session">6</p>
		<p n="room">319 - Amphipôle</p>
      </sourceDesc>
    </fileDesc>
    <profileDesc>
      <textClass>
        <keywords scheme="original" n="category">
          <term>Paper</term>
        </keywords>
        <keywords scheme="original" n="subcategory">
          <term>Long Paper</term>
        </keywords>
        <keywords scheme="original" n="keywords">
          <term>Naive Bayes</term>
          <term>classification</term>
          <term>word sense disambiguation</term>
          <term>orthography</term>
          <term>identity</term>
        </keywords>
        <keywords scheme="original" n="topic">
          <term>Classification</term>
          <term>sociolinguistics</term>
          <term>linguistics</term>
          <term>word sense disambiguation</term>
        </keywords>
      </textClass>
    </profileDesc>
  </teiHeader>
  <text type="paper">
    <front>
      
      <div>
        <p></p>
      </div>
    </front>
    <body>
      <div>
        <p>The orthography/identity hypothesis proposes
that a speaker’s motivation for selecting between available orthographic
variants in a language (e.g. between British <hi rend="italic">colour</hi> and American <hi rend="italic">color</hi>
in English) is to some extent informed by the speaker’s desire to express a
certain identity <ref target="n1" rend="sup">1</ref> <ref target="n2" rend="sup">2</ref> <ref target="n3" rend="sup">3</ref>.  In the Canadian context, where a mixture of
American/British variants are used – often with non-categorical preference
<ref target="n4" rend="sup">4</ref><ref target="n5" rend="sup">5</ref> – Heffernan et al. <ref target="n6" rend="sup">6</ref> developed a method to
qualify the orthography/identity connection in terms of ideology and show that
during periods of increased “anti-Americanism,” specifically during unpopular
American-led wars, American variant use declines relative to the British.  Heffernan et al.’s data cover the
years 1921 to 2004, and are derived from the student newspaper <hi rend="italic">The Gateway</hi> at the University of Alberta
in Alberta, Canada.  Their method
involved locating expressions of national sentiment for each year of the data,
rating “anti-American sentiment” on a 7-point Likert scale (255 ratings over 85
years performed by each author) and correlating this with the relative
frequencies of 15 orthographic variables (Table 2, though <hi rend="italic">color </hi>/ <hi rend="italic">colour </hi>is my addition): the negative correlation obtained was quite high, with Pearson-r -0.715, <hi rend="italic">p</hi> = 0.001.

</p>
        <p>However, follow-up
work by the present author, using data in the same timeframe from the archive of the University of British
Columbia’s student newspaper <hi rend="italic">The Ubyssey</hi>
(~50 million words) in the neighbouring province of British Columbia, failed to
find similar short-term diachronic changes in variant use correlated with
periods of increased “anti-American sentiment” <ref target="n7" rend="sup">7</ref>. 
Following Heffernan et al.’s method, an insignificant correlation was
obtained: Pearson-r -0.434,
<hi rend="italic">p</hi> = 0.064.  Historical relative orthographies do differ
between Canada’s provinces <ref target="n8" rend="sup">8</ref> <ref target="n9" rend="sup">9</ref><ref target="n10" rend="sup">10</ref> but,
assuming the strong connection between orthography and identity, no clear
explanation remains for the lack of correlation in other Canadian data.  Without dispensing with the
orthography/identity hypothesis, I hypothesize that proximal linguistic contexts are also motivating factors in variant selection, and propose to integrate a more context sensitive model into this top-down, language-external theory of linguistic identity performance.</p>
        <p>To test for contextual
differences, I treated the problem as one of word sense disambiguation, where
the goal is to distinguish lexemes using a set of features and a computational language model—a
technique most often used to distinguish between ambiguous meanings of homonyms
(such as <hi rend="italic">judge</hi>, <hi rend="italic">bank</hi>, <hi rend="italic">bow</hi>, etc.) <ref target="n11" rend="sup">11</ref>.  Features used were a window of
words surrounding each variant (8 words either side of the target was found
optimal, excluding other instances of variables if present) and the model was
Naïve Bayes.  If orthographic variants
can be discriminated based on surrounding context, we can assume that those words
are in some way unique—with the interesting implication, in the extreme case, that spelling variants
might not just diverge orthographically but semantically, as well <ref target="n12" rend="sup">12</ref>.  Maybe they mean different things.  My experiments attempted to disambiguate
variants in each variable from one another using unsupervised and supervised classification, in both cases using
the Naïve Bayes form.

</p>
        <p>Though Naïve Bayes
makes the linguistically improbable assumption of feature independence, it has
been noted for its precision in classification problems in spite of this simplification
(i.e. its ‘naiveté’) <ref target="n13" rend="sup">13</ref>.  For unsupervised
classification I used my own <hi rend="italic">Python</hi> implementation
of a Naïve Bayes classifier where the parameter estimates are learned through
Estimation Maximization (EM), as described in e.g. Manning and Schütze <ref target="n14" rend="sup">14</ref>.  As Pedersen <ref target="n15" rend="sup">15</ref> observes, testing the
results of unsupervised classification is complicated by the fact that the
algorithm does not assign labels to inputs, instead clustering them, but accuracy
can be represented as the proportion of the dominant variant in each cluster.  My classifier outputs two ‘sense groups’, which
would ideally correspond to the American or Canadian variant.  After performing 10 trials and averaging the
results, I found that only three variables out of 16 (Heffernan et al. exclude <hi rend="italic">color </hi>/<hi rend="italic"> </hi><hi rend="italic">colour</hi>—I include it) produced
significant results, in that their prediction accuracies departed from – or improved upon – their ‘lower bound’ accuracies,
where the lower bound is the relative frequency of each variant and therefore
the accuracy one would achieve simply by assigning each variant to a category
based on its occurrence.  For brevity,
only these three are represented in Table 1.</p>
        <table>
          <row>
            <cell role="label"> <hi rend="bold"> American variant</hi></cell>
            <cell role="label">
              <hi rend="bold"> accuracy </hi>
            </cell>
            <cell role="label">
              <hi rend="bold"> lower bound </hi>
            </cell>
            <cell role="label">
              <hi rend="bold"> Canadian variant </hi>
            </cell>
            <cell role="label">
              <hi rend="bold"> accuracy </hi>
            </cell>
            <cell role="label">
              <hi rend="bold"> lower bound </hi>
            </cell>
          </row>
          <row>
            <cell role="data"> color</cell>
            <cell role="data">55.5% </cell>
            <cell role="data">54% </cell>
            <cell role="data">colour </cell>
            <cell role="data">65.6% </cell>
            <cell role="data">46% </cell>
          </row>
          <row>
            <cell role="data"> gray</cell>
            <cell role="data">23.2% </cell>
            <cell role="data">17% </cell>
            <cell role="data">grey </cell>
            <cell role="data">86.2% </cell>
            <cell role="data">83% </cell>
          </row>
          <row>
            <cell role="data"> jewelry</cell>
            <cell role="data">51.3% </cell>
            <cell role="data">49% </cell>
            <cell role="data">jewellery </cell>
            <cell role="data">55.4% </cell>
            <cell role="data">51% </cell>
          </row>
        </table>
        <p>Unsupervised classification for <hi rend="italic">colour</hi>
improves accuracy by 19.4% over its lower bound, but increases for other
variables are marginal and – like <hi rend="italic">colour</hi>
– generally apply to one variant only.</p>
        <p>For supervised classification I used the Naïve
Bayes classifier in the <hi rend="italic">Python</hi>
library Natural Language Tool Kit (NLTK)<ref target="n16" rend="sup">16</ref>, a similar method to
Mahowald’s <ref target="n17" rend="sup">17</ref> recent study in which <hi rend="italic">y</hi>-
and ­<hi rend="italic">th</hi>- pronouns were disambiguated
in a corpus of Shakespeare’s plays based on context.  Whereas unsupervised classification performed
poorly, supervised classification obtained surprising accuracy for multiple
variables after 10 validation trials.  These
results are summarized in Table 2, ranked by accuracy, with an asterisk denoting
significance at the <hi rend="italic">p</hi> = 0.001
level.  In this experiment, the lower
bound for each variable is 50% because a random subset of the tokens was evaluated
and counts were set equal for each variant during testing.</p>
        <table>
          <row>
            <cell role="data">
              <hi rend="bold">         <hi rend="bold">  variable                    </hi></hi>
            </cell>
            <cell role="data">
              <hi rend="bold">
                <hi rend="bold">accuracy</hi>
              </hi>
            </cell>
            <cell role="data">
      <hi rend="bold"><hi rend="bold">total count</hi></hi></cell>
          </row>
          <row>
            <cell role="data">
  jewelry / jewellery
  </cell>
            <cell role="data">
  81.6%*
  </cell>
            <cell role="data">
           564
  </cell>
          </row>
          <row>
            <cell role="data">
  gray / grey
  </cell>
            <cell role="data">
  79.3%*
  </cell>
            <cell role="data">
           3112
  </cell>
          </row>
          <row>
            <cell role="data">
  color /colour
  </cell>
            <cell role="data">
  74.5%*
  </cell>
            <cell role="data">
           5312
  </cell>
          </row>
          <row>
            <cell role="data">
  program / programme
  </cell>
            <cell role="data">
  70.1%*
  </cell>
            <cell role="data">
           5704
  </cell>
          </row>
          <row>
            <cell role="data">
  honor / honour
  </cell>
            <cell role="data">
  62.0%*
  </cell>
            <cell role="data">
           2538
  </cell>
          </row>
          <row>
            <cell role="data">
  enrollment / enrolment
  </cell>
            <cell role="data">
  61.2%*
  </cell>
            <cell role="data">
           2086
  </cell>
          </row>
          <row>
            <cell role="data">
  humor / humour
  </cell>
            <cell role="data">
  61.1%*
  </cell>
            <cell role="data">
           2862
  </cell>
          </row>
          <row>
            <cell role="data">
  neighbor / neighbour
  </cell>
            <cell role="data">
  60.7%*
  </cell>
            <cell role="data">
           494
  </cell>
          </row>
          <row>
            <cell role="data">
  defense / defence
  </cell>
            <cell role="data">
  58.6%*
  </cell>
            <cell role="data">
           5640
  </cell>
          </row>
          <row>
            <cell role="data">
  judgment / judgement
  </cell>
            <cell role="data">
  56.8%
  </cell>
            <cell role="data">
           928
  </cell>
          </row>
          <row>
            <cell role="data">
  offense / offence
  </cell>
            <cell role="data">
  56.3%*
  </cell>
            <cell role="data">
           1568
  </cell>
          </row>
          <row>
            <cell role="data">
  centered / centred
  </cell>
            <cell role="data">
  55.7%
  </cell>
            <cell role="data">
           488
  </cell>
          </row>
          <row>
            <cell role="data">
  marvelous / marvellous
  </cell>
            <cell role="data">
  55.6%
  </cell>
            <cell role="data">
           316
  </cell>
          </row>
          <row>
            <cell role="data">
  fulfill / fulfil
  </cell>
            <cell role="data">
  54.7%
  </cell>
            <cell role="data">
           312
  </cell>
          </row>
          <row>
            <cell role="data">
  labeled / labelled         
  </cell>
            <cell role="data">
  54.4%
  </cell>
            <cell role="data">
           270
  </cell>
          </row>
          <row>
            <cell role="data">
  kilometers / kilometres
  </cell>
            <cell role="data">
  40.0%
  </cell>
            <cell role="data">
          
  72
  </cell>
          </row>
        </table>
        <p>It would seem that we are able to predict, sometimes with high
accuracy, whether certain variables will realize their American or British variant based on context.  But why?  If orthographic variations are simply
different graphemes of the same lexeme, decided rather capriciously by an
American lexicographer in the nineteenth century <ref target="n18" rend="sup">18</ref>, why should
this be possible?</p>
        <p>The Naïve Bayes module
in NLTK provides output for identifying features most useful in making its
decisions, and can help answer this question. 
For <hi rend="italic">gray </hi>/ <hi rend="italic">grey</hi>, the case is clear, since the terms
most likely to indicate British <hi rend="italic">grey</hi>
are <hi rend="italic">Pt.</hi> and <hi rend="italic">Point </hi>(Point Grey is the name of the land on which the University
of British Columbia lies), and terms indicating American <hi rend="italic">gray</hi> are proper nouns like <hi rend="italic">Bob</hi>, <hi rend="italic">John</hi>, and <hi rend="italic">Stuart </hi>(Gray is a common
surname).  A revealing result, but only
so far as it reveals a highly restrictive context in non-compositional forms,
and might suggest this variable be excluded from further testing.  Contexts for <hi rend="italic">color </hi>/ <hi rend="italic">colour</hi> are more interesting, however, and fall into two large
subjective categories: ‘cultural’ and ‘technological’ (Table 3).</p>
        <table>
          <row>
            <cell role="data">
              <hi rend="bold">
                <hi rend="bold">  variant</hi>
              </hi>
            </cell>
            <cell role="data">
              <hi rend="bold">
                <hi rend="bold">  category</hi>
              </hi>
            </cell>
            <cell role="data">
              <hi rend="bold">
                <hi rend="bold">  informative</hi>
                <hi rend="bold">features</hi>
              </hi>
            </cell>
          </row>
          <row>
            <cell role="data">colour</cell>
            <cell role="data">
  cultural
  </cell>
            <cell role="data">
  diversity, women, people,
  racism, queer
  </cell>
          </row>
          <row>
            <cell role="data">color</cell>
            <cell role="data">
  cultural
  </cell>
            <cell role="data">
  people
  </cell>
          </row>
          <row>
            <cell role="data">colour</cell>
            <cell role="data">
  technological
  </cell>
            <cell role="data">
  connected, jet, print,
  modem, monitor
  </cell>
          </row>
          <row>
            <cell role="data">color</cell>
            <cell role="data">
  technological
  </cell>
            <cell role="data">
  cartoons,
  TV
 </cell>
          </row>
        </table>
        <p>As a collocation analysis reveals, in the ‘cultural’
category phrases such as <hi rend="italic">women of colour</hi>, <hi rend="italic">people of colour</hi>, and<hi rend="italic">queers
of colour</hi> occur often with <hi rend="italic">colour </hi>– 225 total instances, its most frequent collocate – but hardly ever with <hi rend="italic">color </hi>(11 instances).  In the ‘technological’ category, computer
terms appear with <hi rend="italic">colour</hi> and
entertainment terms with <hi rend="italic">color</hi>, where
these terms are often found in advertisements and the site of these interactions
tend to be local for <hi rend="italic">colour</hi> and
global for <hi rend="italic">color</hi> (a local transaction
for a <hi rend="italic">colour monitor</hi>, at least prior
to the expansion of current global markets, but the international consumption
of <hi rend="italic">color television</hi>).  However, these phrases are easily
recognizable as historically specific (to around post-1980).  Indeed, the unsupervised classification of <hi rend="italic">colour</hi> backs up this historical
selectivity: significantly more of the items grouped at 65.6% accuracy are from this
decade—context and history are intertwined, of course, and it exceeds my scope
to disambiguate these here.  But the more
a-historical distribution of terms predicting <hi rend="italic">jewelry </hi>/ <hi rend="italic">jewellery</hi> suggests historical clustering is not inevitably
the rule: local activities like <hi rend="italic">piercing</hi>
and <hi rend="italic">repairs</hi>, and localities denoted
by <hi rend="italic">West</hi> and <hi rend="italic">Point</hi> (i.e. the location of a shop in <hi rend="italic">West</hi><hi rend="italic">Point</hi> Grey) predict
British <hi rend="italic">jewellery</hi>, but generic sales
terms <hi rend="italic">accessories</hi>, <hi rend="italic">fine</hi>, <hi rend="italic">place</hi>, and <hi rend="italic">giftware</hi> predict American <hi rend="italic">jewelry</hi>.  In sum, advertisements, or, more generically,
‘solicitations’, are the dominant vehicle of these variants and prefer the
British when the activity is local (both economically and socially—these will
be further described) and the American generally.  I will also further discuss how accounting for genre affects classification accuracy.  Overall, British variants are more uniquely contextualized, and therefore more easily discriminated, than American.

</p>
        <p>Qualitative
sociolinguistic approaches like Heffernan et al.’s (2010) locate identity as an
exterior motivating condition for language, with the necessary assumption that orthography
is selected independently of linguistic context.  And though this paper finds that this assumption
does not hold, the ability to disambiguate orthographic variants based on
context is interesting, but not explanatory in its own right.  These contexts are also motivated, and computational
techniques take us full-circle back to considering ideological – but more
interactional – motivations for linguistic context. </p>
      </div>
    </body>
    <back>
      <div type="References">
        <listBibl>
          <bibl>1. <hi rend="bold">Lipski, J</hi>. (1975). <hi rend="italic">Orthographic variation and linguistic nationalism</hi>. La Monda Lingvo-Problemo 6. 37-48.
          </bibl>
          <bibl>2. <hi rend="bold">Schieffelin, B. B., and Doucet, R. C.</hi> (1994). <hi rend="italic">The ‘real’ Haitian Creole: Ideology, metalinguistics and orthographic choice</hi>. American Ethnologist 21. 176–200.
          </bibl>
          <bibl>3. <hi rend="bold">Sebba, M.</hi> (2000). <hi rend="italic">Orthography and ideology: Issues in Sranan spelling</hi>. Linguistics 38. 925–948.
          </bibl>
          <bibl>4. <hi rend="bold">Chambers, J. K.</hi> (2011). <hi rend="italic">‘Canadian dainty’: The rise and decline of Briticisms in Canada</hi>.  In Legacies of Colonial English: Studies in Transported Dialects, 224-241.  Cambridge: Cambridge UP.
          </bibl>
          <bibl>5. <hi rend="bold">Pratt, T. K.</hi> (1993). <hi rend="italic">The hobgoblin of Canadian English spelling</hi>. In S. Clarke (ed.), Focus  on Canada, 45–64. Amsterdam: Benjamins.
          </bibl>
          <bibl>6. <hi rend="bold">Heffernan, K., Borden, A., Erath, A. C., and Yang, J-L.</hi> (2010). <hi rend="italic">Preserving Canada’s  ‘honour’: Ideology and diachronic change in Canadian spelling variants</hi>.  Written Language and Literacy 13(1). 1-23.
          </bibl>
          <bibl>7. <hi rend="bold">Grue, D.</hi> (forthcoming). <hi rend="italic">Testing Canada's 'honour': Does orthography index ideology?</hi> Strathy Student Working Papers on Canadian English.
          </bibl>
          <bibl>8. <hi rend="bold">Brinton, L. and Fee, M.</hi> (2001). <hi rend="italic">Canadian English</hi>. In John Algeo (ed.), The  Cambridge history of the English language, vol. 6, 422-439. Cambridge:  Cambridge UP.
          </bibl>
          <bibl>9. <hi rend="bold">Ireland, R. J.</hi> (1979). <hi rend="italic">Canadian spelling: An empirical and historical survey of  selected word</hi>s. Ph.D. dissertation, York University, Toronto.
          </bibl>
          <bibl>10. <hi rend="bold">Ireland, R. J.</hi> (1980). <hi rend="italic">Canadian spelling: How much British? How much  American?</hi> English Quarterly 12(4). 64-80.
          </bibl>
          <bibl>11. <hi rend="bold">Pedersen, T.</hi> (2002). <hi rend="italic">A baseline methodology for word sense disambiguation</hi>. Proceedings of the Third International Conference on Intelligent Text Processing and Computational Linguistics. 126-135.
          </bibl>
          <bibl>12. <hi rend="bold">Miller, G. A. and Charles, W. G.</hi> (1991). <hi rend="italic">Contextual correlates of semantic similarity</hi>. Language and Cognitive Processes 6(1). 1-28.
          </bibl>
          <bibl>13. <hi rend="bold">Abney, S.</hi> (2008). <hi rend="italic">Semisupervised Learning for Computational Linguistics</hi>. New York: Chapman &amp; Hall.
          </bibl>
          <bibl>14. <hi rend="bold">Manning, C. D. and Schütze, H.</hi> (1999). <hi rend="italic">Foundations of Statistical Natural Language Processing</hi>. Cambridge, Mass.: MIT Press.
          </bibl>
          <bibl>15. <hi rend="bold">Pedersen, T.</hi> (1998). <hi rend="italic">Learning Probabilistic Models of Word Sense Disambiguation</hi>. Ph.D. Dissertation, Southern Methodist University, University Park, Texas.
          </bibl>
          <bibl>16. <hi rend="bold">Bird, S., Klein, E., and E. Lopez.</hi> (2009). <hi rend="italic">Natural Language Processing with Python</hi>. Sebastopol, CA: O'Reilly Media.
          </bibl>
          <bibl>17. <hi rend="bold">Mahowald, K.</hi> (2012). <hi rend="italic">A Naïve Bayes classifier for Shakespeare's second-person pronoun</hi>. Literary and Linguistic Computing 27(1). 17-23.
          </bibl>
          <bibl>18. <hi rend="bold">Webster, N.</hi> (1846). <hi rend="italic">A dictionary of the English language</hi>; abridged from the American dictionary. [American Dictionary]. New York: Huntington and Savage.
          </bibl>
        </listBibl>
      </div>
    </back>
  </text>
</TEI>
