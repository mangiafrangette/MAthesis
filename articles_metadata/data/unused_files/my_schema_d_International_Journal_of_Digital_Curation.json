[
    {
        "url": "http://www.ijdc.net/article/view/8",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v1i1.4",
            "id_scheme": "DOI"
        },
        "abstract": "The use of digital technologies within research has led to a proliferation of data, many new forms of research output and new modes of presentation and analysis. Many scientific communities are struggling with the challenge of how to manage the terabytes of data and new forms of output, they are producing. They are also under increasing pressure from funding organizations to publish their raw data, in addition to their traditional publications, in open archives. In this paper I describe an approach that involves the selective encapsulation of raw data, derived products, algorithms, software and textual publications within “scientific publication packages”. Such packages provide an ideal method for: encapsulating expert knowledge; for publishing and sharing scientific process and results; for teaching complex scientific concepts; and for the selective archival, curation and preservation of scientific data and output. They also provide a bridge between technological advances in the Digital Libraries and eScience domains. In particular, I describe the RDF-based architecture that we are adopting to enable scientists to construct, publish and manage “scientific publication packages” - compound digital objects that encapsulate and relate the raw data to its derived products, publications and the associated contextual, provenance and administrative metadata.",
        "article_title": "Scientific Publication Packages – A Selective Approach to the Communication and Archival of Scientific Output",
        "authors": [
            {
                "given": "Jane",
                "family": "Hunter"
            }
        ],
        "publisher": "",
        "date": "2020-08-21T14:47:10.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/148",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v5i1.145",
            "id_scheme": "DOI"
        },
        "abstract": "Software preservation has not had detailed consideration as a research topic or in practical application. In this paper, we present a conceptual framework to capture and organise the main notions of software preservation, which are required for a coherent and comprehensive approach. This framework has three main aspects. Firstly a discussion of what it means to preserve software via a performance model which considers how a software artefact can be rebuilt from preserved components and can then be seen to be representative of the original software product. Secondly the development of a model of software artefacts, describing the basic components of all software, loosely based on the FRBR model for representing digital artefacts and their history within a library context. Finally, the definition and categorisation of the properties of software artefacts which are required to ensure that the software product has been adequately preserved. These are broken down into a number of categories and related to the concepts defined in the OAIS standard. We also discuss our experience of recording these preservation properties for a number of BADC software products, which arose from a series of case studies conducted to evaluate the software preservation framework, and also briefly describe the SPEQS toolkit, a tool to capture software preservation properties within a software development.",
        "article_title": "A Framework for Software Preservation",
        "authors": [
            {
                "given": "Brian",
                "family": "Matthews"
            },
            {
                "given": "Arif",
                "family": "Shaon"
            },
            {
                "given": "Juan",
                "family": "Bicarregui"
            },
            {
                "given": "Catherine",
                "family": "Jones"
            }
        ],
        "publisher": "",
        "date": "2020-08-01T16:57:08.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/144",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v5i1.141",
            "id_scheme": "DOI"
        },
        "abstract": "This paper reports on research of scholarly research practices and requirements conducted in the context of the Preparing DARIAH European e-Infrastructures project, with a view to ensuring current and future fitness for purpose of the planned digital infrastructure, services and tools. It summarises the findings of earlier research, primarily from the field of human information behaviour as applied in scholarly work, it presents a conceptual perspective informed by cultural-historical activity theory, it introduces briefly a formal conceptual model for scholarly research activity compliant with CIDOC CRM, it describes the plan of work and methodology of an empirical research project based on open-questionnaire interviews with arts and humanities researchers, and presents illustrative examples of segmentation, tagging and initial conceptual analysis of the empirical evidence. Finally, it presents plans for future work, consisting, firstly, of a comprehensive re-analysis of interview segments within the framework of the scholarly research activity model, and, secondly, of the integration of this analysis with the extended digital curation process model we presented in earlier work.",
        "article_title": "Understanding the Information Requirements of Arts and Humanities Scholarship",
        "authors": [
            {
                "given": "Agiatis",
                "family": "Benardou"
            },
            {
                "given": "Panos",
                "family": "Constantopoulos"
            },
            {
                "given": "Costis",
                "family": "Dallas"
            },
            {
                "given": "Dimitris",
                "family": "Gavrilis"
            }
        ],
        "publisher": "",
        "date": "2020-08-01T06:24:54.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/174",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v6i1.183",
            "id_scheme": "DOI"
        },
        "abstract": "Within information systems, a significant aspect of search and retrieval across information objects, such as datasets, journal articles, or images, relies on the identity construction of the objects. This paper uses identity to refer to the qualities or characteristics of an information object that make it definable and recognizable, and can be used to distinguish it from other objects. Identity, in this context, can be seen as the foundation from which citations, metadata and identifiers are constructed.In recent years the idea of including datasets within the scientific record has been gaining significant momentum, with publishers, granting agencies and libraries engaging with the challenge. However, the task has been fraught with questions of best practice for establishing this infrastructure, especially in regards to how citations, metadata and identifiers should be constructed. These questions suggests a problem with how dataset identities are formed, such that an engagement with the definition of datasets as conceptual objects is warranted.This paper explores some of the ways in which scientific data is an unruly and poorly bounded object, and goes on to propose that in order for datasets to fulfill the roles expected for them, the following identity functions are essential for scholarly publications: (i) the dataset is constructed as a semantically and logically concrete object, (ii) the identity of the dataset is embedded, inherent and/or inseparable, (iii) the identity embodies a framework of authorship, rights and limitations, and (iv) the identity translates into an actionable mechanism for retrieval or reference.",
        "article_title": "Linking to Scientific Data: Identity Problems of Unruly and Poorly Bounded Digital Objects",
        "authors": [
            {
                "given": "Laura",
                "family": "Wynholds"
            }
        ],
        "publisher": "",
        "date": "2020-08-21T14:47:35.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/173",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v6i1.182",
            "id_scheme": "DOI"
        },
        "abstract": "We report on an exploratory study consisting of brief case studies in selected disciplines, examining what motivates researchers to work (or want to work) in an open manner with regard to their data, results and protocols, and whether advantages are delivered by working in this way. We review the policy background to open science, and literature on the benefits attributed to open data, considering how these relate to curation and to questions of who participates in science. The case studies investigate the perceived benefits to researchers, research institutions and funding bodies of utilising open scientific methods, the disincentives and barriers, and the degree to which there is evidence to support these perceptions. Six case study groups were selected in astronomy, bioinformatics, chemistry, epidemiology, language technology and neuroimaging. The studies identify relevant examples and issues through qualitative analysis of interview transcripts. We provide a typology of degrees of open working across the research lifecycle, and conclude that better support for open working, through guidelines to assist research groups in identifying the value and costs of working more openly, and further research to assess the risks, incentives and shifts in responsibility entailed by opening up the research process are needed.",
        "article_title": "Open Science in Practice: Researcher Perspectives and Participation",
        "authors": [
            {
                "given": "Angus",
                "family": "Whyte"
            },
            {
                "given": "Graham",
                "family": "Pryor"
            }
        ],
        "publisher": "",
        "date": "2020-08-01T12:01:20.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/163",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v6i1.172",
            "id_scheme": "DOI"
        },
        "abstract": "There is almost universal agreement that scientific data should be shared for use beyond the purposes for which they were initially collected. Access to data enables system-level science, expands the instruments and products of research to new communities, and advances solutions to complex human problems. While demands for data are not new, the vision of open access to data is increasingly ambitious. The aim is to make data accessible and usable to anyone, anytime, anywhere, and for any purpose. Until recently, scholarly investigations related to data sharing and reuse were sparse. They have become more common as technology and instrumentation have advanced, policies that mandate sharing have been implemented, and research has become more interdisciplinary. Each of these factors has contributed to what is commonly referred to as the \"data deluge\". Most discussions about increases in the scale of sharing and reuse have focused on growing amounts of data. There are other issues related to open access to data that also concern scale which have not been as widely discussed: broader participation in data sharing and reuse, increases in the number and types of intermediaries, and more digital data products. The purpose of this paper is to develop a research agenda for scientific data sharing and reuse that considers these three areas.",
        "article_title": "Beyond the Data Deluge: A Research Agenda for Large-Scale Data Sharing and Reuse",
        "authors": [
            {
                "given": "Ixchel M.",
                "family": "Faniel"
            },
            {
                "given": "Ann",
                "family": "Zimmerman"
            }
        ],
        "publisher": "",
        "date": "2020-08-22T02:19:55.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/8.1.157",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v8i1.252",
            "id_scheme": "DOI"
        },
        "abstract": "In contemporary scientific research, standard-making and standardization are key processes for the sharing and reuse of data. The goals of this paper are twofold: 1) to stress that collaboration is crucial to standard-making, and 2) to urge recognition of metadata standardization as part of the scientific process. To achieve these goals, a participatory framework for developing and implementing scientific metadata standards is presented. We highlight the need for ongoing, open dialogue within and among research communities at multiple levels. Using the Long Term Ecological Research network adoption of the Ecological Metadata Language as a case example in the natural sciences, we illustrate how a participatory framework addresses the need for active coordination of the evolution of scientific metadata standards. The participatory framework is contrasted with a hierarchical framework to underscore how the development of scientific standards is a dynamic and continuing process. The roles played by ‘best practices’ and ‘working standards’ are identified in relation to the process of standardization.",
        "article_title": "Towards Standardization: A Participatory Framework for Scientific Standard-Making",
        "authors": [
            {
                "given": "Lynn",
                "family": "Yarmey"
            },
            {
                "given": "Karen S.",
                "family": "Baker"
            }
        ],
        "publisher": "",
        "date": "2020-07-31T21:55:19.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/8.1.107",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v8i1.248",
            "id_scheme": "DOI"
        },
        "abstract": "The LOCKSS system is a leading technology in the field of Distributed Digital Preservation. Libraries run LOCKSS boxes to collect and preserve content published on the Web in PC servers with local disk storage. They form nodes in a network that continually audits their content and repairs any damage. Libraries wondered whether they could use cloud storage for their LOCKSS boxes instead of local disks. We review the possible configurations, evaluate their technical feasibility, assess their economic feasibility, report on an experiment in which we ran a production LOCKSS box in Amazon’s cloud service, and describe some simulations of future costs of cloud and local storage. We conclude that current cloud storage services are not cost-competitive with local hardware for long term storage, including for LOCKSS boxes.",
        "article_title": "Distributed Digital Preservation in the Cloud",
        "authors": [
            {
                "given": "David S. H.",
                "family": "Rosenthal"
            },
            {
                "given": "Daniel L.",
                "family": "Vargas"
            }
        ],
        "publisher": "",
        "date": "2020-08-01T02:28:42.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/8.1.29",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v8i1.247",
            "id_scheme": "DOI"
        },
        "abstract": "‘Big Science’ - that is, science which involves large collaborations with dedicated facilities, and involving large data volumes and multinational investments – is often seen as different when it comes to data management and preservation planning. Big Science handles its data differently from other disciplines and has data management problems that are qualitatively different from other disciplines. In part, these differences arise from the quantities of data involved, but possibly more importantly from the cultural, organisational and technical distinctiveness of these academic cultures. Consequently, the data management systems are typically and rationally bespoke, but this means that the planning for data management and preservation (DMP) must also be bespoke.These differences are such that ‘just read and implement the OAIS specification’ is reasonable Data Management and Preservation (DMP) advice, but this bald prescription can and should be usefully supported by a methodological ‘toolkit’, including overviews, case-studies and costing models to provide guidance on developing best practice in DMP policy and infrastructure for these projects, as well as considering OAIS validation, audit and cost modelling.In this paper, we build on previous work with the LIGO collaboration to consider the role of DMP planning within these big science scenarios, and discuss how to apply current best practice. We discuss the result of the MaRDI-Gross project (Managing Research Data Infrastructures – Big Science), which has been developing a toolkit to provide guidelines on the application of best practice in DMP planning within big science projects. This is targeted primarily at projects’ engineering managers, but intending also to help funders collaborate on DMP plans which satisfy the requirements imposed on them.",
        "article_title": "Data Management and Preservation Planning for Big Science",
        "authors": [
            {
                "given": "Juan",
                "family": "Bicarregui"
            },
            {
                "given": "Norman",
                "family": "Gray"
            },
            {
                "given": "Rob",
                "family": "Henderson"
            },
            {
                "given": "Roger",
                "family": "Jones"
            },
            {
                "given": "Simon",
                "family": "Lambert"
            },
            {
                "given": "Brian",
                "family": "Matthews"
            }
        ],
        "publisher": "",
        "date": "2020-08-21T21:37:51.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/8.2.5",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v8i2.263",
            "id_scheme": "DOI"
        },
        "abstract": "Academic librarians are increasingly engaging in data curation by providing infrastructure (e.g., institutional repositories) and offering services (e.g., data management plan consultations) to support the management of research data on their campuses. Efforts to develop these resources may benefit from a greater understanding of disciplinary differences in research data management needs. After conducting a survey of data management practices and perspectives at our research university, we categorized faculty members into four research domains—arts and humanities, social sciences, medical sciences, and basic sciences—and analyzed variations in their patterns of survey responses. We found statistically significant differences among the four research domains for nearly every survey item, revealing important disciplinary distinctions in data management actions, attitudes, and interest in support services. Serious consideration of both the similarities and dissimilarities among disciplines will help guide academic librarians and other data curation professionals in developing a range of data-management services that can be tailored to the unique needs of different scholarly researchers.",
        "article_title": "Disciplinary differences in faculty research data management practices and perspectives",
        "authors": [
            {
                "given": "Katherine G.",
                "family": "Akers"
            },
            {
                "given": "Jennifer",
                "family": "Doty"
            }
        ],
        "publisher": "",
        "date": "2020-07-31T19:07:49.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/9.1.57",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v9i1.301",
            "id_scheme": "DOI"
        },
        "abstract": "We present a case study of data integration and reuse involving 12 researchers who published datasets in Open Context, an online data publishing platform, as part of collaborative archaeological research on early domesticated animals in Anatolia. Our discussion reports on how different editorial and collaborative review processes improved data documentation and quality, and created ontology annotations needed for comparative analyses by domain specialists. To prepare data for shared analysis, this project adapted editor-supervised review and revision processes familiar to conventional publishing, as well as more novel models of revision adapted from open source software development of public version control. Preparing the datasets for publication and analysis required significant investment of effort and expertise, including archaeological domain knowledge and familiarity with key ontologies. To organize this work effectively, we emphasized these different models of collaboration at various stages of this data publication and analysis project. Collaboration first centered on data editors working with data contributors, then widened to include other researchers who provided additional peer-review feedback, and finally the widest research community, whose collaboration is facilitated by GitHub’s version control system. We demonstrate that the “publish” and “push” models of data dissemination need not be mutually exclusive; on the contrary, they can play complementary roles in sharing high quality data in support of research. This work highlights the value of combining multiple models in different stages of data dissemination.",
        "article_title": "Publishing and Pushing: Mixing Models for Communicating Research Data in Archaeology",
        "authors": [
            {
                "given": "Eric C.",
                "family": "Kansa"
            },
            {
                "given": "Sarah Whitcher",
                "family": "Kansa"
            },
            {
                "given": "Benjamin",
                "family": "Arbuckle"
            }
        ],
        "publisher": "",
        "date": "2020-08-01T16:50:42.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/10.1.68",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v10i1.289",
            "id_scheme": "DOI"
        },
        "abstract": "In order to better understand the factors that most influence where researchers deposit their data when they have a choice, we collected survey data from researchers who deposited phylogenetic data in either the TreeBASE or Dryad data repositories. Respondents were asked to rank the relative importance of eight possible factors. We found that factors differed in importance for both TreeBASE and Dryad, and that the rankings differed subtly but significantly between TreeBASE and Dryad users. On average, TreeBASE users ranked the domain specialization of the repository highest, while Dryad users ranked as equal highest their trust in the persistence of the repository and the ease of its data submission process. Interestingly, respondents (particularly Dryad users) were strongly divided as to whether being directed to choose a particular repository by a journal policy or funding agency was among the most or least important factors. Some users reported depositing their data in multiple repositories and archiving their data voluntarily.",
        "article_title": "What Factors Influence Where Researchers Deposit their Data? A Survey of Researchers Submitting to Data Repositories",
        "authors": [
            {
                "given": "Shea",
                "family": "Swauger"
            },
            {
                "given": "Todd J.",
                "family": "Vision"
            }
        ],
        "publisher": "",
        "date": "2020-08-21T13:20:13.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/10.2.110",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v10i2.346",
            "id_scheme": "DOI"
        },
        "abstract": "Digital data are accumulating rapidly, yet issues relating to data production remain unexamined. Data sharing efforts in particular are nascent, disunited and incomplete. We investigate the development of data products tailored for diverse communities with differing knowledge bases. We explore not the technical aspects of how, why, or where data are made available, but rather the socio-scientific aspects influencing what data products are created and made available for use. These products differ from compact data summaries often published in journals. We report on development by a national data center of two data collections describing the changing polar environment. One collection characterizes sea ice products derived from satellite remote sensing data and development unfolds over three decades. The second collection characterizes the Greenland Ice Sheet melt where development of an initial collection of data products over a period of several months was informed by insights gained from earlier experience. In documenting the generation of these two collections, a data product development cycle supported by a data product team is identified as key to mobilizing scientific knowledge. The collections reveal a co-evolution of data products and designated communities where community interest may be triggered by events such as environmental disturbance and new modes of communication. These examples of data product development in practice illustrate knowledge mobilization in the earth sciences; the collections create a bridge between data producers and a growing number of audiences interested in making evidence-based decisions.",
        "article_title": "Scientific Knowledge Mobilization: Co-evolution of Data Products and Designated Communities",
        "authors": [
            {
                "given": "Karen S.",
                "family": "Baker"
            },
            {
                "given": "Ruth E.",
                "family": "Duerr"
            },
            {
                "given": "Mark A.",
                "family": "Parsons"
            }
        ],
        "publisher": "",
        "date": "2020-08-01T02:23:44.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/11.1.232",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v11i1.389",
            "id_scheme": "DOI"
        },
        "abstract": "In order to better understand the current state of data management education in multiple fields of science, this study surveyed scientists, including information scientists, about their data management education practices, including at what levels they are teaching data management, which topics they covering, and what barriers they experience in teaching these topics. We found that a handful of scientists are teaching data management in undergraduate, graduate, and other types of courses, as well as outside of classroom settings. Commonly taught data management topics included quality control, protecting data, and management planning. However, few instructors felt they were covering data management topics thoroughly, and respondents cited barriers such as lack of time, lack of necessary expertise, and lack of information for teaching data management. We offer some potential explanations for the existing state of data management education and suggest areas for further research.",
        "article_title": "Data Management Education from the Perspective of Science Educators",
        "authors": [
            {
                "given": "Carol",
                "family": "Tenopir"
            },
            {
                "given": "Suzie",
                "family": "Allard"
            },
            {
                "given": "Priyanki",
                "family": "Sinha"
            },
            {
                "given": "Danielle",
                "family": "Pollock"
            },
            {
                "given": "Jess",
                "family": "Newman"
            },
            {
                "given": "Elizabeth",
                "family": "Dalton"
            },
            {
                "given": "Mike",
                "family": "Frame"
            },
            {
                "given": "Lynn",
                "family": "Baird"
            }
        ],
        "publisher": "",
        "date": "2020-08-01T08:19:34.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://ijdc.net/index.php/ijdc/article/view/11.1.150",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v11i1.400",
            "id_scheme": "DOI"
        },
        "abstract": "While stakeholders in scholarly communication generally agree on the importance of data citation, there is not consensus on where those citations should be placed within the publication â€“ particularly when the publication is citing original data. Recently, CrossRef and the Digital Curation Center (DCC) have recommended as a best practice that original data citations appear in the works cited sections of the article. In some fields, such as the life sciences, this contrasts with the common practice of only listing data identifier(s) within the article body (intratextually). We inquired whether data citation practice has been changing in light of the guidance from CrossRef and the DCC. We examined data citation practices from 2011 to 2014 in a corpus of 1,125 articles associated with original data in the Dryad Digital Repository. The percentage of articles that include no reference to the original data has declined each year, from 31% in 2011 to 15% in 2014. The percentage of articles that include data identifiers intratextually has grown from 69% to 83%, while the percentage that cite data in the works cited section has grown from 5% to 8%. If the proportions continue to grow at the current rate of 19-20% annually, the proportion of articles with data citations in the works cited section will not exceed 90% until 2030.Â",
        "article_title": "The location of the citation: changing practices in how publications cite original data in the Dryad Digital Repository",
        "authors": [
            {
                "given": "Christine",
                "family": "Mayo"
            },
            {
                "given": "Todd J.",
                "family": "Vision"
            },
            {
                "given": "Elizabeth A.",
                "family": "Hull"
            }
        ],
        "publisher": "",
        "date": "2020-08-21T13:17:41.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/481",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v12i1.481",
            "id_scheme": "DOI"
        },
        "abstract": "The Data Seal of Approval (DSA) is one of the most widely used standards for Trusted Digital Repositories to date. Those who developed this standard have articulated seven main benefits of acquiring DSAs: 1) stakeholder confidence, 2) improvements in communication, 3) improvement in processes, 4) transparency, 5) differentiation from others, 6) awareness raising about digital preservation, and 7) less labor- and time-intensive. Little research has focused on if and how those who have acquired DSAs actually perceive these benefits. Consequently, this study examines the benefits of acquiring DSAs from the point of view of those who have them. In a series of 15 semi-structured interviews with representatives from 16 different organizations, participants described the benefits of having DSAs in their own words. Our findings suggest that participants experience all of the seven benefits that those who developed the standard promised. Additionally, our findings reflect the greater importance of some of those benefits compared to others. For example, participants mentioned the benefits of stakeholder confidence, transparency, improvement in processes and awareness raising about digital preservation more frequently than they discussed less labor- and time-intensive (e.g. it being less labor- and time-intensive to acquire DSAs than becoming certified by other standards), improvements in communication, and differentiation from others. Participants also mentioned two additional benefits of acquiring DSAs that are not explicitly listed on the DSA website that were very important to them: 1) the impact of acquiring the DSA on documentation of their workflows, and 2) assurance that they were following best practice. Implications and future directions for research are discussed.",
        "article_title": "The Perceived Value of Acquiring Data Seals of Approval",
        "authors": [
            {
                "given": "Devan Ray",
                "family": "Donaldson"
            },
            {
                "given": "Ingrid",
                "family": "Dillo"
            },
            {
                "given": "Robert",
                "family": "Downs"
            },
            {
                "given": "Sarah",
                "family": "Ramdeen"
            }
        ],
        "publisher": "",
        "date": "2020-08-22T05:56:22.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/500",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v12i2.500",
            "id_scheme": "DOI"
        },
        "abstract": "Social scientists are producing an ever-expanding volume of data, leading to questions about appraisal and selection of content given finite resources to process data for reuse. We analyze users’ search activity in an established social science data repository to better understand demand for data and more effectively guide collection development. By applying a data-driven approach, we aim to ensure curation resources are applied to make the most valuable data findable, understandable, accessible, and usable. We analyze data from a domain repository for the social sciences that includes over 500,000 annual searches in 2014 and 2015 to better understand trends in user search behavior. Using a newly created search-to-study ratio technique, we identified gaps in the domain data repository’s holdings and leveraged this analysis to inform our collection and curation practices and policies. The evaluative technique we propose in this paper will serve as a baseline for future studies looking at trends in user demand over time at the domain data repository being studied with broader implications for other data repositories.",
        "article_title": "A Data-Driven Approach to Appraisal and Selection at a Domain Data Repository",
        "authors": [
            {
                "given": "Amy M",
                "family": "Pienta"
            },
            {
                "given": "Dharma",
                "family": "Akmon"
            },
            {
                "given": "Justin",
                "family": "Noble"
            },
            {
                "given": "Lynette",
                "family": "Hoelter"
            },
            {
                "given": "Susan",
                "family": "Jekielek"
            }
        ],
        "publisher": "",
        "date": "2020-08-22T05:42:21.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/429",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v12i2.429",
            "id_scheme": "DOI"
        },
        "abstract": "This paper develops and tests a lifecycle model for the preservation of research data by investigating the research practices of scientists. This research is based on a mixed-method approach. An initial study was conducted using case study analytical techniques; insights from these case studies were combined with grounded theory in order to develop a novel model of the Digital Research Data Lifecycle. A broad-based quantitative survey was then constructed to test and extend the components of the model. The major contribution of these research initiatives are the creation of the Digital Research Data Lifecycle, a data lifecycle that provides a generalized model of the research process to better describe and explain both the antecedents and barriers to preservation. The antecedents and barriers to preservation are data management, contextual metadata, file formats, and preservation technologies. The availability of data management support and preservation technologies, the ability to create and manage contextual metadata, and the choices of file formats all significantly effect the preservability of research data.",
        "article_title": "Modelling the Research Data Lifecycle",
        "authors": [
            {
                "given": "Stacy T",
                "family": "Kowalczyk"
            }
        ],
        "publisher": "",
        "date": "2020-08-22T05:47:20.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/534",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v13i1.534",
            "id_scheme": "DOI"
        },
        "abstract": "This paper describes the findings from a participatory prototype design project, where the authors worked with maternal and child health (MCH) researchers and stakeholders to develop a MCH metadata profile and sustainable curation workflow. This work led to the development of three prototypes: 1) a study catalogue hosted in Dataverse, 2) a metadata and research records repository hosted in REDCap and 3) a metadata harvesting tool/dashboard hosted within the Shiny RStudio environment. We present a brief overview of the methods used to develop the metadata profile, curation workflow and prototypes. Researchers and other stakeholders were participant-collaborators throughout the project. The participatory process involved a number of steps, including but not limited to: initial project design and grant writing; scoping and mapping existing practices, workflows and relevant metadata standards; creating the metadata profile; developing semi-automated and manual techniques to harvest and transform metadata; and end project sustainability/future planning. In this paper, we discuss the design process and project outcomes, limitations and benefits of the approach, and implications for researcher-oriented metadata and data curation initiatives.",
        "article_title": "Participatory Prototype Design: Developing a Sustainable Metadata Curation Workflow for Maternal Child Health Research",
        "authors": [
            {
                "given": "Amanda",
                "family": "Harrigan"
            },
            {
                "given": "Saurabh",
                "family": "Vashishtha"
            },
            {
                "given": "Sharon",
                "family": "Farnel"
            },
            {
                "given": "Kendall",
                "family": "Roark"
            }
        ],
        "publisher": "",
        "date": "2020-08-22T07:50:21.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/492",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v13i1.492",
            "id_scheme": "DOI"
        },
        "abstract": "In this article, we examine how data producers’ and reusers’ privacy concerns shape their views about data sharing and reuse in the field of education, with an emphasis on video records of practice. We find that data producers and reusers were concerned about the risks that qualitative data, and video records of practice in particular, present to themselves, their colleagues, and the subjects represented in the data. Specifically, they emphasized risks relating to the privacy the subjects – teachers and students who appear in the videos. In response to these risks, data producers have engaged in a number of strategies to minimize risk and/or mitigate potential harm including: (1) education and training; (2) using informed consent to facilitate and/or restrict data sharing; and (3) limiting data capture/production. We discuss the implications that our findings have for digital repositories, and for efforts to facilitate the sharing and reuse of qualitative video data in education.",
        "article_title": "Issues of Privacy in Qualitative Video Data Reuse",
        "authors": [
            {
                "given": "Rebecca D.",
                "family": "Frank"
            },
            {
                "given": "Allison R. B.",
                "family": "Tyler"
            },
            {
                "given": "Anna",
                "family": "Gault"
            },
            {
                "given": "Kara",
                "family": "Suzuka"
            },
            {
                "given": "Elizabeth",
                "family": "Yakel"
            }
        ],
        "publisher": "",
        "date": "2020-08-22T08:27:37.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/502",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v13i1.502",
            "id_scheme": "DOI"
        },
        "abstract": "Since its creation nearly a decade ago, the Digital Curation Centre (DCC) Curation Lifecycle Model has become the quintessential framework for understanding digital curation. Organizations and consortia around the world have used the DCC Curation Lifecycle Model as a tool to ensure that all the necessary stages of digital curation are undertaken, to define roles and responsibilities, and to build a framework of standards and technologies for digital curation. Yet, research on the application of the model to large-scale digitization projects as a way of understanding their efforts at digital curation is scant. This paper reports on findings of a qualitative case study analysis of Indiana University Bloomington’s multi-million-dollar Media Digitization and Preservation Initiative (MDPI), employing the DCC Curation Lifecycle Model as a lens for examining the scope and effectiveness of its digital curation efforts. Findings underscore the success of MDPI in performing digital curation by illustrating the ways it implements each of the model’s components. Implications for the application of the DCC Curation Lifecycle Model in understanding digital curation for mass digitization projects are discussed as well as directions for future research.",
        "article_title": "Media Digitization and Preservation Initiative: A Case Study",
        "authors": [
            {
                "given": "Devan Ray",
                "family": "Donaldson"
            },
            {
                "given": "Allison",
                "family": "McClanahan"
            },
            {
                "given": "Leif",
                "family": "Christiansen"
            },
            {
                "given": "Laura",
                "family": "Bell"
            },
            {
                "given": "Mikala",
                "family": "Narlock"
            },
            {
                "given": "Shannon",
                "family": "Martin"
            },
            {
                "given": "Haley",
                "family": "Suby"
            }
        ],
        "publisher": "",
        "date": "2020-08-22T08:02:13.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/588",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v14i1.588",
            "id_scheme": "DOI"
        },
        "abstract": "This study identifies challenges and promising directions in the curation of 3D data. 3D visualization shows great promise for a range of scholarly fields through interactive engagement with and analysis of spatially complex artifacts, spaces, and data. While the new affordability of emerging 3D capture technologies presents greater academic possibilities, academic libraries need more effective workflows, policies, standards, and practices to ensure that they can support the creation, discovery, access, preservation, and reproducibility of 3D data sets. This study uses nominal group technique with invited experts across several disciplines and sectors to identify common challenges in the creation and re-use of 3D data for the purpose of developing library strategy for supporting curation of 3D data. This article identifies staffing needs for 3D imaging; alignment with IT resources; the roll of archivists in addressing unique challenges posed by these datasets; the importance of data annotation, metadata, and transparency for research integrity and reproducibility; and features for storage, access, and management to facilitate re-use by researchers and educators. Participants identified three main challenges for supporting 3D data that align with the strengths of libraries: 1) development of crosswalks and aggregation tools for discipline-specific metadata models, data dictionaries for 3D research, and aggregation tools for expanding discovery; 2) development of an open source viewer that supports streaming and annotation on archival formats of 3D models and makes archival master files accessible, while also serving derivative files based on user requirements; and 3) widespread of adoption of better documentation and technical metadata for image capture and modeling processes in order to support replicability of research, reproducibility of models, and transparency of scientific process.",
        "article_title": "Challenges and Directions in 3D and VR Data Curation",
        "authors": [
            {
                "given": "Nathan Frank",
                "family": "Hall"
            },
            {
                "given": "Juliet",
                "family": "Hardesty"
            },
            {
                "given": "Zack",
                "family": "Lischer-Katz"
            },
            {
                "given": "Jennifer",
                "family": "Johnson"
            },
            {
                "given": "Matt",
                "family": "Cook"
            },
            {
                "given": "Julie",
                "family": "Griffin"
            },
            {
                "given": "Andrea",
                "family": "Ogier"
            },
            {
                "given": "Tara",
                "family": "Carlisle"
            },
            {
                "given": "Zhiwu",
                "family": "Xie"
            },
            {
                "given": "Robert",
                "family": "McDonald"
            },
            {
                "given": "Jamie",
                "family": "Wittenberg"
            }
        ],
        "publisher": "",
        "date": "2020-08-21T23:44:50.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/643",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v14i1.643",
            "id_scheme": "DOI"
        },
        "abstract": "The Data Curation Continuum was developed as a way of thinking about data repository infrastructure. Since its original development over a decade ago, a number of things have changed in the data infrastructure domain. This paper revisits the thinking behind the original data curation continuum and updates it to respond to changes in research objects, storage models, and the repository landscape in general.",
        "article_title": "Updating the Data Curation Continuum",
        "authors": [
            {
                "given": "Andrew",
                "family": "Treloar"
            },
            {
                "given": "Jens",
                "family": "Klump"
            }
        ],
        "publisher": "",
        "date": "2020-08-21T23:25:51.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/594",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v14i1.594",
            "id_scheme": "DOI"
        },
        "abstract": "The National Imaging Facility (NIF) provides Australian researchers with state-of-the-art instrumentation—including magnetic resonance imaging (MRI), positron emission tomography (PET), X-ray computed tomography (CT) and multispectral imaging – and expertise for the characterisation of animals, plants and materials. To maximise research outcomes, as well as to facilitate collaboration and sharing, it is essential not only that the data acquired using these instruments be managed, curated and archived in a trusted data repository service, but also that the data itself be of verifiable quality. In 2017, several NIF nodes collaborated on a national project to define the requirements and best practices necessary to achieve this, and to establish exemplar services for both preclinical MRI data and clinical ataxia MRI data. In this paper we describe the project, its key outcomes, challenges and lessons learned, and future developments, including extension to other characterisation facilities and instruments/modalities.",
        "article_title": "Putting the Trust into Trusted Data Repositories: A Federated Solution for the Australian National Imaging Facility",
        "authors": [
            {
                "given": "Andrew James",
                "family": "Mehnert"
            },
            {
                "given": "Andrew",
                "family": "Janke"
            },
            {
                "given": "Marco",
                "family": "Gruwel"
            },
            {
                "given": "Wojtek James",
                "family": "Goscinski"
            },
            {
                "given": "Thomas",
                "family": "Close"
            },
            {
                "given": "Dean",
                "family": "Taylor"
            },
            {
                "given": "Aswin",
                "family": "Narayanan"
            },
            {
                "given": "George",
                "family": "Vidalis"
            },
            {
                "given": "Graham",
                "family": "Galloway"
            },
            {
                "given": "Andrew",
                "family": "Treloar"
            }
        ],
        "publisher": "",
        "date": "2020-08-21T23:23:42.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/598",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v14i1.598",
            "id_scheme": "DOI"
        },
        "abstract": "PARADISEC’s PNG collections represent the great diversity in the regions and languages of PNG. In 2016 and 2017, in recognition of the value of PARADISEC’s collections, ANDS (the Australian National Data Service) provided funding for us to concentrate efforts on enhancing the metadata that describes our Papua New Guinea (PNG) collections, an effort designed to maximise the findability and useability of the language and music recordings preserved in the archive for both source communities and researchers. PARADISEC's subsequent engagement with PNG language experts has led to collaborations with members of speaker communities who are part of the PNG diaspora in Australia. In this paper, we show that making historical recordings more findable, accessible and better described can result in meaningful interactions with and responses to the data in source communities. The effects of empowering speaker communities in their relationships to archives can be far reaching – even inverting, or disrupting the power relationships that have resulted from the colonial histories in which archives are embedded.",
        "article_title": "Making Meaning of Historical Papua New Guinea Recordings",
        "authors": [
            {
                "given": "Amanda",
                "family": "Harris"
            },
            {
                "given": "Steven",
                "family": "Gagau"
            },
            {
                "given": "Jodie",
                "family": "Kell"
            },
            {
                "given": "Nick",
                "family": "Thieberger"
            },
            {
                "given": "Nick",
                "family": "Ward"
            }
        ],
        "publisher": "",
        "date": "2020-08-21T23:43:40.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/595",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v14i1.595",
            "id_scheme": "DOI"
        },
        "abstract": "University libraries have played an important role in constructing an infrastructure of support for Research Data Management at an institutional level. This paper presents a comparative analysis of two international surveys of libraries about their involvement in Research Data Services conducted in 2014 and 2018. The aim was to explore how services had developed over this time period, and to explore the drivers and barriers to change. In particular, there was an interest in how far the FAIR data principles had been adopted. Services in nearly every area were more developed in 2018 than before, but technical services remained less developed than advisory. Progress on institutional policy was also evident. However, priorities did not seem to have shifted significantly. Open ended answers suggested that funder policy, rather than researcher demand, remained the main driver of service development and that resources and skills gaps remained issues. While widely understood as an important reference point and standard, because of their relatively recent publication date, FAIR principles had not been widely adopted explicitly in policy.",
        "article_title": "Progress in Research Data Services",
        "authors": [
            {
                "given": "Andrew M",
                "family": "Cox"
            },
            {
                "given": "Mary Anne",
                "family": "Kennan"
            },
            {
                "given": "Elizabeth Josephine",
                "family": "Lyon"
            },
            {
                "given": "Stephen",
                "family": "Pinfield"
            },
            {
                "given": "Laura",
                "family": "Sbaffi"
            }
        ],
        "publisher": "",
        "date": "2020-08-21T23:56:57.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/602",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v15i1.602",
            "id_scheme": "DOI"
        },
        "abstract": "The decision to allow users access to restricted and protected data is based on the development of trust in the user by data repositories. In this article, I propose a model of the process of trust development at restricted data repositories, a model which emphasizes the increasing levels of trust dependent on prior interactions between repositories and users. I find that repositories develop trust in their users through the interactions of four dimensions – promissory, experience, competence, and goodwill – that consider distinct types of researcher expertise and the role of a researcher’s reputation in the trust process. However, the processes used by repositories to determine a level of trust corresponding to data access are inconsistent and do not support the sharing of trusted users between repositories to maximize efficient yet secure access to restricted research data. I highlight the role of a researcher’s reputation as an important factor in trust development and trust transference, and discuss the implications of modelling the restricted data access process as a process of trust development.",
        "article_title": "Facilitating Access to Restricted Data",
        "authors": [
            {
                "given": "Allison Rae Bobyak",
                "family": "Tyler"
            }
        ],
        "publisher": "",
        "date": "2020-08-21T10:11:32.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/646",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v15i1.646",
            "id_scheme": "DOI"
        },
        "abstract": "One of the grand curation challenges is to secure metadata quality in the ever-changing environment of metadata standards and file formats. As the Red Queen tells Alice in Through the Looking-Glass: “Now, here, you see, it takes all the running you can do, to keep in the same place.” That is, there is some “running” needed to keep metadata records in a research data repository fit for long-term use and put in place. One of the main tools of adaptation and keeping pace with the evolution of new standards, formats – and versions of standards in this ever-changing environment are validation schemas. Validation schemas are mainly seen as methods of checking data quality and fitness for use, but are also important for long-term preservation. We might like to think that our present (meta)data standards and formats are made for eternity, but in reality we know that standards evolve, formats change (some even become obsolete with time), and so do our needs for storage, searching and future dissemination for re-use. Eventually, we come to a point where transformation of our archival records and migration to other formats will be necessary. This could also mean that even if the AIPs, the Archival Information Packages stay the same in storage, the DIPs, the Dissemination Information Packages that we want to extract from the archive are subject to change of format. Further, in order for archival information packages to be self-sustainable, as required in the OAIS model, it is important to take interdependencies between individual files in the information packages into account. This should be done already by the time of ingest and validation of the SIPs, the Submission Information Packages, and along the line at different points of necessary transformation/migration (from SIP to AIP, from AIP to DIP etc.), in order to counter obsolescence. This paper investigates possible validation errors and missing elements in metadata records from three general purpose, multidisciplinary research data repositories – Figshare, Harvard’s Dataverse and Zenodo, and explores the potential effects of these errors on future transformation to AIPs and migration to other formats within a digital archive.",
        "article_title": "The Red Queen in the Repository",
        "authors": [
            {
                "given": "Joakim",
                "family": "Philipson"
            }
        ],
        "publisher": "",
        "date": "2020-08-22T14:22:09.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/710",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v15i1.710",
            "id_scheme": "DOI"
        },
        "abstract": "This paper explores the tension between the tools that data reusers in the field of education prefer to use when working with qualitative video data and the tools that repositories make available to data reusers. Findings from this mixed-methods study show that data reusers utilizing qualitative video data did not use repository-based tools. Rather, they valued common, widely available tools that were collaborative and easy to use.",
        "article_title": "Tool Selection Among Qualitative Data Reusers",
        "authors": [
            {
                "given": "Rebecca D.",
                "family": "Frank"
            },
            {
                "given": "Kara",
                "family": "Suzuka"
            },
            {
                "given": "Eric",
                "family": "Johnson"
            },
            {
                "given": "Elizabeth",
                "family": "Yakel"
            }
        ],
        "publisher": "",
        "date": "2020-08-20T11:42:58.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/601",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v15i1.601",
            "id_scheme": "DOI"
        },
        "abstract": "This paper describes the development of a systematic approach to the creation, management and curation of linguistic resources, particularly spoken language corpora. It also presents first steps towards a framework for continuous quality control to be used within external research projects by non-technical users, and discuss various domain and discipline specific problems and individual solutions. The creation of spoken language corpora is not only a time-consuming and costly process, but the created resources often represent intangible cultural heritage, containing recordings of, for example, extinct languages or historical events. Since high quality resources are needed to enable re-use in as many future contexts as possible, researchers need to be provided with the necessary means for quality control. We believe that this includes methods and tools adapted to Humanities researchers as non-technical users, and that these methods and tools need to be developed to support existing tasks and goals of research projects.",
        "article_title": "Towards Continuous Quality Control for Spoken Language Corpora",
        "authors": [
            {
                "given": "Anne",
                "family": "Ferger"
            },
            {
                "given": "Hanna",
                "family": "Hedeland"
            }
        ],
        "publisher": "",
        "date": "2020-08-21T10:13:28.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    },
    {
        "url": "http://www.ijdc.net/article/view/671",
        "identifier": {
            "string_id": "https://doi.org/10.2218/ijdc.v15i1.671",
            "id_scheme": "DOI"
        },
        "abstract": "Effective data management and data sharing are crucial components of the research lifecycle, yet evidence suggests that many social science graduate programs are not providing training in these areas. The current exploratory study assesses how U.S. masters and doctoral programs in the social sciences include formal, non-formal, and informal training in data management and sharing. We conducted a survey of 150 graduate programs across six social science disciplines, and used a mix of closed and open-ended questions focused on the extent to which programs provide such training and exposure. Results from our survey suggested a deficit of formal training in both data management and data sharing, limited non-formal training, and cursory informal exposure to these topics. Utilizing the results of our survey, we conducted a syllabus analysis to further explore the formal and non-formal content of graduate programs beyond self-report. Our syllabus analysis drew from an expanded seven social science disciplines for a total of 140 programs. The syllabus analysis supported our prior findings that formal and non-formal inclusion of data management and data sharing training is not common practice. Overall, in both the survey and syllabi study we found a lack of both formal and non-formal training on data management and data sharing. Our findings have implications for data repository staff and data service professionals as they consider their methods for encouraging data sharing and prepare for the needs of data depositors. These results can also inform the development and structuring of graduate education in the social sciences, so that researchers are trained early in data management and sharing skills and are able to benefit from making their data available as early in their careers as possible.",
        "article_title": "An Exploratory Analysis of Social Science Graduate Education in Data Management and Data Sharing",
        "authors": [
            {
                "given": "Ashley",
                "family": "Doonan"
            },
            {
                "given": "Dharma",
                "family": "Akmon"
            },
            {
                "given": "Evan",
                "family": "Cosby"
            }
        ],
        "publisher": "",
        "date": "2020-08-22T14:21:20.000Z",
        "keywords": [],
        "journal_title": "",
        "volume": "",
        "issue": "",
        "ISSN": []
    }
]