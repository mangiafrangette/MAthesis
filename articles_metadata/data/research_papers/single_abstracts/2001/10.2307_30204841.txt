Classification in music analysis involves the segmentation of a music piece and the categorisation of the segments depending on similarity-based criteria. In this paper we investigate, based on a formal approach, how variations in the representation of the musical segments and in the categorisation algorithm influence the outcome of the classification. More specifically, we vary the choice of features describing each segment, the way these features are represented, and the categorisation algorithm. At the same time, we keep the other parameters, that is the overall model architecture, the music pieces, and the segmentation, fixed. We show that the choice and representation of the features, but not the specific categorisation algorithm, have a strong impact on the obtained analysis. We introduce a distance function to compare the results of algorithmic and human classification, and we show that an appropriate choice of features can yield results that are very similar to a human classification. These results allow an objective evaluation of different approaches to music classification in a uniform setting.