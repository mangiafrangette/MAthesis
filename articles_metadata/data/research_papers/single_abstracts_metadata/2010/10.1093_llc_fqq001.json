{"url": "http://dx.doi.org/10.1093/llc/fqq001", "identifier": {"string_id": "10.1093/llc/fqq001", "id_scheme": "DOI"}, "abstract": "We compare and benchmark the performance of five classification methods, four of which are taken from the machine learning literature, in a classic authorship attribution problem involving the Federalist Papers. Cross-validation results are reported for each method, and each method is further employed in classifying the disputed papers and the few papers that are generally understood to be coauthored. These tests are performed using two separate feature sets: a “raw” feature set containing all words and word bigrams that are common to all of the authors, and a second “pre-processed” feature set derived by reducing the raw feature set to include only words meeting a minimum relative frequency threshold. Each of the methods tested performed well, but nearest shrunken centroids and regularized discriminant analysis had the best overall performances with 0/70 cross-validation errors.", "article_title": "A comparative study of machine learning methods for authorship attribution", "authors": [{"given": " Matthew L.", "family": "Jockers", "affiliation": [{"original_name": "Department of English, Stanford University, Stanford, CA 94305, USA", "normalized_name": "Stanford University", "country": "United States", "identifiers": {"ror": "https://ror.org/00f54p054", "GRID": "grid.168010.e"}}]}, {"given": " Daniela M.", "family": "Witten", "affiliation": [{"original_name": "Department of Statistics, Stanford University, Stanford, CA 94305, USA", "normalized_name": "Stanford University", "country": "United States", "identifiers": {"ror": "https://ror.org/00f54p054", "GRID": "grid.168010.e"}}]}], "publisher": "Oxford University Press (OUP)", "date": "2010-04-13", "keywords": null, "journal_title": "Literary and Linguistic Computing", "volume": "25", "issue": "2", "ISSN": [{"value": "0268-1145", "type": "print"}, {"value": "1477-4615", "type": "electronic"}]}