{"url": "http://dx.doi.org/10.1093/llc/fqu061", "identifier": {"string_id": "10.1093/llc/fqu061", "id_scheme": "DOI"}, "abstract": " This article presents an approach to citation segmentation that addresses special challenges as typically found in Digital Humanities applications. We perform citation segmentation from Optical Character Recognition (OCR) input obtained from volumes of a printed bibliography, the Turkology Annual . This showcase application features serious difficulties for state-of-the-art techniques in citation segmentation: multilingual citation entries , lack of data redundancy , inconsistencies , and noise from OCR input . Our approach is based on Markov logic networks (MLN) (Richardson and Domingos, Markov logic networks. Machine Learning , 62 (1): 107–36, 2006), a framework of statistical relational learning that combines first-order logic with probabilistic modeling. Formalization in first-order logic offers high expressivity and flexibility, and makes it possible to tailor segmentation to specific conventions of a given bibliography. We show that in face of the specific difficulties found with segmenting references from a digitized bibliography, our MLN formalizations outperform state-of-the-art statistical methods. We obtain 88% F 1 -score for exact field match, a 24.8% increase over a conditional random fields-based system baseline. In contrast to prior work, we address a data set featuring sparse and noisy data. Our method extends Poon and Domingos (Joint Inference in information extraction. In Proceedings of the Twenty-Second National Conference on Artificial Intelligence . Vancouver, Canada: AAAI Press, 2007)’s approach by applying joint inference at the field level . By this move, we are able to cope with the lack of citation redundancy and noise in the data. Our approach can be characterized as knowledge-based and hence does not rely on annotated training data. The rule sets we designed can be adapted to other bibliographies, or further types of digitized sources, such as historical dictionaries or encyclopedias. ", "article_title": "Citation segmentation from sparse & noisy data: A joint inference approach with Markov logic networks", "authors": [{"given": " Dustin", "family": "Heckmann", "affiliation": [{"original_name": "Department of Computational Linguistics, Heidelberg University, Germany", "normalized_name": "Heidelberg University", "country": "Germany", "identifiers": {"ror": "https://ror.org/038t36y30", "GRID": "grid.7700.0"}}]}, {"given": " Anette", "family": "Frank", "affiliation": [{"original_name": "Department of Computational Linguistics, Heidelberg University, Germany", "normalized_name": "Heidelberg University", "country": "Germany", "identifiers": {"ror": "https://ror.org/038t36y30", "GRID": "grid.7700.0"}}]}, {"given": " Matthias", "family": "Arnold", "affiliation": [{"original_name": "Cluster of Excellence “Asia and Europe”, Heidelberg University, Germany", "normalized_name": "Heidelberg University", "country": "Germany", "identifiers": {"ror": "https://ror.org/038t36y30", "GRID": "grid.7700.0"}}]}, {"given": " Peter", "family": "Gietz", "affiliation": [{"original_name": "Cluster of Excellence “Asia and Europe”, Heidelberg University, Germany", "normalized_name": "Heidelberg University", "country": "Germany", "identifiers": {"ror": "https://ror.org/038t36y30", "GRID": "grid.7700.0"}}]}, {"given": " Christian", "family": "Roth", "affiliation": [{"original_name": "Cluster of Excellence “Asia and Europe”, Heidelberg University, Germany", "normalized_name": "Heidelberg University", "country": "Germany", "identifiers": {"ror": "https://ror.org/038t36y30", "GRID": "grid.7700.0"}}]}], "publisher": "Oxford University Press (OUP)", "date": "2014-12-10", "keywords": null, "journal_title": "Digital Scholarship in the Humanities", "volume": "31", "issue": "2", "ISSN": [{"value": "2055-7671", "type": "print"}, {"value": "2055-768X", "type": "electronic"}]}