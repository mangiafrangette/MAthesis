{"url": "http://dx.doi.org/10.2218/ijdc.v10i2.342", "identifier": {"string_id": "10.2218/ijdc.v10i2.342", "id_scheme": "DOI"}, "abstract": "As science becomes more data-intensive and collaborative, researchers increasingly use larger and more complex data to answer research questions. The capacity of storage infrastructure, the increased sophistication and deployment of sensors, the ubiquitous availability of computer clusters, the development of new analysis techniques, and larger collaborations allow researchers to address grand societal challenges in a way that is unprecedented. In parallel, research data repositories have been built to host research data in response to the requirements of sponsors that research data be publicly available. Libraries are re-inventing themselves to respond to a growing demand to manage, store, curate and preserve the data produced in the course of publicly funded research. As librarians and data managers are developing the tools and knowledge they need to meet these new expectations, they inevitably encounter conversations around Big Data. This paper explores definitions of Big Data that have coalesced in the last decade around four commonly mentioned characteristics: volume, variety, velocity, and veracity. We highlight the issues associated with each characteristic, particularly their impact on data management and curation. We use the methodological framework of the data life cycle model, assessing two models developed in the context of Big Data projects and find them lacking. We propose a Big Data life cycle model that includes activities focused on Big Data and more closely integrates curation with the research life cycle. These activities include planning, acquiring, preparing, analyzing, preserving, and discovering, with describing the data and assuring quality being an integral part of each activity. We discuss the relationship between institutional data curation repositories and new long-term data resources associated with high performance computing centers, and reproducibility in computational science. We apply this model by mapping the four characteristics of Big Data outlined above to each of the activities in the model. This mapping produces a set of questions that practitioners should be asking in a Big Data project ", "article_title": "Revisiting the Data Lifecycle with Big Data Curation", "authors": [{"given": "Line", "family": "Pouchard", "affiliation": [{"original_name": "Purdue University Libraries", "normalized_name": null, "country": null, "identifiers": {"ror": null, "GRID": null}}]}], "publisher": "Edinburgh University", "date": "2016-05-27", "keywords": null, "journal_title": "International Journal of Digital Curation", "volume": "10", "issue": "2", "ISSN": [{"value": "1746-8256", "type": "electronic"}]}