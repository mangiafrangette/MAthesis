{"url": "http://dx.doi.org/10.1093/llc/fqr050", "identifier": {"string_id": "10.1093/llc/fqr050", "id_scheme": "DOI"}, "abstract": "This article provides an account of the steps involved in adapting IBM's Languageware natural language processing software to a large corpus of highly non-standard 17th century documents. It examines the challenges encountered as part of this process, and outlines the approach adopted to provide a robust and reusable tool for the linguistic analysis of early modern source texts.", "article_title": "Natural language processing and early-modern dirty data: applying IBM Languageware to the 1641 depositions", "authors": [{"given": " Mark S.", "family": "Sweetnam", "affiliation": [{"original_name": "Department of History, School of Histories and Humanities, Trinity College Dublin", "normalized_name": "Trinity College Dublin", "country": "Ireland", "identifiers": {"ror": "https://ror.org/02tyrky19", "GRID": "grid.8217.c"}}]}, {"given": " Barbara A.", "family": "Fennell", "affiliation": [{"original_name": "School of Languages and Literature, University of Aberdeen", "normalized_name": "University of Aberdeen", "country": "United Kingdom", "identifiers": {"ror": "https://ror.org/016476m91", "GRID": "grid.7107.1"}}]}], "publisher": "Oxford University Press (OUP)", "date": "2011-12-17", "keywords": null, "journal_title": "Literary and Linguistic Computing", "volume": "27", "issue": "1", "ISSN": [{"value": "0268-1145", "type": "print"}, {"value": "1477-4615", "type": "electronic"}]}