[
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa027",
 "identifier": {
 "string_id": "10.1093/llc/fqaa027",
 "id_scheme": "DOI"
 },
 "abstract": "Local historical documents originated from daily life of people belong to special collection resources that were not published publicly. They are valuable assets of universities and libraries. At present, most documents had only finished digitalization or partial datalization work. However, the requirements of deep knowledge mining in documents data, providing visual analysis, and effectively supporting the research of historic humanities scholars had not been fully met. Taking the local historical documents project of Shanghai Jiao Tong University as an example, using relevant techniques of digital humanities (DH), the in-depth analysis and utilization research of documents data were carried out. On the one hand, the core database of the documents was established based on standardizing metadata cataloguing and establishing metadata association. On the other hand, based on the core database, an intelligent DH system platform was constructed. The platform is to realize full-field retrieval and display of the documents, text analysis, association analysis, statistics, and visual presentation of knowledge. In addition, in the process of using the platform for research, humanities scholars can continuously expand the data dimensions and the relationships between data, achieve intelligent supplementation of documents data and platform self-learning. The concept of DH has led to a new direction of database construction and platform development. In the exploration and practice of DH, libraries should continue to widen thinking, improve service and innovation capabilities, and provide better research perspectives, research environments, research support, and research experience for humanities scholars.",
 "article_title": "From collection resources to intelligent data: Construction of intelligent digital humanities platform for local historical documents of Shanghai Jiao Tong University",
 "authors": [
 {
 "given": " Yin",
 "family": "Qian",
 "affiliation": [
 {
 "original_name": "Shanghai Jiao Tong University, China",
 "normalized_name": "Shanghai Jiao Tong University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/0220qvk04",
 "GRID": "grid.16821.3c"
 }
 }
 ]
 },
 {
 "given": " Zhuoyuan",
 "family": "Xing",
 "affiliation": [
 {
 "original_name": "Shanghai Jiao Tong University, China",
 "normalized_name": "Shanghai Jiao Tong University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/0220qvk04",
 "GRID": "grid.16821.3c"
 }
 }
 ]
 },
 {
 "given": " Xiaohua",
 "family": "Shi",
 "affiliation": [
 {
 "original_name": "Shanghai Jiao Tong University, China",
 "normalized_name": "Shanghai Jiao Tong University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/0220qvk04",
 "GRID": "grid.16821.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-04-02",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa015",
 "identifier": {
 "string_id": "10.1093/llc/fqaa015",
 "id_scheme": "DOI"
 },
 "abstract": "The objective of this study is to answer the question: Do the central nodes of a social network of characters correspond with the protagonists of a theater play? To answer this question we evaluate different measures of centrality along with other textual quantitative values in relation to other manually annotated metadata on a corpus of twenty five dramatic plays of the Spanish theatre of the Silver Age (1868-1936). The found results show that centrality correlates moderately with importance, but the correlation with the textual quantitative values is stronger.",
 "article_title": "¿Existe correlación entre importancia y centralidad? Evaluación de personajes con redes sociales en obras teatrales de la Edad de Plata",
 "authors": [
 {
 "given": " María Teresa",
 "family": "Santa María",
 "affiliation": [
 {
 "original_name": "Universidad Internacional de La Rioja, Spain",
 "normalized_name": "Universidad Internacional De La Rioja",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/029gnnp81",
 "GRID": "grid.13825.3d"
 }
 }
 ]
 },
 {
 "given": " José",
 "family": "Calvo Tello",
 "affiliation": [
 {
 "original_name": "Göttingen State and University Library, Germany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Concepción María",
 "family": "Jiménez",
 "affiliation": [
 {
 "original_name": "Universidad Internacional de La Rioja, Spain",
 "normalized_name": "Universidad Internacional De La Rioja",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/029gnnp81",
 "GRID": "grid.13825.3d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-02-29",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa023",
 "identifier": {
 "string_id": "10.1093/llc/fqaa023",
 "id_scheme": "DOI"
 },
 "abstract": "Higher education operates in a quickly changing, progressively more globalized, cosmopolitan, and interconnected world (Bauman, 2000, Globalization: The Human Consequences. New York/Chichester: Columbia University Press; Appiah, 2006, Cosmopolitanism: Ethics in a World of Strangers. New York: W.W. Norton & Co; Zuckerman, 2013, Rewire: Digital Cosmopolitans in the Age of Connection. New York: W. W. Norton & Company). At the same time, substantive inequalities between people and places mean that this connectivity and knowledge is unevenly spread (Hallberg Adu, 2014, What is the opposite of a knowledge society? A critical reflection from Ghana. In Amoah, L. (ed.), Impacts of the Knowledge Society on Economic and Social Growth in Africa. IGI Global). For our students, the future leaders of this unequal world, critical reasoning becomes a key skill, and perhaps especially so for students in the Global South. This paper argues that digital humanities (DH) can provide both a theoretical framework for decolonizing the academy and technological solutions to hurdles in this process. The paper argues that assignments, their theoretical underpinnings, and implementation are key to decolonizing higher education. It describes three accessible technology-driven assignments with DH pedagogy created for diverse classrooms at Ashesi University in Ghana and discusses their outcomes.",
 "article_title": "The promise of digital humanities pedagogy: Decolonizing a diverse classroom in Ghana",
 "authors": [
 {
 "given": " Kajsa",
 "family": "Hallberg Adu",
 "affiliation": [
 {
 "original_name": "The Nordic Africa Institute, Uppsala, Sweden",
 "normalized_name": "Nordic Africa Institute",
 "country": "Sweden",
 "identifiers": {
 "ror": "https://ror.org/05q84se63",
 "GRID": "grid.451863.d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-04-08",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa025",
 "identifier": {
 "string_id": "10.1093/llc/fqaa025",
 "id_scheme": "DOI"
 },
 "abstract": "The experiences of murdered victims of Nazi persecutions perished with them. This article discusses how text and data mining technology has helped to recover fragments of these lost experiences out of 2,500 oral history interviews with survivors. This gave rise to Let them Speak, a data edition of Holocaust testimonies. The first part situates the challenge of revealing lost experiences in historiography, and argues that the experience of murdered victims can be reconstructed through the collective experience. The second part shows how text and data mining techniques assisted the author to identify some pieces of the collective experience. The third part presents how web technology and visualization are used to render pieces of the collective experience as testimonial fragments of the Holocaust. ",
 "article_title": "Recovering and rendering silenced experiences of genocides: testimonial fragments of the Holocaust",
 "authors": [
 {
 "given": " Gábor",
 "family": "Mihály Tóth",
 "affiliation": [
 {
 "original_name": "USC Shoah Foundation",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "Signal Analysis and Interpretation Laboratory (SAIL), Viterbi School of Engineering, University of Southern California, USA",
 "normalized_name": "University of Southern California",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/03taz7m60",
 "GRID": "grid.42505.36"
 }
 },
 {
 "original_name": "Yale University, Digital Humanities Laboratory and Fortunoff Video Archive for Holocaust Testimonies",
 "normalized_name": "Yale University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/03v76x132",
 "GRID": "grid.47100.32"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-04-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz092",
 "identifier": {
 "string_id": "10.1093/llc/fqz092",
 "id_scheme": "DOI"
 },
 "abstract": "The moods, feelings, and attitudes represented in a novel will resonate in the reader by activating similar sentiments. It is generally accepted that sentiment analysis can capture aspects of such moods, feelings, and attitudes and can be used to summarize a novel’s plot in a story arc. With the availability of a number of algorithms to automatically extract sentiment-based story arcs, new approaches for their utilization becomes pertinent. We propose to use nonlinear adaptive filtering and fractal analysis in order to analyze the narrative coherence and dynamic evolution of a novel. Using Never Let Me Go by Kazuo Ishiguro, the winner of the 2017 Nobel Prize for Literature as an illustrative example, we show that: (1) nonlinear adaptive filtering can extract a story arc that reflects the tragic trend of the novel; (2) the story arc displays persistent dynamics as measured by the Hurst exponent at short and medium timescales; (3) the plot’s dynamic evolution is reflected in the time-varying Hurst exponent. We argue that these findings are indicative of the potential that multifractal theory has for computational narratology and large-scale literary analysis. Specifically that the global Hurst exponent of a story arc is an index of narrative coherence that can identify bland, incoherent, and coherent narratives on a continuous scale. And, further, that the local time-varying Hurst exponent captures variation of a novel’s plot such that the extrema have specific narratological interpretations.",
 "article_title": "Dynamic evolution of sentiments in Never Let Me Go: Insights from multifractal theory and its implications for literary analysis",
 "authors": [
 {
 "given": " Qiyue",
 "family": "Hu",
 "affiliation": [
 {
 "original_name": "Center for Geodata and Analysis, Faculty of Geographical Science, Beijing Normal University, China",
 "normalized_name": "Beijing Normal University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/022k4wk35",
 "GRID": "grid.20513.35"
 }
 }
 ]
 },
 {
 "given": " Bin",
 "family": "Liu",
 "affiliation": [
 {
 "original_name": "Business School, Guangxi University, China",
 "normalized_name": "Guangxi University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/02c9qn167",
 "GRID": "grid.256609.e"
 }
 }
 ]
 },
 {
 "given": " Mads Rosendahl",
 "family": "Thomsen",
 "affiliation": [
 {
 "original_name": "School of Communication and Culture, Aarhus University, Denmark",
 "normalized_name": "Aarhus University",
 "country": "Denmark",
 "identifiers": {
 "ror": "https://ror.org/01aj84f44",
 "GRID": "grid.7048.b"
 }
 }
 ]
 },
 {
 "given": " Jianbo",
 "family": "Gao",
 "affiliation": [
 {
 "original_name": "Center for Geodata and Analysis, Faculty of Geographical Science, Beijing Normal University, China",
 "normalized_name": "Beijing Normal University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/022k4wk35",
 "GRID": "grid.20513.35"
 }
 },
 {
 "original_name": "Institute of Automation, Chinese Academy of Sciences, China and International College, Guangxi University, China",
 "normalized_name": "Guangxi University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/02c9qn167",
 "GRID": "grid.256609.e"
 }
 }
 ]
 },
 {
 "given": " Kristoffer L",
 "family": "Nielbo",
 "affiliation": [
 {
 "original_name": "Center for Humanities Computing, Aarhus University, Denmark",
 "normalized_name": "Aarhus University",
 "country": "Denmark",
 "identifiers": {
 "ror": "https://ror.org/01aj84f44",
 "GRID": "grid.7048.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-01-24",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz086",
 "identifier": {
 "string_id": "10.1093/llc/fqz086",
 "id_scheme": "DOI"
 },
 "abstract": "Situated within the debate that has taken place in the recent years on how Digital Humanities can break down barriers between countries of the Global North and South (Intersectionality in Digital Humanities Conference, 2016), and how materials in minority langauges can have presence in the network for the generation of new knowledge (Thieberger, 2017; Rodríguez-Ortega and Cruces Rodríguez, 2018), the objective of this article is to explain how (and if) digitalization and Digital Humanities can facilitate research in the Philippines, as well as make it visible, and how this can be facilitated by cooperation projects, citing the example of the project Philperiodicals, carried out by the University of Antwerp and the University of the Philippies. What opportunities and difficulties were encountered upon proposing a project with such characteristics? What problems (ethical, at times) do we encounter when subsidizing projects in the South from the North? We shall address these questions based on the current status of digitalization and Digital Humanities in the country. Lastly, we offer a series of good practices concluded from debates and experiences from the project Philperiodicals, in the hopes that our previous difficulties and discussions may be of use for the development of similar projects in what has been called the Global South. ",
 "article_title": "Humanidades Digitales en Filipinas: proyectos, dificultades y oportunidades de la colaboración Norte-Sur",
 "authors": [
 {
 "given": " Rocío",
 "family": "Ortuño Casanova",
 "affiliation": [
 {
 "original_name": "Department of Literature, Universiteit Antwerpen, Belgium",
 "normalized_name": "University of Antwerp",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/008x57b05",
 "GRID": "grid.5284.b"
 }
 }
 ]
 },
 {
 "given": " Anna",
 "family": "Sarmiento",
 "affiliation": [
 {
 "original_name": "Department of European Languages, University of the Philippines Diliman, Philippines",
 "normalized_name": "University of the Philippines Diliman",
 "country": "Philippines",
 "identifiers": {
 "ror": "https://ror.org/03tbh6y23",
 "GRID": "grid.11134.36"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-01-23",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa024",
 "identifier": {
 "string_id": "10.1093/llc/fqaa024",
 "id_scheme": "DOI"
 },
 "abstract": "This article brings current core concerns of multimodality into dialogue with approaches identified with media archaeology. I begin by considering the development of multimodality in relation to the emphasis that media archaeologists place on non-linear and parallel histories, the relativity of ‘newness’, and cyclical thinking. I then move on to consider some of the respective conceptual undergirding of multimodality and media archaeology, focussing on key issues of materiality and media specificity, signs and signals, media convergence and commensurability. I argue that this juxtaposition brings fresh perspectives to the question of ‘mode’. Significantly, these are attuned both to social and formal considerations, but in ways that differ from both social semiotic orientations and other approaches to multimodality. Having considered these fundamentals, I turn to questions of interactivity, product, and process, and the blurring of boundaries between categories such as reading and writing. As a final intersection, I bring the growing interest in integrating quantitative, corpus-based methods in multimodal analysis into dialogue with the prioritization of the digital archive as a site of specific media archaeological interest with inherent potential for algorithmic manipulation. I conclude with some observations about the status of multimodality and media archaeology as communities and, more specifically, the potential for complementarity between them.",
 "article_title": "Multimodality and media archaeology: Complementary optics for looking at digital stuff?",
 "authors": [
 {
 "given": " Martin",
 "family": "Thomas",
 "affiliation": [
 {
 "original_name": "University of Leeds, School of Languages, Cultures and Societies, Leeds, UK",
 "normalized_name": "University of Leeds",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/024mrxd33",
 "GRID": "grid.9909.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-04-02",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa021",
 "identifier": {
 "string_id": "10.1093/llc/fqaa021",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents a relational database capable of integrating data from a variety of types of written sources as well as material remains. In response to historical research questions, information from such diverse sources as documentary, bioanthropological, isotopic, and DNA analyses has been assessed, homogenized, and situated in time and space. Multidisciplinary ontologies offer complementary and integrated perspectives regarding persons and goods. While responding to specific research questions about the impact of globalization on the isthmus of Panama during the sixteenth and seventeenth centuries, the data model and user interface promote the ongoing interrogation of diverse information about complex, changing societies. To this end, the application designed makes it possible to search, consult, and download data that researchers have contributed from anywhere in the world.",
 "article_title": "The integration of heterogeneous information from diverse disciplines regarding persons and goods",
 "authors": [
 {
 "given": " Bethany",
 "family": "Aram",
 "affiliation": [
 {
 "original_name": "Department of Geography, History and Philosophy, Universidad Pablo de Olavide de Sevilla, Spain",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Aurelio",
 "family": "López Fernández",
 "affiliation": [
 {
 "original_name": "Department of Sports and Computer Science, Universidad Pablo de Olavide de Sevilla, Spain",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Daniel",
 "family": "Muñiz Amian",
 "affiliation": [
 {
 "original_name": "Department of Sports and Computer Science, Universidad Pablo de Olavide de Sevilla, Spain",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-03-26",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa017",
 "identifier": {
 "string_id": "10.1093/llc/fqaa017",
 "id_scheme": "DOI"
 },
 "abstract": "Correctness of the designed system is one of the most important issues in the software development process. Therefore, various tests have been defined and designed to help software teams develop software with little or no problem. Finding a proper link between test class and the class under the test is an important but difficult task. Finding this relation helps the developers to conduct regression tests more efficiently. In this paper, we seek to propose a model for recovering traceable links between test classes and the classes under the test. The proposed method encompasses three parts: (1) method for extracting keywords and the measure of similarity of a specific part of code, (2) backward chain method based on a rule-based system, (3) using hybrid model to find traceable links between test classes and the code under test. This study uses three open-source and one industrial source projects to conduct experiments. The results are satisfactory compared to previous studies.",
 "article_title": "Traceability mining between unit test and source code based on textual analysis applied to software systems",
 "authors": [
 {
 "given": " Amir Hossein",
 "family": "Arshia",
 "affiliation": [
 {
 "original_name": "School of Computer and Electrical Engineering, Shiraz University, Shiraz, Iran",
 "normalized_name": "Shiraz University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/028qtbk54",
 "GRID": "grid.412573.6"
 }
 }
 ]
 },
 {
 "given": " Amir Hossein",
 "family": "Rasekh",
 "affiliation": [
 {
 "original_name": "School of Computer and Electrical Engineering, Shiraz University, Shiraz, Iran",
 "normalized_name": "Shiraz University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/028qtbk54",
 "GRID": "grid.412573.6"
 }
 }
 ]
 },
 {
 "given": " Mohammad Reza",
 "family": "Moosavi",
 "affiliation": [
 {
 "original_name": "School of Computer and Electrical Engineering, Shiraz University, Shiraz, Iran",
 "normalized_name": "Shiraz University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/028qtbk54",
 "GRID": "grid.412573.6"
 }
 }
 ]
 },
 {
 "given": " Seyed Mostafa",
 "family": "Fakhrahmad",
 "affiliation": [
 {
 "original_name": "School of Computer and Electrical Engineering, Shiraz University, Shiraz, Iran",
 "normalized_name": "Shiraz University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/028qtbk54",
 "GRID": "grid.412573.6"
 }
 }
 ]
 },
 {
 "given": " Mohammad Hadi",
 "family": "Sadreddini",
 "affiliation": [
 {
 "original_name": "School of Computer and Electrical Engineering, Shiraz University, Shiraz, Iran",
 "normalized_name": "Shiraz University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/028qtbk54",
 "GRID": "grid.412573.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-03-07",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa028",
 "identifier": {
 "string_id": "10.1093/llc/fqaa028",
 "id_scheme": "DOI"
 },
 "abstract": "Building upon Walsh’s Comic Book Markup Language (CMBL) used for encoding text features of comics documents, this essay explores how CBML can be modified and expanded using additional Text Encoding Initiative (TEI) features to reflect alternative theoretical and critical approaches to comics. In doing so, this essay argues that markup languages offer not only a means for analyzing encoded documents but also a means for analyzing critical approaches to documents. Because markup language reflects the critical stance of whoever produces the encoding, any revision to the markup potentially reflects a revision to the critical theoretical framework from which the encoder operates. As such, implementation of markup language in comics studies can function not only as a metalanguage for describing comics but also as a form of meta-criticism. To this end, this essay explores methods for incorporating CBML and TEI to reflect commonly opposed approaches to analyzing comics documents.",
 "article_title": "On the use of XML markup language in comics criticism",
 "authors": [
 {
 "given": " Jacob",
 "family": "Murel",
 "affiliation": [
 {
 "original_name": "Department of English, Northeastern University, USA",
 "normalized_name": "Universidad del Noreste",
 "country": "Mexico",
 "identifiers": {
 "ror": "https://ror.org/02ahky613",
 "GRID": "grid.441462.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-04-09",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa030",
 "identifier": {
 "string_id": "10.1093/llc/fqaa030",
 "id_scheme": "DOI"
 },
 "abstract": "Complex network approach provides language research with quantitative measures that can capture global features of language. Although translational language has been recognized as a ‘third code’ by some researchers, its independence still calls for further and quantitative validation in an overall manner. In this study, we intend to examine this independence and explore comprehensively its features. We investigated macroscopically translational language from English into Chinese and from Chinese into English by comparing with its source language and native language through syntactic dependency networks. The results show that: (1) translational language presents small-world and scale-free properties like most languages do; (2) however, it is independent of and different from both source language and native language in terms of its network parameters; (3) its network parameters show values eclectic between source language and native language, and this eclectic tendency may be regarded as a new candidate for universal features of translational language, which certainly needs further validation in other genres and language pairs. This study also corroborates that quantitative linguistic method of complex network approach can be well utilized in the study of translational language.",
 "article_title": "A syntactic dependency network approach to the study of translational language",
 "authors": [
 {
 "given": " Lu",
 "family": "Fan",
 "affiliation": [
 {
 "original_name": "Foreign Languages Research Center, Xi'an Jiaotong University, P.R. China",
 "normalized_name": "Xi'an Jiaotong University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/017zhmm22",
 "GRID": "grid.43169.39"
 }
 }
 ]
 },
 {
 "given": " Yue",
 "family": "Jiang",
 "affiliation": [
 {
 "original_name": "Foreign Languages Research Center, Xi'an Jiaotong University, P.R. China",
 "normalized_name": "Xi'an Jiaotong University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/017zhmm22",
 "GRID": "grid.43169.39"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-04-29",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa018",
 "identifier": {
 "string_id": "10.1093/llc/fqaa018",
 "id_scheme": "DOI"
 },
 "abstract": "This article revisits the study of the poetry communities, sisa, in the eighteenth-century Seoul, in terms of their membership, structural patterns, and boundaries of interaction. By applying methods in the digital humanities such as social network analysis and geographical information systems, I argue that literary activities in the sisa were performed beyond the factional demarcations, and cultural leverage was determined by their positional advantage in the community structure, not imposed by the political dominance. The factional affiliations of the participants were not directly correlated with the formation of cultural identities. The poetry communities functioned as major loci of cultural textual networks in the late Chosŏn Seoul. Paying no heed to hierarchical distinction, the participants enjoyed the convivial spontaneous environments and shared their literary works with one another. Focusing on the collaborative nature of the era, many modern scholars have examined the kinship, social classes, and political orientations of the community members; furthermore, some argue that those who belonged to influential political factions also exercised their cultural influence and set mainstream literary trends. My research differs from previous contributions in its emphasis on the relational community structure and the information flow. Measuring the homogeneity, centralities, and membership, I prove that the cultural practices were much more complicated beyond the social–political system, and explain how politically marginalized people were able to gain leverage in the cultural world.",
 "article_title": "Poetry in action: Networks of literary communication and the cultural leverage in the eighteenth-century Seoul",
 "authors": [
 {
 "given": " Jamie Jungmin",
 "family": "Yoo",
 "affiliation": [
 {
 "original_name": "Institute of Humanities, Yonsei University, Seoul, Republic of Korea",
 "normalized_name": "Yonsei University",
 "country": "South Korea",
 "identifiers": {
 "ror": "https://ror.org/01wjejq96",
 "GRID": "grid.15444.30"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-03-26",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa011",
 "identifier": {
 "string_id": "10.1093/llc/fqaa011",
 "id_scheme": "DOI"
 },
 "abstract": "Using citation analysis, we consider the role of gender in citation practices in conference special issues of Digital Scholarship in the Humanities. Our examination of citations in Digital Humanities conference special issues from 2006 to 2015 demonstrates gender bias in citational practices. This bias is consistent with broader trends in citational politics across the academy more broadly but is a threat to equity and justice within the scholarly community. We further offer proposals for improving citational practices to resist gender bias. Quantifying the impact of gender on citations, we argue, is one approach to understanding gender inequalities within digital humanities communities and to generating solutions to promote the broadest representation of digital humanities scholarship in scholarly communications.",
 "article_title": "Citational politics: Quantifying the influence of gender on citation in Digital Scholarship in the Humanities",
 "authors": [
 {
 "given": " Amy E",
 "family": "Earhart",
 "affiliation": [
 {
 "original_name": "Department of English, Texas A&M University, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Roopika",
 "family": "Risam",
 "affiliation": [
 {
 "original_name": "Departments of Secondary and Higher Education and English, Salem State University, USA",
 "normalized_name": "Salem State University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/023qmza96",
 "GRID": "grid.419433.8"
 }
 }
 ]
 },
 {
 "given": " Matthew",
 "family": "Bruno",
 "affiliation": [
 {
 "original_name": "Department of English, Salem State University, USA",
 "normalized_name": "Salem State University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/023qmza96",
 "GRID": "grid.419433.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-02-19",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa033",
 "identifier": {
 "string_id": "10.1093/llc/fqaa033",
 "id_scheme": "DOI"
 },
 "abstract": "Open social scholarship highlights outreach and partnerships by emphasizing community-driven initiatives in an attempt to bridge the gap between the practices of the university and the goals of the community. Over the last few years, the Electronic Textual Cultures Lab at the University of Victoria has introduced a number of initiatives to this end, including the Open Knowledge Program and Open Scholarship Awards. In describing these initiatives, the article engages the larger framework of community engagement and public-facing scholarship. The guiding questions for this article and our work more broadly are: how can we productively put open social scholarship into practice? What type of scholarship is considered public facing? What is the best practice around co-creating knowledge in the humanities with communities that are academic-aligned or non-academic?",
 "article_title": "Open social scholarship in action",
 "authors": [
 {
 "given": " Randa",
 "family": "El Khatib",
 "affiliation": [
 {
 "original_name": "University of Victoria, Canada",
 "normalized_name": "University of Victoria",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04s5mat29",
 "GRID": "grid.143640.4"
 }
 }
 ]
 },
 {
 "given": "the Electronic Textual Cultures Lab",
 "family": null,
 "affiliation": [
 {
 "original_name": "University of Victoria, Canada",
 "normalized_name": "University of Victoria",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04s5mat29",
 "GRID": "grid.143640.4"
 }
 }
 ]
 },
 {
 "given": " Alyssa",
 "family": "Arbuckle",
 "affiliation": [
 {
 "original_name": "University of Victoria, Canada",
 "normalized_name": "University of Victoria",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04s5mat29",
 "GRID": "grid.143640.4"
 }
 }
 ]
 },
 {
 "given": "the Electronic Textual Cultures Lab",
 "family": null,
 "affiliation": [
 {
 "original_name": "University of Victoria, Canada",
 "normalized_name": "University of Victoria",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04s5mat29",
 "GRID": "grid.143640.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-06-13",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz088",
 "identifier": {
 "string_id": "10.1093/llc/fqz088",
 "id_scheme": "DOI"
 },
 "abstract": "Stylometric methods can be used to reveal similarities between texts and, combined with network analysis, to depict the stylistic relations between those texts. The research conducted here focuses on a corpus of letters written by Jacob and Wilhelm Grimm. Using stylometric analysis, we model the writing styles of the brothers depending on the addressees and chronology. The brothers have individual styles: Wilhelm has a more friendly and personal tone independent on addresses, while Jacob has a more impersonal style, unless he was writing to Wilhelm. Their styles merge at the interactions of their career or personal development.",
 "article_title": "The Grimm Brothers: A stylometric network analysis",
 "authors": [
 {
 "given": " Gabriela",
 "family": "Rotari",
 "affiliation": [
 {
 "original_name": "University of Göttingen, Germany",
 "normalized_name": "University of Göttingen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/01y9bpm73",
 "GRID": "grid.7450.6"
 }
 }
 ]
 },
 {
 "given": " Melina",
 "family": "Jander",
 "affiliation": [
 {
 "original_name": "University of Göttingen, Germany",
 "normalized_name": "University of Göttingen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/01y9bpm73",
 "GRID": "grid.7450.6"
 }
 }
 ]
 },
 {
 "given": " Jan",
 "family": "Rybicki",
 "affiliation": [
 {
 "original_name": "Jagiellonian University, Poland",
 "normalized_name": "Jagiellonian University",
 "country": "Poland",
 "identifiers": {
 "ror": "https://ror.org/03bqmcz70",
 "GRID": "grid.5522.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-12-13",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz094",
 "identifier": {
 "string_id": "10.1093/llc/fqz094",
 "id_scheme": "DOI"
 },
 "abstract": "Color preference in Chinese folksongs is examined from the perspectives of themes, ethnicity, and geographical environment. The results yield that self-organization property of language system plays the role in color use and color preference varies with theme, ethnicity, and geographical environment. Specifically, the color of white is preferred by twenty-three ethnic minorities and the color of red is much more popular among the Han. Only in love songs, the preference for white and red exhibits an approximate north and south dimension. The study shows that digital approaches related to colors in folklore are an effective and promising tool to explore human’s response to colors.",
 "article_title": "Red or white? Color in Chinese folksongs",
 "authors": [
 {
 "given": " Xiaojin",
 "family": "Zhang",
 "affiliation": [
 {
 "original_name": "Zhejiang University, China",
 "normalized_name": "Zhejiang University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/00a2xv884",
 "GRID": "grid.13402.34"
 }
 },
 {
 "original_name": "North Minzu University, China",
 "normalized_name": "North Minzu University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/05xjevr11",
 "GRID": "grid.464238.f"
 }
 }
 ]
 },
 {
 "given": " Haitao",
 "family": "Liu",
 "affiliation": [
 {
 "original_name": "Zhejiang University, China",
 "normalized_name": "Zhejiang University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/00a2xv884",
 "GRID": "grid.13402.34"
 }
 },
 {
 "original_name": "Beijing Language and Culture University China",
 "normalized_name": "Beijing Language and Culture University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/03te2zs36",
 "GRID": "grid.443257.3"
 }
 },
 {
 "original_name": "Guangdong University of Foreign Studies, China",
 "normalized_name": "Guangdong University of Foreign Studies",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/00fhc9y79",
 "GRID": "grid.440718.e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-12-18",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz091",
 "identifier": {
 "string_id": "10.1093/llc/fqz091",
 "id_scheme": "DOI"
 },
 "abstract": "Cultural heritage connects the past with the future by forming an integral part of the identities of societies. Thus, countries must protect their cultural heritage and create policies to ensure that people benefit today and pass the heritage on to future generations. Beyond physical protection in the face of globalization, increasing access to cultural heritage is necessary to ensure participation and evaluate practices from an international perspective. Advances in computer and communication technologies are being exploited for these requirements. Acquiring knowledge about and interacting with cultural objects in any part of the world today is possible through the digital humanities approach. In this study, a conceptual model was formed to increase visibility and usage of Kandilli Observatory and Earthquake Research Institute Manuscripts, the Hittite cuneiform tablets from Bogazköy, the works of Ibn Sina at the Süleymaniye Manuscript Library, Evliya Çelebi’s ‘Book of Travels’, and the Old Assyrian Merchant Archives of Kültepe registered in UNESCO’s Memory of the World List. In this model, which is prepared with the digital humanities approach, best practices applied in the field are considered as examples in the literature. Suggestions are made on how to utilize digital humanities tools to increase access and visibility by revealing the economic, social, and cultural values of the works based on the model.",
 "article_title": "A conceptual model to increase the visibility and usage of cultural heritage objects: The case of UNESCO’s Memory of the World list1",
 "authors": [
 {
 "given": " Sümeyye",
 "family": "Akça",
 "affiliation": [
 {
 "original_name": "Department of Information Management, Ardahan University, Ardahan, Turkey",
 "normalized_name": "Ardahan University",
 "country": "Turkey",
 "identifiers": {
 "ror": "https://ror.org/042ejbk14",
 "GRID": "grid.449062.d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-12-17",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa002",
 "identifier": {
 "string_id": "10.1093/llc/fqaa002",
 "id_scheme": "DOI"
 },
 "abstract": "The extraction of large amounts of multilingual parallel text from web resources is a widely used technique in natural language processing. However, automatically collected parallel corpora usually lack precise metadata, which are crucial to accurate data analysis and interpretation. The combination of automated extraction procedures and manual metadata enrichment may help address this issue. Wikipedia is a promising candidate for the exploration of the potential of said combination of methods because it is a rich source of translations in a large number of language pairs and because its open and collaborative nature makes it possible to identify and contact the users who produce translations. This article tests to what extent translated texts automatically extracted from Wikipedia by means of neural networks can be enriched with pertinent metadata through a self-submission-based user survey. Special emphasis is placed on data usefulness, defined in terms of a catalogue of previously established assessment criteria, most prominently metadata quality. The results suggest that from a quantitative perspective, the proposed methodology is capable of capturing metadata otherwise not available. At the same time, the crowd-based collection of data and metadata may face important technical and social limitations.",
 "article_title": "Automatically extracted parallel corpora enriched with highly useful metadata? A Wikipedia case study combining machine learning and social technology",
 "authors": [
 {
 "given": " Ahmad",
 "family": "Aghaebrahimian",
 "affiliation": [
 {
 "original_name": "Department of Translation Studies, University of Innsbruck, Austria",
 "normalized_name": "Universität Innsbruck",
 "country": "Austria",
 "identifiers": {
 "ror": "https://ror.org/054pv6659",
 "GRID": "grid.5771.4"
 }
 }
 ]
 },
 {
 "given": " Andy",
 "family": "Stauder",
 "affiliation": [
 {
 "original_name": "Department of Translation Studies, University of Innsbruck, Austria",
 "normalized_name": "Universität Innsbruck",
 "country": "Austria",
 "identifiers": {
 "ror": "https://ror.org/054pv6659",
 "GRID": "grid.5771.4"
 }
 }
 ]
 },
 {
 "given": " Michael",
 "family": "Ustaszewski",
 "affiliation": [
 {
 "original_name": "Department of Translation Studies, University of Innsbruck, Austria",
 "normalized_name": "Universität Innsbruck",
 "country": "Austria",
 "identifiers": {
 "ror": "https://ror.org/054pv6659",
 "GRID": "grid.5771.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-01-23",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa006",
 "identifier": {
 "string_id": "10.1093/llc/fqaa006",
 "id_scheme": "DOI"
 },
 "abstract": "Data mining, statistics, and data analysis are popular techniques to study datasets and extract knowledge from them. In this article, principal component analysis and factor analysis were applied to cluster thirteen different given arrangements about the Suras of the Holy Quran. The results showed that these thirteen arrangements can be categorized in two parts such that the first part includes Blachère, Davood, Grimm, Nöldeke, Bazargan, E’temad-al-Saltane and Muir, and the second part includes Ebn Nadim, Jaber, Ebn Abbas, Hazrat Ali, Khazan, and Al-Azhar.",
 "article_title": "Statistical approaches in literature: An application of principal component analysis and factor analysis to analyze the different arrangements about the Quran’s Suras",
 "authors": [
 {
 "given": " Yanwen",
 "family": "Wang",
 "affiliation": [
 {
 "original_name": "School of Literature, Shandong University, Jinan, Shandong Province, China",
 "normalized_name": "Shandong University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/0207yh398",
 "GRID": "grid.27255.37"
 }
 }
 ]
 },
 {
 "given": " Javad",
 "family": "Garjami",
 "affiliation": [
 {
 "original_name": "Arabic Language and Literature, Faculty of Literature and Humanities, University of Mohaghegh Ardabili, Ardabili, Iran",
 "normalized_name": "University of Mohaghegh Ardabili",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/045zrcm98",
 "GRID": "grid.413026.2"
 }
 }
 ]
 },
 {
 "given": " Milena",
 "family": "Tsvetkova",
 "affiliation": [
 {
 "original_name": "Faculty of Journalism and Mass Communication, Sofia University, Sofia, Bulgaria",
 "normalized_name": "Sofia University",
 "country": "Bulgaria",
 "identifiers": {
 "ror": "https://ror.org/02jv3k292",
 "GRID": "grid.11355.33"
 }
 }
 ]
 },
 {
 "given": " Nguyen",
 "family": "Huu Hau",
 "affiliation": [
 {
 "original_name": "Department of Training Management, Hong Duc University, Thanh Hoa City, Vietnam",
 "normalized_name": "Hồng Đức University",
 "country": "Vietnam",
 "identifiers": {
 "ror": "https://ror.org/05dp8mg49",
 "GRID": "grid.444885.1"
 }
 }
 ]
 },
 {
 "given": " Kim-Hung",
 "family": "Pho",
 "affiliation": [
 {
 "original_name": "Fractional Calculus, Optimization and Algebra Research Group, Faculty of Mathematics and Statistics, Ton Duc Thang University, Ho Chi Minh City, Vietnam",
 "normalized_name": "Ton Duc Thang University",
 "country": "Vietnam",
 "identifiers": {
 "ror": "https://ror.org/01drq0835",
 "GRID": "grid.444812.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-01-29",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa005",
 "identifier": {
 "string_id": "10.1093/llc/fqaa005",
 "id_scheme": "DOI"
 },
 "abstract": "The aim of this article was to investigate the influence of medical discourse of the turn of the nineteenth and the twentieth centuries through a case study of dramatic works of the Polish modernism. It was based on a detailed analysis of ninety plays randomly selected out of all performances staged between 1890 and 1913 at two major theatres from Krakow and Warsaw. The author analysed the ways of dramatizing symptoms of hysteria and compared the language used in describing disorders in female and male characters, combining quantitative and qualitative methods of text analysis. Almost all the plays included the symptoms of hysteria; most of them presented characters prone to hysteria. The number of symptoms and hysterical characters increased in periods when new medical theories had gained popularity. The image of hysteria that emerges from the surveyed works both defied the stereotype of hysteria as a specifically feminine illness and confirmed these stereotypes. Dramatic works could have played an important role in the process of popularizing hysteria.",
 "article_title": "The art of nerves: A quantitative and qualitative analysis of drama at the turn of nineteenth and twentieth century",
 "authors": [
 {
 "given": " Agnieszka",
 "family": "Karlińska",
 "affiliation": [
 {
 "original_name": "Institute of Sociology, University of Warsaw, Poland",
 "normalized_name": "University of Warsaw",
 "country": "Poland",
 "identifiers": {
 "ror": "https://ror.org/039bjqg32",
 "GRID": "grid.12847.38"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-01-28",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa008",
 "identifier": {
 "string_id": "10.1093/llc/fqaa008",
 "id_scheme": "DOI"
 },
 "abstract": "This article examines the impact of the digital humanities on information science and information scientists and how information scientists can contribute to digital collaborations in the digital humanities. This article uses three basic concepts—user-researcher, digital information system, and digital research object—as the framework for a description of the digital humanities shift and discusses the consequences of this shift for information science with reference to these concepts. The second part of the article investigates the two pillars of the digital humanities shift, acknowledgement of digital structure and the exploring mind, in more detail. In the case of correspondences, acknowledgement of digital structure involves respecting the ‘thing-like’ properties of letters that cannot be handled (searched, classified, etc.) unless they are translated into digitized metadata; this elevates metadata to genuine digital research objects. These theoretical issues are illustrated by the Prior archive, a collection of digitized letters, manuscript drafts, and other ‘grey’ material bequeathed from the New Zealand logician-philosopher Arthur Norman Prior. The concept of the ‘exploring mind’ is connected to a movement in information science, away from the needful user and information gap paradigm towards more open and exploratory information behaviour in the digital humanities. A concluding literature review examines selected works of information science that deals with non-standard, serendipitous information behaviour and identifies exploratory and serendipitous design features of information systems for the digital humanities. These features are represented in a taxonomy consisting of six design categories.",
 "article_title": "‘Attention, attention, exploring minds acknowledge digital structure!’ The shift to digital humanities has happened, so what should information scientists do in response?",
 "authors": [
 {
 "given": " Volkmar P",
 "family": "Engerer",
 "affiliation": [
 {
 "original_name": "Department of Communication, University of Copenhagen, Copenhagen, Denmark",
 "normalized_name": "University of Copenhagen",
 "country": "Denmark",
 "identifiers": {
 "ror": "https://ror.org/035b05819",
 "GRID": "grid.5254.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-01-31",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa007",
 "identifier": {
 "string_id": "10.1093/llc/fqaa007",
 "id_scheme": "DOI"
 },
 "abstract": "Computing machines allow quantitative analysis of large databases of text, providing knowledge that is difficult to obtain without using automation. This article describes Universal Data Analysis of Text (UDAT) —a text analysis method that extracts a large set of numerical text content descriptors from text files and performs various pattern recognition tasks such as classification, similarity between classes, correlation between text and numerical values, and query by example. Unlike several previously proposed methods, UDAT is not based on frequency of words and links between certain key words and topics. The method is implemented as an open-source software tool that can provide detailed reports about the quantitative analysis of sets of text files, as well as exporting the numerical text content descriptors in the form of comma-separated values files to allow statistical or pattern recognition analysis with external tools. It also allows the identification of specific text descriptors that differentiate between classes or correlate with numerical values and can be applied to problems related to knowledge discovery in domains such as literature and social media. UDAT is implemented as a command-line tool that runs in Windows, and the open source is available and can be compiled in Linux systems. UDAT can be downloaded from http://people.cs.ksu.edu/∼lshamir/downloads/udat.",
 "article_title": "UDAT: Compound quantitative analysis of text using machine learning",
 "authors": [
 {
 "given": " Lior",
 "family": "Shamir",
 "affiliation": [
 {
 "original_name": "Kansas State University, USA",
 "normalized_name": "Kansas State University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05p1j8758",
 "GRID": "grid.36567.31"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-01-30",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz048",
 "identifier": {
 "string_id": "10.1093/llc/fqz048",
 "id_scheme": "DOI"
 },
 "abstract": "Word sense disambiguation (WSD) is the task of selecting correct sense for an ambiguous word in its context. Since WSD is one of the most challenging tasks in various text processing systems, improving its accuracy can be very beneficial. In this article, we propose a new unsupervised method based on co-occurrence graph created by monolingual corpus without any dependency on the structure and properties of the language itself. In the proposed method, the context of an ambiguous word is represented as a sub-graph extracted from a large word co-occurrence graph built based on a corpus. Most of the words are connected in this graph. To clarify the exact sense of an ambiguous word, its senses and relations are added to the context graph, and various similarity functions are employed based on the senses and context graph. In the disambiguation process, we select senses with highest similarity to the context graph. As opposite to other WSD methods, the proposed method does not use any language-dependent resources (e.g. WordNet) and it just uses a monolingual corpus. Therefore, the proposed method can be employed for other languages. Moreover, by increasing the size of corpus, it is possible to enhance the accuracy of WSD. Experimental results on English and Persian datasets show that the proposed method is competitive with existing supervised and unsupervised WSD approaches.",
 "article_title": "Co-occurrence graph-based context adaptation: a new unsupervised approach to word sense disambiguation",
 "authors": [
 {
 "given": " Saeed",
 "family": "Rahmani",
 "affiliation": [
 {
 "original_name": "Computer Science and Engineering Department, Shiraz University, Shiraz, Iran",
 "normalized_name": "Shiraz University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/028qtbk54",
 "GRID": "grid.412573.6"
 }
 }
 ]
 },
 {
 "given": " Seyed Mostafa",
 "family": "Fakhrahmad",
 "affiliation": [
 {
 "original_name": "Computer Science and Engineering Department, Shiraz University, Shiraz, Iran",
 "normalized_name": "Shiraz University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/028qtbk54",
 "GRID": "grid.412573.6"
 }
 }
 ]
 },
 {
 "given": " Mohammad Hadi",
 "family": "Sadreddini",
 "affiliation": [
 {
 "original_name": "Computer Science and Engineering Department, Shiraz University, Shiraz, Iran",
 "normalized_name": "Shiraz University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/028qtbk54",
 "GRID": "grid.412573.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-06-29",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa009",
 "identifier": {
 "string_id": "10.1093/llc/fqaa009",
 "id_scheme": "DOI"
 },
 "abstract": "By incorporating computational methods into reading literary texts, this study examines the literary implications of the ‘vocabulary density’ and frequency of nouns and adjectives in T. S. Eliot’s poetry. This study analyzes 4,689,655 words from forty-seven poets available on Project Gutenberg, a catalog spanning from the eighteenth century to the early twentieth century. The data illustrate both the continuity and discontinuity found in English and American poetry dependent on conventional divisions between literary movements: eighteenth century, Romanticism, Imagism, and Modernism. The findings shed light on the similarities and differences between Eliot’s poetry and others’, particularly in terms of Franco Moretti’s concept of ‘modern epic’ and his methodology of ‘distant reading’. Through this combined quantitative and qualitative research, this article ultimately upholds the notion that the linguistic distinction of Eliot’s high modernist poetry lies, by and large, in his use of invented and equivocal words that reflects and represents an artistic response to modern human, cultural, social conditions, and experiment with poetic diction and polyphonic voice in the early twentieth century.",
 "article_title": "Implications of vocabulary density for poetry: Reading T. S. Eliot’s poetry through computational methods",
 "authors": [
 {
 "given": " Seonghoon",
 "family": "Kim",
 "affiliation": [
 {
 "original_name": "Department of English Language and Literature, Chonnam National University, Republic of Korea",
 "normalized_name": "Chonnam National University",
 "country": "South Korea",
 "identifiers": {
 "ror": "https://ror.org/05kzjxq56",
 "GRID": "grid.14005.30"
 }
 }
 ]
 },
 {
 "given": " Jin-young",
 "family": "Tak",
 "affiliation": [
 {
 "original_name": "Department of English Language and Literature, Sejong University, Republic of Korea",
 "normalized_name": "Sejong University",
 "country": "South Korea",
 "identifiers": {
 "ror": "https://ror.org/00aft1q37",
 "GRID": "grid.263333.4"
 }
 }
 ]
 },
 {
 "given": " Eun Joo",
 "family": "Kwak",
 "affiliation": [
 {
 "original_name": "Department of English Language and Literature, Sejong University, Republic of Korea",
 "normalized_name": "Sejong University",
 "country": "South Korea",
 "identifiers": {
 "ror": "https://ror.org/00aft1q37",
 "GRID": "grid.263333.4"
 }
 }
 ]
 },
 {
 "given": " Tae Yun",
 "family": "Lim",
 "affiliation": [
 {
 "original_name": "Department of English Language and Literature, Hongik University, Republic of Korea",
 "normalized_name": "Hongik University",
 "country": "South Korea",
 "identifiers": {
 "ror": "https://ror.org/00egdv862",
 "GRID": "grid.412172.3"
 }
 }
 ]
 },
 {
 "given": " Shin Haeng",
 "family": "Lee",
 "affiliation": [
 {
 "original_name": "School of Media and Communication, Chung-Ang University, Republic of Korea",
 "normalized_name": "Chung-Ang University",
 "country": "South Korea",
 "identifiers": {
 "ror": "https://ror.org/01r024a98",
 "GRID": "grid.254224.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-02-15",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa016",
 "identifier": {
 "string_id": "10.1093/llc/fqaa016",
 "id_scheme": "DOI"
 },
 "abstract": "Recently, with an increasing number of metaphor studies being conducted, research on metaphor interpretation has set off an upsurge. Although a multitude of studies on the interpretation of metaphors exists, many are limited to the understanding of literal meanings without attempting an interpretation of hidden emotions in metaphorical expressions. There are particularly few studies on metaphorical emotions interpretation in literary studies with rich and implicit emotions, such as classical Chinese poetry. This study proposes the interpretation of the metaphorical emotions of special objects in Chinese poetry based on emotion distribution. We present a statistical approach to calculate the emotion distribution of our target objects by exploiting contextual emotion mining. According to the emotion distribution, the emotion with the highest probability is considered the metaphorical emotion of the target object. Subsequently, the metaphorical emotion can be determined as a positive or negative sentiment based on expert annotations. Using the proposed method, we have tested two representative objects, ‘月’ (moon) and ‘风’ (wind), and the accuracy performances were 84% and 83.33%, respectively, for sentiment detection and 66% and 70% for emotion-specific metaphorical interpretation. The results demonstrate that our approach can be used to assist readers with metaphorical emotional understanding in Chinese poetry.",
 "article_title": "Interpretation of metaphors in Chinese poetry: Where did Li Bai place his emotions?",
 "authors": [
 {
 "given": " Ciyuan",
 "family": "Peng",
 "affiliation": [
 {
 "original_name": "Knowledge Engineering Laboratory, Department of Computer Engineering, Chung-Ang University, Seoul, Korea",
 "normalized_name": "Chung-Ang University",
 "country": "South Korea",
 "identifiers": {
 "ror": "https://ror.org/01r024a98",
 "GRID": "grid.254224.7"
 }
 }
 ]
 },
 {
 "given": " Jason J",
 "family": "Jung",
 "affiliation": [
 {
 "original_name": "Knowledge Engineering Laboratory, Department of Computer Engineering, Chung-Ang University, Seoul, Korea",
 "normalized_name": "Chung-Ang University",
 "country": "South Korea",
 "identifiers": {
 "ror": "https://ror.org/01r024a98",
 "GRID": "grid.254224.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-02-28",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa010",
 "identifier": {
 "string_id": "10.1093/llc/fqaa010",
 "id_scheme": "DOI"
 },
 "abstract": "Following Dr Barber’s unfortunate criticism (Barber, 2018, Marlowe and overreaching: a misuse of stylometry. Digital Scholarship in the Humanities, 34:1–12), in which she, with an obvious lack of familiarity with them, subjected the Rolling Delta procedures used, to the caveats of Delta and traditional stylometry, this article makes use of an extended methodological framework and applies Rolling Delta to the target texts with a totality of reference texts. The outcome is different from the expected, since the author of Tamburlaine 1 and 2 emerges as stylistically also dominant in the anonymous play The Tragedy of Locrine, in Kyd’s closet play Cornelia, in Peele’s The Battle of Alcazar and David and Bethsabe. In contrast, the official Marlowe corpus relates stylistically to contemporary authors, but not to the two Tamburlaines. Traditional scholarship and learning do not refute conjectures of misattributed Peele plays and there are also strong indications that plays associated with Lord Strange’s Men nominally became Marlowe plays when Henslowe acquired them in 1594 for his Admiral’s Men and printers made use of the cult of personality, in which the author’s death became an important factor in the marketing of printed playbooks. Otherwise, there is no documentary and empirical evidence that Marlowe wrote the plays in question. The canonization of the plays occurred only in the nineteenth century, and the Marlowe we have inherited—the poet, spy, atheist, homosexual, and so on—is almost entirely an invention of the twentieth century (Hooks, 2018, Making Marlowe. In Melnikoff, K. and Knutson, R. (eds), Christopher Marlowe, Theatrical Commerce, and the Book Trade. Cambridge: University Press, p. 98).",
 "article_title": "The Marlowe corpus revisited",
 "authors": [
 {
 "given": " Hartmut",
 "family": "Ilsemann",
 "affiliation": [
 {
 "original_name": "English Department, Leibniz Universität Hannover, Germany",
 "normalized_name": "University of Hannover",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/0304hq317",
 "GRID": "grid.9122.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-02-14",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa022",
 "identifier": {
 "string_id": "10.1093/llc/fqaa022",
 "id_scheme": "DOI"
 },
 "abstract": "Although most would agree that the future of the scholarly edition lies in the digital medium, it is the print scholarly edition that is still more often cited and read. The production of digital scholarly editions (DSEs) is still seen as an experimental field whose methodology has not yet settled to the extent that a digital editing project can be approached with the same confidence as the making of a print edition. This article describes an experimental conversion of a print scholarly edition—Giacomo Leopardi’s Idilli by Paola Italia (2008)—into a DSE. This posed a challenge due to the complexity of its internal evidence, but was also relatively short and suitable for an experimental edition. Our objective was to assimilate into a web-based DSE all the information contained in the text and apparatus of the print edition. We also sought to discover whether the making of a DSE today that could fully utilize the affordances of the web, would necessarily place a significant technical load on editors who are more accustomed to solving textual problems. We review briefly a number of generic tools for making DSEs and describe two attempts at making our own DSE of Leopardi’s Idilli: a wiki edition whose primary purpose was pedagogical and a DSE based on the software used to make the Charles Harpur Critical Archive (Eggert, 2019, Charles Harpur Critical Archive. http://charles-harpur.org). We compare these experiences and draw conclusions about the prospects of making DSEs today.",
 "article_title": "From print to digital: A web edition of Giacomo Leopardi’s Idilli",
 "authors": [
 {
 "given": " Milena",
 "family": "Giuffrida",
 "affiliation": [
 {
 "original_name": "University of Catania, Italy",
 "normalized_name": "University of Catania",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/03a64bh57",
 "GRID": "grid.8158.4"
 }
 }
 ]
 },
 {
 "given": " Paola",
 "family": "Italia",
 "affiliation": [
 {
 "original_name": "University of Bologna, Italy",
 "normalized_name": "University of Bologna",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/01111rn36",
 "GRID": "grid.6292.f"
 }
 }
 ]
 },
 {
 "given": " Simone",
 "family": "Nieddu",
 "affiliation": [
 {
 "original_name": "Sapienza University of Rome, Italy",
 "normalized_name": "Sapienza University of Rome",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/02be6w209",
 "GRID": "grid.7841.a"
 }
 }
 ]
 },
 {
 "given": " Desmond",
 "family": "Schmidt",
 "affiliation": [
 {
 "original_name": "Charles Harpur Critical Archive",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-04-08",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz096",
 "identifier": {
 "string_id": "10.1093/llc/fqz096",
 "id_scheme": "DOI"
 },
 "abstract": "Deep neural networks have been widely used in various language processing tasks. Recurrent neural networks (RNNs) and convolutional neural networks (CNN) are two common types of neural networks that have a successful history in capturing temporal and spatial features of texts. By using RNN, we can encode input text to a lower space of semantic features while considering the sequential behavior of words. By using CNN, we can transfer the representation of input text to a flat structure to be used for classifying text. In this article, we proposed a novel recurrent CNN model to capture not only the temporal but also the spatial features of the input poem/verse to be used for poet identification. Considering the shortcomings of the normal RNNs, we try both long short-term memory and gated recurrent unit units in the proposed architecture and apply them to the poet identification task. There are a large number of poems in the history of literature whose poets are unknown. Considering the importance of the task in the information processing field, a great variety of methods from traditional learning models, such as support vector machine and logistic regression, to deep neural network models, such as CNN, have been proposed to address this problem. Our experiments show that the proposed model significantly outperforms the state-of-the-art models for poet identification by receiving either a poem or a single verse as input. In comparison to the state-of-the-art CNN model, we achieved 9% and 4% improvements in f-measure for poem- and verse-based tasks, respectively.",
 "article_title": "Recurrent convolutional neural networks for poet identification",
 "authors": [
 {
 "given": " Dariush",
 "family": "Salami",
 "affiliation": [
 {
 "original_name": "Department of Communication and Networking, School of Electrical Engineering, Aalto University, Finland",
 "normalized_name": "Aalto University",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/020hwjq30",
 "GRID": "grid.5373.2"
 }
 }
 ]
 },
 {
 "given": " Saeedeh",
 "family": "Momtazi",
 "affiliation": [
 {
 "original_name": "Computer Engineering Department, Amirkabir University of Technology, Tehran, Iran",
 "normalized_name": "Amirkabir University of Technology",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/04gzbav43",
 "GRID": "grid.411368.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-12-18",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa014",
 "identifier": {
 "string_id": "10.1093/llc/fqaa014",
 "id_scheme": "DOI"
 },
 "abstract": "This article investigates the collocational behavior of English modal auxiliaries such as may and might with the aim of finding corpus-based measures that distinguish between different modal expressions and that allow insights into why speakers may choose one over another in a given context. The analysis uses token-based semantic vector space modeling (Heylen et al., 2015, Monitoring polysemy. Word space models as a tool for large-scale lexical semantic analysis. Lingua, 157: 153–72; Hilpert and Correia Saavedra, 2017, Using token-based semantic vector spaces for corpus-linguistic analyses: From practical applications to tests of theoretical claims. Corpus Linguistics and Linguistic Theory) in order to determine whether different modal auxiliaries can be distinguished in terms of their collocational profiles. The analysis further examines whether different senses of the same auxiliary exhibit divergent collocational preferences. The results indicate that near-synonymous pairs of modal expressions, such as may and might or must and have to, differ in their distributional characteristics. Also, different senses of the same modal expression, such as deontic and epistemic uses of may, can be distinguished on the basis of distributional information. We discuss these results against the background of previous empirical findings (Hilpert, 2016, Construction Grammar and its Application to English, 2nd edn. Edinburgh: Edinburgh University Press, Flach, in press, Beyond modal idioms and modal harmony: a corpus-based analysis of gradient idiomaticity in modal-adverb collocations. English Language and Linguistics) and theoretical issues such as degrees of grammaticalization (Correia Saavedra, 2019, Measurements of Grammaticalization: Developing a Quantitative Index for the Study of Grammatical Change. PhD Dissertation, Université de Neuchâtel) and the avoidance of synonymy (Bolinger, 1968, Entailment and the meaning of structures. Glossa, 2(2): 119–27).",
 "article_title": "Disentangling modal meanings with distributional semantics",
 "authors": [
 {
 "given": " Martin",
 "family": "Hilpert",
 "affiliation": [
 {
 "original_name": "Department of English, Université de Neuchâtel, Neuchâtel, Switzerland",
 "normalized_name": "University of Neuchâtel",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/00vasag41",
 "GRID": "grid.10711.36"
 }
 }
 ]
 },
 {
 "given": " Susanne",
 "family": "Flach",
 "affiliation": [
 {
 "original_name": "Department of English, Université de Neuchâtel, Neuchâtel, Switzerland",
 "normalized_name": "University of Neuchâtel",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/00vasag41",
 "GRID": "grid.10711.36"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-02-28",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqaa019",
 "identifier": {
 "string_id": "10.1093/llc/fqaa019",
 "id_scheme": "DOI"
 },
 "abstract": "The growing amount of openly available research data enables various possibilities of reuse. Data can be analyzed, visualized, or even further processed, enriched, and combined with other sources to enable new research questions and a different view on the material. Several catalogues and research tools aggregate collections on specific topics to make them searchable and reusable. To be able to bring together different collections, a common data standard is necessary. This article discusses how semantic web technologies can be used to connect digital as well as analogue music catalogues and music editions. The article first discusses how music can be searched using its characteristic melody and presents the approach of the open-source search engine for music incipits, IncipitSearch. Subsequently, the advantages of semantic web standards for musicology are highlighted. Then, the underlying RDF- and schema.org-based metadata standard, which is used to aggregate and distribute the data, is discussed. The article concludes with an outlook on research perspectives for digital musicology and musicology in general.",
 "article_title": "Interconnecting music repositories with semantic web technologies—an RDF- and schema.org-based approach",
 "authors": [
 {
 "given": " Anna",
 "family": "Neovesky",
 "affiliation": [
 {
 "original_name": "Academy of Sciences and Literature, Mainz, Germany",
 "normalized_name": "Academy of Sciences and Literature",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/01kdxra28",
 "GRID": "grid.461597.8"
 }
 }
 ]
 },
 {
 "given": " Frederic",
 "family": "von Vlahovits",
 "affiliation": [
 {
 "original_name": "Academy of Sciences and Literature, Mainz, Germany",
 "normalized_name": "Academy of Sciences and Literature",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/01kdxra28",
 "GRID": "grid.461597.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2020-03-25",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz070",
 "identifier": {
 "string_id": "10.1093/llc/fqz070",
 "id_scheme": "DOI"
 },
 "abstract": "How to classify short texts effectively remains an important question in computational stylometry. This study presents the results of an experiment involving authorship attribution of ancient Greek texts. These texts were chosen to explore the effectiveness of digital methods as a supplement to the author’s work on text classification based on traditional stylometry. Here it is crucial to avoid confounding effects of shared topic, etc. Therefore, this study attempts to identify authorship using only morpho-syntactic data without regard to specific vocabulary items. The data are taken from the dependency annotations published in the Ancient Greek and Latin Dependency Treebank. The independent variables for classification are combinations generated from the dependency label and the morphology of each word in the corpus and its dependency parent. To avoid the effects of the combinatorial explosion, only the most frequent combinations are retained as input features. The authorship classification (with thirteen classes) is done with standard algorithms—logistic regression and support vector classification. During classification, the corpus is partitioned into increasingly smaller ‘texts’. To explore and control for the possible confounding effects of, e.g. different genre and annotator, three corpora were tested: a mixed corpus of several genres of both prose and verse, a corpus of prose including oratory, history, and essay, and a corpus restricted to narrative history. Results are surprisingly good as compared to those previously published. Accuracy for fifty-word inputs is 84.2–89.6%. Thus, this approach may prove an important addition to the prevailing methods for small text classification.",
 "article_title": "Author identification of short texts using dependency treebanks without vocabulary",
 "authors": [
 {
 "given": " Robert",
 "family": "Gorman",
 "affiliation": [
 {
 "original_name": "Classics & Religious Studies, University of Nebraska-Lincoln, Lincoln, Nebraska, USA",
 "normalized_name": "University of Nebraska–Lincoln",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/043mer456",
 "GRID": "grid.24434.35"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-10-09",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz076",
 "identifier": {
 "string_id": "10.1093/llc/fqz076",
 "id_scheme": "DOI"
 },
 "abstract": "An empirical study on about 1.7 million dictionary words from seven languages viz. English, French, Dutch, Spanish, Italian, Hindi, and German has been conducted. Three intriguing characteristic features have been analyzed. First, the alphabet usage pattern in a language was determined which can be used to give an idea on how alphabets have been employed. For instance, the alphabet ‘e’ is highly used in English, while ‘q’ is least used. Second, the average and range of word lengths in the languages were computed and seen to vary from 1 to 37. Average word lengths were computed in the range (6.665–11.14). For comparison, word lengths have been fitted using Gaussian distribution. Third, a new measure was derived; which we termed ‘Language Sparsity’; computed as one minus ratio of number of words of a particular length already existing to the total number of possible words that can be formed. Sparsity hence gives a measure of the scope of fruition in languages. Two such measures have been defined: a weighted and a nonweighted sparsity. Nonweighted sparsity was found to be minimum (0.877) for English and maximum (0.982) for Dutch. The results obtained can play a significant role in propagating the synergy of language evolution.",
 "article_title": "Alphabet usage pattern, word lengths, and sparsity in seven Indo-European languages",
 "authors": [
 {
 "given": " Nikhil Kumar",
 "family": "Rajput",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, Ramanujan College, New Delhi, India",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Bhavya",
 "family": "Ahuja",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, Ramanujan College, New Delhi, India",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Manoj Kumar",
 "family": "Riyal",
 "affiliation": [
 {
 "original_name": "VCSG Uttarakhand University of Horticulture and Forestry, Tehri Garhwal, India",
 "normalized_name": "Veer Chandra Singh Garhwali Uttarakhand University of Horticulture & Forestry",
 "country": "India",
 "identifiers": {
 "ror": "https://ror.org/00sfe1713",
 "GRID": "grid.506070.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-10-03",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz074",
 "identifier": {
 "string_id": "10.1093/llc/fqz074",
 "id_scheme": "DOI"
 },
 "abstract": "This study examines whether a qualitative analysis of news headlines produces complementary, convergent, or dissonant findings with a quantitative analysis of the full news story. Headlines are among the most important parts of a news story and its summary. This study investigates the construction of Qaddafi in the headlines of two newspapers before and during the 2011 Libyan civil war. This is based on a sub-corpus of headlines that was taken from a 6.5-million-word corpus of two newspapers; one published in English; The Guardian, and the other in Arabic; Asharq Al-Awsat from 2009 to 2011. The analysis of the headlines has produced complementary and convergent findings with the corpus analysis and suggests that the 2011 Libyan civil war represents a turning point on how Qaddafi is represented in the investigated newspapers. This study concludes that analysing headlines proves to be a good down-sampling option to reduce large news corpora to a workable amount of data.",
 "article_title": "Analysing headlines as a way of downsizing news corpora: Evidence from an Arabic–English comparable corpus of newspaper articles",
 "authors": [
 {
 "given": " Ahmad S",
 "family": "Haider",
 "affiliation": [
 {
 "original_name": "Department of English Language and Translation, Applied Science Private University, Amman 11192, Jordan",
 "normalized_name": "Applied Science Private University",
 "country": "Jordan",
 "identifiers": {
 "ror": "https://ror.org/01ah6nb52",
 "GRID": "grid.411423.1"
 }
 }
 ]
 },
 {
 "given": " Riyad F",
 "family": "Hussein",
 "affiliation": [
 {
 "original_name": "Department of English Language and Translation, Applied Science Private University, Amman 11192, Jordan",
 "normalized_name": "Applied Science Private University",
 "country": "Jordan",
 "identifiers": {
 "ror": "https://ror.org/01ah6nb52",
 "GRID": "grid.411423.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-10-01",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz073",
 "identifier": {
 "string_id": "10.1093/llc/fqz073",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents a digitally assisted mode of close listening as an innovative way of analysing poetry, through the implementation of a recently developed web-based tool called Visualising Voice, initially conceived to facilitate performance studies of French poetry. This article begins by establishing the status of close listening practices and their importance as a means of studying poetry in French, as well as considering the possibilities afforded by applying these practices to studying poetry in other languages. It then goes on to examine how the Visualising Voice tool can be applied to case studies of two poems—Charles Baudelaire’s ‘L’Albatros’ (‘The Albatross’) and Paul Verlaine’s ‘Green’—each performed by three different speakers. This article argues that close listening using the Visualising Voice tool reveals subtle differences in the handling of metrical features and differences in performance styles of the same poem, which would be unlikely to be perceived by traditional listening methods. This article thus contends that close listening practices not only take the study of poetry beyond traditional modes of textual analysis but also that facilitating these practices through digital methodologies—such as those offered by the Visualising Voice tool—can transform the way in which poetry is read and understood beyond the academic sphere, in particular by general and younger audiences.",
 "article_title": "Visualising Voice: Analysing spoken recordings of nineteenth-century French poetry",
 "authors": [
 {
 "given": " Caroline",
 "family": "Ardrey",
 "affiliation": [
 {
 "original_name": "Department of Modern Languages, University of Birmingham, Edgbaston, Birmingham, UK",
 "normalized_name": "University of Birmingham",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/03angcq70",
 "GRID": "grid.6572.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-10-04",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz060",
 "identifier": {
 "string_id": "10.1093/llc/fqz060",
 "id_scheme": "DOI"
 },
 "abstract": "I model a critical posthumanist pedagogy that uses text analysis software and is aimed at higher education students. A key purpose of the pedagogy is to help students enhance empathetic, critical and independent thinking. For their project assignment, the student chooses an unfamiliar campaign seeking to eliminate suffering and extend rights. They gather all texts from the campaign website into a corpus, which thus represents the campaign writ large. Then they use appropriate software to ascertain, efficiently and rigorously, common campaign concerns across this corpus. This puts students in a position to discern any significant concerns in the campaign corpus that are not addressed in text(s) supporting the status quo which the campaign opposes. Should significant omissions be found, students critically evaluate the status quo text(s) from the campaign’s perspective. Since this perspective derives from the student identifying (at least temporarily) with software generated data, it is a posthuman subjectivity. Engaging digitally and empathetically with a campaign’s data at scale for creation of a posthuman subjectivity can broaden awareness of disadvantage, discrimination, and suffering as well as expand horizons. Moreover, at the end of the assignment, the student is expected to formulate their own position vis-à-vis the previously unfamiliar campaign. Conditions have been created then for the student to enhance independent thinking too.",
 "article_title": "A posthumanist pedagogy using digital text analysis to enhance critical thinking in higher education",
 "authors": [
 {
 "given": " Kieran",
 "family": "O'Halloran",
 "affiliation": [
 {
 "original_name": "School of Education, Communication and Society, King's College London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-08-23",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz083",
 "identifier": {
 "string_id": "10.1093/llc/fqz083",
 "id_scheme": "DOI"
 },
 "abstract": "Cultural data and information on the web are continuously increasing, evolving, and reshaping in the form of big data due to globalization, digitization, and its vast exploration, with common people realizing the importance of ancient values. Therefore, before it becomes unwieldy and too complex to manage, its integration in the form of big data repositories is essential. This article analyzes the complexity of the growing cultural data and presents a Cultural Big Data Repository as an efficient way to store and retrieve cultural big data. The repository is highly scalable and provides integrated high-performance methods for big data analytics in cultural heritage. Experimental results demonstrate that the proposed repository outperforms in terms of space as well as storage and retrieval time of Cultural Big Data.",
 "article_title": "CBDR: An efficient storage repository for cultural big data",
 "authors": [
 {
 "given": " Seemu",
 "family": "Sharma",
 "affiliation": [
 {
 "original_name": "Thapar Institute of Engineering and Technology, India",
 "normalized_name": "Thapar University",
 "country": "India",
 "identifiers": {
 "ror": "https://ror.org/00wdq3744",
 "GRID": "grid.412436.6"
 }
 }
 ]
 },
 {
 "given": " Seema",
 "family": "Bawa",
 "affiliation": [
 {
 "original_name": "Thapar Institute of Engineering and Technology, India",
 "normalized_name": "Thapar University",
 "country": "India",
 "identifiers": {
 "ror": "https://ror.org/00wdq3744",
 "GRID": "grid.412436.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-10-20",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz079",
 "identifier": {
 "string_id": "10.1093/llc/fqz079",
 "id_scheme": "DOI"
 },
 "abstract": "Is there a way to ensure older adults can bridge the digital divide and engage with online cultural heritage? How can cinema-going memories encourage cross-generational engagement? This article proposes to address these issues by using the Italian Cinema Audiences research project as a case study, and specifically cinema-going memories as intangible cultural heritage (Ercole et al., 2016, Cinema heritage in Europe: preserving and sharing culture by engaging with film exhibition and audiences. Editorial. Alphaville: Journal of Film and Screen Media, 11(Summer): 1–12. Web. ISSN: 2009-4078). It aims to tackle the difficulty of engaging the older generation with the digital world, by proposing and testing new ways to resolve it. Through a mixed-methods ethnographic approach, this article investigates different strategies: the use of social media platforms; a cross-generational activity involving Historypin, a digital, user-generated archive of crowdsourced historical material; an online dedicated archive built in collaboration with the older adults involved in the project. These different solutions aim not only at increasing digital engagement among older adults, but also at furthering younger generations’ involvement in shared cultural heritage in an online context. By focusing on the memories of cinema-going in 1950s Italy, the article explores the implications of the advantages and disadvantages of these different approaches. It also tests Anja K. Leist’s research findings (2013, Social media use of older adults: a mini-review. Gerontology, 59(4): 378–84) on the key role of moderators (the younger generation) to help novice users (the older generation) in the ‘continuous engagement’ in digital environments. We conclude that in order to bridge the digital divide two components are necessary simultaneously: the creation of digital platforms in which the older generations are both curators and users, and the support of and interaction with younger generations.",
 "article_title": "Bridging the digital divide: Older adults’ engagement with online cinema heritage",
 "authors": [
 {
 "given": " Silvia",
 "family": "Dibeltulo",
 "affiliation": [
 {
 "original_name": "School of History, Philosophy and Culture, Oxford Brookes University, Oxford, UK",
 "normalized_name": "Oxford Brookes University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04v2twj65",
 "GRID": "grid.7628.b"
 }
 }
 ]
 },
 {
 "given": " Sarah",
 "family": "Culhane",
 "affiliation": [
 {
 "original_name": "Media Studies Department, Maynooth University, Maynooth, County Kildare, Ireland",
 "normalized_name": "National University of Ireland, Maynooth",
 "country": "Ireland",
 "identifiers": {
 "ror": "https://ror.org/048nfjm95",
 "GRID": "grid.95004.38"
 }
 }
 ]
 },
 {
 "given": " Daniela",
 "family": "Treveri Gennari",
 "affiliation": [
 {
 "original_name": "School of Arts, Oxford Brookes University, Oxford, UK",
 "normalized_name": "Oxford Brookes University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04v2twj65",
 "GRID": "grid.7628.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-10-22",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz081",
 "identifier": {
 "string_id": "10.1093/llc/fqz081",
 "id_scheme": "DOI"
 },
 "abstract": "This article reports on a study of interfaces to long-lived digital humanities (DH) resources using an innovative combination of research methods from book history, interface design, and digital preservation and curation to investigate how interfaces to DH resources have changed over time. To do this, we used the Internet Archive’s Wayback machine to investigate the original presentation and all subsequent changes to the interfaces of a small sample of projects. The study addresses the following questions: What can we learn from a study of interfaces to DH material? How have interfaces to DH materials changed over the course of their existence? Do these changes affect the way the resource is used, and the way it conveys meaning? Should we preserve interfaces for future scholarship? We show that a valuable information may be derived from the interfaces of long-lived projects. Visual design can communicate subtle messages about the way the resource was originally conceived by its creators and subsequent changes show how knowledge of user behaviour developed in the DH community. Interfaces provide information about the intellectual context of early digital projects. They can also provide information about the changing place of DH projects in local and national infrastructures, and the way that projects have sought to survive in challenging funding environments.",
 "article_title": "Interfaces, ephemera, and identity: A study of the historical presentation of digital humanities resources",
 "authors": [
 {
 "given": " Claire",
 "family": "Warwick",
 "affiliation": [
 {
 "original_name": "Department of English Studies, Durham University, UK",
 "normalized_name": "Durham University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01v29qb04",
 "GRID": "grid.8250.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-10-30",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz063",
 "identifier": {
 "string_id": "10.1093/llc/fqz063",
 "id_scheme": "DOI"
 },
 "abstract": "Our article uses text mining techniques to examine confidential letters sent from the Bank of England’s Prudential Regulation Authority (PRA) to financial institutions it supervises. These letters are a ‘report card’ written to firms annually, and are the most important, regularly recurring written communication sent from the PRA to firms it supervises. Using two complementary machine learning techniques—random forests and logistic ridge regression—we explore whether the letters vary in substance and style depending on the size and importance of the firm to whom the PRA is writing. We find that letters to high impact firms use more evaluative, judgment-based language, and adopt a more forward-looking perspective. We also examine how PRA letters differ from similarly purposed letters written by its predecessor, the Financial Services Authority. We find evidence that PRA letters are different, with a greater degree of forward-looking language and directiveness, reflecting the shift in supervisory approach that has occurred in the UK following the financial crisis of 2007–09.",
 "article_title": "Text mining letters from financial regulators to firms they supervise",
 "authors": [
 {
 "given": " David",
 "family": "Bholat",
 "affiliation": [
 {
 "original_name": "Advanced Analytics, Bank of England, UK",
 "normalized_name": "Bank of England",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04p3y0q03",
 "GRID": "grid.465255.5"
 }
 }
 ]
 },
 {
 "given": " James",
 "family": "Brookes",
 "affiliation": [
 {
 "original_name": "Advanced Analytics, Bank of England, UK",
 "normalized_name": "Bank of England",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04p3y0q03",
 "GRID": "grid.465255.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-10-18",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz084",
 "identifier": {
 "string_id": "10.1093/llc/fqz084",
 "id_scheme": "DOI"
 },
 "abstract": "A growing body of critical works on the digital expressions of African literature confirms the importance of digital literary studies in Africa. Examples of this growing scholarship include those of Shola Adenekan (2012) and Stephanie Santana (2018). Adenekan’s work focuses on ‘the Internetting of African literature’, while Santana's essay uses digital fiction from South Africa to offer a brilliant treatment of the connections between national spaces and digital networks. Several questions emerge, though, in considering how digital technologies reformulate the form, function, and audience of African literature. How are we, for instance, to understand the role of digital publics? What kind of ideological terrains emerge in online literary representations? What mediations do digital technologies bring to the changing forms and publics of contemporary writing in Africa? How does the ontology of the digital reconfigure the behaviour of the audience in the interpretation of literary meaning and how might previous scholarship such as those of Karin Barber’s on publics and audiences be read in the context of digitality? This article aims to answer these questions by examining some articulations of reader agency to Chinua Achebe’s There was a Country on digital avenues such as Facebook. Aside from an exploration of the intersection of digital culture and African literary forms, I hope to use online responses to Achebe’s memoir to track the trajectories of the new publics of African literature, showing how the ethnopolitics that greeted the publication of Achebe’s wartime narrative explicates the nature of digital publics",
 "article_title": "Chinua Achebe’s There was a Country and the digital publics of African literature",
 "authors": [
 {
 "given": " James",
 "family": "Yeku",
 "affiliation": [
 {
 "original_name": "Department of African and African American Studies, University of Kansas, Lawrence, KS, USA",
 "normalized_name": "University of Kansas",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/001tmjg57",
 "GRID": "grid.266515.3"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-10-26",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz087",
 "identifier": {
 "string_id": "10.1093/llc/fqz087",
 "id_scheme": "DOI"
 },
 "abstract": "While the field of digital humanities continues to evolve and expand, the affordances of the digital medium are becoming increasingly applicable to research in the field of education. This article provides an overview of some of the issues involved with publishing educational research as a digital web-based thesis. It also introduces the term multimodal theses and dissertations (MTDs) and reports on a Ph.D. research project which is an early example of an MTD in the field of education. The purpose of this article is three-fold: (1) to stand on the shoulders of those in the digital humanities to expand the growing field of digital scholarship to include education; (2) to report on a range of unanticipated affordances arising from the MTD format in addition to the obvious benefits of ease of use, embedded media, and functionality; (3) to propose a transdisciplinary protocol for digital scholarship to assist researchers, librarians, and graduate school administrators in various disciplines.",
 "article_title": "A transdisciplinary protocol for digital scholarship",
 "authors": [
 {
 "given": " Brendan",
 "family": "Jacobs",
 "affiliation": [
 {
 "original_name": "School of Education and the Arts, CQUniversity, Australia",
 "normalized_name": "Central Queensland University",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/023q4bk22",
 "GRID": "grid.1023.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-12-13",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz085",
 "identifier": {
 "string_id": "10.1093/llc/fqz085",
 "id_scheme": "DOI"
 },
 "abstract": "Computational stylistics has developed various methods for investigating and attributing authorship of collaborative literary texts. This article investigates ‘precursory authorship’ (Love, 2002): that is, the authorial traces of a source text that inform—to a greater or lesser degree—a subsequent literary output, in order to establish its relevance for our approach to and understanding of the linguistic properties of literary style. Precursory authorship and derivative adaptations are common features of early modern English drama, and the study focusses on two case studies relating to the plays of Restoration playwright, Aphra Behn (c. 1640–89). Using a combination of quantitative methods (Rolling Delta (RD), principal components analysis (PCA), Delta, and Hierarchical Cluster Analysis), the investigation highlights the presence of precursory authorial style in Behn’s The Rover and an anonymous work associated with Behn, The Counterfeit Bridegroom. The results suggest that precursory authorial style is identifiable in both cases, not only through a similarity with the source text but, to a lesser degree, other texts by the precursory author as well. The anonymous play yields complex and non-confirmatory evidence for Behn’s authorship. Methodologically, RD is most sensitive to precursory collaboration. Collectively, the findings highlight the importance of stylistic factors when describing and interpreting literary linguistic quantitative data: precursory authorial style is another facet that intersects with properties such as time period and genre. The article urges a more critical and theoretically informed view of authorially aligned linguistic style.",
 "article_title": "Stylistic palimpsests: Computational stylistic perspectives on precursory authorship in Aphra Behn’s drama",
 "authors": [
 {
 "given": " Mel",
 "family": "Evans",
 "affiliation": [
 {
 "original_name": "School of Arts, University of Leicester, Leicester, UK",
 "normalized_name": "University of Leicester",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04h699437",
 "GRID": "grid.9918.9"
 }
 }
 ]
 },
 {
 "given": " Alan",
 "family": "Hogarth",
 "affiliation": [
 {
 "original_name": "School of Arts, University of Leicester, Leicester, UK",
 "normalized_name": "University of Leicester",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04h699437",
 "GRID": "grid.9918.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-12-02",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz050",
 "identifier": {
 "string_id": "10.1093/llc/fqz050",
 "id_scheme": "DOI"
 },
 "abstract": "Psychological analysis of characters in ordinary novels is mainly a qualitative analysis, which is easily affected by the researchers’ reading level, theoretical literacy, subjective experience, and other factors. With the development of computer technology and big data, stable and systematic personality can more accurately describe the psychology of text characters. This article adopts the method of literary intelligence analysis based on data mining and statistics, through the Chinese psychological analysis system, the language of the characters in the novel of ordinary world can be counted, processed, and disposed, and then obtains the big five personality prediction scores of the characters. Furthermore, the validity of the intelligent analysis method is confirmed by examining the verification of the predictive scores in the text and literature. After verification by many parties, the predicted results of this article are supported by the text and literature, which shows that literary intelligence analysis of novel characters’ personalities is effective.",
 "article_title": "The intelligence analysis of personal characters about ordinary world",
 "authors": [
 {
 "given": " Ying",
 "family": "Yuan",
 "affiliation": [
 {
 "original_name": "College of Chinese Language and Literature, Xinyang College, Xinyang 464000, China",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-06-20",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz043",
 "identifier": {
 "string_id": "10.1093/llc/fqz043",
 "id_scheme": "DOI"
 },
 "abstract": "Experience through sight has been recognized as a contributing factor in the shaping of historic landscapes, where humans could express themselves in response to their aesthetic and intellectual qualities. What was experienced, however, was not only dependent on the ‘prospect’, or landscape view, but also on the individual ‘perspective’ of the spectator. Three-dimensional Geographical Information Systems (3D GIS) has enabled investigations into landscape visibility within digitized historic environments and can therefore assist the analysis and understanding of this phenomenon. This article applies 3D GIS to a currently under-researched area of landscape history, English designed landscapes of the 16th and 17th centuries. From country houses and gardens to parks and working estates, these landscapes were manipulated in response to the landowners’ ‘perspectives’ towards the landscape, which subsequently determined the visibility or invisibility of features within certain ‘prospects’. This concept was dubbed ‘The Royaltie of Sight’ by Henry Wotton in 1624. By using 3D GIS to recreate a designed landscape that poses challenges which have previously hindered its analysis, the characteristics of ‘prospects’ can be ascertained using viewshed analysis and the individual ‘perspective’ of the landowner interpreted using phenomenology and reception theory. The results presented in this article demonstrate how 3D GIS has benefited studies into English designed landscapes and improved knowledge of how perception influenced landscape change. ",
 "article_title": "3D GIS and ‘The Royaltie Of Sight’: Recreating ‘Prospects’ and ‘Perspectives’ within an English designed landscape c. 1550–1660",
 "authors": [
 {
 "given": " Elizabeth",
 "family": "Stewart",
 "affiliation": [
 {
 "original_name": "School of History, University of East Anglia, Norwich, UK",
 "normalized_name": "University of East Anglia",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/026k5mg93",
 "GRID": "grid.8273.e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-06-20",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz051",
 "identifier": {
 "string_id": "10.1093/llc/fqz051",
 "id_scheme": "DOI"
 },
 "abstract": "The fact about the way God has described himself or how Muslims regard God’s traits is a significant point because that is the path to know the truth about God in his own words, and the verification of Muslims understanding of God through their thoughts and behaviors in accordance with Quran can be studied. In Islamic mysticism, the names and traits of God are categorized into two groups: beauty and divine glory. Although there have been widespread studies in regard to God’s traits, casting a statistical view on these traits can help with the understanding of God, because it would ease the recognition of the way God has introduced himself or envisages traits he most used for himself which in its turn will enlighten the path a Muslim should take. Therefore, with regard to statistics in this work, we would like to study the idea that which group of God’s traits (beauty or divine grace) is more repeated or what the proportion of the two is, and also what difference there is between the Meccan and Medinan suras in the description of God.",
 "article_title": "Statistical analysis about the God’s traits in Quran",
 "authors": [
 {
 "given": " Junqi",
 "family": "Liu",
 "affiliation": [
 {
 "original_name": "School of Communication and Design, Sun Yat-Sen University, Guangzhou, China",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Mohammad Reza",
 "family": "Mahmoudi",
 "affiliation": [
 {
 "original_name": "Department of Statistics, Faculty of Science, Fasa University, Iran",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Ali",
 "family": "Abasalizadeh",
 "affiliation": [
 {
 "original_name": "Department of Persian Literature, Fasa University, Iran",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-06-26",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz027",
 "identifier": {
 "string_id": "10.1093/llc/fqz027",
 "id_scheme": "DOI"
 },
 "abstract": "Eye-tracking—the process of capturing and measuring human eye movement—is becoming an increasingly prevalent tool in the cultural heritage sector to understand visual processing and audience behaviours. Yet, most applications to date have focused on individual artworks and distinctions between representative/non-representative topics, with little prior work on the effects of differing written interpretations on the visual exploration of collections of artworks, particularly with devotional themes. This article reports on an eye-tracking study that explored responses to the unique collection of Francisco de Zurbarán paintings in County Durham. Using eye-tracking technology in a laboratory setting, we evaluated the viewing behaviour of three participant groups to determine whether the accompanying written context influences how digital reproductions are experienced. In addition to demonstrating statistically significant variations in aesthetic appreciation, the experiments showed that the gaze can be redirected towards areas of conceptual significance. Most importantly, we were able to challenge the assumption that viewers always look at faces (Bindemann et al., 2005). Our findings make an important new contribution to the scholarly understanding of how audiences view, appreciate, and understand artworks and to museum and heritage practices relevant to the display of art.",
 "article_title": "Aesthetic appreciation and Spanish art: insights from eye-tracking",
 "authors": [
 {
 "given": " Claire",
 "family": "Bailey-Ross",
 "affiliation": [
 {
 "original_name": "School of Creative Technologies, University of Portsmouth, UK",
 "normalized_name": "University of Portsmouth",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/03ykbk197",
 "GRID": "grid.4701.2"
 }
 }
 ]
 },
 {
 "given": " Andrew M",
 "family": "Beresford",
 "affiliation": [
 {
 "original_name": "School of Modern Languages and Cultures, Durham University, UK",
 "normalized_name": "Durham University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01v29qb04",
 "GRID": "grid.8250.f"
 }
 }
 ]
 },
 {
 "given": " Daniel T",
 "family": "Smith",
 "affiliation": [
 {
 "original_name": "Department of Psychology, Durham University, UK",
 "normalized_name": "Durham University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01v29qb04",
 "GRID": "grid.8250.f"
 }
 }
 ]
 },
 {
 "given": " Claire",
 "family": "Warwick",
 "affiliation": [
 {
 "original_name": "Department of English Studies, Durham University, UK",
 "normalized_name": "Durham University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01v29qb04",
 "GRID": "grid.8250.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-06-05",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "Supplement_1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz054",
 "identifier": {
 "string_id": "10.1093/llc/fqz054",
 "id_scheme": "DOI"
 },
 "abstract": "Multispectral (MSI) imaging of historical documents can recover lost features, such as text or drawings. This technique involves capturing multiple images of a document illuminated using different wavelengths of light. The images created must be registered in order to ensure optimal results are produced from any subsequent image processing techniques. However, the images may be misaligned due to the presence of optical elements such as filters, or because they were acquired at different times or because the images were captured from different copies of the documents . There is little prior work or information available about which image registration techniques are most appropriate. Image registration of multispectral images is challenging as the illumination changes for each image and the features visible in images captured at different wavelengths may not appear consistently throughout the image sequence. Here, we compare three image registration techniques: two based on similarity measures and a method based on phase correlation. These methods are characterized by applying them to realistic surrogate images and then assessed on three different sets of real multispectral images. Mutual information is recommended as a measure for affine image registration when working with multispectral images of documentary material as it was proven to be more robust than the other techniques tested.",
 "article_title": "Affine registration of multispectral images of historical documents for optimized feature recovery",
 "authors": [
 {
 "given": " Cerys",
 "family": "Jones",
 "affiliation": [
 {
 "original_name": "UCL Department of Medical Physics and Biomedical Engineering, London, UK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " William A",
 "family": "Christens-Barry",
 "affiliation": [
 {
 "original_name": "Equipoise Imaging LLC, Ellicott City, MD, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Melissa",
 "family": "Terras",
 "affiliation": [
 {
 "original_name": "College of Arts, Humanities and Social Sciences, University of Edinburgh, Edinburgh, UK",
 "normalized_name": "University of Edinburgh",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01nrxwf90",
 "GRID": "grid.4305.2"
 }
 }
 ]
 },
 {
 "given": " Michael B",
 "family": "Toth",
 "affiliation": [
 {
 "original_name": "R.B. Toth Associates, Oakton, VA, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Adam",
 "family": "Gibson",
 "affiliation": [
 {
 "original_name": "UCL Department of Medical Physics and Biomedical Engineering, London, UK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-07-04",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz053",
 "identifier": {
 "string_id": "10.1093/llc/fqz053",
 "id_scheme": "DOI"
 },
 "abstract": "Over the past few years, research carried out at large-scale materials science facilities in the USA and elsewhere has undergone a phase transition that affected its character and culture. Research cultures at these facilities now resemble ecosystems, comprising of complex and evolving interactions between individuals, institutions, and the overall research environment. The outcome of this phase transition, which has been gradual and building since the 1980s, is known as the New (or Ecologic) Big Science [Crease, R. and Westfall, C. (2016). The new big science. Physics Today, 69: 30–6]. In this article, we describe this phase transition, review the practical challenges that it poses for historians, review some potential digital tools that might respond to these challenges, and then assess the theoretical implications posed by “database history’. ",
 "article_title": "Database thinking and deep description: designing a digital archive of the National Synchrotron Light Source",
 "authors": [
 {
 "given": " Robert",
 "family": "Crease",
 "affiliation": [
 {
 "original_name": "Department of Philosophy, Stony Brook University, Stony Brook, NY, USA",
 "normalized_name": "Stony Brook University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05qghxh33",
 "GRID": "grid.36425.36"
 }
 }
 ]
 },
 {
 "given": " Elyse",
 "family": "Graham",
 "affiliation": [
 {
 "original_name": "Department of English, Stony Brook University, Stony Brook, NY, USA",
 "normalized_name": "Stony Brook University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05qghxh33",
 "GRID": "grid.36425.36"
 }
 }
 ]
 },
 {
 "given": " Jamie",
 "family": "Folsom",
 "affiliation": [
 {
 "original_name": "Performant Software Solutions LLC, Boston, MA, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-07-03",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "Supplement_1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz045",
 "identifier": {
 "string_id": "10.1093/llc/fqz045",
 "id_scheme": "DOI"
 },
 "abstract": "Although in the digital humanities, researchers use software tools to conduct their research, and often apply these tools to data the software was not developed for, there has been little attention for investigating tool performance on this data. This is strange because in order to be able to appraise the results of digital humanities research, it is important to understand to what extent the tool output is correct. To illustrate the importance of the validation of tools, this article presents a case study of validating Arabic root extraction tools. Arabic words are based on root letters; three root letters usually demarcate a semantic field. Thus, roots can be used for studying semantic fields. For example, researchers can gain insight into the relative importance of the different senses (i.e. seeing, hearing, touching, smelling, and tasting) in Arabic jurisprudence (fiqh) by extracting and counting roots. A problem is that there are only a few usable tools available. We take three root extraction tools, Khoja (Khoja and Garside, 1999, Stemming Arabic Text. Lancaster, England: Lancaster University), ISRI (Taghva et al., 2005, Arabic stemming without a root dictionary. In International Conference on Information Technology: Coding and Computing (ITCC’05). Vol. 2. Las Vegas, NV, April 2005 pp. 152–57), and AlKhalil (Boudlal et al., 2010, Alkhalil morpho sys1: a morphosyntactic analysis system for Arabic texts. In International Arab Conference on Information Technology. New York, NY: Elsevier Science Inc., April 2017, pp. 1–6), and create manually annotated gold standard data consisting of three samples of approximately 1,000 words from important books of Islamic jurisprudence. We show that Khoja is the best root extraction tool for our data. We also demonstrate that the relative counts of individual roots differ among tools, which leads to a different interpretation depending on which tool is chosen. This means that findings based on automatically extracted roots should always be interpreted with care.",
 "article_title": "Are you sure your tool does what it is supposed to do? Validating Arabic root extraction",
 "authors": [
 {
 "given": " Janneke van der",
 "family": "Zwaan",
 "affiliation": [
 {
 "original_name": "Netherlands eScience Center, Amsterdam, the Netherlands",
 "normalized_name": "Netherlands eScience Center",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/00rbjv475",
 "GRID": "grid.454309.f"
 }
 }
 ]
 },
 {
 "given": " Maksim Abdul",
 "family": "Latif",
 "affiliation": [
 {
 "original_name": "Department of Philosophy and Religion Studies, Utrecht University, Utrecht, the Netherlands",
 "normalized_name": "Utrecht University",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/04pp8hn57",
 "GRID": "grid.5477.1"
 }
 }
 ]
 },
 {
 "given": " Dafne van",
 "family": "Kuppevelt",
 "affiliation": [
 {
 "original_name": "Netherlands eScience Center, Amsterdam, the Netherlands",
 "normalized_name": "Netherlands eScience Center",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/00rbjv475",
 "GRID": "grid.454309.f"
 }
 }
 ]
 },
 {
 "given": " Melle",
 "family": "Lyklema",
 "affiliation": [
 {
 "original_name": "Department of History and Art History, Utrecht University, Utrecht, the Netherlands",
 "normalized_name": "Utrecht University",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/04pp8hn57",
 "GRID": "grid.5477.1"
 }
 }
 ]
 },
 {
 "given": " Christian",
 "family": "Lange",
 "affiliation": [
 {
 "original_name": "Department of Philosophy and Religion Studies, Utrecht University, Utrecht, the Netherlands",
 "normalized_name": "Utrecht University",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/04pp8hn57",
 "GRID": "grid.5477.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-06-25",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz042",
 "identifier": {
 "string_id": "10.1093/llc/fqz042",
 "id_scheme": "DOI"
 },
 "abstract": "The article offers a state-of-the-art overview of a number of Digital Humanities (DH) initiatives that have emerged in Sweden over the past decade. We identify two major developments that seem to be taking place within DH, with a specific focus on the infrastructural aspects of the development: (1) a strive to open up and broaden the research output and (2) multi-disciplinary collaboration and its effects. The two major components accentuate the new infrastructural patterns that are developing and the challenges these infer on universities. While current research is at large multi-disciplinary, developing infrastructures also enable the move towards post-disciplinarity, bringing the universities closer to the surrounding society. At five universities in Sweden, individual-sited infrastructures supporting DH research have been built today. They are complemented by national and international infrastructures, thus supporting developments and tackling some of the major challenges. In the article, the relations between individual disciplines, the question of multi- and post-disciplinarity, and the field of Digital Humanities are discussed, while stressing the factors necessary—sine qua non—for a fruitful development of the scholarly infrastructures.",
 "article_title": "Digital humanities in Sweden and its infrastructure: Status quo and the sine qua non",
 "authors": [
 {
 "given": " Koraljka",
 "family": "Golub",
 "affiliation": [
 {
 "original_name": "Institute and Department of Library and Information Science, School of Cultural Sciences, Faculty of Arts and Humanities, Linnaeus University, Sweden",
 "normalized_name": "Linnaeus University",
 "country": "Sweden",
 "identifiers": {
 "ror": "https://ror.org/00j9qag85",
 "GRID": "grid.8148.5"
 }
 }
 ]
 },
 {
 "given": " Elisabet",
 "family": "Göransson",
 "affiliation": [
 {
 "original_name": "Centre for Theology and Religious Studies and Centre for Languages and Literature, Lund University, Sweden",
 "normalized_name": "Lund University",
 "country": "Sweden",
 "identifiers": {
 "ror": "https://ror.org/012a77v79",
 "GRID": "grid.4514.4"
 }
 }
 ]
 },
 {
 "given": " Anna",
 "family": "Foka",
 "affiliation": [
 {
 "original_name": "Digital Humanities Uppsala (DH Uppsala), Department of ALM, Faculty of Arts, Uppsala University, Sweden",
 "normalized_name": "Uppsala University",
 "country": "Sweden",
 "identifiers": {
 "ror": "https://ror.org/048a87296",
 "GRID": "grid.8993.b"
 }
 },
 {
 "original_name": "Humlab, Umeå University, Sweden",
 "normalized_name": "Umeå University",
 "country": "Sweden",
 "identifiers": {
 "ror": "https://ror.org/05kb8h459",
 "GRID": "grid.12650.30"
 }
 }
 ]
 },
 {
 "given": " Isto",
 "family": "Huvila",
 "affiliation": [
 {
 "original_name": "Department of ALM, Faculty of Arts, Uppsala University, Sweden",
 "normalized_name": "Uppsala University",
 "country": "Sweden",
 "identifiers": {
 "ror": "https://ror.org/048a87296",
 "GRID": "grid.8993.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-06-18",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz056",
 "identifier": {
 "string_id": "10.1093/llc/fqz056",
 "id_scheme": "DOI"
 },
 "abstract": "In 1985, Italo Calvino wrote a series of lectures (later published as ‘memos’) in which he proposed six values he deemed crucial to literature as it moved into the next millennium: lightness, quickness, ‘crystal’ exactitude, visibility, multiplicity, and consistency. Though never a writer of electronic literature, Calvino has frequently been associated or referenced in relation to digital works. J.R. Carpenter’s web-based work The Gathering Cloud (2016) (hereafter TGC) exhibits Calvino’s values. TGC is informed by Howard’s 1803 Essay on the Modifications of Clouds. Howard’s ‘frontispiece’ and five ‘plates’ are used in Carpenter’s web-based work. Poetry is then superimposed on these repurposed illustrations. Situated ‘within’ the poetry, animated gif collages play. Where Calvino in his memos writes that he considers the virtues of the binary opposites of his values (i.e., weight, lingering, ‘flame’ exactitude, ambiguity, singularity, and inconsistency) no less compelling, Carpenter’s work suggests that Calvino’s values (or rather the absence or removal of their binary opposites) are not only preferable in terms of contemporary literary challenges, but an ethical imperative in relation to environmental impact as it relates to contemporary media, dissemination, and indeed everyday life. In this analysis of TGC, Calvino’s values will be discussed in relation to each of the work’s six sections (i.e., the ‘frontispiece’ and five ‘plates’).",
 "article_title": "Italo Calvino’s Six Memos as ethical imperative in J.R. Carpenter’s The Gathering Cloud",
 "authors": [
 {
 "given": " David Thomas Henry",
 "family": "Wright",
 "affiliation": [
 {
 "original_name": "School of Arts, Murdoch University, Australia",
 "normalized_name": "Murdoch University",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00r4sry34",
 "GRID": "grid.1025.6"
 }
 },
 {
 "original_name": "Queensland University of Technology, Queensland, Australia",
 "normalized_name": "Queensland University of Technology",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/03pnv4752",
 "GRID": "grid.1024.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-08-03",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz046",
 "identifier": {
 "string_id": "10.1093/llc/fqz046",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents technical approaches and innovations in digital library design developed during the design and implementation of the Chinese Text Project, a widely-used, large-scale full-text digital library of premodern Chinese writing. By leveraging a combination of domain-optimized Optical Character Recognition, a purpose-designed crowdsourcing system, and an Application Programming Interface (API), this project simultaneously provides a sustainable transcription system, search interface and reading environment, as well as an extensible platform for transcribing and working with premodern Chinese textual materials. By means of the API, intentionally loosely integrated text mining tools are used to extend the platform, while also being reusable independently with materials from other sources and in other languages.",
 "article_title": "Chinese Text Project: a dynamic digital library of premodern Chinese",
 "authors": [
 {
 "given": " Donald",
 "family": "Sturgeon",
 "affiliation": [
 {
 "original_name": "East Asian Languages and Civilizations, Harvard University, USA",
 "normalized_name": "Harvard University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/03vek6s52",
 "GRID": "grid.38142.3c"
 }
 },
 {
 "original_name": "Computer Science, Durham University, UK",
 "normalized_name": "Durham University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01v29qb04",
 "GRID": "grid.8250.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-06-19",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz059",
 "identifier": {
 "string_id": "10.1093/llc/fqz059",
 "id_scheme": "DOI"
 },
 "abstract": "Despite the commonly reported underuse of linking adverbials of contrast and concession (such as yet, nevertheless) by English as a Foreign Language (EFL) learners in writing, relatively little is known about the use of structural conjunctions in this regard. The present work uses a corpus approach to investigate the use of while, a polysemous conjunction of contrast and concession, in the writing of Chinese EFL learners as compared with their British native-speaker counterparts. The analysis of while-clauses is informed by clause-complexing and textual descriptions of clause in Systemic Functional Linguistics (Halliday and Matthiessen, 2013). Preference for initial concessive while-clauses by native-speaker students was found, in sharp contrast to the dominant use of final adversative while-clauses by Chinese EFL learners. Analysis of the native-speaker data revealed that initial concessive while-clause is characterized by equivalence or relatedness of topical themes of while-clause and its main clause, confirming the discourse-organizing function of thematic hypotactic clauses. In addition, the pattern of non-human subjects and low-value modal operators (e.g. While this … may …) associated dominantly and exclusively with initial concessive while-clauses in the native corpus serves further evidence of distinctive features of concessive while-clauses. This study adds to a growing body of literature on the SFL approach to second language writing and is among the first to combine corpus-based methodologies and SFL theoretical framework to analyze logico-semantic relations. The study concludes with some pedagogical implications for teaching adversative and concessive while-clauses to EFL learners.",
 "article_title": "Adversative versus concessive while-clauses in native and learner English texts: A corpus-based systemic functional description",
 "authors": [
 {
 "given": " Yan",
 "family": "Zhang",
 "affiliation": [
 {
 "original_name": "School of Foreign Languages, East China University of Science and Technology, China",
 "normalized_name": "East China University of Science and Technology",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/01vyrm377",
 "GRID": "grid.28056.39"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-08-15",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz058",
 "identifier": {
 "string_id": "10.1093/llc/fqz058",
 "id_scheme": "DOI"
 },
 "abstract": "In this paper, we present a new semi-automatic methodology for construction of event-based ontology from the library catalogue of the largest collection in the world of metadata records of historical Hebrew manuscripts. Based on the constructed ontology, we developed and implemented a new framework for catalogue data enrichment, correction, and its systematic quantitative analysis. Finally, we demonstrate the results of the proposed large-scale analysis of three most prominent event types in the corpus, as well as a few cross-event relations and trends.",
 "article_title": "Ontology-based analysis of the large collection of historical Hebrew manuscripts",
 "authors": [
 {
 "given": "Zhitomirsky-Geffet, Gila Prebor and Isaac Miller, Maayan",
 "family": null,
 "affiliation": [
 {
 "original_name": "Department of Information Science, Bar-Ilan University, Ramat Gan, 5290002, Israel",
 "normalized_name": "Bar-Ilan University",
 "country": "Israel",
 "identifiers": {
 "ror": "https://ror.org/03kgsv495",
 "GRID": "grid.22098.31"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-08-15",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz052",
 "identifier": {
 "string_id": "10.1093/llc/fqz052",
 "id_scheme": "DOI"
 },
 "abstract": "Over the last few decades, there has been tremendous growth in online communication through different types of media. Communication via the Internet is anonymous, which causes a critical issue regarding identity tracing. Authorship identification can apply to tasks such as identifying an anonymous author, detecting plagiarism, or finding a ghostwriter. Previous research has outlined the various methods and their improvements for the identification of anonymous authors based on stylometry. However, changes in the writing style of an author over a long period has not been addressed. In this article, we propose a methodology for author identification where the writing style of an author changes. The proposed methodology consists of two phases: the first will show the change in writing style of the author and in another phase the change is mitigated by a new feature normalization technique. A novel Transform Feature to Current Time function is proposed for normalization, where features are shifted to current time and made available for further classification. A machine-learning algorithm is used to identify an author candidate. The experiments of the proposed methodology conducted on a set of text samples by several authors were collected over a different time period and the results show an improvement in performance.",
 "article_title": "Author identification with feature transformation method",
 "authors": [
 {
 "given": " Mubin Shoukat",
 "family": "Tamboli",
 "affiliation": [
 {
 "original_name": "Department of Computer Engineering, Matoshri College of Engineering, Nashik, Maharashtra, India",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Rajesh",
 "family": "Prasad",
 "affiliation": [
 {
 "original_name": "Sinhgad Institute of Technology and Science, Narhe, Pune, India",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-07-03",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz075",
 "identifier": {
 "string_id": "10.1093/llc/fqz075",
 "id_scheme": "DOI"
 },
 "abstract": "Besides the Holly Quran, Nahj al-Balagha is the main source of literature in Arabian nations, especially for Shia as one of the main branches of the Muslims. Along with literary brilliance, the text of this book covers the broad topics. This research deals with the application of the statistical text and data analysis to extract knowledge from the aphorisms in Nahj al-Balaghah. First, we classify these aphorisms in seven topics. Then, the count of the aphorisms in each category is computed. Finally, the counts of the aphorisms of the categories are compared using the chi-square test and the cluster analysis.",
 "article_title": "A statistical view to study the aphorisms in Nahj al-Balaghah",
 "authors": [
 {
 "given": " Yu",
 "family": "Tian",
 "affiliation": [
 {
 "original_name": "College of Literature, Northwest University, Xi'an City, Shaanxi Province, China",
 "normalized_name": "Northwest University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00y7snj24",
 "GRID": "grid.441153.6"
 }
 }
 ]
 },
 {
 "given": " Kim-Hung",
 "family": "Pho",
 "affiliation": [
 {
 "original_name": "Fractional Calculus, Optimization and Algebra Research Group, Faculty of Mathematics and Statistics, Ton Duc Thang University, Ho Chi Minh City, Vietnam",
 "normalized_name": "Ton Duc Thang University",
 "country": "Vietnam",
 "identifiers": {
 "ror": "https://ror.org/01drq0835",
 "GRID": "grid.444812.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-10-01",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz017",
 "identifier": {
 "string_id": "10.1093/llc/fqz017",
 "id_scheme": "DOI"
 },
 "abstract": "‘And Quiet Flows the Don’ is an epic novel, considered one of the most significant works of Russian and world literature. The debate on the authorship of ‘And Quiet Flows the Don’ had been surrounding the novel since its first release in 1928 by Mikhail Sholokhov, who was repeatedly accused of plagiarism. The supporters of the plagiarism theory often indicate that the real author of the novel is the Cossack writer, Fyodor Kryukov, who died before ‘And Quiet Flows the Don’ was published. In the present study we applied the information-based similarity analysis (Yang et al., 2003a, Linguistic analysis of human heartbeats using frequency and rank order statistics. Physical Review Letters, 90: 108103; Yang et al., 2003b, Information categorization approach to literary authorship disputes. Physica A, 329, 473) and Burrows's Delta (Burrows, 2002, ‘Delta’: a measure of stylistic difference and a guide to likely authorship. Literary and Linguistic Computing, 17(3):267–87) to a corpus of Russian literature of XIX and XX centuries. We next used these two methods to compare ‘And Quiet Flows the Don’ to Sholokhov’s and Kryukov’s writings. It was found that Fyodor Kryukov writings are distinct from ‘And Quiet Flows the Don’, whilst Sholokhov’s writings being close to the Don novel. The results also highlight how both information similarity analysis and Delta analysis can be used Russian language.",
 "article_title": "And Quiet Flows the Don: the Sholokhov-Kryukov authorship debate",
 "authors": [
 {
 "given": " Marina",
 "family": "Iosifyan",
 "affiliation": [
 {
 "original_name": "Moscow State University, Moscow, Russia",
 "normalized_name": "Lomonosov Moscow State University",
 "country": "Russia",
 "identifiers": {
 "ror": "https://ror.org/010pmpe69",
 "GRID": "grid.14476.30"
 }
 },
 {
 "original_name": "National Research University Higher School of Economics, Moscow, Russia",
 "normalized_name": "National Research University Higher School of Economics",
 "country": "Russia",
 "identifiers": {
 "ror": "https://ror.org/055f7t516",
 "GRID": "grid.410682.9"
 }
 }
 ]
 },
 {
 "given": " Igor",
 "family": "Vlasov",
 "affiliation": [
 {
 "original_name": "MIS and Strategic Planning, VTB Capital, Moscow, Russia",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-02-22",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "35",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz016",
 "identifier": {
 "string_id": "10.1093/llc/fqz016",
 "id_scheme": "DOI"
 },
 "abstract": "Reliable high-quality transcription and/or annotation (a.k.a. ‘coding’) is essential for research in a variety of areas in Humanities and Social Sciences which make use of qualitative data such as interviews, focus groups, classroom observations, or any other audio/video recordings. A good tool can facilitate the work of transcription and annotation because the process is notoriously time-consuming and challenging. However, our survey indicates that few existing tools can accommodate the requirements for transcription and annotation (e.g. audio/video playback, spelling checks, keyboard shortcuts, adding tags of annotation) in one place so that a user does not need to constantly switch between multiple windows, for example, an audio player and a text editor. ‘Transcribear’ (https://transcribear.com) is therefore developed as an easy-to-use online tool which facilitates transcription and annotation on the same interface while this web tool operates offline so that a user’s recordings and transcripts can remain secure and confidential. To minimize human errors, the functionality of tag validation is also added. Originally designed for a multimodal corpus project UNNC CAWSE (https://www.nottingham.edu.cn/en/english/research/cawse/), this browser-based application can be customized for individual users’ needs in terms of the annotation scheme and corresponding shortcut keys. This article will explain how this new tool can make tedious and repetitive manual work faster and easier and at the same time improve the quality of outputs as the process of transcription and annotation tends to be prone to human errors. The limitations of Transcribear and future work will also be discussed.",
 "article_title": "Transcribear – Introducing a secure online transcription and annotation tool",
 "authors": [
 {
 "given": " Yu-Hua",
 "family": "Chen",
 "affiliation": [
 {
 "original_name": "School of English, University of Nottingham Ningbo China, Ningbo, China",
 "normalized_name": "University of Nottingham Ningbo China",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/03y4dt428",
 "GRID": "grid.50971.3a"
 }
 }
 ]
 },
 {
 "given": " Radovan",
 "family": "Bruncak",
 "affiliation": [
 {
 "original_name": "Independent Computer Scientist, London, UK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-02-27",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "35",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz023",
 "identifier": {
 "string_id": "10.1093/llc/fqz023",
 "id_scheme": "DOI"
 },
 "abstract": "Digital Humanities (DH) within Coptic Studies, an emerging field of development, will be much aided by the digitization of large quantities of typeset Coptic texts. Until recently, the only Optical Character Recognition (OCR) analysis of printed Coptic texts had been executed by Moheb S. Mekhaiel, who used the Tesseract program to create a text model for liturgical books in the Bohairic dialect of Coptic. However, this model is not suitable for the many scholarly editions of texts in the Sahidic dialect of Coptic which use noticeably different fonts. In the current study, DH and Coptological projects based in Göttingen, Germany, collaborated to develop a new Coptic OCR pipeline suitable for use with all Coptic dialects. The objective of the study was to generate a model which can facilitate digital Coptic Studies and produce Coptic corpora from existing printed texts. First, we compared the two available OCR programs that can recognize Coptic: Tesseract and Ocropy. The results indicated that the neural network model, i.e. Ocropy, performed better at recognizing the letters with supralinear strokes that characterize the published Sahidic texts. After training Ocropy for Coptic using artificial neural networks, the team achieved an accuracy rate of >91% for the OCR analysis of Coptic typeset. We subsequently compared the efficiency of Ocropy to that of manual transcribing and concluded that the use of Ocropy to extract Coptic from digital images of printed texts is highly beneficial to Coptic DH.",
 "article_title": "Optical character recognition of typeset Coptic text with neural networks",
 "authors": [
 {
 "given": " So",
 "family": "Miyagawa",
 "affiliation": [
 {
 "original_name": "Collaborative Research Centre 1136 “Education and Religion in Cultures of the Mediterranean and Its Environment from Ancient to Medieval Times and to the Classical Islam,” Seminar for Egyptology and Coptic Studies",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "eTRAP Research Group, University of Göttingen, Germany",
 "normalized_name": "University of Göttingen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/01y9bpm73",
 "GRID": "grid.7450.6"
 }
 }
 ]
 },
 {
 "given": " Kirill",
 "family": "Bulert",
 "affiliation": [
 {
 "original_name": "eTRAP Research Group, Institute of Computer Science, University of Göttingen, Germany",
 "normalized_name": "University of Göttingen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/01y9bpm73",
 "GRID": "grid.7450.6"
 }
 }
 ]
 },
 {
 "given": " Marco",
 "family": "Büchler",
 "affiliation": [
 {
 "original_name": "eTRAP Research Group, Institute of Computer Science, University of Göttingen, Germany",
 "normalized_name": "University of Göttingen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/01y9bpm73",
 "GRID": "grid.7450.6"
 }
 }
 ]
 },
 {
 "given": " Heike",
 "family": "Behlmer",
 "affiliation": [
 {
 "original_name": "Seminar for Egyptology and Coptic Studies, and Collaborative Research Centre 1136 “Education and Religion in Cultures of the Mediterranean and Its Environment from Ancient to Medieval Times and to the Classical Islam,” University of Göttingen, Germany",
 "normalized_name": "University of Göttingen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/01y9bpm73",
 "GRID": "grid.7450.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-03-11",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "Supplement_1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy076",
 "identifier": {
 "string_id": "10.1093/llc/fqy076",
 "id_scheme": "DOI"
 },
 "abstract": "Semantic Textual Similarity (STS), which measures the equivalence of meanings between two textual segments, is an important and useful task in Natural Language Processing. In this article, we have analyzed the datasets provided by the Semantic Evaluation (SemEval) 2012–2014 campaigns for this task in order to find out appropriate linguistic features for each dataset, taking into account the influence that linguistic features at different levels (e.g. syntactic constituents and lexical semantics) might have on the sentence similarity. Results indicate that a linguistic feature may have a different effect on different corpus due to the great difference in sentence structure and vocabulary between datasets. Thus, we conclude that the selection of linguistic features according to the genre of the text might be a good strategy for obtaining better results in the STS task. This analysis could be a useful reference for measuring system building and linguistic feature tuning.",
 "article_title": "Linguistic analysis of datasets for semantic textual similarity",
 "authors": [
 {
 "given": " Chunlin",
 "family": "Wang",
 "affiliation": [
 {
 "original_name": "Artificial Solutions Iberia S.L., Barcelona",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Irene",
 "family": "Castellón",
 "affiliation": [
 {
 "original_name": "Departamento de Filología Catalana y Lingüística General, Universidad de Barcelona, Gran Via de les Corts Catalanes, Barcelona",
 "normalized_name": "University of Barcelona",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/021018s57",
 "GRID": "grid.5841.8"
 }
 }
 ]
 },
 {
 "given": " Elisabet",
 "family": "Comelles",
 "affiliation": [
 {
 "original_name": "Departamento de Lenguas y Literaturas Modernas y de Estudios Ingleses, Universidad de Barcelona, Gran Via de les Corts Catalanes, Barcelona",
 "normalized_name": "University of Barcelona",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/021018s57",
 "GRID": "grid.5841.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-01-17",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "35",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz019",
 "identifier": {
 "string_id": "10.1093/llc/fqz019",
 "id_scheme": "DOI"
 },
 "abstract": "Humour relies on dominant cultural values and outlooks in its environment in enacting its comic content. However, since humour sometimes encompasses global experiences, it often transcends artificial human barriers. Its transcendence has been facilitated through online digitized content, in the present case—Internet memes. In exploring transnationalization, fifty purposively selected memes are culled from the Facebook group Robert Mugabe Quotes and subjected to critical linguistic analysis. In the evaluation of the data which is achieved through the linguistic examination of cross-cultural themes in the formulation of identity, didactics, and ideology, sixteen memes, representative of the overarching tripartite concerns, are used as exemplifications. Reliant on the bipartite postulations of Critical Linguistic Stylistics—a linguistic theory that examines the style and peculiarities of linguistic data—and Relief Theory of Humour—which considers humour as a platform for the assuagement of tension and emotions, the memes are testamental of prevailing concerns— politics, technology, social/international relations, sex, male–female relations, etc.—in the human society at large. Linguistic markers such as oppositional expressions, capitalization, and other graphological features are annexed in meaning-formation. I conclude that although humour is generally regarded as a light-hearted routine geared towards the provision of momentary relief, a close scrutiny reveals that deep messages targeted at stimulating consciousness and social transformation find provenance in these artefacts.",
 "article_title": "Transnationalizing humour on social media: A linguistic analysis of ideology, identity and didactics in Robert Mugabe Quotes memes1",
 "authors": [
 {
 "given": " Paul",
 "family": "Onanuga",
 "affiliation": [
 {
 "original_name": "Federal University Oye-Ekiti, Oye-Ekiti, Nigeria",
 "normalized_name": "Federal University Oye Ekiti",
 "country": "Nigeria",
 "identifiers": {
 "ror": "https://ror.org/02q5h6807",
 "GRID": "grid.448729.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-03-08",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "35",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz022",
 "identifier": {
 "string_id": "10.1093/llc/fqz022",
 "id_scheme": "DOI"
 },
 "abstract": "Although the digital humanities have traditionally been conceived as a text-based discipline, both digital visualization techniques as well as visual analysis are increasingly used for research in various humanities disciplines. Since there are several overlaps in epistemic cultures of visually oriented and digitally supported research in art and architectural history studies, museology, and archaeology, as well as cultural heritage, we introduce ‘visual digital humanities’ as novel ‘umbrella’ term to cover research approaches in the digital humanities that are dependent on both consuming and producing pictorial, rather than textual, information to answer their humanities research questions. This article aims to determine this particular field of research in terms of (1) research topics, (2) disciplinary standards, and (3) a scholarly culture as well as (4) researchers’ habits and backgrounds. This study is intended to highlight a scope of phenomena and aspects of relevance. Information is gathered by interviews with researchers at London universities and workshops held in Germany and Sweden.",
 "article_title": "The visual side of digital humanities: a survey on topics, researchers, and epistemic cultures",
 "authors": [
 {
 "given": " Sander",
 "family": "Münster",
 "affiliation": [
 {
 "original_name": "Media Center, Technische Universität Dresden, Dresden, Germany",
 "normalized_name": "TU Dresden",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/042aqky30",
 "GRID": "grid.4488.0"
 }
 }
 ]
 },
 {
 "given": " Melissa",
 "family": "Terras",
 "affiliation": [
 {
 "original_name": "College of Arts, Humanities and Social Sciences, University of Edinburgh, Edinburgh, UK",
 "normalized_name": "University of Edinburgh",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01nrxwf90",
 "GRID": "grid.4305.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-04-24",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "35",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz029",
 "identifier": {
 "string_id": "10.1093/llc/fqz029",
 "id_scheme": "DOI"
 },
 "abstract": "Many classical texts are available in multiple versions that almost always differ from each other due to transcription error and editorial discretion. One of the central challenges in the study of such texts is the preparation of a ‘synoptic’ text: an aligned presentation of the various versions in which corresponding words or phrases, even if not identical, are mapped to each other. Multiple text alignment of this sort must take into account orthographic and conceptual relationships between words. In this article, we define this text alignment problem as an optimization problem by providing a formal measure of alignment quality. Unlike previous measures, our measure uses word embeddings to take into account conceptual similarity between aligned words. We propose an efficient and scalable alignment method in accordance with the proposed criteria. This method splits the texts to be aligned into smaller subtexts, thus improving both efficiency and accuracy. Empirical comparisons on sample data indicate our method is significantly faster than existing methods, often rendering intractable problems tractable, and that the alignment obtained by our method is considerably better than that obtained by other methods.",
 "article_title": "FAST: Fast and Accurate Synoptic Texts",
 "authors": [
 {
 "given": " Oran",
 "family": "Brill",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, Bar-Ilan University, Israel",
 "normalized_name": "Bar-Ilan University",
 "country": "Israel",
 "identifiers": {
 "ror": "https://ror.org/03kgsv495",
 "GRID": "grid.22098.31"
 }
 }
 ]
 },
 {
 "given": " Moshe",
 "family": "Koppel",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, Bar-Ilan University, Israel",
 "normalized_name": "Bar-Ilan University",
 "country": "Israel",
 "identifiers": {
 "ror": "https://ror.org/03kgsv495",
 "GRID": "grid.22098.31"
 }
 }
 ]
 },
 {
 "given": " Avi",
 "family": "Shmidman",
 "affiliation": [
 {
 "original_name": "Department of Hebrew Literature, Bar-Ilan University, Israel",
 "normalized_name": "Bar-Ilan University",
 "country": "Israel",
 "identifiers": {
 "ror": "https://ror.org/03kgsv495",
 "GRID": "grid.22098.31"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-04-03",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "35",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz028",
 "identifier": {
 "string_id": "10.1093/llc/fqz028",
 "id_scheme": "DOI"
 },
 "abstract": "The judgments by members of the US Supreme Court in the 2000 case of Bush versus Gore remain controversial to the present. We use text mining and machine learning methods to compare the word usage patterns of Supreme Court Justices in order to explore the likely authorship of both the anonymous 5-4 per curiam decision in this case and the concurrence that is attributed to Chief Justice Rehnquist, with Scalia and Thomas joining. An analysis of high and medium frequency words suggests that Justice Kennedy was likely the main contributor to the per curiam decision. A similar analysis of the concurrence, however, suggests that Justice Scalia may have played a more central role than the document’s purported author, Justice Rehnquist. Our analysis indicates that while Chief Justice Rehnquist was likely to have been the crafter of the document, much of the more forceful language of the concurrence resonates more clearly with a vocabulary that is indicative of Justice Scalia.",
 "article_title": "Judging style: The case of Bush versus Gore",
 "authors": [
 {
 "given": " Matthew L",
 "family": "Jockers",
 "affiliation": [
 {
 "original_name": "Department of English, Washington State University, USA",
 "normalized_name": "Washington State University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05dk0ce17",
 "GRID": "grid.30064.31"
 }
 }
 ]
 },
 {
 "given": " Fernando",
 "family": "Nascimento",
 "affiliation": [
 {
 "original_name": "Bowdoin College, USA",
 "normalized_name": "Bowdoin College",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/03gh96r95",
 "GRID": "grid.253245.7"
 }
 }
 ]
 },
 {
 "given": " George H",
 "family": "Taylor",
 "affiliation": [
 {
 "original_name": "School of Law, University of Pittsburgh, USA",
 "normalized_name": "University of Pittsburgh",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/01an3r305",
 "GRID": "grid.21925.3d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-03-28",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "35",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy077",
 "identifier": {
 "string_id": "10.1093/llc/fqy077",
 "id_scheme": "DOI"
 },
 "abstract": "Recent studies have shown that macroscopic patterns of continuity and change over the course of centuries can be detected through the analysis of time series extracted from massive textual corpora. Similar data-driven approaches have already revolutionized the natural sciences and are widely believed to hold similar potential for the humanities and social sciences, driven by the mass-digitization projects that are currently under way, and coupled with the ever-increasing number of documents which are ‘born digital’. As such, new interactive tools are required to discover and extract macroscopic patterns from these vast quantities of textual data. Here we present History Playground, an interactive web-based tool for discovering trends in massive textual corpora. The tool makes use of scalable algorithms to first extract trends from textual corpora, before making them available for real-time search and discovery, presenting users with an interface to explore the data. Included in the tool are algorithms for standardization, regression, change-point detection in the relative frequencies of n-grams, multi-term indices, and comparison of trends across different corpora.",
 "article_title": "History playground: A tool for discovering temporal trends in massive textual corpora",
 "authors": [
 {
 "given": " Thomas",
 "family": "Lansdall-Welfare",
 "affiliation": [
 {
 "original_name": "Intelligent Systems Laboratory, Department of Engineering Mathematics, University of Bristol, Bristol, UK",
 "normalized_name": "University of Bristol",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0524sp257",
 "GRID": "grid.5337.2"
 }
 }
 ]
 },
 {
 "given": " Nello",
 "family": "Cristianini",
 "affiliation": [
 {
 "original_name": "Intelligent Systems Laboratory, Department of Engineering Mathematics, University of Bristol, Bristol, UK",
 "normalized_name": "University of Bristol",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0524sp257",
 "GRID": "grid.5337.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-12-31",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "35",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz035",
 "identifier": {
 "string_id": "10.1093/llc/fqz035",
 "id_scheme": "DOI"
 },
 "abstract": "In this study, I frame the concept of techno-poetics by analyzing Alex Epstein’s micro-stories and by examining the development of the micro-fiction genre throughout the world. Epstein is a contemporary Israeli author whose universal micro-stories have been translated into several languages (English, Spanish, French, and Russian). Epstein uses a dual language: given his career as a computer programmer in a high-tech company, the language of his thoughts is conveyed through the logic of technology, whereas, as an artist, he is loyal to the language of poetics. Is Epstein a “programmer” of micro-stories? Within the framework of this study, I analyze the dynamic relationship between the polar opposites of technology and poetics, as it is revealed in Epstein’s micro-stories, taking into account the genre’s characteristics as well as the unique features with which Epstein—as a contemporary author—imbues his works. More specifically, I analyze six categories that describe the relationship between digital technology and the world of art, a relationship that informs Epstein's micro-stories. Epstein's work was not created in a void; nevertheless, his micro-stories differ not only from the works of previous authors of the genre, but also from those of his contemporaries, whose work, likewise, deals with the tension between technology and poetics. A major difference is the methods of publication that Epstein uses, which form part of the techno-poetical process. In this sense, the themes, the conception of art, and the method of publication are all indications of a unique artistic phenomenon.",
 "article_title": "Techno-poetics in micro-stories of the digital age: The case of Alex Epstein",
 "authors": [
 {
 "given": " Orna",
 "family": "Levin",
 "affiliation": [
 {
 "original_name": "Achva Academic College, Israel",
 "normalized_name": "Achva Academic College",
 "country": "Israel",
 "identifiers": {
 "ror": "https://ror.org/024hcay96",
 "GRID": "grid.443007.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-05-06",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "35",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz030",
 "identifier": {
 "string_id": "10.1093/llc/fqz030",
 "id_scheme": "DOI"
 },
 "abstract": "Ever since the beginnings of the modern historiography, the court books have posed a challenge for editors in Poland, both due to their number and variety. They constitute one of the richest sources enabling a variety of historical research. The publication of the sources’ content can be shared owing to new approaches stemming from constant development of IT tools and their application in the humanities. The solution proposed in our article is a digital indexing based on a relational database enabling access to the sources’ scans. The characterization of the method is preceded by a description of the theoretical foundations of the presented method. The assumed principals are implemented by the use of a dedicated to this project online INDXR application which functionalities is thoroughly described. Using the INDXR application, the data acquired from the sources are collected and stored in the database which structure is also illustrated along with its theoretical foundations. The database is established in order to better reflect the typical elements comprising the court books as well as to store the acquired information. The issues stemming from the process of indexing the court books, such as categorizing of the entries, their spatial context, and the problem of how to describe the persons appearing in the manuscript are also presented.",
 "article_title": "Technical and methodological foundations of digital indexing of medieval and early modern court books",
 "authors": [
 {
 "given": " Arkadiusz",
 "family": "Borek",
 "affiliation": [
 {
 "original_name": "Department of Historical Atlas, The Tadeusz Manteuffel Institute of History, Polish Academy of Sciences, Warszawa, Poland",
 "normalized_name": "Polish Academy of Sciences",
 "country": "Poland",
 "identifiers": {
 "ror": "https://ror.org/01dr6c206",
 "GRID": "grid.413454.3"
 }
 }
 ]
 },
 {
 "given": " Tomasz",
 "family": "Związek",
 "affiliation": [
 {
 "original_name": "Department of Historical Atlas, The Tadeusz Manteuffel Institute of History, Polish Academy of Sciences, Warszawa, Poland",
 "normalized_name": "Polish Academy of Sciences",
 "country": "Poland",
 "identifiers": {
 "ror": "https://ror.org/01dr6c206",
 "GRID": "grid.413454.3"
 }
 }
 ]
 },
 {
 "given": " Michał",
 "family": "Słomski",
 "affiliation": [
 {
 "original_name": "Department of Historical Atlas, The Tadeusz Manteuffel Institute of History, Polish Academy of Sciences, Warszawa, Poland",
 "normalized_name": "Polish Academy of Sciences",
 "country": "Poland",
 "identifiers": {
 "ror": "https://ror.org/01dr6c206",
 "GRID": "grid.413454.3"
 }
 }
 ]
 },
 {
 "given": " Michał",
 "family": "Gochna",
 "affiliation": [
 {
 "original_name": "Department of Historical Atlas, The Tadeusz Manteuffel Institute of History, Polish Academy of Sciences, Warszawa, Poland",
 "normalized_name": "Polish Academy of Sciences",
 "country": "Poland",
 "identifiers": {
 "ror": "https://ror.org/01dr6c206",
 "GRID": "grid.413454.3"
 }
 }
 ]
 },
 {
 "given": " Grzegorz",
 "family": "Myrda",
 "affiliation": [
 {
 "original_name": "Department of Historical Atlas, The Tadeusz Manteuffel Institute of History, Polish Academy of Sciences, Warszawa, Poland",
 "normalized_name": "Polish Academy of Sciences",
 "country": "Poland",
 "identifiers": {
 "ror": "https://ror.org/01dr6c206",
 "GRID": "grid.413454.3"
 }
 }
 ]
 },
 {
 "given": " Marek",
 "family": "Słoń",
 "affiliation": [
 {
 "original_name": "Department of Historical Atlas, The Tadeusz Manteuffel Institute of History, Polish Academy of Sciences, Warszawa, Poland",
 "normalized_name": "Polish Academy of Sciences",
 "country": "Poland",
 "identifiers": {
 "ror": "https://ror.org/01dr6c206",
 "GRID": "grid.413454.3"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-04-16",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "35",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz031",
 "identifier": {
 "string_id": "10.1093/llc/fqz031",
 "id_scheme": "DOI"
 },
 "abstract": "Determining the date of writing is a practical problem often encountered in the study of ancient and medieval texts. The problem is compounded by differences in genre, register and style, but in particular by our frequent dependence on much later copies of lost originals. This article examines how a method of classification with flexible time intervals has been developed for a corpus of medieval Irish annals (c.700–c.1600). It is shown that the method can deal successfully with an unparsed, complex corpus containing contaminated data. A method of extending the model from good quality, uncontaminated data to more complex texts is also demonstrated by identifying temporal characteristics and typical entries in the high-quality source.",
 "article_title": "Dating medieval texts by classification with flexible time intervals",
 "authors": [
 {
 "given": " Gregory",
 "family": "Toner",
 "affiliation": [
 {
 "original_name": "Queen's University Belfast, UK",
 "normalized_name": "Queen's University Belfast",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/00hswnk62",
 "GRID": "grid.4777.3"
 }
 }
 ]
 },
 {
 "given": " Xiwu",
 "family": "Han",
 "affiliation": [
 {
 "original_name": "Queen's University Belfast, UK",
 "normalized_name": "Queen's University Belfast",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/00hswnk62",
 "GRID": "grid.4777.3"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-04-16",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "35",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz038",
 "identifier": {
 "string_id": "10.1093/llc/fqz038",
 "id_scheme": "DOI"
 },
 "abstract": "In this article, we utilized large-scale statistical analysis and data visualization techniques of the greatest collection in the world of Hebrew manuscript metadata records to develop a new methodology for quantitative investigation of the palaeographic, geographic, and temporal characteristics of historical manuscripts. The study aims to explore whether and to what extent the script type of the manuscript and its changes over time can be used to automatically predict and complete missing geospatial data of the manuscripts. To this end, various ontological entities were used as features to train supervised machine-learning algorithms to predict the places of writing of manuscripts which were often absent in the catalogue records. The obtained results show that while the script type as an only feature might not be sufficient for prediction of the location of the manuscript’s writing, its combination with temporal data of the manuscript yielded about 80% accuracy. Eventually, our system was able to complete the missing places of writing for over 60% of the manuscripts in the corpus. Moreover, we found that through typical and marginal script types in different regions and their changes over time, it is possible to draw the migration map of the Jewish communities over the centuries. This reinforces the findings of historical research on Jewish migration patterns and communal formation. For example, the waves of immigration from Western Europe can be seen clearly from the second half of the 13th century, which continued until the 17th century and greatly increased the Eastern European Jewish community.",
 "article_title": "A new analytic framework for prediction of migration patterns and locations of historical manuscripts based on their script types",
 "authors": [
 {
 "given": " Gila",
 "family": "Prebor",
 "affiliation": [
 {
 "original_name": "Department of Information Science, Bar-Ilan University, Ramat-Gan 5290002, Israel",
 "normalized_name": "Bar-Ilan University",
 "country": "Israel",
 "identifiers": {
 "ror": "https://ror.org/03kgsv495",
 "GRID": "grid.22098.31"
 }
 }
 ]
 },
 {
 "given": " Maayan",
 "family": "Zhitomirsky-Geffet",
 "affiliation": [
 {
 "original_name": "Department of Information Science, Bar-Ilan University, Ramat-Gan 5290002, Israel",
 "normalized_name": "Bar-Ilan University",
 "country": "Israel",
 "identifiers": {
 "ror": "https://ror.org/03kgsv495",
 "GRID": "grid.22098.31"
 }
 }
 ]
 },
 {
 "given": " Yitzchak",
 "family": "Miller",
 "affiliation": [
 {
 "original_name": "Department of Information Science, Bar-Ilan University, Ramat-Gan 5290002, Israel",
 "normalized_name": "Bar-Ilan University",
 "country": "Israel",
 "identifiers": {
 "ror": "https://ror.org/03kgsv495",
 "GRID": "grid.22098.31"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-05-17",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "35",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz039",
 "identifier": {
 "string_id": "10.1093/llc/fqz039",
 "id_scheme": "DOI"
 },
 "abstract": "This study investigates ‘otherness’ in gender identity creation in social media memes. Nineteen ‘Correct Bro’ and ‘Correct Bae’ memes from Facebook are purposively selected for the study. The analysis is qualitative in approach and is anchored on Incongruity Theory of humour and Gender Social Theory. Linguistic tools from Critical Stylistics are employed for the linguistic interpretation of the data. Specific gender otherness identified are the dependent other, irrational other, opportunistic other, weak other, and the unreal other. Humorous forms identified are parody, teasing, pun, and sarcasm among others. Otherness is constructed within these humorous forms with linguistic and rhetorical tools, such as structural opposition, lexical absence, prioritizing, repetition, and so on. The study identified that gender ‘otherness’ is expressed in humorous memes to either reinforce existing gender ideologies or challenge them. Also, humorous memes are not just created to evoke laughter but are tools for expressing new tendencies in gender ideological orientation in the society.",
 "article_title": "Gender ideology and identity in humorous social media memes",
 "authors": [
 {
 "given": " Victoria O",
 "family": "Gbadegesin",
 "affiliation": [
 {
 "original_name": "Department of English and Literary Studies, Federal University Oye-Ekiti, Nigeria",
 "normalized_name": "Federal University Oye Ekiti",
 "country": "Nigeria",
 "identifiers": {
 "ror": "https://ror.org/02q5h6807",
 "GRID": "grid.448729.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-05-17",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz033",
 "identifier": {
 "string_id": "10.1093/llc/fqz033",
 "id_scheme": "DOI"
 },
 "abstract": "Data driven approaches for machine translation, such as statistical and neural machine translation, suffer from sparsity when dealing with low-resource languages. In these cases, using other sources of information including linguistic information could alleviate the problem. In this article, we focus on the problem of word ordering in translation from a high-resource to a low-resource language and try to improve the quality by using syntactic information from the high-resource side. We propose some syntactic features based on Tree Adjoining Grammar (TAG) to be employed in a phrase-based SMT model in order to improve the word ordering. In this work, a set of synchronous TAG rules is extracted and used to estimate the probability of the phrase orders suggested by the phrase-based model. The main idea of the article is to handle the word ordering by using the extended domain of locality property of TAG and abstracting the long distance dependencies into a local view, which is a TAG elementary tree. The experiments on English–Persian and English–German translation showed that, by combining the proposed TAG-based reordering features with lexical and hierarchical reordering models, we gain significant improvements over the baseline and in comparison with a neural reordering model and a pre-reordering model.",
 "article_title": "Using syntax for improving phrase-based SMT in low-resource languages",
 "authors": [
 {
 "given": " Hakimeh",
 "family": "Fadaei",
 "affiliation": [
 {
 "original_name": "School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Tehran, Iran",
 "normalized_name": "University of Tehran",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/05vf56z40",
 "GRID": "grid.46072.37"
 }
 }
 ]
 },
 {
 "given": " Heshaam",
 "family": "Faili",
 "affiliation": [
 {
 "original_name": "School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Tehran, Iran School of Computer Science, Institute for Research in Fundamental Sciences (IPM), Tehran, Iran",
 "normalized_name": "University of Tehran",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/05vf56z40",
 "GRID": "grid.46072.37"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-04-27",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy085",
 "identifier": {
 "string_id": "10.1093/llc/fqy085",
 "id_scheme": "DOI"
 },
 "abstract": "Digital humanities research has focused primarily on the analysis of texts. This emphasis stems from the availability of technology to study digitized text. Optical character recognition allows researchers to use keywords to search and analyze digitized texts. However, archives of digitized sources also contain large numbers of images. This article shows how convolutional neural networks (CNNs) can be used to categorize and analyze digitized historical visual sources. We present three different approaches to using CNNs for gaining a deeper understanding of visual trends in an archive of digitized Dutch newspapers. These include detecting medium-specific features (separating photographs from illustrations), querying images based on abstract visual aspects (clustering visually similar advertisements), and training a neural network based on visual categories developed by domain experts. We argue that CNNs allow researchers to explore the visual side of the digital turn. They allow archivists and researchers to classify and spot trends in large collections of digitized visual sources in radically new ways.",
 "article_title": "The visual digital turn: Using neural networks to study historical images",
 "authors": [
 {
 "given": " Melvin",
 "family": "Wevers",
 "affiliation": [
 {
 "original_name": "DHLab, KNAW Humanities Cluster, Amsterdam, The Netherlands",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Thomas",
 "family": "Smits",
 "affiliation": [
 {
 "original_name": "Department of Cultural Studies, Radboud University, Nijmegen, The Netherlands",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-01-08",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy083",
 "identifier": {
 "string_id": "10.1093/llc/fqy083",
 "id_scheme": "DOI"
 },
 "abstract": "This article explores the intersection of biomechanics and culturally situated dance scholarship. We focus on ‘Sendratari Ramayana’, a 50-year-old dance form heavily influenced by classical Javanese dance traditions dating back to the 19th century. We used a full-body plug-in gait model to record differences in character typology—a key concern of Javanese dance scholarship. The results are presented through online visualizations and analyzed quantitatively. This approach outlines a digital stylometry of movement that contributes to the long tradition of formalist analysis of Javanese dance.",
 "article_title": "Digital dance scholarship: Biomechanics and culturally situated dance analysis",
 "authors": [
 {
 "given": " Miguel",
 "family": "Escobar Varela",
 "affiliation": [
 {
 "original_name": "English Language and Literature, National University of Singapore, Singapore",
 "normalized_name": "National University of Singapore",
 "country": "Singapore",
 "identifiers": {
 "ror": "https://ror.org/01tgyzw49",
 "GRID": "grid.4280.e"
 }
 }
 ]
 },
 {
 "given": " Luis",
 "family": "Hernández-Barraza",
 "affiliation": [
 {
 "original_name": "Department of Biomedical Engineering, National University of Singapore, Singapore",
 "normalized_name": "National University of Singapore",
 "country": "Singapore",
 "identifiers": {
 "ror": "https://ror.org/01tgyzw49",
 "GRID": "grid.4280.e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-12-27",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy084",
 "identifier": {
 "string_id": "10.1093/llc/fqy084",
 "id_scheme": "DOI"
 },
 "abstract": "In 2005, the National Library of Australia (NLA) began a pilot project to selectively digitize back issues of major Australian newspapers to provide free public access to over 60 million digitized newspaper articles, dating from the first years of Australian colonization to the early 1960s. Trove, a faceted search engine maintained by NLA, provides access to this very large collection. Unfortunately, Trove lacked any means to filter by location, which raised the tantalizing possibility of using advanced computational techniques to identify long-term patterns and trends in newspaper reportage of people, events, concepts, and many other historical entities. PaperMiner, which utilizes text mining techniques for extracting metadata information, was developed that enabled the inclusion of geolocations of the places cited in the newspaper articles and supported the searching of articles by location and visualizing the results of searches using both location and time using a map of Australia. Using PaperMiner, researchers could see when and where the anti-Chinese leagues movement started in Australia and how it spread, to better focus their subsequent research. PaperMiner can be used as a digital humanities tool to assist in research by replacing the tedium of a shallow scan through thousands of Trove search results with a more efficient method that draws the researchers’ attention to more significant times and places where their time can be better spent in deeper analysis. In this article, we describe the techniques utilized in creating PaperMiner and discuss its usability testing with a group of leading researchers in Australian history.",
 "article_title": "PaperMiner—a real-time spatiotemporal visualization for newspaper articles",
 "authors": [
 {
 "given": " Sangeetha",
 "family": "Kutty",
 "affiliation": [
 {
 "original_name": "Science and Engineering Faculty, Queensland University of Technology, Australia",
 "normalized_name": "Queensland University of Technology",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/03pnv4752",
 "GRID": "grid.1024.7"
 }
 }
 ]
 },
 {
 "given": " Richi",
 "family": "Nayak",
 "affiliation": [
 {
 "original_name": "Science and Engineering Faculty, Queensland University of Technology, Australia",
 "normalized_name": "Queensland University of Technology",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/03pnv4752",
 "GRID": "grid.1024.7"
 }
 }
 ]
 },
 {
 "given": " Paul",
 "family": "Turnbull",
 "affiliation": [
 {
 "original_name": "School of Historical and Philosophical Studies, University of Queensland, Australia",
 "normalized_name": "University of Queensland",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00rqy9422",
 "GRID": "grid.1003.2"
 }
 },
 {
 "original_name": "School of Humanities, University of Tasmania",
 "normalized_name": "University of Tasmania",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/01nfmeh72",
 "GRID": "grid.1009.8"
 }
 }
 ]
 },
 {
 "given": " Ron",
 "family": "Chernich",
 "affiliation": [
 {
 "original_name": "Science and Engineering Faculty, Queensland University of Technology, Australia",
 "normalized_name": "Queensland University of Technology",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/03pnv4752",
 "GRID": "grid.1024.7"
 }
 }
 ]
 },
 {
 "given": " Gavin",
 "family": "Kennedy",
 "affiliation": [
 {
 "original_name": "Smart Services Co-operative Research Centre, Queensland Cyber Infrastructure Foundation, Australia",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Kerry",
 "family": "Raymond",
 "affiliation": [
 {
 "original_name": "Science and Engineering Faculty, Queensland University of Technology, Australia",
 "normalized_name": "Queensland University of Technology",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/03pnv4752",
 "GRID": "grid.1024.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-01-10",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy087",
 "identifier": {
 "string_id": "10.1093/llc/fqy087",
 "id_scheme": "DOI"
 },
 "abstract": "Vossian antonomasia is a prolific stylistic device, in use since antiquity. It can compress the introduction or description of a person or another named entity into a terse, poignant formulation and can best be explained by an example: When Norwegian world champion Magnus Carlsen is described as ‘the Mozart of chess’, it is Vossian antonomasia we are dealing with. The pattern is simple: A source (Mozart) is used to describe a target (Magnus Carlsen), the transfer of meaning is reached via a modifier (‘of chess’). This phenomenon has been discussed before (as ‘metaphorical antonomasia’ or, with special focus on the source object, as ‘paragons’), but no corpus-based approach has been undertaken as yet to explore its breadth and variety. We are looking into a full-text newspaper corpus (The New York Times, 1987–2007) and describe a new method for the automatic extraction of Vossian antonomasia based on Wikidata entities. Our analysis offers new insights into the occurrence of popular paragons and their distribution.",
 "article_title": "‘The Michael Jordan of greatness’—Extracting Vossian antonomasia from two decades ofThe New York Times, 1987–2007",
 "authors": [
 {
 "given": " Frank",
 "family": "Fischer",
 "affiliation": [
 {
 "original_name": "National Research University Higher School of Economics, Moscow",
 "normalized_name": "National Research University Higher School of Economics",
 "country": "Russia",
 "identifiers": {
 "ror": "https://ror.org/055f7t516",
 "GRID": "grid.410682.9"
 }
 }
 ]
 },
 {
 "given": " Robert",
 "family": "Jäschke",
 "affiliation": [
 {
 "original_name": "Humboldt University of Berlin, Germany",
 "normalized_name": "Humboldt University of Berlin",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/01hcx6992",
 "GRID": "grid.7468.d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-12-21",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy074",
 "identifier": {
 "string_id": "10.1093/llc/fqy074",
 "id_scheme": "DOI"
 },
 "abstract": "In this article, we introduce the first Kurdish text corpus for Central Kurdish (Sorani) branch, called AsoSoft text corpus. Kurdish language, which is spoken by more than 30 million people, has various dialects. As one of the two main branches of Kurdish, Central Kurdish is the formal dialect of Kurdish literature. AsoSoft text corpus is of size 188 million tokens and has been collected mostly from Web sites, published books, and magazines. The corpus has been normalized and converted into Text Encoding Initiative XML format. In both collecting and processing the text, we have faced several challenges and have proposed solutions to them. About 22% of the corpus is topic annotated with six topic tags, and a topic identification task has been done to evaluate the correctness of annotation. The computational experiments of the Central Kurdish text processing are also presented with the support of related supplementary statistics. For the first time, the validity of Zipf’s law for Central Kurdish is presented and also perplexity of this language is calculated using standard N-gram language models. The perplexity of Central Kurdish is 276 for a tri-gram language model.",
 "article_title": "Toward Kurdish language processing: Experiments in collecting and processing the AsoSoft text corpus",
 "authors": [
 {
 "given": " Hadi",
 "family": "Veisi",
 "affiliation": [
 {
 "original_name": "Faculty of New Sciences and Technologies, University of Tehran, Iran",
 "normalized_name": "University of Tehran",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/05vf56z40",
 "GRID": "grid.46072.37"
 }
 }
 ]
 },
 {
 "given": " Mohammad",
 "family": "MohammadAmini",
 "affiliation": [
 {
 "original_name": "IT Department, Faculty of Engineering, Tarbiat Modares University, Iran",
 "normalized_name": "Tarbiat Modares University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/03mwgfy56",
 "GRID": "grid.412266.5"
 }
 }
 ]
 },
 {
 "given": " Hawre",
 "family": "Hosseini",
 "affiliation": [
 {
 "original_name": "Electrical and Computer Engineering, Ryerson University, Canada",
 "normalized_name": "Ryerson University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/05g13zd79",
 "GRID": "grid.68312.3e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-14",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz003",
 "identifier": {
 "string_id": "10.1093/llc/fqz003",
 "id_scheme": "DOI"
 },
 "abstract": "Selecting effective features from data sets is a particularly important part in text classification, data mining, pattern recognition, and artificial intelligence. Feature selection (FS) is capable of excluding irrelevant features for the classification task and reducing the dimensionality of data sets, which help us better understand data. Through FS selection, the performance of machine learning techniques is improved, and computation requirement is minimized. Thus far, a large number of FS methods have been proposed, whereas the most practically effective one has not been found. Although it is conceivable that different categories of FS methods follow different criteria for evaluating variables, rare studies have focused on evaluating various categories of FS methods. This article first lists thirteen superior FS methods under five different categories and focuses on evaluating and comparing the effectiveness and general versatility of these methods. The thirteen FS methods were ranked using rank aggregation method. Subsequently, the best five FS methods were elected to perform multi-class classifications. Support vector machine served as the classifier. Different languages, different numbers of selected features, and different performance measures were employed to measure the effectiveness and general versatility of these methods together. The analysis results suggest that Mahalanobis distance is the best method on the whole.",
 "article_title": "Comparing multiple categories of feature selection methods for text classification",
 "authors": [
 {
 "given": " Wanwan",
 "family": "Zheng",
 "affiliation": [
 {
 "original_name": "Graduate School of Culture and Information Science, Doshisha University, Japan",
 "normalized_name": "Doshisha University",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/01fxdkm29",
 "GRID": "grid.255178.c"
 }
 }
 ]
 },
 {
 "given": " Mingzhe",
 "family": "Jin",
 "affiliation": [
 {
 "original_name": "Graduate School of Culture and Information Science, Doshisha University, Japan",
 "normalized_name": "Doshisha University",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/01fxdkm29",
 "GRID": "grid.255178.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-01-09",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz009",
 "identifier": {
 "string_id": "10.1093/llc/fqz009",
 "id_scheme": "DOI"
 },
 "abstract": "This article describes work undertaken at the Warburg Institute in London into the definition of machine-readable ontologies for the identification of iconographic subjects. Iconography, a descriptive discipline concerned with the identification of the content or subject of an image, is a core component of the wider discipline of iconology, the study of the meanings of images in their cultural or historical contexts. The research detailed here attempts to define the core of an ontology for the indicators of an iconographic subject that would be employed by an art historian in making an identification: these are encoded in OWL, the Web Ontology Language. The article demonstrates how such an ontology may be queried in XML format using simple XQUERY queries. Future directions for this research are discussed, including its possible integration with image recognition technologies to facilitate more automated approaches to iconographic identification.",
 "article_title": "Towards an ontology-based iconography",
 "authors": [
 {
 "given": " Richard",
 "family": "Gartner",
 "affiliation": [
 {
 "original_name": "Warburg Institute, School of Advanced Study, University of London, UK",
 "normalized_name": "University of London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04cw6st05",
 "GRID": "grid.4464.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-01-15",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz004",
 "identifier": {
 "string_id": "10.1093/llc/fqz004",
 "id_scheme": "DOI"
 },
 "abstract": "This article describes a first attempt to annotate the full Greek papyrus corpus automatically for linguistic information. It gives an overview of existing work on Ancient Greek and analyzes the typical problems one encounters when using natural language processing techniques on (1) a historical corpus of (2) a highly inflectional language (as opposed to the more analytic present-day English) and offers solutions to them, testing several different approaches. The focus is on part-of-speech/morphological tagging and lemmatization; some syntactic parsing experiments are also briefly discussed. The conclusion discusses the strengths and shortcomings of the examined techniques and suggests possible ways to further improve tagging and parsing accuracy.",
 "article_title": "Creating a richly annotated corpus of papyrological Greek: The possibilities of natural language processing approaches to a highly inflected historical language",
 "authors": [
 {
 "given": " Alek",
 "family": "Keersmaekers",
 "affiliation": [
 {
 "original_name": "KU Leuven, Belgium",
 "normalized_name": "KU Leuven",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/05f950310",
 "GRID": "grid.5596.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-01-09",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz007",
 "identifier": {
 "string_id": "10.1093/llc/fqz007",
 "id_scheme": "DOI"
 },
 "abstract": "The Territorial Papers of the United States are a valuable and underused resource containing almost 10,000 documents written between 1789 and 1848 about the formation of new sovereign states from US territory. These communications between the federal government and frontier settlers comprise the actual discourse of the nation’s expansion over six decades. Digitizing the Territorial Papers permits the possibility of analyzing the entire corpus globally. Text mining and topic modeling methods give us a lens on the language patterns through which new state governments and the expanding nation were formed. An initial statistical analysis of the textual information provides a visualization of content, helps discern how ideals about governance emerged, and lays the foundation for developing more sophisticated hypotheses and theoretical constructs.",
 "article_title": "A case study in text mining: Textual analysis of the Territorial Papers",
 "authors": [
 {
 "given": " Johannes",
 "family": "Ledolter",
 "affiliation": [
 {
 "original_name": "Tippie College of Business, University of Iowa, IA, USA",
 "normalized_name": "University of Iowa",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/036jqmy94",
 "GRID": "grid.214572.7"
 }
 }
 ]
 },
 {
 "given": " Lea",
 "family": "VanderVelde",
 "affiliation": [
 {
 "original_name": "College of Law, University of Iowa, IA, USA",
 "normalized_name": "University of Iowa",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/036jqmy94",
 "GRID": "grid.214572.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-01-18",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz005",
 "identifier": {
 "string_id": "10.1093/llc/fqz005",
 "id_scheme": "DOI"
 },
 "abstract": "This article explores the linguistic features of different registers in Chinese through text clustering driven by the Menzerath–Altmann (MA) law. We propose to calculate the average word length distribution according to clause length. The MA law predicts that texts from different registers will show differences in terms of average word length distribution in texts. As predicted by the MA law, analysis result demonstrates that average word length decreases with the increase of clause length in each register and that their relationship can be fitted by the formula y = axbe-cx. We hypothesize that it is the situation type, i.e. whether the text is dialectic or monologue, that is the linguistic characteristic behind the dichotomy of word length distribution. To confirm these register-distinguishing linguistic features, texts were represented by the average word length distribution and the fitted parameters using the vector space model and clustered according to their register categories. Good clustering results show that average word length distribution in certain length clauses and their fitted parameters can be used as the distinctive characteristics of these three registers.",
 "article_title": "Linguistic characteristics of Chinese register based on the Menzerath—Altmann law and text clustering",
 "authors": [
 {
 "given": " Renkui",
 "family": "Hou",
 "affiliation": [
 {
 "original_name": "School of Humanities, Guangzhou University, China",
 "normalized_name": "Guangzhou University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/05ar8rn06",
 "GRID": "grid.411863.9"
 }
 },
 {
 "original_name": "Department of Chinese and Bilingual Studies, The Hong Kong Polytechnic University, Hong Kong",
 "normalized_name": "Hong Kong Polytechnic University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/0030zas98",
 "GRID": "grid.16890.36"
 }
 }
 ]
 },
 {
 "given": " Chu-Ren",
 "family": "Huang",
 "affiliation": [
 {
 "original_name": "Department of Chinese and Bilingual Studies, The Hong Kong Polytechnic University, Hong Kong",
 "normalized_name": "Hong Kong Polytechnic University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/0030zas98",
 "GRID": "grid.16890.36"
 }
 }
 ]
 },
 {
 "given": " Kathleen",
 "family": "Ahrens",
 "affiliation": [
 {
 "original_name": "Department of English, The Hong Kong Polytechnic University, Hong Kong",
 "normalized_name": "Hong Kong Polytechnic University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/0030zas98",
 "GRID": "grid.16890.36"
 }
 }
 ]
 },
 {
 "given": " Yat-Mei Sophia",
 "family": "Lee",
 "affiliation": [
 {
 "original_name": "Department of Chinese and Bilingual Studies, The Hong Kong Polytechnic University, Hong Kong",
 "normalized_name": "Hong Kong Polytechnic University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/0030zas98",
 "GRID": "grid.16890.36"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-01-18",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz001",
 "identifier": {
 "string_id": "10.1093/llc/fqz001",
 "id_scheme": "DOI"
 },
 "abstract": "In this article, we analyze the social networks of Paradise Lost at multiple scales of analysis: from the whole poem, down to the level of the individual book and character, and also through quantitative analysis of social network analysis metrics, to understand from multiple angles how network structure can inflect the plot and the effects of relationships between characters. In the case of Eve, our multiscaled analysis reveals her complex role binding together her social world in ways not previously considered. Only through examining the network do we see that Milton has placed her at the very center of the human universe, providing the primary connection between the reader and the world of God. This example shows promise that our multiscaled network analysis can come to important conclusions about the role of gender in a text, and the method can be expanded outward to come to conclusions about other social identities that likewise remain largely overlooked in current implementations of digital humanities scholarship.",
 "article_title": "Epic social networks and Eve's centrality in Milton’sParadise Lost",
 "authors": [
 {
 "given": " Claire",
 "family": "Ruegg",
 "affiliation": [
 {
 "original_name": "Department of English, Grinnell College, IA, USA",
 "normalized_name": "Grinnell College",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/04tmmky42",
 "GRID": "grid.256592.f"
 }
 }
 ]
 },
 {
 "given": " James Jaehoon",
 "family": "Lee",
 "affiliation": [
 {
 "original_name": "Digital Scholarship Center, University of Cincinnati, OH, USA",
 "normalized_name": "University of Cincinnati",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/01e3m7079",
 "GRID": "grid.24827.3b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-01-14",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz014",
 "identifier": {
 "string_id": "10.1093/llc/fqz014",
 "id_scheme": "DOI"
 },
 "abstract": "Nudging is simply guiding people behaviors by the use of user-interface and design elements in digital environments. Today, many decisions are made in online environments. Gaining insights about digital nudging can greatly help communicators, policy makers, and designers lead users to make the most desirable choice for them and/or for the wealth of the society as well. Digital nudges can be used in many digital environments like e-mail, SMS, push notifications, mobile apps, social media, gamification, e-commerce, e-government, location services, corporate digital information systems, and many other digital interfaces that include any kind of decision-making processes. This study is a descriptive study and more of a qualitative nature and aims to identify the digital nudging concept, dark patterns, and usage of digital nudges in real-life applications. It also proposes a brief digital nudging process schema to be used for designing behavioral digital interventions. ",
 "article_title": "Digital nudges and dark patterns: The angels and the archfiends of digital communication",
 "authors": [
 {
 "given": " Şebnem",
 "family": "Özdemir",
 "affiliation": [
 {
 "original_name": "Department of Public Relations and Publicity, Faculty of Communication, Sivas Cumhuriyet University, Sivas, Türkiye",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-02-18",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "35",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz011",
 "identifier": {
 "string_id": "10.1093/llc/fqz011",
 "id_scheme": "DOI"
 },
 "abstract": "Digital humanities projects have long relied on various schema languages—chiefly, RELAX NG and Schematron—for validating the XML documents in their data collections; however, these languages are limited in their ability to check for consistency, coherence, and completeness across the entire project. In our work as part of “Endings”, an umbrella project that comprises four diverse digital edition projects from different fields, we have developed a methodology for checking and enforcing correctness, completeness, and coherence across the entire document set. The following article describes the various stages (what we term “levels”) of our diagnostics process, all of which are driven by XSLT (Extensible Stylesheet Language Transformations) stylesheets, and produce a human readable report. These levels include checks for referential integrity, correct entity tagging, and potential duplicates in the data set. Using examples from the Endings projects, we show how diagnostic processes not only ensure correctness in the data set, but can also aid in determining project milestones and completion dates. Diagnostics, we argue, are thus a crucial extension to schema-based validation for complex digital projects and can provide concrete ways for digital humanities projects to enforce coherence and consistency and track their progress toward completion.",
 "article_title": "Beyond validation: Using programmed diagnostics to learn about, monitor, and successfully complete your DH project",
 "authors": [
 {
 "given": " Martin",
 "family": "Holmes",
 "affiliation": [
 {
 "original_name": "Humanities Computing and Media Centre, University of Victoria, Canada",
 "normalized_name": "University of Victoria",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04s5mat29",
 "GRID": "grid.143640.4"
 }
 }
 ]
 },
 {
 "given": " Joseph",
 "family": "Takeda",
 "affiliation": [
 {
 "original_name": "Department of English Language and Literatures, University of British Columbia, Canada",
 "normalized_name": "University of British Columbia",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03rmrcq20",
 "GRID": "grid.17091.3e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-02-08",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "Supplement_1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz015",
 "identifier": {
 "string_id": "10.1093/llc/fqz015",
 "id_scheme": "DOI"
 },
 "abstract": "Text analysis provides an exciting approach for extracting knowledge from text data. Recently, text analysis has been applied in many research fields. In this study, it was demonstrated that how text analysis can be applied to literary researches. All the lines of Khaghani’s Divan have been considered using different text analysis methods. Then the accuracy of the applied methods is compared.",
 "article_title": "Analysis of mystical concepts in Khaghani’s Divan",
 "authors": [
 {
 "given": " Ming-Ming",
 "family": "Yin",
 "affiliation": [
 {
 "original_name": "Department of Chinese Language and Literature, Hefei University, China",
 "normalized_name": "Hefei University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/01f5rdf64",
 "GRID": "grid.412053.1"
 }
 }
 ]
 },
 {
 "given": " Mohammad Reza",
 "family": "Mahmoudi",
 "affiliation": [
 {
 "original_name": "Department of Statistics, Faculty of Science, Fasa University, Iran",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Ali",
 "family": "Abbasalizadeh",
 "affiliation": [
 {
 "original_name": "Department of Persian Literature, Fasa University, Iran",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-02-18",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "35",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/digitalsh/fqz013",
 "identifier": {
 "string_id": "10.1093/digitalsh/fqz013",
 "id_scheme": "DOI"
 },
 "abstract": "In this article we establish a methodological and theoretical framework for the study of large collections of visual materials. Our framework, distant viewing, is distinguished from other approaches by making explicit the interpretive nature of extracting semantic metadata from images. In other words, one must ‘view’ visual materials before studying them. We illustrate the need for the interpretive process of viewing by simultaneously drawing on theories of visual semiotics, photography, and computer vision. Two illustrative applications of the distant viewing framework to our own research are draw upon to explicate the potential and breadth of the approach. A study of television series shows how facial detection is used to compare the role of actors within the narrative arcs across two competing series. An analysis of the Farm Security Administration–Office of War Information corpus of documentary photography is used to establish how photographic style compared and differed amongst those photographers involved with the collection. We then aim to show how our framework engages with current methodological and theoretical conversations occurring within the digital humanities.",
 "article_title": "Distant viewing: analyzing large visual corpora",
 "authors": [
 {
 "given": " Taylor",
 "family": "Arnold",
 "affiliation": [
 {
 "original_name": "Department of Mathematics and Computer Science, University of Richmond, Richmond, VA, USA",
 "normalized_name": "University of Richmond",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/03y71xh61",
 "GRID": "grid.267065.0"
 }
 }
 ]
 },
 {
 "given": " Lauren",
 "family": "Tilton",
 "affiliation": [
 {
 "original_name": "Department of Rhetoric and Communication Studies, University of Richmond, Richmond, VA, USA",
 "normalized_name": "University of Richmond",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/03y71xh61",
 "GRID": "grid.267065.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-03-17",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqz018",
 "identifier": {
 "string_id": "10.1093/llc/fqz018",
 "id_scheme": "DOI"
 },
 "abstract": "This research starts from the observation that Bernard Stiegler’s general organology draws from the philosophical rethinking of the original practice of organology in musicology. Stiegler’s main philosophical concepts that led to the establishment of general organology, as well as the trajectory of development of Stiegler’ general organology from his musical/musicological experience are discussed and explained. The main claim of this article is that the philosophical platform of general organology has an activist potential for the revitalization of the contemporary humanities and the transformation of the humanities into digital studies. This transformation takes place in the manner of two-level transcontextualization. The first level concerns the transcontextualization of the musicological organology into the general organology as a philosophical platform for understanding the phenomenological and ontological questions of a human being in the world mediated by digital technology. The second level concerns the activist potential of the general organology in relation to the humanities. The transformation of the humanities into digital studies is enabled through the transcontextualization of the general organology as the new, revitalized philosophical ground of the humanities that are dealing with the conditions of humanity in our contemporaneity. This means that digital studies involve not only the digital mediation of the knowledge, but researching that should be implemented in improving the humans' skills, knowledge, attention, and perceptive capabilities through digital technologies.",
 "article_title": "Digital studies and transcontextualization of the humanities: The case of organology",
 "authors": [
 {
 "given": " Sanela",
 "family": "Nikolić",
 "affiliation": [
 {
 "original_name": "Faculty of Music, University of Arts, Belgrade, Serbia",
 "normalized_name": "University of Arts",
 "country": "Albania",
 "identifiers": {
 "ror": "https://ror.org/030rcn265",
 "GRID": "grid.444949.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2019-02-22",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "35",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy063",
 "identifier": {
 "string_id": "10.1093/llc/fqy063",
 "id_scheme": "DOI"
 },
 "abstract": "Scattered throughout the International Tracing Service (ITS) digital archive, one of the largest and most heterogeneous collections of Holocaust-related material, are hundreds of thousands of reference cards to official death certificates recording a fraction of individuals who perished within concentration camps. These cards represent the most comprehensive collection of digital material pertaining to these death certificates issued by Sonderstandesamt Arolsen, a German civil registry office. However, the reference cards can only be found dispersed throughout the Central Name Index (CNI), ITS’s 46+ million-card finding aid that is indexed only by name. Consequently, aggregating the death certificate reference cards for research requires an intractable manual search. I adopt template matching and machine learning to automate the retrieval of these cards from the ITS digital archive. I demonstrate the efficacy of my method on a test set of 22,117 hand-classified cards, reporting 100% precision and 100% recall. Running this algorithm on 39,967,358 scans of cards from the CNI, I identify 312,183 death certificate reference cards in 13.75 days of elapsed real runtime on a personal computer with only a single, $600 Intel processor. Finally, I demonstrate that this approach can be generalized to many different card types within the CNI, showing great promise for application to other archives.",
 "article_title": "Machine learning, template matching, and the International Tracing Service digital archive: Automating the retrieval of death certificate reference cards from 40 million document scans",
 "authors": [
 {
 "given": " Benjamin Charles Germain",
 "family": "Lee",
 "affiliation": [
 {
 "original_name": "Levine Institute for Holocaust Education",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "Jack, Joseph and Morton Mandel Center for Advanced Holocaust Studies, United States Holocaust Memorial Museum, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "Visiting Fellow, Department of History, Harvard University Cambridge, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-10-24",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy066",
 "identifier": {
 "string_id": "10.1093/llc/fqy066",
 "id_scheme": "DOI"
 },
 "abstract": "Microattribution is the name of a method which has recently started to be used in the attribution of parts of early modern plays. The method seeks to make authorship attributions by using samples of writing consisting of less than two hundred words. This article argues that the method should not be used, fundamentally because it flouts the well-founded scientific insistence on the sufficiency of sample sizes. The article considers two recent applications of the method, showing that huge amounts of evidence were overlooked which would have invalidated the conclusions drawn. Moreover, the article demonstrates that the method is biased in favour of authors with large surviving canons, such as Shakespeare, and it cannot therefore be relied upon.",
 "article_title": "The problem of microattribution",
 "authors": [
 {
 "given": " Pervez",
 "family": "Rizvi",
 "affiliation": [
 {
 "original_name": "Independent student",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-10-24",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy062",
 "identifier": {
 "string_id": "10.1093/llc/fqy062",
 "id_scheme": "DOI"
 },
 "abstract": "Recent advances in data science and machine learning have enhanced our ability to analyze and understand the structure of social interactions in fictional stories by using formal and quantitative approaches. However, an objective assessment of these aspects of fictional stories remains a relatively new and technically difficult field. In this brief report, we introduce our study in which we modeled story dynamics from a novel perspective. By implementing a relational event model based on a two-mode network framework in an analytical system for movie scripts, we examined the interdependence of character activities and their participation in a given plot on the basis of an analysis of more than 900 scripts from the Internet Movie Script Database.",
 "article_title": "Representing stories as interdependent dynamics of character activities and plots: A two-mode network relational event model",
 "authors": [
 {
 "given": " Dingding",
 "family": "Chao",
 "affiliation": [
 {
 "original_name": "Department of Systems Innovation, The University of Tokyo, Japan",
 "normalized_name": "University of Tokyo",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/057zh3y96",
 "GRID": "grid.26999.3d"
 }
 }
 ]
 },
 {
 "given": " Taro",
 "family": "Kanno",
 "affiliation": [
 {
 "original_name": "Department of Systems Innovation, The University of Tokyo, Japan",
 "normalized_name": "University of Tokyo",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/057zh3y96",
 "GRID": "grid.26999.3d"
 }
 }
 ]
 },
 {
 "given": " Kazuo",
 "family": "Furuta",
 "affiliation": [
 {
 "original_name": "The University of Tokyo, Japan",
 "normalized_name": "University of Tokyo",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/057zh3y96",
 "GRID": "grid.26999.3d"
 }
 }
 ]
 },
 {
 "given": " Chen",
 "family": "Lin",
 "affiliation": [
 {
 "original_name": "Department of Systems Innovation, The University of Tokyo, Japan",
 "normalized_name": "University of Tokyo",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/057zh3y96",
 "GRID": "grid.26999.3d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-10-24",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy065",
 "identifier": {
 "string_id": "10.1093/llc/fqy065",
 "id_scheme": "DOI"
 },
 "abstract": "In this research we devised and implemented a semi-automatic approach for building a SageBook–a cross-generational social network of the Jewish sages from the Rabbinic literature. The proposed methodology is based on a shallow argumentation analysis leading to detection of lexical–syntactic patterns which represent different relationships between the sages in the text. The method was successfully applied and evaluated on the corpus of the Mishna, the first written work of the Rabbinic Literature which provides the foundation to the Jewish law development. The constructed prosopographical database and the network generated from its data enable a large-scale quantitative analysis of the sages and their related data, and therefore might contribute to the research of the Talmudic literature and evolution of the Jewish thought throughout the two last millennia.",
 "article_title": "SageBook: Toward a cross-generational social network for the Jewish sages’ prosopography",
 "authors": [
 {
 "given": " Maayan",
 "family": "Zhitomirsky-Geffet",
 "affiliation": [
 {
 "original_name": "Department of Information Science, Bar-Ilan University, Israel",
 "normalized_name": "Bar-Ilan University",
 "country": "Israel",
 "identifiers": {
 "ror": "https://ror.org/03kgsv495",
 "GRID": "grid.22098.31"
 }
 }
 ]
 },
 {
 "given": " Gila",
 "family": "Prebor",
 "affiliation": [
 {
 "original_name": "Department of Information Science, Bar-Ilan University, Israel",
 "normalized_name": "Bar-Ilan University",
 "country": "Israel",
 "identifiers": {
 "ror": "https://ror.org/03kgsv495",
 "GRID": "grid.22098.31"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-10-24",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy061",
 "identifier": {
 "string_id": "10.1093/llc/fqy061",
 "id_scheme": "DOI"
 },
 "abstract": "In the late evening of 18 March 2014, students and activists stormed into and occupied the main chamber of Taiwan's Legislature. The event set off the Sunflower Movement, signifying a turning point in Taiwan's recent history. Researchers at Academia Sinica arranged to acquire all the supporting artifacts and documentary materials in the chamber before the protest came to a peaceful end. In this article, we discuss the issues in archiving and making available to the public a large collection of artifacts created by thousands of participants during a contemporary event. We demonstrate systems designed to encourage people to identify objects of their own in the archive. We show how an accessible catalog to the archive can help people tell their stories, hence collectively may strengthen the public's recollections about the movement.",
 "article_title": "Remembrance of contemporary events: On setting up the Sunflower Movement Archive",
 "authors": [
 {
 "given": " Tyng-Ruey",
 "family": "Chuang",
 "affiliation": [
 {
 "original_name": "Institute of Information Science, Research Center for Information Technology Innovation and the Research Center for Humanities and Social Sciences, Academia Sinica, Taiwan",
 "normalized_name": "Institute of Information Science",
 "country": "Slovenia",
 "identifiers": {
 "ror": "https://ror.org/055q8rh54",
 "GRID": "grid.493361.a"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-10-24",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "Supplement_1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy064",
 "identifier": {
 "string_id": "10.1093/llc/fqy064",
 "id_scheme": "DOI"
 },
 "abstract": "The recent digital-born electronic literature has heterogeneous components such as kinetic texts, kinetic images, graphical designs, sounds, and videos. These digital components are embedded with the main text as the paratext of print and digital works such as preface, author’s name, illustrations, and title. However, the comparative study between paratext and embedded paratext of electronic literature shows the different strategic patterns and functions of these entities. We discuss the conceptual framework of illuminant devices of paratexts and propose a new term technoeikon to recognize the functions of embedded literary artifact in digital literary works. We examine the critical construction of new term technoeikon which has a unique characteristic that makes electronic literary works different from print literature. This essay reviews the cyclical process of technoeikon from the historical perspective of pre-print culture and print culture and acknowledges technoeikon as inherited from our tradition. Due to digital contrivances, technoeikon takes a new expression as performing in digital ecology which is different from our traditional analog. This article presents a case study on Andy Campbell's (2007b) Dim O'Gauble. Also, Campbell responds to the interpretation of new term technoeikon in the fourth section of the essay.",
 "article_title": "An introduction to the functioning process of embedded paratext of digital literature: Technoeikon of digital poetry",
 "authors": [
 {
 "given": " T",
 "family": "Shanmugapriya",
 "affiliation": [
 {
 "original_name": "Digital Humanities and Publishing Studies Research Group, School of Humanities and Social Sciences, Indian Institute of Technology Indore, India",
 "normalized_name": "Indian Institute of Technology Indore",
 "country": "India",
 "identifiers": {
 "ror": "https://ror.org/01hhf7w52",
 "GRID": "grid.450280.b"
 }
 }
 ]
 },
 {
 "given": " Nirmala",
 "family": "Menon",
 "affiliation": [
 {
 "original_name": "Digital Humanities and Publishing Studies Research Group, School of Humanities and Social Sciences, Indian Institute of Technology Indore, India",
 "normalized_name": "Indian Institute of Technology Indore",
 "country": "India",
 "identifiers": {
 "ror": "https://ror.org/01hhf7w52",
 "GRID": "grid.450280.b"
 }
 }
 ]
 },
 {
 "given": " Andy",
 "family": "Campbell",
 "affiliation": [
 {
 "original_name": "One to One Development Trust, UK",
 "normalized_name": "One to One Development Trust",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/03nnaq439",
 "GRID": "grid.500662.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-10-24",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy050",
 "identifier": {
 "string_id": "10.1093/llc/fqy050",
 "id_scheme": "DOI"
 },
 "abstract": "Statistical approaches have become the mainstream in machine translation (MT), for their potential in producing less rigid and more natural translations than rule-based approaches. However, on closer examination, the uses of function words between statistical machine-translated Chinese and the original Chinese are different, and such differences may be associated with translationese as discussed in translation studies. This article examines the distribution of Chinese function words in a comparable corpus consisting of MTs and the original Chinese texts extracted from Wikipedia. An attribute selection technique is used to investigate which types of function words are significant in discriminating between statistical machine-translated Chinese and the original texts. The results show that statistical MT overuses the most frequent function words, even when alternatives exist. To improve the quality of the end product, developers of MT should pay close attention to modelling Chinese conjunctions and adverbial function words. The results also suggest that machine-translated Chinese shares some characteristics with human-translated texts, including normalization and being influenced by the source language; however, machine-translated texts do not exhibit other characteristics of translationese such as explicitation.",
 "article_title": "Function words in statistical machine-translated Chinese and original Chinese: A study into the translationese of machine translation systems",
 "authors": [
 {
 "given": " Chen-li",
 "family": "Kuo",
 "affiliation": [
 {
 "original_name": "Chang Gung Memorial Hospital and Chang Gung University, Taiwan",
 "normalized_name": "Chang Gung University",
 "country": "Taiwan",
 "identifiers": {
 "ror": "https://ror.org/00d80zx46",
 "GRID": "grid.145695.a"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-29",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy067",
 "identifier": {
 "string_id": "10.1093/llc/fqy067",
 "id_scheme": "DOI"
 },
 "abstract": "We describe the first wide results of the linguistic profiling of the Common European Framework of Reference (CEFR)-levelled English Corpus (CLEC), a corpus built up for Natural Language Processing purposes. The CLEC is a proficiency-levelled English corpus that covers A1, A2, B1, B2, and C1 CEFR levels and that has been built up to train statistic models for automatic proficiency assessment. We describe not only the main aspects of the corpus development but also display the linguistic features and the statistic results for levels A2, B1, and B2 written examples, carried out automatically. We show how raw text, lexical, morphosyntactic, or syntactic statistic outcomes can help to identify levels of proficiency, to test teaching materials accurate proficiency classification, to provide computable support to new text proficiency validation, and to specify level boundaries. In fact, upper levels strengthen proficiency by showing higher outcomes of lexical and syntactic complexity. This analysis validates the use of automatic tools for proficiency level identification based on lexical and syntactic data, whereas morphosyntactic features strengthen competence-level distinctions. Finally, we suggest that these results are a first step onto the CEFR-levelled automatic assessment of new texts.",
 "article_title": "Automatic profiling of L2-simplified texts: Identifying discriminate features of linguistic proficiency",
 "authors": [
 {
 "given": " Maria Angeles",
 "family": "Zarco-Tejada",
 "affiliation": [
 {
 "original_name": "Department of French and English Philology, University of Cádiz",
 "normalized_name": "University of Cádiz",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/04mxxkb11",
 "GRID": "grid.7759.c"
 }
 },
 {
 "original_name": "Applied Linguistics Institute, University of Cádiz",
 "normalized_name": "University of Cádiz",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/04mxxkb11",
 "GRID": "grid.7759.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-10-24",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy069",
 "identifier": {
 "string_id": "10.1093/llc/fqy069",
 "id_scheme": "DOI"
 },
 "abstract": "Statistics and data mining techniques provide exciting approaches for extracting knowledge from data. Recently, using statistics and data mining has sought to be exploited in many research fields. In this study, it was demonstrated that how statistics can be applied to literary studies. First, all the lines in Khaghani’s divan are classified and coded into three categories (mystical, non-mystical, and borderline). Then a set of chi-square goodness-of-fit tests are used to investigate and compare the frequency of different line’s categories for all lines and all odes, separately. Finally, the chi-square independence test (crosstabs) is employed to investigate the existence of trend in the lines.",
 "article_title": "How statistics and text mining can be applied to literary studies?",
 "authors": [
 {
 "given": " Mohammad Reza",
 "family": "Mahmoudi",
 "affiliation": [
 {
 "original_name": "Department of Statistics, Faculty of Science, Fasa University, Iran",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Ali",
 "family": "Abbasalizadeh",
 "affiliation": [
 {
 "original_name": "Department of Persian Literature, Fasa University, Iran",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-10-24",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy068",
 "identifier": {
 "string_id": "10.1093/llc/fqy068",
 "id_scheme": "DOI"
 },
 "abstract": "Although music is an important part of cremation rituals, there is hardly any research regarding music and cremations. This lack of research has inspired the authors to conduct a long-term research project, focusing on musical and linguistic aspects of music played during cremations. This article presents the analysis of a playlist consisting of twenty-five sets of music, each consisting of three tracks, used in a crematorium in the south of The Netherlands from 1986 onward. The main objective is to identify the differences and similarities of the twenty-five sets of musical tracks regarding content and musical properties. Consequently, we aim to provide insight in the history of (music played during) cremation rituals in The Netherlands. To analyze the musical properties of the sets, the authors use both a qualitative approach (close reading and musical analysis) and a computational analysis approach. The article demonstrates that a combination of a close reading and musical analysis and a computational analysis is necessary to explain the differences in properties of the sets. The presented multi-method approach may allow for comparisons against musical preferences in the context of current cremations, which makes it possible to trace the development of music and cremation rituals.",
 "article_title": "Music and cremation rituals in The Netherlands: A fine-grained analysis of a crematorium’s playlist",
 "authors": [
 {
 "given": " Doris",
 "family": "van der Smissen",
 "affiliation": [
 {
 "original_name": "Tilburg School of Humanities and Digital Sciences, Tilburg University, The Netherlands",
 "normalized_name": "Tilburg University",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/04b8v1s79",
 "GRID": "grid.12295.3d"
 }
 }
 ]
 },
 {
 "given": " Margaret A",
 "family": "Steenbakker",
 "affiliation": [
 {
 "original_name": "Tilburg School of Humanities and Digital Sciences, Tilburg University, The Netherlands",
 "normalized_name": "Tilburg University",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/04b8v1s79",
 "GRID": "grid.12295.3d"
 }
 }
 ]
 },
 {
 "given": " Martin J M",
 "family": "Hoondert",
 "affiliation": [
 {
 "original_name": "Tilburg School of Humanities and Digital Sciences, Tilburg University, The Netherlands",
 "normalized_name": "Tilburg University",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/04b8v1s79",
 "GRID": "grid.12295.3d"
 }
 }
 ]
 },
 {
 "given": " Menno M",
 "family": "van Zaanen",
 "affiliation": [
 {
 "original_name": "Tilburg School of Humanities and Digital Sciences, Tilburg University, The Netherlands",
 "normalized_name": "Tilburg University",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/04b8v1s79",
 "GRID": "grid.12295.3d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-10-30",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy060",
 "identifier": {
 "string_id": "10.1093/llc/fqy060",
 "id_scheme": "DOI"
 },
 "abstract": "This article describes methods that can be used to construct a Latin morphological and syntactic parser, including resources that enable reordering the sentence according to the SVO (subject + verb + object) standard order, aiming to facilitate the translation of Latin phrases by users. The article also addresses the solutions that can be implemented to overcome some of the problems found in this context, namely, the difficulties in accessing different forms of dictionarization, the lack of lexicographic resources, and a methodology for processing the ‘special constructions’ required by adverbs and adjectives.",
 "article_title": "Deciphering Latin sentences using traditional linguistic resources",
 "authors": [
 {
 "given": " Cláudia",
 "family": "Teixeira",
 "affiliation": [
 {
 "original_name": "Departamento Linguística e Literaturas, Universidade de Évora, Portugal",
 "normalized_name": "University of Évora",
 "country": "Portugal",
 "identifiers": {
 "ror": "https://ror.org/02gyps716",
 "GRID": "grid.8389.a"
 }
 },
 {
 "original_name": "Centro de Estudos Clássicos e Humanísticos, Portugal",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Irene",
 "family": "Rodrigues",
 "affiliation": [
 {
 "original_name": "Departamento de Informática, Universidade de Évora, Portugal",
 "normalized_name": "University of Évora",
 "country": "Portugal",
 "identifiers": {
 "ror": "https://ror.org/02gyps716",
 "GRID": "grid.8389.a"
 }
 },
 {
 "original_name": "Laboratório de Informática Sistemas e Paralelismo, Portugal",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-12-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy071",
 "identifier": {
 "string_id": "10.1093/llc/fqy071",
 "id_scheme": "DOI"
 },
 "abstract": "The Guidelines of the Text Encoding Initiative are generally recognized in the digital humanities as important and foundational standards for many types of research in the field. The TEI Guidelines are generalistic, seeking to enable the largest possible user base encoding digital texts for a wide range of purposes. Consulting on many TEI-based projects, teaching TEI workshops, and volunteering as part of the TEI Technical Council, I have encountered many myths, misconceptions, and misunderstandings about the TEI. Indeed, one plenary lecturer once claimed ‘the problem with the TEI is it has too many tags and there is no way to change it’. Inspired by myths such as this, this article will detail common misconceptions about the TEI that I have encountered, concentrating on those technical myths that will help increase knowledge about the TEI misconceptions along the way. The article ends with a consideration of why these myths might have arisen, and what might be able to be done about them.",
 "article_title": "A world of difference: Myths and misconceptions about the TEI",
 "authors": [
 {
 "given": " James",
 "family": "Cummings",
 "affiliation": [
 {
 "original_name": "Newcastle University, UK",
 "normalized_name": "University of Newcastle Australia",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00eae9z71",
 "GRID": "grid.266842.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-19",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy078",
 "identifier": {
 "string_id": "10.1093/llc/fqy078",
 "id_scheme": "DOI"
 },
 "abstract": "The question of why Pablo Picasso dedicated a considerable amount of his time to writing around 1935 is open to speculation. Many have cited, among possible causes: the Spanish artist’s emotional crisis, the political turmoil in Europe in the period between the two wars, and the menace of a confrontation in Spain. All of these views are predicated on an assumed irreducible conflict between visual composition and verbal expression. However, we cannot forget that Picasso’s interest in alternative methods of expression might have started with his fascination for linguistic structure as a whole during his cubist period. In this article, we explore the possibility that the transition into poetry that we observe in Picasso is simply one more manifestation of his pursuit of alternative approaches to language as a means of representation. In this sense, one thing that remained to be determined was how concrete concepts in both languages cluster into representative semantic categories and how these categories interact with each other in semantic networks.",
 "article_title": "Semantic domains in Picasso’s poetry",
 "authors": [
 {
 "given": " Luis",
 "family": "Meneses",
 "affiliation": [
 {
 "original_name": "Electronic Textual Cultures Laboratory, University of Victoria, Canada",
 "normalized_name": "University of Victoria",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04s5mat29",
 "GRID": "grid.143640.4"
 }
 }
 ]
 },
 {
 "given": " Enrique",
 "family": "Mallen",
 "affiliation": [
 {
 "original_name": "Department of Foreign Languages, Sam Houston State University, USA",
 "normalized_name": "Sam Houston State University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00yh3cz06",
 "GRID": "grid.263046.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-30",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "Supplement_1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy072",
 "identifier": {
 "string_id": "10.1093/llc/fqy072",
 "id_scheme": "DOI"
 },
 "abstract": "The article proposes, justifies, and tests a new methodological framework to measure museum ‘soft power’ by employing geo-visualization as a new method empowered by the rapid development of digital humanities. This research not only demystifies the buzz term of ‘soft power’ that is frequently applied in relation to contemporary museums and their international cultural engagements but also develops an evaluation framework to assess museum capacities to exert global impacts. Specifically, the article draws on the academic scholarship outlining a plethora of approaches for ‘soft power’ evaluation, including Resources, Outputs, Perceptions, and Networks evaluation models. It argues for a new integrative approach that can comprehensively combine different methods to construct a more advanced tool to measure museum ‘soft power’. The article draws on preliminary results of developing a digital mapping system to assess museum soft power. It shares findings from the pilot project, Australian Center of the Moving Image (ACMI) on the Global Map, designed in collaboration with the ACMI in Melbourne.",
 "article_title": "Mapping museum ‘Soft Power’: Adding geo-visualization to the methodological framework",
 "authors": [
 {
 "given": " Natalia",
 "family": "Grincheva",
 "affiliation": [
 {
 "original_name": "Research Unit in Public Cultures, The University of Melbourne, Australia",
 "normalized_name": "University of Melbourne",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/01ej9dk98",
 "GRID": "grid.1008.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-20",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy070",
 "identifier": {
 "string_id": "10.1093/llc/fqy070",
 "id_scheme": "DOI"
 },
 "abstract": "Identifying the stylistic signatures characteristic of different genres is of central importance to literary theory and criticism. In this article we report a large-scale computational analysis of Latin prose and verse using a combination of quantitative stylistics and supervised machine learning. We train a set of classifiers to differentiate prose and poetry with high accuracy (>97%) based on a set of twenty-six text-based, primarily syntactic features and rank the relative importance of these features to identify a low-dimensional set still sufficient to achieve excellent classifier performance. This analysis demonstrates that Latin prose and verse can be classified effectively using just three top features. From examination of the highly ranked features, we observe that measures of the hypotactic style favored in Latin prose (i.e. subordinating constructions in complex sentences, such as relative clauses) are especially useful for classification.",
 "article_title": "A small set of stylometric features differentiates Latin prose and verse",
 "authors": [
 {
 "given": " Pramit",
 "family": "Chaudhuri",
 "affiliation": [
 {
 "original_name": "Department of Classics, University of Texas at Austin, TX, USA",
 "normalized_name": "The University of Texas at Austin",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00hj54h04",
 "GRID": "grid.89336.37"
 }
 }
 ]
 },
 {
 "given": " Tathagata",
 "family": "Dasgupta",
 "affiliation": [
 {
 "original_name": "Department of Systems Biology, Harvard Medical School, MA, USA",
 "normalized_name": "Harvard Medical School",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/03wevmz92",
 "GRID": "grid.471403.5"
 }
 }
 ]
 },
 {
 "given": " Joseph P",
 "family": "Dexter",
 "affiliation": [
 {
 "original_name": "Department of Systems Biology, Harvard Medical School, MA, USA",
 "normalized_name": "Harvard Medical School",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/03wevmz92",
 "GRID": "grid.471403.5"
 }
 }
 ]
 },
 {
 "given": " Krithika",
 "family": "Iyer",
 "affiliation": [
 {
 "original_name": "Plano East Senior High School, TX, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "Center for Excellence in Education, Research Science Institute, VA, US",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-10-30",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy073",
 "identifier": {
 "string_id": "10.1093/llc/fqy073",
 "id_scheme": "DOI"
 },
 "abstract": "While the challenge of historical reconstruction of past musical performances is not a fully solved problem, not all the elements are equally unknown, or of equal magnitude. Despite some uncertainty about the interpretation of individual performers on specific dates, scholarship can still inform other factors of greater perceptual importance, leading to a good approximation of historical performances. In addition to performance style and period instruments, computer simulations make it possible to also account for the acoustics of the period performance space. In addition, the most accurate reconstruction should simulate the room’s acoustics in real time for the performers, thus retaining the feedback mechanisms of room response on performance practice.",
 "article_title": "Computational acoustic musicology",
 "authors": [
 {
 "given": " Braxton B",
 "family": "Boren",
 "affiliation": [
 {
 "original_name": "Audio Technology, Department of Performing Arts, American University, USA",
 "normalized_name": "American University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/052w4zt36",
 "GRID": "grid.63124.32"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-15",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy081",
 "identifier": {
 "string_id": "10.1093/llc/fqy081",
 "id_scheme": "DOI"
 },
 "abstract": "The course of reprocessing knowledge and information about social sciences and humanities using digital technology is taking root as a new field of academia called the ‘digital humanities’ (DH). While the social sciences and humanities in South Korea have shown a marked reluctance toward the integration of digital technology, the perception of its necessity as a new methodology for developing these fields in the digital age is growing. Until recently, analytical studies on the status and contents of DH were conducted on data from the western world. Despite their late start, however, Asian countries have begun conducting research on DH with enthusiasm. In order for DH to be properly established in each country, it is essential to set the direction by investigating the pre-requisites for DH studies in that country, as well as the current and future demands. As such, this study discusses the current status and issues regarding DH in South Korea by analyzing the trends of DH research published in South Korea, as well as by examining the status and perception of DH among actual scholars. Based on this study’s findings, we present strategies for improving education programs on DH in South Korea and promulgate the necessity of using DH methodologies in the study of social sciences and humanities to develop global networks and academic communication.",
 "article_title": "Digital humanities and new directions in South Korea",
 "authors": [
 {
 "given": " Jisu",
 "family": "Lee",
 "affiliation": [
 {
 "original_name": "Research Institution of Korean Studies, Korea University, Seoul, Korea",
 "normalized_name": "Korea University",
 "country": "South Korea",
 "identifiers": {
 "ror": "https://ror.org/047dqcg40",
 "GRID": "grid.222754.4"
 }
 }
 ]
 },
 {
 "given": " Hye-Eun",
 "family": "Lee",
 "affiliation": [
 {
 "original_name": "Department of Library and Information Science, Sookmyung Women’s University, Seoul, Korea",
 "normalized_name": "Sookmyung Women's University",
 "country": "South Korea",
 "identifiers": {
 "ror": "https://ror.org/00vvvt117",
 "GRID": "grid.412670.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-12-03",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy079",
 "identifier": {
 "string_id": "10.1093/llc/fqy079",
 "id_scheme": "DOI"
 },
 "abstract": "A large portion of the research carried out in the digital humanities has an online digital object (usually referred as a project) as one of its components. In turn, these online digital objects can be catalogued as distributed resources, which implies that the administrative control of information related to a topic may be spread across online resources and/or collections maintained by multiple scholars in different institutions. This administrative decentralization can lead to changes in content that are often unexpected by a researcher, which can be caused by different factors or circumstances. This reasoning led us to formulate the following question: When can online digital humanities projects be considered abandoned? In this article, we carry out a study on the persistence and average life span of online projects in the digital humanities. More specifically, we will elaborate on their reliance on distributed resources and methods for measuring their shelf life: the average length of time that a digital project can endure without updates until it can ultimately be considered abandoned by its researcher.",
 "article_title": "Shelf life: Identifying the abandonment of online digital humanities projects",
 "authors": [
 {
 "given": " Luis",
 "family": "Meneses",
 "affiliation": [
 {
 "original_name": "Electronic Textual Cultures Laboratory, University of Victoria, Canada",
 "normalized_name": "University of Victoria",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04s5mat29",
 "GRID": "grid.143640.4"
 }
 }
 ]
 },
 {
 "given": " Richard",
 "family": "Furuta",
 "affiliation": [
 {
 "original_name": "Center for the Study of Digital Libraries, Texas A&M University, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-30",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "Supplement_1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy082",
 "identifier": {
 "string_id": "10.1093/llc/fqy082",
 "id_scheme": "DOI"
 },
 "abstract": "This article addresses an important challenge in artificial intelligence research in the humanities, which has impeded progress with supervised methods. It introduces a novel method to creating test collections from smaller subsets. This method is based on what we will introduce as distant supervision’ and will allow us to improve computational modelling in the digital humanities by including new methods of supervised learning. Using recurrent neural networks, we generated a training corpus and were able to train a highly accurate model that qualitatively and quantitatively improved a baseline model. To demonstrate our new approach experimentally, we employ a real-life research question based on existing humanities collections. We use neural network based sentiment analysis to decode Holocaust memories and present a methodology to combine supervised and unsupervised sentiment analysis to analyse the oral history interviews of the United States Holocaust Memorial Museum. Finally, we employed three advanced methods of computational semantics. These helped us decipher the decisions by the neural network and understand, for instance, the complex sentiments around family memories in the testimonies.",
 "article_title": "Understanding memories of the Holocaust—A new approach to neural networks in the digital humanities",
 "authors": [
 {
 "given": " Tobias",
 "family": "Blanke",
 "affiliation": [
 {
 "original_name": "Department of Digital Humanities, King's College London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 },
 {
 "given": " Michael",
 "family": "Bryant",
 "affiliation": [
 {
 "original_name": "Department of Digital Humanities, King's College London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 },
 {
 "given": " Mark",
 "family": "Hedges",
 "affiliation": [
 {
 "original_name": "Department of Digital Humanities, Centre for e-Research, King's College London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-12-04",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "35",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy023",
 "identifier": {
 "string_id": "10.1093/llc/fqy023",
 "id_scheme": "DOI"
 },
 "abstract": "The R Stylo program features, Rolling Delta and Rolling Classify, were applied to Thomas Kyd’s closet drama Cornelia. After the elimination of a large number of unsuitable reference texts, Marlowe’s Tamburlaine 1 turned out to be the play with the lowest delta values; that is it showed the smallest stylistic difference from Cornelia. In previous investigations the anonymous play The Tragedy of Locrine had been identified as a play by Christopher Marlowe (see Appendix). In a double check the procedures were repeated with Locrine, and it was Locrine in particular that came to the foreground. This was confirmed by traditional stylometric measurements like bootstrap consensus trees, multivariate analyses, and multidimensional scaling. Craig’s Zeta located Cornelia’s preferred vocabulary in the vicinity of the Marlowe compound. The safe conclusion is that Cornelia’s real provenance is Christopher Marlowe, who had shared lodgings with Kyd before he was killed by fellow government agent Frizer in Deptford on 30 May 1593. ",
 "article_title": "Forensic stylometry",
 "authors": [
 {
 "given": " Hartmut",
 "family": "Ilsemann",
 "affiliation": [
 {
 "original_name": "English Department, Leibniz Universität Hannover, Königsworther Platz 1, 30167 Hannover, Germany",
 "normalized_name": "University of Hannover",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/0304hq317",
 "GRID": "grid.9122.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy039",
 "identifier": {
 "string_id": "10.1093/llc/fqy039",
 "id_scheme": "DOI"
 },
 "abstract": "Zeta has been described as ‘the most powerful general-purpose authorship tool currently available.’ It has been used to attribute parts of Arden of Faversham to Shakespeare and parts of 3 Henry VI to Marlowe, among other uses. The method was invented by John Burrows, but it is currently used in an adapted form developed by Hugh Craig. This article demonstrates that the method has not been adapted into its simplest form, thereby obscuring a true understanding of what it does. The article proposes an improvement to the method, which makes it easier to implement and may also help to improve researchers’ understanding of it, without affecting the results of Zeta tests already completed.",
 "article_title": "An improvement to Zeta",
 "authors": [
 {
 "given": " Pervez",
 "family": "Rizvi",
 "affiliation": [
 {
 "original_name": "Independent student",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-09-07",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy031",
 "identifier": {
 "string_id": "10.1093/llc/fqy031",
 "id_scheme": "DOI"
 },
 "abstract": "Recent research has demonstrated the potential of corpus linguistics as a solid aid in children’s understanding of how language works. However, the availability of data from the UK is still somewhat limited. Most corpora are either based on a small number of schools, synchronic in nature, or focused on the post-National Curriculum era (cf. Lancaster Corpus of Children’s Project Writing, the Oxford Children’s Corpus, the Growth in Grammar Corpus); on the other hand, historical corpora are, unfortunately, not publicly available in electronic format (cf. the Child Language Survey or the Aspects of Writing in 16+ English Examinations, Cambridge Assessment). This article introduces the APU Writing and Reading Corpus 1979–1988, a new large electronic data set of historical materials which are linguistically annotated. The aim is two-fold. First, to describe the contents of the corpus and its compilation procedure. Second, to illustrate its potential as a research and pedagogical tool by presenting a number of research case studies and teaching materials that are currently being developed based on the corpus data. All in all, the Assessment Performance Unit (APU) Corpus contributes to both Corpus Linguistics and Educational Linguistics by presenting itself as a new resource tool with replicable methodology and objective empirical evidence, which will be of interest to academics and school teachers as well as to school material developers and policymakers.",
 "article_title": "‘he liked to read, write, and whatch televishon’—The APU Writing and Reading Corpus (1979–1988)",
 "authors": [
 {
 "given": " Nuria",
 "family": "Yáñez-Bouza",
 "affiliation": [
 {
 "original_name": "Universidade de Vigo, Facultade de Filoloxía e Tradución, Filoloxía Inglesa, Francesa e Alemá, Spain",
 "normalized_name": "Universidade de Vigo",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/05rdf8595",
 "GRID": "grid.6312.6"
 }
 }
 ]
 },
 {
 "given": " Victorina",
 "family": "González-Díaz",
 "affiliation": [
 {
 "original_name": "University of Liverpool, Department of English, School of The Arts, UK",
 "normalized_name": "University of Liverpool",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04xs57h96",
 "GRID": "grid.10025.36"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-09-10",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy043",
 "identifier": {
 "string_id": "10.1093/llc/fqy043",
 "id_scheme": "DOI"
 },
 "abstract": "In the summer of 2012, the Institute of Fine Arts, New York University Selinunte Mission began to explore the interior of the cella of Temple R. This excavation showed that the classical and archaic layers had been sealed by a deep fill of the Hellenistic period and left untouched by earlier archaeological research at the site. Among the discoveries were a series of votive depositions positioned against the walls, dating to the sixth century BCE. One of the most striking finds among those votive depositions was the discovery of two parts of a bone aulos, which can be dated to 570 BCE. The virtual reconstruction of the aulos found in Temple R at Selinunte aims to increase and improve its scientific investigation, overcoming the limitations caused by the fragility of the instrument. Digital technology has allowed us to produce a three-dimensional (3D) model of the aulos. This digital model has been translated into a 3D artificial copy, using polymer as a material. Our goal is to reconstruct the aulos, after analysing its organological characteristics. We also hope that this new study of the aulos will increase our knowledge of Ancient Greek music.",
 "article_title": "Towards a new approach in the study of Ancient Greek music: Virtual reconstruction of an ancient musical instrument from Greek Sicily",
 "authors": [
 {
 "given": " Angela",
 "family": "Bellia",
 "affiliation": [
 {
 "original_name": "Institute for Archaeological and Monumental Heritage, National Research Council of Italy",
 "normalized_name": "Institute for Archaeological and Monumental Heritage",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/00x5wpm25",
 "GRID": "grid.503058.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-09-11",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy035",
 "identifier": {
 "string_id": "10.1093/llc/fqy035",
 "id_scheme": "DOI"
 },
 "abstract": "We compare the scope of museum digitization in the Russian Federation, a country with diverse cultural heritage and over 2,300 museums, with the scope of digitization in Europe as measured by the Enumerate Survey of 355 museums from twenty European countries initiated by the Collections Trust, UK, in 2011. Our article shows that the reach and scope of digitization in Russia is lesser than that of European museums. Digitization is mainly done in Russia for inventory purposes. The share of digitized objects published online is comparable to that in Europe if we consider images published on museum websites; however, much content from Russia is not licensed as reusable, partly due to the different legal framework that exists there. The article challenges the perceptions that global heritage collections are becoming more visible and accessible. It shows that future digital analysis of cultural heritage may be only possible with corpora of images provided by museums that publish numerous images from their digital collections online while pursuing the policies of free image reuse alongside open licensing. Such corpora may not be found beyond a limited number of Western collections, which may result in excluding many cultures from humanities research.",
 "article_title": "Accessing Russian culture online: The scope of digitization in museums across Russia",
 "authors": [
 {
 "given": " Inna",
 "family": "Kizhner",
 "affiliation": [
 {
 "original_name": "Siberian Federal University, Krasnoyarsk, Krasnoyarskiy Kray, Russia",
 "normalized_name": "Siberian Federal University",
 "country": "Russia",
 "identifiers": {
 "ror": "https://ror.org/05fw97k56",
 "GRID": "grid.412592.9"
 }
 }
 ]
 },
 {
 "given": " Melissa",
 "family": "Terras",
 "affiliation": [
 {
 "original_name": "College of Arts, Humanities, and Social Sciences, University of Edinburgh, Edinburgh, Midlothian, Scotland",
 "normalized_name": "University of Edinburgh",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01nrxwf90",
 "GRID": "grid.4305.2"
 }
 }
 ]
 },
 {
 "given": " Maxim",
 "family": "Rumyantsev",
 "affiliation": [
 {
 "original_name": "Siberian Federal University, Krasnoyarsk, Krasnoyarskiy Kray, Russia",
 "normalized_name": "Siberian Federal University",
 "country": "Russia",
 "identifiers": {
 "ror": "https://ror.org/05fw97k56",
 "GRID": "grid.412592.9"
 }
 }
 ]
 },
 {
 "given": " Kristina",
 "family": "Sycheva",
 "affiliation": [
 {
 "original_name": "Siberian Federal University, Krasnoyarsk, Krasnoyarskiy Kray, Russia",
 "normalized_name": "Siberian Federal University",
 "country": "Russia",
 "identifiers": {
 "ror": "https://ror.org/05fw97k56",
 "GRID": "grid.412592.9"
 }
 }
 ]
 },
 {
 "given": " Ivan",
 "family": "Rudov",
 "affiliation": [
 {
 "original_name": "Siberian Federal University, Krasnoyarsk, Krasnoyarskiy Kray, Russia",
 "normalized_name": "Siberian Federal University",
 "country": "Russia",
 "identifiers": {
 "ror": "https://ror.org/05fw97k56",
 "GRID": "grid.412592.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy028",
 "identifier": {
 "string_id": "10.1093/llc/fqy028",
 "id_scheme": "DOI"
 },
 "abstract": "In this article, we describe and contrast relevant properties of two electronic registers of Jakarta Indonesian instant messaging, or SMS, and Twitter against a continuum of conversation and writing features. Many linguists (Crystal, 2008, Txting: the Gr8 Db8. Oxford University Press; Carter and McCarthy, 2015, Applied Linguistics, 38(1): 1–20; McWhorter, 2013; Sindoni, 2013, Spoken and Written Discourse in Online Interactions. New York, NY; London: Routledge) have turned their attention to the properties of language evidenced in various social media. Taken as a whole, electronic media have become the predominant channel of non-speech language interaction (CNN.com reports (11/3/2015) that teens spend nine hours a day on electronic media: www.cnn.com/2015/11/03/health/). However, the study of these media is still in its early stages and, in our opinion, suffers from two flaws: instant messaging is relatively understudied, given its prevalence; and contrastive studies of different media are also rare (but cf. Danet and Herring’s, 2007, Handbook of Language and Communication: Diversity and Change. Handbook of Applied Linguistics, vol. 9. Berlin: Mouton De Gruyter, review of genre-specific analyses). Similarly, most linguistic studies we are aware of take European languages as the object of study; since any contrastive or variationist study takes the grammatical features of some standard as its point of departure, insights into register-based variation are limited by the typological features of the language. As a highly isolating, free word order language, Indonesian represents a typologically very different basic grammar from which to view register-based variation. This study contributes to the broadening of linguistic study of social media by contrasting rather than conflating two media, demonstrating that different register properties are associated with distinct social media platforms.",
 "article_title": "Distinguishing properties of SMS and Twitter in Indonesian: A contrastive study",
 "authors": [
 {
 "given": " Claudia M",
 "family": "Brugman",
 "affiliation": [
 {
 "original_name": "University of Maryland, College Park, MD, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Thomas J",
 "family": "Conners",
 "affiliation": [
 {
 "original_name": "University of Maryland, College Park, MD, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy049",
 "identifier": {
 "string_id": "10.1093/llc/fqy049",
 "id_scheme": "DOI"
 },
 "abstract": "This article explores the linguistic landscape of social media posts associated with specific geographic locations using computational methods. Because physical and virtual spaces have become increasingly intertwined due to location-aware mobile devices, we propose extending the concept of linguistic landscape to cover both physical and virtual environments. To cope with the high volume of social media data, we adopt computational methods for studying the richness and diversity of the virtual linguistic landscape, namely, automatic language identification and topic modelling, together with diversity indices commonly used in ecology and information sciences. We illustrate the proposed approach in a case study covering nearly 120,000 posts uploaded on Instagram over 4.5 years at the Senate Square in Helsinki, Finland. Our analysis reveals the richness and diversity of the virtual linguistic landscape, which is also shown to be susceptible to continuous change.",
 "article_title": "Exploring the linguistic landscape of geotagged social media content in urban environments",
 "authors": [
 {
 "given": " Tuomo",
 "family": "Hiippala",
 "affiliation": [
 {
 "original_name": "Department of Languages, University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 },
 {
 "original_name": "Digital Geography Lab, University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 },
 {
 "original_name": "Helsinki Institute of Sustainability Science, University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 }
 ]
 },
 {
 "given": " Anna",
 "family": "Hausmann",
 "affiliation": [
 {
 "original_name": "Digital Geography Lab, University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 },
 {
 "original_name": "Department of Geography and Geosciences, University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 },
 {
 "original_name": "Helsinki Institute of Sustainability Science, University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 }
 ]
 },
 {
 "given": " Henrikki",
 "family": "Tenkanen",
 "affiliation": [
 {
 "original_name": "Digital Geography Lab, University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 },
 {
 "original_name": "Department of Geography and Geosciences, University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 },
 {
 "original_name": "Helsinki Institute of Sustainability Science, University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 }
 ]
 },
 {
 "given": " Tuuli",
 "family": "Toivonen",
 "affiliation": [
 {
 "original_name": "Digital Geography Lab, University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 },
 {
 "original_name": "Department of Geography and Geosciences, University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 },
 {
 "original_name": "Helsinki Institute of Sustainability Science, University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy044",
 "identifier": {
 "string_id": "10.1093/llc/fqy044",
 "id_scheme": "DOI"
 },
 "abstract": "To assist legal professionals with more effective information processing and evaluation, we aim to develop software to identify and visualize the key information dispersed in the unstructured language data of a criminal case. A preliminary model of the software, Worldbuilder, is described in Wang et al. (2016a, b). The present article focuses on explaining the theory and vision behind the computational development of the software, which has involved establishing a means to annotate discourse for visualization purposes. The design of the annotation scheme is based on a cognitive model of discourse processing, Text World Theory (TWT), which describes and tracks how language users create a dynamic representation of events (i.e. text-worlds) in their minds as they communicate. As this is the first time TWT has informed the computational analysis of language, the model is augmented with Contextual Frame Theory, among other linguistic apparatus, to account for the complexities in the data and its translation from text to visualization. Using a statement from the Meredith Kercher murder trial as a case study, we illustrate the efficacy of the augmented TWT framework in the careful and purposeful preparation of linguistic data for computational visualization. Ultimately, this research bridges Cognitive and Computational Linguistics, improves the TWT model’s analytical accuracy, and yields a potentially useful tool for forensic work.",
 "article_title": "Text-world annotation and visualization for crime narrative reconstruction",
 "authors": [
 {
 "given": " Yu-Fang",
 "family": "Ho",
 "affiliation": [
 {
 "original_name": "Linguistics and Modern Languages, University of Huddersfield, UK",
 "normalized_name": "University of Huddersfield",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05t1h8f27",
 "GRID": "grid.15751.37"
 }
 }
 ]
 },
 {
 "given": " Jane",
 "family": "Lugea",
 "affiliation": [
 {
 "original_name": "School of Arts, English and Languages, Queen's University Belfast, UK",
 "normalized_name": "Queen's University Belfast",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/00hswnk62",
 "GRID": "grid.4777.3"
 }
 }
 ]
 },
 {
 "given": " Dan",
 "family": "McIntyre",
 "affiliation": [
 {
 "original_name": "Linguistics and Modern Languages, University of Huddersfield, UK",
 "normalized_name": "University of Huddersfield",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05t1h8f27",
 "GRID": "grid.15751.37"
 }
 }
 ]
 },
 {
 "given": " Zhijie",
 "family": "Xu",
 "affiliation": [
 {
 "original_name": "Department of Informatics, University of Huddersfield, UK",
 "normalized_name": "University of Huddersfield",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05t1h8f27",
 "GRID": "grid.15751.37"
 }
 }
 ]
 },
 {
 "given": " Jing",
 "family": "Wang",
 "affiliation": [
 {
 "original_name": "Department of Computing, Sheffield Hallam University, UK",
 "normalized_name": "Sheffield Hallam University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/019wt1929",
 "GRID": "grid.5884.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-10-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy048",
 "identifier": {
 "string_id": "10.1093/llc/fqy048",
 "id_scheme": "DOI"
 },
 "abstract": "In the past decade, an increasing set of digital tools has been developed with which digital sources can be selected, analyzed, and presented. Many tools go beyond key word search and perform different types of analysis, aggregation, mapping, and linking of data selections, which transforms materials and creates new perspectives, thereby changing the way scholars interact with and perceive their materials. These tools, together with the massive amount of digital and digitized data available for humanities research, put a strain on traditional humanities research methods. Currently, there is no established method of assessing the role of digital tools in the research trajectory of humanities scholars. There is no consensus on what questions researchers should ask themselves to evaluate digital sources beyond those of traditional analogue source criticism. This article aims to contribute to a better understanding of digital tools and the discussion of how to evaluate and incorporate them in research, based on findings from a digital tool criticism workshop held at the 2017 Digital Humanities Benelux conference. The overall goal of this article is to provide insight in the actual use and practice of digital tool criticism, offer a ready-made format for a workshop on digital tool criticism, give insight in aspects that play a role in digital tool criticism, propose an elaborate model for digital tool criticism that can be used as common ground for further conversations in the field, and finally, provide recommendations for future workshops, researchers, data custodians, and tool builders.",
 "article_title": "Toward a model for digital tool criticism: Reflection as integrative practice",
 "authors": [
 {
 "given": " Marijn",
 "family": "Koolen",
 "affiliation": [
 {
 "original_name": "Royal Netherlands Academy of Arts and Sciences - Humanities Cluster, The Netherlands",
 "normalized_name": "Royal Netherlands Academy of Arts and Sciences",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/043c0p156",
 "GRID": "grid.418101.d"
 }
 }
 ]
 },
 {
 "given": " Jasmijn",
 "family": "van Gorp",
 "affiliation": [
 {
 "original_name": "Department of Media and Culture Studies, Utrecht University, The Netherlands",
 "normalized_name": "Utrecht University",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/04pp8hn57",
 "GRID": "grid.5477.1"
 }
 }
 ]
 },
 {
 "given": " Jacco",
 "family": "van Ossenbruggen",
 "affiliation": [
 {
 "original_name": "Centrum Wiskunde & Informatica, VU University Amsterdam",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "Network Institute, The Netherlands",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy053",
 "identifier": {
 "string_id": "10.1093/llc/fqy053",
 "id_scheme": "DOI"
 },
 "abstract": "A language-independent stemmer has always been looked for. Single N-gram tokenization technique works well; however, it often generates stems that start with intermediate characters, rather than initial ones. We present a novel technique that takes the concept of N-gram stemming one step ahead and compare our method with an established algorithm in the field, say, Porter’s stemmer for English, Spanish, and Portuguese languages. Results indicate that our N-gram stemmer is comparable with the Porter’s linguistic stemmer.",
 "article_title": "Generation, implementation, and appraisal of an N-gram-based stemming algorithm",
 "authors": [
 {
 "given": " Bhagwati P",
 "family": "Pande",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, SSJ Campus, Kumaun University, Almora, Uttarakhand, India",
 "normalized_name": "Kumaun University",
 "country": "India",
 "identifiers": {
 "ror": "https://ror.org/038e9x269",
 "GRID": "grid.411155.5"
 }
 }
 ]
 },
 {
 "given": " Pawan",
 "family": "Tamta",
 "affiliation": [
 {
 "original_name": "Government Post Graduate College, Manila, Almora, Uttarakhand, India",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Hoshiyar S",
 "family": "Dhami",
 "affiliation": [
 {
 "original_name": "Uttarakhand Residential University, Almora, Uttarakhand, India",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy052",
 "identifier": {
 "string_id": "10.1093/llc/fqy052",
 "id_scheme": "DOI"
 },
 "abstract": "Library-based publishing initiatives are on the rise in a rapidly diversifying scholarly publishing ecosystem. This article presents selected results from a US-based survey on the needs of humanities scholars in a contemporary publishing environment, emphasizing survey responses that shed light on key aspects of access for scholars seeking to publish: access to support services, access to content, and access to audience. Survey responses suggest a profile of the authors for whom libraries are poised to offer attractive publishing solutions: (1) those whose scholarship is not sufficiently represented in the print medium and (2) those who place a high value on the technological affordances provided by open-access digital scholarship to reach their intended audiences. Compared to other publishing models, situating support for scholarly communication in the research library creates opportunities for addressing challenges related to access and sustainability in the digital scholarly publishing.",
 "article_title": "Informing library-based digital publishing: Selected findings from a survey of scholars' needs in a contemporary publishing environment",
 "authors": [
 {
 "given": " Megan",
 "family": "Senseney",
 "affiliation": [
 {
 "original_name": "School of Information Sciences, University of Illinois at Urbana-Champaign, USA",
 "normalized_name": "University of Illinois at Urbana-Champaign",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047426m28",
 "GRID": "grid.35403.31"
 }
 }
 ]
 },
 {
 "given": " Maria",
 "family": "Bonn",
 "affiliation": [
 {
 "original_name": "School of Information Sciences, University of Illinois at Urbana-Champaign, USA",
 "normalized_name": "University of Illinois at Urbana-Champaign",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047426m28",
 "GRID": "grid.35403.31"
 }
 }
 ]
 },
 {
 "given": " Christoper",
 "family": "Maden",
 "affiliation": [
 {
 "original_name": "University Library, University of Illinois at Urbana-Champaign, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Janet",
 "family": "Swatscheno",
 "affiliation": [
 {
 "original_name": "University Library, University of Illinois at Urbana-Champaign, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " LaTesha",
 "family": "Velez",
 "affiliation": [
 {
 "original_name": "School of Education, University of North Carolina at Greensboro, USA",
 "normalized_name": "University of North Carolina at Greensboro",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/04fnxsj42",
 "GRID": "grid.266860.c"
 }
 }
 ]
 },
 {
 "given": " Harriett",
 "family": "Green",
 "affiliation": [
 {
 "original_name": "University Libraries, Washington University in St. Louis, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Katrina",
 "family": "Fenlon",
 "affiliation": [
 {
 "original_name": "College of Information Studies, University of Maryland, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "Supplement_1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy059",
 "identifier": {
 "string_id": "10.1093/llc/fqy059",
 "id_scheme": "DOI"
 },
 "abstract": "We have designed an ontology to index a corpus of digital literature works. We have given this ontology the shape of a memory island, a navigable virtual territory where categories are regions and descriptor places, and where archives of these ephemeral works are made accessible.",
 "article_title": "An ontology and a memory island to give access to digital literature works",
 "authors": [
 {
 "given": " Yan",
 "family": "Rucar",
 "affiliation": [
 {
 "original_name": "Sorbonne University – Obvil",
 "normalized_name": "Sorbonne University",
 "country": "France",
 "identifiers": {
 "ror": "https://ror.org/02en5vm52",
 "GRID": "grid.462844.8"
 }
 }
 ]
 },
 {
 "given": " Jean-Gabriel",
 "family": "Ganascia",
 "affiliation": [
 {
 "original_name": "Sorbonne University - LIP6",
 "normalized_name": "Sorbonne University",
 "country": "France",
 "identifiers": {
 "ror": "https://ror.org/02en5vm52",
 "GRID": "grid.462844.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-10-24",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "Supplement_1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy055",
 "identifier": {
 "string_id": "10.1093/llc/fqy055",
 "id_scheme": "DOI"
 },
 "abstract": "During World War I (WWI), between 1916 and 1917, Robert Musil was the chief editor of the Tiroler Soldaten-Zeitung in Bozen. This activity probably also involved authorship of articles and has posed a philological problem to scholars, who have not been able to attribute with certainty a range of relatively short texts to Musil. With this article, we present a new approach that combines philological research with stylometric methods. Exploration of WWI archives and digitization of historical documents were paired with application of authorship attribution techniques, following extensive evaluation. To build the training set, we adapted the ‘impostors method’ by grouping three ‘distractor authors’ (similar to Musil in terms of style) and three actual candidates for authorship. In the test set, we developed two designs for tackling the issue of text length: a combinatory design, where longer chunks were composed by the juxtaposition of short texts; a simplified design, where the texts for attribution were merged with already attributed texts. Results of our experiment suggest that Musil attribution may be disproved with a high level of confidence for ten texts that were more probably written by a less well-known author, Albert Ritter. We carried out a keyness analysis on the specific words preferred or avoided by the two authors, which not only corroborated the results of the quantitative analysis but also findings from Musil philology. Our study showcases the potentialities of using mixed methods in stylometry.",
 "article_title": "Robert Musil, a war journal, and stylometry: Tackling the issue of short texts in authorship attribution",
 "authors": [
 {
 "given": " Simone",
 "family": "Rebora",
 "affiliation": [
 {
 "original_name": "Foreign Languages and Literatures, University of Verona, Italy",
 "normalized_name": "University of Verona",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/039bp8j42",
 "GRID": "grid.5611.3"
 }
 }
 ]
 },
 {
 "given": " J Berenike",
 "family": "Herrmann",
 "affiliation": [
 {
 "original_name": "University of Basel, Switzerland",
 "normalized_name": "University of Basel",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/02s6k3f65",
 "GRID": "grid.6612.3"
 }
 }
 ]
 },
 {
 "given": " Gerhard",
 "family": "Lauer",
 "affiliation": [
 {
 "original_name": "University of Basel, Switzerland",
 "normalized_name": "University of Basel",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/02s6k3f65",
 "GRID": "grid.6612.3"
 }
 }
 ]
 },
 {
 "given": " Massimo",
 "family": "Salgaro",
 "affiliation": [
 {
 "original_name": "Foreign Languages and Literatures, University of Verona, Italy",
 "normalized_name": "University of Verona",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/039bp8j42",
 "GRID": "grid.5611.3"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy047",
 "identifier": {
 "string_id": "10.1093/llc/fqy047",
 "id_scheme": "DOI"
 },
 "abstract": "Four letters in the Adventurer are currently attributed to Johnson, who allegedly disguised his style so that they could be plausibly ascribed to his friend Richard Bathurst. A stylometric analysis, supported by internal evidence, finds the case for disguise implausible, and suggests that the letters are a collaboration between Johnson and Bathurst.",
 "article_title": "Johnson, ‘Misargyrus’, and Richard Bathurst",
 "authors": [
 {
 "given": " Peter",
 "family": "Dixon",
 "affiliation": [
 {
 "original_name": "School of English and Drama, Queen Mary, University of London, UK",
 "normalized_name": "University of London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04cw6st05",
 "GRID": "grid.4464.2"
 }
 }
 ]
 },
 {
 "given": " David",
 "family": "Mannion",
 "affiliation": [
 {
 "original_name": "Department of Mathematics, Royal Holloway, University of London, UK",
 "normalized_name": "University of London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04cw6st05",
 "GRID": "grid.4464.2"
 }
 }
 ]
 },
 {
 "given": " W G",
 "family": "Burgess",
 "affiliation": [
 {
 "original_name": "School of English and Drama, Queen Mary, University of London, UK",
 "normalized_name": "University of London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04cw6st05",
 "GRID": "grid.4464.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-10-26",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy042",
 "identifier": {
 "string_id": "10.1093/llc/fqy042",
 "id_scheme": "DOI"
 },
 "abstract": "There is a long-standing debate about the authorship of the Bixby Letter, one of the most famous pieces of correspondence in American history. Despite being signed by President Abraham Lincoln, some historians have claimed that its true author was John Hay, Lincoln’s personal secretary. Analyses of the letter have been inconclusive in part because the text totals only 139 words and is thus far too short to be attributed using standard methods. To test whether Lincoln or Hay wrote this letter, we therefore introduce and apply a new technique for attributing short texts called ‘n-gram tracing’. After demonstrating that our method can distinguish between the known writings of Lincoln and Hay with a very high degree of accuracy, we use it to attribute the Bixby Letter. We conclude that the text was authored by John Hay—rewriting this one episode in the history of the USA, while offering a solution to one of the most persistent problems in authorship attribution.",
 "article_title": "Attributing the Bixby Letter using n-gram tracing",
 "authors": [
 {
 "given": " Jack",
 "family": "Grieve",
 "affiliation": [
 {
 "original_name": "Department of English Language and Linguistics, University of Birmingham, UK",
 "normalized_name": "University of Birmingham",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/03angcq70",
 "GRID": "grid.6572.6"
 }
 }
 ]
 },
 {
 "given": " Isobelle",
 "family": "Clarke",
 "affiliation": [
 {
 "original_name": "Department of English Language and Linguistics, University of Birmingham, UK",
 "normalized_name": "University of Birmingham",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/03angcq70",
 "GRID": "grid.6572.6"
 }
 }
 ]
 },
 {
 "given": " Emily",
 "family": "Chiang",
 "affiliation": [
 {
 "original_name": "Centre for Forensic Linguistics, Aston University, UK",
 "normalized_name": "Aston University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05j0ve876",
 "GRID": "grid.7273.1"
 }
 }
 ]
 },
 {
 "given": " Hannah",
 "family": "Gideon",
 "affiliation": [
 {
 "original_name": "Centre for Forensic Linguistics, Aston University, UK",
 "normalized_name": "Aston University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05j0ve876",
 "GRID": "grid.7273.1"
 }
 }
 ]
 },
 {
 "given": " Annina",
 "family": "Heini",
 "affiliation": [
 {
 "original_name": "Centre for Forensic Linguistics, Aston University, UK",
 "normalized_name": "Aston University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05j0ve876",
 "GRID": "grid.7273.1"
 }
 }
 ]
 },
 {
 "given": " Andrea",
 "family": "Nini",
 "affiliation": [
 {
 "original_name": "Department of Linguistics and English Language, University of Manchester, UK",
 "normalized_name": "University of Manchester",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/027m9bs27",
 "GRID": "grid.5379.8"
 }
 }
 ]
 },
 {
 "given": " Emily",
 "family": "Waibel",
 "affiliation": [
 {
 "original_name": "Centre for English Language and Communication, Aston University, UK",
 "normalized_name": "Aston University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05j0ve876",
 "GRID": "grid.7273.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-12-19",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy037",
 "identifier": {
 "string_id": "10.1093/llc/fqy037",
 "id_scheme": "DOI"
 },
 "abstract": "In this article, an innovative approach to perform the sentiment analysis (SA) has been presented. The proposed system handles the issues of Romanized or abbreviated text and spelling variations in the text to perform the sentiment analysis. The training data set of 3,000 movie reviews and tweets has been manually labeled by native speakers of Hindi in three classes, i.e. positive, negative, and neutral. The system uses WEKA (Waikato Environment for Knowledge Analysis) tool to convert these string data into numerical matrices and applies three machine learning techniques, i.e. Naive Bayes (NB), J48, and support vector machine (SVM). The proposed system has been tested on 100 movie reviews and tweets, and it has been observed that SVM has performed best in comparison to other classifiers, and it has an accuracy of 68% for movie reviews and 82% in case of tweets. The results of the proposed system are very promising and can be used in emerging applications like SA of product reviews and social media analysis. Additionally, the proposed system can be used in other cultural/social benefits like predicting/fighting human riots.",
 "article_title": "A sentiment analysis system for social media using machine learning techniques: Social enablement",
 "authors": [
 {
 "given": " Sujata",
 "family": "Rani",
 "affiliation": [
 {
 "original_name": "TIET, CSED, India",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Parteek",
 "family": "Kumar",
 "affiliation": [
 {
 "original_name": "TIET, India",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-10-30",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy051",
 "identifier": {
 "string_id": "10.1093/llc/fqy051",
 "id_scheme": "DOI"
 },
 "abstract": "Although recent research acknowledges the potential of visualization methods in digital humanities (DH), the predominant terminology used to describe visualizations (prototypes and tools) focuses on their use as a means to an end and, more importantly, as an instrument in the service of humanities research. We introduce the sandcastle as a metaphorical lens and provocative term to highlight visualization as a research process in its own right. We argue that building visualization sandcastles provides a holistic approach to cross-disciplinary knowledge generation that embraces visualization as (1) an aesthetic provocation to elicit critical insights, interpretation, speculation, and discussions within and beyond scholarly audiences, (2) a dynamic process wherein speculation and re-interpretation advance knowledge within all disciplines involved, and (3) a mediator of ideas and theories within and across disciplines. Our argument is grounded in critical theory, DH, design, human–computer interaction, and visualization, and based on our own research on an exceptional literary collection. We argue that considering visualizations as sandcastles foregrounds valuable insights into the roles of visualization as a mindset, methodology, and praxis within humanities research and beyond.",
 "article_title": "In defense of sandcastles: Research thinking through visualization in digital humanities",
 "authors": [
 {
 "given": " Uta",
 "family": "Hinrichs",
 "affiliation": [
 {
 "original_name": "School of Computer Science, University of St Andrews, Scotland",
 "normalized_name": "University of St Andrews",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02wn5qz54",
 "GRID": "grid.11914.3c"
 }
 }
 ]
 },
 {
 "given": " Stefania",
 "family": "Forlini",
 "affiliation": [
 {
 "original_name": "Department of English, University of Calgary, Canada",
 "normalized_name": "University of Calgary",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03yjb2x39",
 "GRID": "grid.22072.35"
 }
 }
 ]
 },
 {
 "given": " Bridget",
 "family": "Moynihan",
 "affiliation": [
 {
 "original_name": "University of Edinburgh, UK",
 "normalized_name": "University of Edinburgh",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01nrxwf90",
 "GRID": "grid.4305.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-10-30",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "Supplement_1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy029",
 "identifier": {
 "string_id": "10.1093/llc/fqy029",
 "id_scheme": "DOI"
 },
 "abstract": "MOOC appearance has produced, in a first phase, more discussions than contributions. Despite pessimistic opinions or those catastrophic foreseeing the end of the classic education by accepting MOOC, the authors consider that, as it is happening in all situations when a field is reformed, instead of criticism or catastrophic predictions, an assessment should be simply made. MOOC will not be better or worse if it is discussed and dissected but can be tested in action, perfected by results, or abandoned if it has no prospects. Without testing, no decision is valid. A similarity between the MOOC appearance and the appearance of the idea of flying machines heavier than air can be made. In the flight case, the first reaction was a strong negation (including at Academies level) and only performing the first independent flight with an apparatus heavier than air has shifted orientation from denial to contributions. So, practical tests clarified the battle between ideas. The authors of this article encourage the idea of testing–assessment and, therefore, imagined and proposed one software for quickly assess whether MOOC produces changes in knowledge, by simply transferring courses from ‘face-to-face’ environment into the virtual one. Among the methods of statistical analysis for student behavioral changes was chosen the Keppel method. It underpins the assessment method of this work being approached using both the version with one variable and also with three variables. It is intended that this attempts to pave the way for other series of rapid assessment regarding MOOC effects (using other statistical methods). We believe, that this is the only approach that can lead either to improve the system or to renunciation.",
 "article_title": "Evaluation software for effects produced by MOOC in mediums with different linguistically levels",
 "authors": [
 {
 "given": " Cornel",
 "family": "Samoilă",
 "affiliation": [
 {
 "original_name": " Department of Materials Engineering, University of Braşov, Romania",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Doru",
 "family": "Ursuţiu",
 "affiliation": [
 {
 "original_name": " Department of Electronics and Computers, University of Braşov, Romania",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Vlad",
 "family": "Jinga",
 "affiliation": [
 {
 "original_name": " Department of Electronics and Computers, University of Braşov, Romania",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-02",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy013",
 "identifier": {
 "string_id": "10.1093/llc/fqy013",
 "id_scheme": "DOI"
 },
 "abstract": "Based on n text excerpts, the authorship linking task is to determine a way to link pairs of documents written by the same person together. This problem is closely related to authorship attribution questions, and its solution can be used in the author clustering task. However, no training information is provided and the solution must be unsupervised. To achieve this, various text representation strategies can be applied, such as characters, punctuation symbols, or letter n-grams as well as words, lemmas, Part-Of-Speech (POS) tags, and sequences of them. To estimate the stylistic distance (or similarity) between two text excerpts, different measures have been suggested based on the L1 norm (e.g. Manhattan, Tanimoto), the L2 norm (e.g. Matusita), the inner product (e.g. Cosine), or the entropy paradigm (e.g. Jeffrey divergence). From those possible implementations, it is not clear which text representation and distance functions produce the best performance, and this study provides an answer to this question. Three corpora, extracted from French and English literature, have been evaluated using standard methodology. Moreover, we suggest an additional performance measure called high precision (HPrec) capable of judging the quality of a ranked list of links to provide only correct answers. No systematic difference can be found between token- or lemma-based text representations. Simple POS tags do not provide an effective solution but short sequences of them form a good text representation. Letter n-grams (with n = 4–6) give high HPrec rates. As distance measures, this study found that the Tanimoto, Matusita, and Clark distance measures perform better than the often-used Cosine function. Finally, applying a pruning procedure (e.g. culling terms appearing once or twice or limiting the vocabulary to the 500 most frequent words) reduces the representation complexity and might even improve the effectiveness of the attribution scheme.",
 "article_title": "Evaluation of text representation schemes and distance measures for authorship linking",
 "authors": [
 {
 "given": " Mirco",
 "family": "Kocher",
 "affiliation": [
 {
 "original_name": "University of Neuchatel, Switzerland",
 "normalized_name": "University of Neuchâtel",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/00vasag41",
 "GRID": "grid.10711.36"
 }
 }
 ]
 },
 {
 "given": " Jacques",
 "family": "Savoy",
 "affiliation": [
 {
 "original_name": "University of Neuchatel, Switzerland",
 "normalized_name": "University of Neuchâtel",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/00vasag41",
 "GRID": "grid.10711.36"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-06-02",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy010",
 "identifier": {
 "string_id": "10.1093/llc/fqy010",
 "id_scheme": "DOI"
 },
 "abstract": "In the present study 2,180 papers related to embodied cognition in the framework of linguistics were reviewed by using the bibliometric approach. The bibliographic records were collected from the Web of Science (Thomson Reuters) from 1992 to 2016 and were composed of a core data set and an expanded data set by topic searching and citation expansion. Document co-citation analysis, citation burst detection, and betweenness centrality measurement were conducted to explore and determine the thematic patterns, emerging trends, and critical articles of the knowledge domain. The results indicate that the study concerning language comprehension is the most prominent cluster. In addition, the labels as conceptual metaphor and conversational analysis are active clusters in a certain period. Meanwhile, the bursts of detected papers demonstrate that the present focus on language comprehension is a process of mental simulation of sensorimotor and other related experiences, and the topic of meaning construction is the product of interactive embodiment and cognitive processing, highlighting the role of simulation in language comprehension in emerging trends and future directions.",
 "article_title": "Visualizing the knowledge domain of embodied language cognition: A bibliometric review",
 "authors": [
 {
 "given": " Huili",
 "family": "Wang",
 "affiliation": [
 {
 "original_name": "School of Foreign Languages, Dalian University of Technology, China",
 "normalized_name": "Dalian University of Technology",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/023hj5876",
 "GRID": "grid.30055.33"
 }
 }
 ]
 },
 {
 "given": " Xiaoli",
 "family": "Yan",
 "affiliation": [
 {
 "original_name": "School of Foreign Languages, Dalian University of Technology, China",
 "normalized_name": "Dalian University of Technology",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/023hj5876",
 "GRID": "grid.30055.33"
 }
 }
 ]
 },
 {
 "given": " Hanning",
 "family": "Guo",
 "affiliation": [
 {
 "original_name": "School of International Education, Dalian University of Technology, China",
 "normalized_name": "Dalian University of Technology",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/023hj5876",
 "GRID": "grid.30055.33"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-06-11",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy005",
 "identifier": {
 "string_id": "10.1093/llc/fqy005",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents a text-analytic approach to analysing media content for evidence of gender bias. Irish newspaper content is examined using machine learning and natural language processing techniques. Systematic differences in the coverage of male and female politicians are uncovered, and these differences are analysed for evidence of gender bias. A corpus of newspaper coverage of politicians over a 15-year period was created. Features of the text were extracted and patterns differentiating coverage of male and female politicians were identified using machine learning. Discriminative features were then analysed for evidence of gender bias. Findings showed evidence of gender bias in how female politicians were portrayed, the policies they were associated with, and how they were evaluated. This research also sets out a methodology whereby natural language processing and machine learning can be used to identify gender bias in media coverage of politicians.",
 "article_title": "Uncovering gender bias in newspaper coverage of Irish politicians using machine learning",
 "authors": [
 {
 "given": " Susan",
 "family": "Leavy",
 "affiliation": [
 {
 "original_name": "University College Dublin, Ireland",
 "normalized_name": "RCSI & UCD Malaysia Campus",
 "country": "Malaysia",
 "identifiers": {
 "ror": "https://ror.org/0474gs458",
 "GRID": "grid.417196.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-06-11",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy021",
 "identifier": {
 "string_id": "10.1093/llc/fqy021",
 "id_scheme": "DOI"
 },
 "abstract": "Academic writing training in various forms has been developed to enhance writing knowledge and skills for graduate students at universities. However, few studies have targeted comparative learning analysis of the Introduction and Method sections in terms of genre structure and language use with the support of technology in the humanities and social sciences contexts. The present study designed a 13-week blended English genre-based writing instruction (GBWI) workshop with an online writing tutorial system—EJP-Write, in conjunction with the peer review and discovery-based learning approaches. This GBWI workshop was designed to help twenty-five graduate students from nine fields of the humanities and social sciences disciplines enhance their genre structure and language use of the Introduction and Method sections in academic writing. The results showed that although the participants benefited from GBWI, their improvements were not significant. The students further reported that the EJP-Write coupled with the peer review and discovery-based learning activities did not completely meet their requirements and anticipations. Overall, this study contributes to aid scholars and educators in better understanding how English as a foreign language (EFL) graduate students respond to GBWI with an integrated system for developing the knowledge and skills of academic writing. Moreover, these preliminary results can be used as guidance to further strengthen the effectiveness and efficiency of future GBWI research.",
 "article_title": "Genre-based writing instruction blended with an online writing tutorial system for the development of academic writing",
 "authors": [
 {
 "given": " Wei-Chen",
 "family": "Hsu",
 "affiliation": [
 {
 "original_name": "Department of Foreign Languages and Literature, National Cheng Kung University, Taiwan, Republic of China",
 "normalized_name": "National Cheng Kung University",
 "country": "Taiwan",
 "identifiers": {
 "ror": "https://ror.org/01b8kcc49",
 "GRID": "grid.64523.36"
 }
 }
 ]
 },
 {
 "given": " Gi-Zen",
 "family": "Liu",
 "affiliation": [
 {
 "original_name": "Department of Foreign Languages and Literature, National Cheng Kung University, Taiwan, Republic of China",
 "normalized_name": "National Cheng Kung University",
 "country": "Taiwan",
 "identifiers": {
 "ror": "https://ror.org/01b8kcc49",
 "GRID": "grid.64523.36"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy024",
 "identifier": {
 "string_id": "10.1093/llc/fqy024",
 "id_scheme": "DOI"
 },
 "abstract": "Love is the most significant subject of mystical path. This study explores all lines of Saadi’s lyric poems. Different words applied as alternatives of love were classified in twelve categories. To compare the frequency of different categories and words that were used as alternatives of love, the chi-square goodness-of-fit test was separately used. Then, using K-means clustering method, these alternatives were clustered in three categories (high frequency, medium frequency, and low frequency). The results indicated that the words Fire and Pain and the categories of Sickness, Human, and Heat had the highest uses as the alternatives of love in Saadi's lyric poems.",
 "article_title": "On comparing and clustering the alternatives of love in Saadi's lyric poems (Ghazals)",
 "authors": [
 {
 "given": " Mohammad Reza",
 "family": "Mahmoudi",
 "affiliation": [
 {
 "original_name": "Department of Statistics, Faculty of Science, Fasa University, Iran",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Ali",
 "family": "Abbasalizadeh",
 "affiliation": [
 {
 "original_name": "Department of Persian Literature, Fasa University, Iran",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-07-19",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy026",
 "identifier": {
 "string_id": "10.1093/llc/fqy026",
 "id_scheme": "DOI"
 },
 "abstract": "The present study exemplifies an action research-based approach to developing learner autonomy in learning productive vocabulary in an English as a foreign language (EFL) setting. We conducted two cycles of teaching actions as interventions to solve immediate learning problems. These actions involved Evernote-aided learning and activities of word guessing, gap noticing, and phonetic drilling. The results of vocabulary tests and interviews were analysed to measure and verify the outcomes of the interventions. Our results reveal that, by the end of the research, learners took initiative in learning productive vocabulary. They became more self-conscious of the knowledge involved in a productive word and more capable of managing vocabulary learning independently. Reflections upon the teachers’ role, their actions in the teaching practice, and the relationship between learner autonomy and vocabulary learning are discussed.",
 "article_title": "Autonomous learning of productive vocabulary in the EFL context: An action research approach",
 "authors": [
 {
 "given": " Yubin",
 "family": "Qian",
 "affiliation": [
 {
 "original_name": "School of International Studies, University of International Business and Economics, China",
 "normalized_name": "University of International Business",
 "country": "Kazakhstan",
 "identifiers": {
 "ror": "https://ror.org/01rvqzw67",
 "GRID": "grid.472445.4"
 }
 }
 ]
 },
 {
 "given": " Ya",
 "family": "Sun",
 "affiliation": [
 {
 "original_name": "Foreign Languages Department, University of Chinese Academy of Sciences, China",
 "normalized_name": "University of Chinese Academy of Sciences",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/05qbk4x57",
 "GRID": "grid.410726.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy025",
 "identifier": {
 "string_id": "10.1093/llc/fqy025",
 "id_scheme": "DOI"
 },
 "abstract": "We propose a novel way to create categorized discourse lexicons for multiple languages. We combine information from the Penn Discourse Treebank with statistical machine translation techniques on the Europarl corpus. Using gender profiling as an application, we evaluate our approach by comparing it with an approach using features from a knowledge-based lexicon and with an Rhetorical structure theory (RST) discourse parser. Our experiments are performed on corpora for three languages (English, Dutch, and German) in two genres (news and blogs). We include a feature analysis in which we look for (in)consistencies of discourse features related to male and female authors between the different experimental settings.",
 "article_title": "Discourse lexicon induction for multiple languages and its use for gender profiling",
 "authors": [
 {
 "given": " Ben",
 "family": "Verhoeven",
 "affiliation": [
 {
 "original_name": "CLiPS Research Center, University of Antwerp, Belgium",
 "normalized_name": "University of Antwerp",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/008x57b05",
 "GRID": "grid.5284.b"
 }
 }
 ]
 },
 {
 "given": " Walter",
 "family": "Daelemans",
 "affiliation": [
 {
 "original_name": "CLiPS Research Center, University of Antwerp, Belgium",
 "normalized_name": "University of Antwerp",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/008x57b05",
 "GRID": "grid.5284.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy012",
 "identifier": {
 "string_id": "10.1093/llc/fqy012",
 "id_scheme": "DOI"
 },
 "abstract": "While studies on diachronic Chinese syntax have identified a number of linguistic changes in Medieval Chinese, they have mostly been underpinned by qualitative analyses. In the most large-scale quantitative analysis to-date, this article investigates changes in the use of classifiers, demonstratives, and copulae. Our analysis, based on the Chinese Buddhist Canon, examines over 40 million characters in texts spanning a millennium. Results suggest that from the late Eastern Han period (circa 150 CE) onwards, the vernacular style became increasingly widespread, at the expense of the literary style, as reflected by changes in the use of classifiers and demonstratives, and in the construction of nominal sentences. However, the vernacular style became less frequently used in the Northern Sung period (960–1127 CE). This reversal may shed light on the work of the Stylists, editors appointed by the Sung court to polish Buddhist texts with more literary elements.",
 "article_title": "Vernacularization in Medieval Chinese: A quantitative study on classifiers, demonstratives, and copulae in the Chinese Buddhist Canon",
 "authors": [
 {
 "given": " Tak-sum",
 "family": "Wong",
 "affiliation": [
 {
 "original_name": "Department of Linguistics and Translation, City University of Hong Kong, Kowloon, Hong Kong",
 "normalized_name": "City University of Hong Kong",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/03q8dnn23",
 "GRID": "grid.35030.35"
 }
 }
 ]
 },
 {
 "given": " John S Y",
 "family": "Lee",
 "affiliation": [
 {
 "original_name": "Department of Linguistics and Translation, City University of Hong Kong, Kowloon, Hong Kong",
 "normalized_name": "City University of Hong Kong",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/03q8dnn23",
 "GRID": "grid.35030.35"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-06-25",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy019",
 "identifier": {
 "string_id": "10.1093/llc/fqy019",
 "id_scheme": "DOI"
 },
 "abstract": "The integration of context-aware ubiquitous learning (CAUL) into English for Specific Purposes (ESP) learning has become increasingly widespread due to the enhanced interaction between learners and situated contexts. Using an authentic learning site on environmental protection and its related discourse-specific English as target knowledge, this study analyzed the learning needs for developing ESP knowledge and skills through the use of smartphones and QR codes. Different need choices of the four language skills, requirements of CAUL system design, and effective audio–visual materials for social interaction are discussed. Based on previous reviewed arguments and current empirical arguments, the quantitative results reveal significant findings in ESP material design, content knowledge, and effective methods for CAUL. Further, qualitative interview results are classified into technological viewpoints and practical infield viewpoints. Consequently, identified themes and contradictions among three target groups—experts, students, and guides—are explained in terms of different pursuits of context-specific English learning needs.",
 "article_title": "Needs analysis for an ESP case study developed for the context-aware ubiquitous learning environment",
 "authors": [
 {
 "given": " Yi-Wen",
 "family": "Chen",
 "affiliation": [
 {
 "original_name": "Department of Foreign Languages & Literature, National Cheng Kung University, Taiwan, Republic of China",
 "normalized_name": "National Cheng Kung University",
 "country": "Taiwan",
 "identifiers": {
 "ror": "https://ror.org/01b8kcc49",
 "GRID": "grid.64523.36"
 }
 }
 ]
 },
 {
 "given": " Gi-Zen",
 "family": "Liu",
 "affiliation": [
 {
 "original_name": "Department of Foreign Languages & Literature, National Cheng Kung University, Taiwan, Republic of China",
 "normalized_name": "National Cheng Kung University",
 "country": "Taiwan",
 "identifiers": {
 "ror": "https://ror.org/01b8kcc49",
 "GRID": "grid.64523.36"
 }
 }
 ]
 },
 {
 "given": " Vivien",
 "family": "Lin",
 "affiliation": [
 {
 "original_name": "Department of Foreign Languages & Literature, National Cheng Kung University, Taiwan, Republic of China",
 "normalized_name": "National Cheng Kung University",
 "country": "Taiwan",
 "identifiers": {
 "ror": "https://ror.org/01b8kcc49",
 "GRID": "grid.64523.36"
 }
 }
 ]
 },
 {
 "given": " Hong-You",
 "family": "Wang",
 "affiliation": [
 {
 "original_name": "Department of Foreign Languages & Literature, National Cheng Kung University, Taiwan, Republic of China",
 "normalized_name": "National Cheng Kung University",
 "country": "Taiwan",
 "identifiers": {
 "ror": "https://ror.org/01b8kcc49",
 "GRID": "grid.64523.36"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy020",
 "identifier": {
 "string_id": "10.1093/llc/fqy020",
 "id_scheme": "DOI"
 },
 "abstract": "Digital technology is drawing more and more research attention in many areas of humanities because of its advantages in objectivity and automation. This work was an attempt to analyze two protagonists’ personality traits and development, through their dialogues in a Chinese novel Ordinary World. We used language technology LTP, a Simplified Chinese segmentation software, to segment dialogues. Then, on the basis of eighty-eight LIWC (Linguistic Inquiry and Word Count) features, personality predictive models were recruited to calculate the Big Five personality. We obtained two sets of predicted Big Five personality scores through dialogues in general and those before versus after the protagonist’s life events (high-school graduation and marriage). As expected, the two protagonists’ (Shaoping Sun and Shaoan Sun) Big Five personality traits were coincided with the portraits in the novel, and the two protagonists showed observable personality development after their life events, which was consistent with previous studies on personality change. This work demonstrates the applicability and validity of literary intelligence analysis in humanistic texts, suggesting a reliable approach to analyze novel protagonists’ personality in an objective manner.",
 "article_title": "Literary intelligence analysis of novel protagonists’ personality traits and development",
 "authors": [
 {
 "given": " Mingming",
 "family": "Liu",
 "affiliation": [
 {
 "original_name": "Institute of Psychology, Chinese Academy of Sciences, China",
 "normalized_name": "Chinese Academy of Sciences",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/034t30j35",
 "GRID": "grid.9227.e"
 }
 }
 ]
 },
 {
 "given": " Yufeng",
 "family": "Wu",
 "affiliation": [
 {
 "original_name": "Department of Psychology, University of Chinese Academy of Sciences, China",
 "normalized_name": "University of Chinese Academy of Sciences",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/05qbk4x57",
 "GRID": "grid.410726.6"
 }
 }
 ]
 },
 {
 "given": " Dongdong",
 "family": "Jiao",
 "affiliation": [
 {
 "original_name": "Institute of Psychology, Chinese Academy of Sciences, China",
 "normalized_name": "Chinese Academy of Sciences",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/034t30j35",
 "GRID": "grid.9227.e"
 }
 }
 ]
 },
 {
 "given": " Michael Shengtao",
 "family": "Wu",
 "affiliation": [
 {
 "original_name": "Institute of Communication, Xiamen University, China",
 "normalized_name": "Xiamen University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/00mcjh785",
 "GRID": "grid.12955.3a"
 }
 }
 ]
 },
 {
 "given": " Tingshao",
 "family": "Zhu",
 "affiliation": [
 {
 "original_name": "College of Humanities, Xiamen University, China",
 "normalized_name": "Xiamen University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/00mcjh785",
 "GRID": "grid.12955.3a"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy033",
 "identifier": {
 "string_id": "10.1093/llc/fqy033",
 "id_scheme": "DOI"
 },
 "abstract": "Man is a Tool-making Animal (Attributed to Benjamin Franklin by Samuel Johnson) Although digital tools built by those outside the Digital Humanities (DH) community (particularly tools for big data analysis or social network analysis) currently take a significant amount of DH attention these days, there has been toolmaking inside the DH for about 70 years. This article’s author has acted as a tool developer from time to time over many years, and this work has been part of his personal experience of DH from the 1970s to the present day (some history of his involvement in DH can be found in Bradley and Nylan, 2016). Text Analysis...",
 "article_title": "Digital tools in the humanities: Some fundamental provocations?",
 "authors": [
 {
 "given": " John",
 "family": "Bradley",
 "affiliation": [
 {
 "original_name": "Department of Digital Humanities, King's College London, London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy018",
 "identifier": {
 "string_id": "10.1093/llc/fqy018",
 "id_scheme": "DOI"
 },
 "abstract": "Cultural analysts are currently faced with an ecosystem of heterogeneous, globally distributed, and mass-scale sources that cannot be ignored in the research process. In addition to that, cultural analysts need to deal with the emergence of a knowledge economy which is no longer based on the value of the information entities contained in one or more documents, but on the potential for heterogeneous data to be recombined to generate previously unknown knowledge. Therefore, the challenge of accessing a set of heterogeneous, mass-scale, dynamic, and globally distributed sources has been joined to that of transforming the content of these sources into reusable data for the creation of knowledge and value. To the traditional question—What sources should be consulted or selected?—must now be added: What tools should be built and what work procedures should be designed to access those sources on a mass basis and analyze them as data? This article aims to provide some possible answers through the work carried out within the Exhibitium Project. This included the design and implementation of the Expofinder system, which is a technological device meant to examine the mechanisms for dissemination of digital information about art exhibitions and reuse this information as data to generate new knowledge and new interpretations about them. We believe that one of the best ways to strengthen the paths of digital research is to make the methodologies and mechanisms that govern decision-making transparent in order to be discussed or to be adopted by other projects. This is the ultimate goal of this article.",
 "article_title": "Development of technological ecosystems for cultural analysis: The case of Expofinder system and art exhibitions",
 "authors": [
 {
 "given": " Nuria",
 "family": "Rodríguez-Ortega",
 "affiliation": [
 {
 "original_name": "Art History Department, University of Málaga, Spain",
 "normalized_name": "University of Malaga",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/036b2ww28",
 "GRID": "grid.10215.37"
 }
 }
 ]
 },
 {
 "given": " Antonio",
 "family": "Cruces Rodríguez",
 "affiliation": [
 {
 "original_name": "Art History Department, University of Málaga, Spain",
 "normalized_name": "University of Malaga",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/036b2ww28",
 "GRID": "grid.10215.37"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-08-02",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy032",
 "identifier": {
 "string_id": "10.1093/llc/fqy032",
 "id_scheme": "DOI"
 },
 "abstract": "Purpose—To identify new information barriers created in the process related to the formation and transfer of humanistic scientific knowledge. Methodology—The reanalysis of the data collected during the earlier research projects. Results—Information barriers were identified, which are created by incomplete bibliographic databases, some solutions used in publishing on the Internet, the low level of information competencies of many humanists, their adverse attitude to open access, and by the education system that prefers knowledge transmission in the linear and text form. Conclusion—New information barriers effectively reduce research capabilities of many humanists, thereby creating a communication barrier between traditional and digital humanists.",
 "article_title": "Information infrastructure of contemporary humanities and the digital humanities development as a cause of creating new information barriers. A Polish case",
 "authors": [
 {
 "given": " Zbigniew",
 "family": "Osiński",
 "affiliation": [
 {
 "original_name": "Maria Curie-Skłodowska University, Faculty of Humanities, Institute of Information and Library Science, Lublin, Poland",
 "normalized_name": "Maria Curie-Skłodowska University",
 "country": "Poland",
 "identifiers": {
 "ror": "https://ror.org/015h0qg34",
 "GRID": "grid.29328.32"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-08-06",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy030",
 "identifier": {
 "string_id": "10.1093/llc/fqy030",
 "id_scheme": "DOI"
 },
 "abstract": "Statistics and data analysis provide exciting approaches for extracting knowledge from data. Recently, statistics and data analysis were sought to be exploited in many research fields. In this study, statistics is applied to religious studies. Thirteen different orders of Quran’s revelation are considered. To start with, by using regression analysis, the similarity between these orders is investigated. The results show that all of the orders are highly related (R2 > 0.7, P < 0.001). Then, the hierarchical clustering method is used to cluster the orders. The results indicate that based on the similarity, different orders can be clustered in two groups; Cluster 1: ‘Ebn Abbas’, ‘Al-Azhar’, ‘Jaber’, ‘Ebn Nadim’, ‘Khazan’, and ‘Hazrat Ali’; Cluster 2: ‘Blachère’, ‘Bazargan’, ‘Nöldeke’, ‘Grimm’, ‘Muir’, ‘E'temad-al-Saltane’, and ‘Davood’. The results also determined that all of the orders are highly similar (mean of similarity >80%).",
 "article_title": "Statistical analysis about the order of Quran’s revelation",
 "authors": [
 {
 "given": " Mohammad",
 "family": "Reza Mahmoudi",
 "affiliation": [
 {
 "original_name": "Department of Statistics, Faculty of Science, Fasa University, Fasa, Iran",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Ali",
 "family": "Abbasalizadeh",
 "affiliation": [
 {
 "original_name": "Department of Persian Literature, Fasa University, Fasa, Iran",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-08-09",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy040",
 "identifier": {
 "string_id": "10.1093/llc/fqy040",
 "id_scheme": "DOI"
 },
 "abstract": "In ‘Christopher Marlowe: Hype and Hoax’(2018), Hartmut Ilsemann implies that his application of the Rolling Delta feature of R Stylo is sufficiently robust that a century and a half of traditional scholarship should be overturned, and Marlowe stripped of the majority of his canon, including Doctor Faustus and Edward II. The article concludes that ‘Marlowe is totally overrated in his influence on modern English drama’ (p. 26), the natural consequence of stripping away 5/7ths of his canon. In this response, I demonstrate that the assumptions underlying this application of the Delta method, and the application itself, are fundamentally flawed, leading to predictably erroneous conclusions. Problems with the study include a poorly designed test environment, incorrect preparation of texts, assuming that ‘Marlowe’s style’ can be determined by a single early play, selecting and constructing Shakespeare’s comparison texts in a manner likely to prejudice results, ignoring the effect upon style of a play’s date and genre, failing to consider the effect of different-length comparison texts, and dismissing external evidence of authorship that conflicts with the test outcomes. I argue that in the light of these issues, the results and conclusions must be dismissed. Further, the question is raised as to whether the current methods of computational stylistics, even when more rigorously applied, are equipped to challenge the attribution of the accepted Marlowe canon.1",
 "article_title": "Marlowe and overreaching: A misuse of stylometry",
 "authors": [
 {
 "given": " Ros",
 "family": "Barber",
 "affiliation": [
 {
 "original_name": "Department of English and Comparative Literature, Goldsmiths, University of London, UK",
 "normalized_name": "University of London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04cw6st05",
 "GRID": "grid.4464.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy036",
 "identifier": {
 "string_id": "10.1093/llc/fqy036",
 "id_scheme": "DOI"
 },
 "abstract": "Some argue that some religious books, Prophetic Traditions in particular, are adulterated, but this was sorted out by introducing a manual methodology for identifying authentic and non-authentic texts. The methodology is not precise and has become time-consuming and a daunting process today. A general motivation for many recent studies has been the desire to automate some descriptive processes and employ scientific observation in authorship identification/verification. Using methods of Authorship Verification to examine sensitive texts, like established religious texts, could challenge the existing paradigms in Islamic discourse and any religion that has sacred texts. However, it could lead to the refining of these texts and eliminate any contested belief/s. The selected linguistic features are used to measure the validity of morphological structures (word length), syntactic structure (word type), and lexical richness across the disputed and undisputed Hadiths. Using the three linguistic measures together enabled us to draw each Hadith in a three-dimensional space, with word length plotted along lexical richness and word type. The results for the selected Hadiths that have been measured showed marked differences that could be augmented by examining further features.",
 "article_title": "Authorship verification of disputed Hadiths in Sahih al-Bukhari and Muslim",
 "authors": [
 {
 "given": "Abdelhamid",
 "family": "Elewa",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy034",
 "identifier": {
 "string_id": "10.1093/llc/fqy034",
 "id_scheme": "DOI"
 },
 "abstract": "Nowadays, text summarization is one of the most important active research fields in information retrieval. The most of the supervised extractive summarization systems utilize learning-to-rank methods to score sentences according to their importance. They need a high-quality comprehensive summarization corpus, which is labeled manually by human experts. Unfortunately, this sort of corpus is not available for most low-resource languages such as Persian. In this study, first of all, a comprehensive human-labeled summarization corpus (called Bistoon) collected by the crowdsourcing approach is introduced, and then a Persian summarizer based on a novel semi-supervised summarization approach, which is a combination of co-training and self-training, is presented to overcome the absence of sufficient data. During an iterative process, the proposed system is learned by Bistoon corpus and applied to unlabeled texts to generate the most confident summaries. These summaries are added to Bistoon for more iterations. During iterations, the training corpus is grown and the quality of the summarizer is simultaneously improved. The proposed system has been compared to other well-known Persian summarizers over the Pasokh and Bistoon standard test data sets. The evaluation results show the superiority of our methods in terms of precision, F-measure, Rouge metrics, and also human judgments.",
 "article_title": "Katibeh: A Persian news summarizer using the novel semi-supervised approach",
 "authors": [
 {
 "given": " Saeed",
 "family": "Farzi",
 "affiliation": [
 {
 "original_name": "Faculty of Computer Engineering, K. N. Toosi University of Technology, Tehran, Iran",
 "normalized_name": "K.N.Toosi University of Technology",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/0433abe34",
 "GRID": "grid.411976.c"
 }
 }
 ]
 },
 {
 "given": " Sahar",
 "family": "Kianian",
 "affiliation": [
 {
 "original_name": "Faculty of Computer Engineering, Shahid Rajaee Teacher Training University, Tehran, Iran",
 "normalized_name": "Shahid Rajaee Teacher Training University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/02nkz4493",
 "GRID": "grid.440791.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-08-17",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy038",
 "identifier": {
 "string_id": "10.1093/llc/fqy038",
 "id_scheme": "DOI"
 },
 "abstract": "Zeta has been described as the most powerful general-purpose authorship tool currently available. It is therefore of the utmost importance that Zeta test results be correctly interpreted, because incorrect interpretations can lead to incorrect authorship attributions. This article argues that the current method of interpreting Zeta results, pioneered by Craig and Kinney (2009) in Shakespeare, Computers, and the Mystery of Authorship and used in the Authorship Companion to The New Oxford Shakespeare, is unsound. The article provides theoretical arguments and a counterexample to demonstrate this. Moreover, the article argues that the validation of the Zeta method that has so far been performed is less strong than it appears, being based on a misunderstanding of what the results are telling us. It suggests that conclusions apparently drawn from Zeta, that shorter n-grams and function word skip bigrams make better authorial markers, are unwarranted. Finally, the article presents the results of new Zeta tests, which show that the method is less reliable than has been supposed.",
 "article_title": "The interpretation of Zeta test results",
 "authors": [
 {
 "given": " Pervez",
 "family": "Rizvi",
 "affiliation": [
 {
 "original_name": "Independent student",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx056",
 "identifier": {
 "string_id": "10.1093/llc/fqx056",
 "id_scheme": "DOI"
 },
 "abstract": "The question of translators’ stylistic visibility in translated texts has been a recurring theme in translation studies. Recently, the employment of state-of-the-art stylometric methods such as multivariate statistical analysis or machine learning techniques has enabled important progress to be made in exploring the problem. Nevertheless, studies are conflicting in their findings. Some find evidence of translators’ stylistic presence, while others fail to do so. The lack of agreement in the literature makes one suspect some contextual factors affecting the degree of translators’ visibility. The present study focuses on one such possible factor—language combinations involved in translation. It is hypothesized that the farther the two languages involved are structurally apart, the more likely it is for the translator’s style to gain visibility as the increased distance will allow the translator greater freedom to be creative with his or her choices. The present study applies bootstrap consensus tree analysis and consensus network analysis to 175 samples of contemporary literary translation in two language pairs—the intimate pair of French and English and the distant pair of Korean and English. The analysis supports the hypothesis by showing that the authors completely override their translators to claim authorship in the French group, while authorial presence is significantly diminished in the Korean group, resulting in greater visibility for some translators.",
 "article_title": "Do language combinations affect translators’ stylistic visibility in translated texts?",
 "authors": [
 {
 "given": " Changsoo",
 "family": "Lee",
 "affiliation": [
 {
 "original_name": "Hankuk University of Foreign Studies, Seoul, Republic of Korea",
 "normalized_name": "Hankuk University of Foreign Studies",
 "country": "South Korea",
 "identifiers": {
 "ror": "https://ror.org/051q2m369",
 "GRID": "grid.440932.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-11-07",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx043",
 "identifier": {
 "string_id": "10.1093/llc/fqx043",
 "id_scheme": "DOI"
 },
 "abstract": "This article looks at the provenance of the unfinished novel The Dark Tower, generally attributed to C. S. Lewis. The manuscript was purportedly rescued from a bonfire shortly after Lewis’s death by his literary executor Walter Hooper, but the quality of the text is hardly vintage Lewis. Using computer stylometric programs made available by Eder et al.’s (2016: Stylometry with R: A package for computational text analysis. R Journal, 8(1): 107–21) ‘stylo’ package and a word length analysis, samples of each chapter of The Dark Tower were compared with works known to be by Lewis, two books by Hooper and a hoax letter concerning the bonfire by Anthony Marchington. Initial experiments found that the first six chapters of The Dark Tower were stylometrically consistent with Lewis’s known works, but the incomplete Chapter 7 was not. This may have been due to an abrupt change in genre, from narrative to pseudoscientific style. Using principal components analysis, it was found that the first and subsequent components were able to separate genre and individual style, and thus a plot of the second against the third principal components enabled the effects of genre to be filtered out. This showed that Chapter 7 was also consistent with the other samples of C. S. Lewis’s writing.",
 "article_title": "Computer stylometry of C. S. Lewis’s The Dark Tower and related texts",
 "authors": [
 {
 "given": " Michael P",
 "family": "Oakes",
 "affiliation": [
 {
 "original_name": "RIILP, University of Wolverhampton, England",
 "normalized_name": "University of Wolverhampton",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01k2y1055",
 "GRID": "grid.6374.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-11-22",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx059",
 "identifier": {
 "string_id": "10.1093/llc/fqx059",
 "id_scheme": "DOI"
 },
 "abstract": "Function word adjacency networks (WANs) are used to study the authorship of plays from the Early Modern English period. In these networks, nodes are function words and directed edges between two nodes represent the relative frequency of directed co-appearance of the two words. For every analyzed play, a WAN is constructed and these are aggregated to generate author profile networks. We first study the similarity of writing styles between Early English playwrights by comparing the profile WANs. The accuracy of using WANs for authorship attribution is then demonstrated by attributing known plays among six popular playwrights. Moreover, the WAN method is shown to outperform other frequency-based methods on attributing Early English plays. In addition, WANs are shown to be reliable classifiers even when attributing collaborative plays. For several plays of disputed co-authorship, a deeper analysis is performed by attributing every act and scene separately, in which we both corroborate existing breakdowns and provide evidence of new assignments.",
 "article_title": "Stylometric analysis of Early Modern period English plays",
 "authors": [
 {
 "given": " Mark",
 "family": "Eisen",
 "affiliation": [
 {
 "original_name": "Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, USA",
 "normalized_name": "University of Pennsylvania",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00b30xv10",
 "GRID": "grid.25879.31"
 }
 }
 ]
 },
 {
 "given": " Alejandro",
 "family": "Ribeiro",
 "affiliation": [
 {
 "original_name": "Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, USA",
 "normalized_name": "University of Pennsylvania",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00b30xv10",
 "GRID": "grid.25879.31"
 }
 }
 ]
 },
 {
 "given": " Santiago",
 "family": "Segarra",
 "affiliation": [
 {
 "original_name": "Institute for Data, Systems, and Society, Massachusetts Institute of Technology, Cambridge, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Gabriel",
 "family": "Egan",
 "affiliation": [
 {
 "original_name": "School of Humanities, De Montfort University, Leicester, UK",
 "normalized_name": "De Montfort University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0312pnr83",
 "GRID": "grid.48815.30"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-02-06",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx062",
 "identifier": {
 "string_id": "10.1093/llc/fqx062",
 "id_scheme": "DOI"
 },
 "abstract": "For the first time, historians of higher education have large data sets of primary sources that reflect the complete output of academic institutions at their disposal. To analyze this unprecedented abundance of digital materials, scholars have access to a large suite of computational methods developed in the field of Natural Language Processing. However, when the intention is to move beyond exploratory studies and use the results of such analyses as quantitative evidences, historians need to take into account the reliability of these techniques. The main goal of this article is to investigate the performance of different text mining methods for a specific task: the automatic identification of interdisciplinary works from a corpus of PhD dissertation abstracts. Based on the output of our study, we provide the research community of a new data set for analyzing recent changes in interdisciplinary practices in a large sample of European universities. We show the potential of this collection by tracking the growth in adoption of computational approaches across different research fields, during the past 30 years.",
 "article_title": "Toward a computational history of universities: Evaluating text mining methods for interdisciplinarity detection from PhD dissertation abstracts",
 "authors": [
 {
 "given": " Federico",
 "family": "Nanni",
 "affiliation": [
 {
 "original_name": "International Centre for the History of Universities and Science, University of Bologna",
 "normalized_name": "University of Bologna",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/01111rn36",
 "GRID": "grid.6292.f"
 }
 },
 {
 "original_name": "Data and Web Science Group, University of Mannheim",
 "normalized_name": "University of Mannheim",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/031bsb921",
 "GRID": "grid.5601.2"
 }
 }
 ]
 },
 {
 "given": " Laura",
 "family": "Dietz",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, University of New Hampshire, USA",
 "normalized_name": "University of New Hampshire",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/01rmh9n78",
 "GRID": "grid.167436.1"
 }
 }
 ]
 },
 {
 "given": " Simone Paolo",
 "family": "Ponzetto",
 "affiliation": [
 {
 "original_name": "Data and Web Science Group, University of Mannheim",
 "normalized_name": "University of Mannheim",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/031bsb921",
 "GRID": "grid.5601.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-02-06",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx064",
 "identifier": {
 "string_id": "10.1093/llc/fqx064",
 "id_scheme": "DOI"
 },
 "abstract": "In recent years, important research on crowdsourcing in the cultural heritage sector has been published, dealing with topics such as the quantity of contributions made by volunteers, the motivations of those who participate in such projects, the design and establishment of crowdsourcing initiatives, and their public engagement value. This article addresses a gap in the literature, and seeks to answer two key questions in relation to crowdsourced transcription: (1) whether volunteers’ contributions are of a high enough standard for creating a publicly accessible database, and for use in scholarly research; and (2) if crowdsourced transcription makes economic sense, and if the investment in launching and running such a project can ever pay off. In doing so, this article takes the award-winning crowdsourced transcription initiative, Transcribe Bentham, which began in 2010, as its case study. It examines a large data set, namely, 4,364 checked and approved transcripts submitted by volunteers between 1 October 2012 and 27 June 2014. These data include metrics such as the time taken to check and approve each transcript, and the number of alterations made to the transcript by Transcribe Bentham staff. These data are then used to evaluate the long-term cost-effectiveness of the initiative, and its potential impact upon the ongoing production of The Collected Works of Jeremy Bentham at UCL. Finally, the article proposes more general points about successfully planning humanities crowdsourcing projects, and provides a framework in which both the quality of their outputs and the efficiencies of their cost structures can be evaluated.",
 "article_title": "‘Making such bargain’: Transcribe Bentham and the quality and cost-effectiveness of crowdsourced transcription1",
 "authors": [
 {
 "given": " Tim",
 "family": "Causer",
 "affiliation": [
 {
 "original_name": "Bentham Project, Faculty of Laws, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Kris",
 "family": "Grint",
 "affiliation": [
 {
 "original_name": "Institute of Intellectual History, University of St. Andrews, UK",
 "normalized_name": "University of St Andrews",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02wn5qz54",
 "GRID": "grid.11914.3c"
 }
 }
 ]
 },
 {
 "given": " Anna-Maria",
 "family": "Sichani",
 "affiliation": [
 {
 "original_name": "Department of Literary Studies, Huygens Institute, Netherlands",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Melissa",
 "family": "Terras",
 "affiliation": [
 {
 "original_name": "College of Arts, Humanities, and Social Sciences, University of Edinburgh, UK",
 "normalized_name": "University of Edinburgh",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01nrxwf90",
 "GRID": "grid.4305.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-02-06",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx066",
 "identifier": {
 "string_id": "10.1093/llc/fqx066",
 "id_scheme": "DOI"
 },
 "abstract": "This article looks at the case of Elena Ferrante, the (presumed) pseudonym of an internationally successful Italian novelist, and has two objectives: first, to observe how her novels are positioned in the panorama of modern Italian literature (represented by an ad hoc reference corpus—composed of 150 novels by forty different authors) and, second, to attempt to understand whether, amongst the authors in the corpus, there are any that can be considered candidates for involvement in the writing of the novels signed Ferrante. Consistent with these two objectives, the analyses also use two methods: correspondence analysis for the content mapping of the novels and Labbé’s intertextual distances to establish a measure of similarity between the novels. In the results, we do not see the expected similarities with writers from the Naples area as Elena Ferrante distinguishes herself with original literary products that, both in terms of theme and style, show her strong individuality. Amongst the authors included, Domenico Starnone, who has been previously identified by other investigations as the possible hand behind this pen name, is the author who has written novels most similar to those of Ferrante and which, over time, has become progressively more similar.",
 "article_title": "What is Elena Ferrante? A comparative analysis of a secretive bestselling Italian writer",
 "authors": [
 {
 "given": " Arjuna",
 "family": "Tuzzi",
 "affiliation": [
 {
 "original_name": "Dipartimento di Filosofia, Sociologia, Pedagogia e Psicologia Applicata (FISPPA), University of Padova, Italy",
 "normalized_name": "University of Padua",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/00240q980",
 "GRID": "grid.5608.b"
 }
 }
 ]
 },
 {
 "given": " Michele A",
 "family": "Cortelazzo",
 "affiliation": [
 {
 "original_name": "Dipartimento di Studi linguistici e letterari (DISLL), University of Padova, Italy",
 "normalized_name": "University of Padua",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/00240q980",
 "GRID": "grid.5608.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-08-23",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx065",
 "identifier": {
 "string_id": "10.1093/llc/fqx065",
 "id_scheme": "DOI"
 },
 "abstract": "The Whitechapel murders that terrorized London in 1888 are still remembered to this day, thanks to the legend of its unapprehended perpetrator, Jack the Ripper. In addition to the gruesomeness of the murders, the name and the persona of the killer have been popularized by the over 200 letters signed as ‘Jack the Ripper’ that have been received following the murders. The most supported theory on the authorship of these letters is that some of the earliest key texts were written by journalists to sell more newspapers and that the same person is responsible for writing the two most iconic earliest letters. The present article reports on an authorship clustering/verification analysis of the Jack the Ripper letters with a view to detect the presence of one writer for the earliest and most historically important texts. After compiling the ‘Jack the Ripper Corpus’ consisting of the 209 letters linked to the case, a cluster analysis of the letters is carried out using the Jaccard distance of word 2-grams. The quantitative results and the discovery of certain shared distinctive lexicogrammatical structures support the hypothesis that the two most iconic texts responsible for the creation of the persona of Jack the Ripper were written by the same person. In addition, there is also evidence that a link exists between these texts and another of the key texts in the case, the Moab and Midian letter.",
 "article_title": "An authorship analysis of the Jack the Ripper letters",
 "authors": [
 {
 "given": " Andrea",
 "family": "Nini",
 "affiliation": [
 {
 "original_name": "Linguistics and English Language, University of Manchester, UK",
 "normalized_name": "University of Manchester",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/027m9bs27",
 "GRID": "grid.5379.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-01-25",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy002",
 "identifier": {
 "string_id": "10.1093/llc/fqy002",
 "id_scheme": "DOI"
 },
 "abstract": "We present the methodological and technical process we adopted to develop DanteSources, a Web application that allows free access to the knowledge about Dante Alighieri’s primary sources, i.e. the works of other authors that Dante cites in his texts. Up to now, this knowledge has been collected in many paper books, making it difficult for the scholars to retrieve it and to produce a complete overview of these data. Using Semantic Web technologies, we developed an ontology expressed in the Resource Description Framework Schema vocabulary providing the terms to represent this knowledge in a machine-readable form. A semi-automatic tool helps the scholars to populate the ontology with the data included in authoritative paper commentaries to Dante’s works. Then, the tool automatically saves the resulting Resource Description Framework graph in a triple store. On top of this graph, we developed DanteSources, a Web application that allows users to extract and display the information stored in the knowledge base in the form of charts and tables. Finally, we report the results of a survey to collect suggestions from end-users on their interactions with DanteSources. The methodology and the tools we developed are easily reusable, e.g. to represent the knowledge about primary sources of other authors of the Italian and the international literature.",
 "article_title": "A web application for exploring primary sources: The DanteSources case study",
 "authors": [
 {
 "given": " Valentina",
 "family": "Bartalesi",
 "affiliation": [
 {
 "original_name": "ISTI-CNR, Italy",
 "normalized_name": "Institute of Information Science and Technologies",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/05kacka20",
 "GRID": "grid.451498.5"
 }
 }
 ]
 },
 {
 "given": " Carlo",
 "family": "Meghini",
 "affiliation": [
 {
 "original_name": "ISTI-CNR, Italy",
 "normalized_name": "Institute of Information Science and Technologies",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/05kacka20",
 "GRID": "grid.451498.5"
 }
 }
 ]
 },
 {
 "given": " Daniele",
 "family": "Metilli",
 "affiliation": [
 {
 "original_name": "ISTI-CNR, Italy",
 "normalized_name": "Institute of Information Science and Technologies",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/05kacka20",
 "GRID": "grid.451498.5"
 }
 }
 ]
 },
 {
 "given": " Mirko",
 "family": "Tavoni",
 "affiliation": [
 {
 "original_name": "Dipartimento di Filologia, Letteratura e Linguistica, Università di Pisa, Italy",
 "normalized_name": "University of Pisa",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/03ad39j10",
 "GRID": "grid.5395.a"
 }
 }
 ]
 },
 {
 "given": " Paola",
 "family": "Andriani",
 "affiliation": [
 {
 "original_name": "Dipartimento di Filologia, Letteratura e Linguistica, Università di Pisa, Italy",
 "normalized_name": "University of Pisa",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/03ad39j10",
 "GRID": "grid.5395.a"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-02-10",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy001",
 "identifier": {
 "string_id": "10.1093/llc/fqy001",
 "id_scheme": "DOI"
 },
 "abstract": "This paper makes use of new tables that provide a comprehensive survey of authorship attributions derived from the Rolling Delta feature of R Stylo. Its main subject is the analysis of the Marlowe corpus and other plays connected to Marlowe. The two Tamburlaines and Locrine turn out to be sole-authored Marlowe plays. The core plays of the Marlowe corpus are largely un-Marlovian in their style and this casts further doubts on his authorship, going well beyond the assessment of Marlowe by Dabbs. But Marlowe was not a phantom. His stylistic presence could be observed in a number of the plays investigated, among them the anonymous Edward III and Shakespeare's Henry V. Contrary to findings of the New Oxford Shakespeare, 3 Henry VI is not found to have been co-authored by Marlowe. Methodological observations offer indicators for the preference of the most frequent character trigrams as variables and the possible provenance of model texts conveyed by the most frequent function words. The latter were often key pieces of evidence in traditional stylometry.",
 "article_title": "Christopher Marlowe: Hype and Hoax",
 "authors": [
 {
 "given": " Hartmut",
 "family": "Ilsemann",
 "affiliation": [
 {
 "original_name": "English Department, Leibniz Universität Hannover, Königsworther Platz 1, Hannover, Germany",
 "normalized_name": "University of Hannover",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/0304hq317",
 "GRID": "grid.9122.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-10-11",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy003",
 "identifier": {
 "string_id": "10.1093/llc/fqy003",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents Parsa as an open information extraction (OIE) system for Persian. Comparing with advanced English approaches, OIE has just started to develop in other languages. Existing systems apply information about the grammar and syntactic structures of the target language to gain domain independence (which is a key goal in OIE). To improve modeling these complex structures, Parsa introduces a novel set of Patterns based on tree format. The patterns also enable Parsa to define POS tags, and lexical constraints to reduce incorrect matches. Each Tree Pattern is placed inside a Package based on its type and priority. The Packages help Parsa to alleviate some challenges in processing Persian like null-subject problem and uninformative extraction. To make the extraction process simple and coherent, we separate matching template from extraction template. An efficient algorithm for matching patterns inside dependency parse of a sentence is presented as well. Our experiments showed that Parsa achieves better performance than the state of the art systems in Persian, and highly comparable with the existing approaches in English.",
 "article_title": "Parsa: An open information extraction system for Persian",
 "authors": [
 {
 "given": " Mahmoud",
 "family": "Rahat",
 "affiliation": [
 {
 "original_name": "Faculty of Computer Science and Engineering, Shahid Beheshti University, Iran",
 "normalized_name": "Shahid Beheshti University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/0091vmj44",
 "GRID": "grid.412502.0"
 }
 }
 ]
 },
 {
 "given": " Alireza",
 "family": "Talebpour",
 "affiliation": [
 {
 "original_name": "Faculty of Computer Science and Engineering, Shahid Beheshti University, Iran",
 "normalized_name": "Shahid Beheshti University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/0091vmj44",
 "GRID": "grid.412502.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-10-11",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy004",
 "identifier": {
 "string_id": "10.1093/llc/fqy004",
 "id_scheme": "DOI"
 },
 "abstract": "Much of the quantitative work undertaken in stylistic analysis has to do with word frequencies—usually the relative frequencies of an appropriate set of single word-types. Those who have sought to go further by choosing word-types that tend to ‘go together’ have taken sequence and close proximity as their criteria. But many words display similar patterns of frequency without necessarily meeting those criteria: sets of grammatical associates, deictic features, archaisms, colloquialisms, Latinisms, and many others. Such sets, moreover, have negative corollaries, the alternatives consistently not chosen. Across a range of texts appropriate to whatever case may be in hand, both positive resemblances and direct contrasts of frequency can be identified by Spearman’s method of correlation. The coefficients for many of the pairs united in this way show very high levels of statistical significance. These pairs can be gathered in sets embracing all the partners of a given member, with separate subsets for positives and negatives. When, for example, ‘the’ is taken as a ‘headword’, it yields positive and negative sets, ‘THE_p’ and ‘THE_n’. Such ‘rho-sets’ can then be treated as composite variables and employed as data in much the same ways as we customarily use single-word variables. The trials undertaken (and illustrated here) suggest that this approach gives unusually accurate measures of stylistic difference, especially with short texts. Many of the sets themselves are of considerable philological interest and help to explain how the study of word frequencies can be so rich in stylistic information.",
 "article_title": "Rho-grams and rho-sets: Significant links in the web of words",
 "authors": [
 {
 "given": " John",
 "family": "Burrows",
 "affiliation": [
 {
 "original_name": "Centre for Literary and Linguistic Computing, University of Newcastle, Australia",
 "normalized_name": "University of Newcastle Australia",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00eae9z71",
 "GRID": "grid.266842.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-10-11",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy006",
 "identifier": {
 "string_id": "10.1093/llc/fqy006",
 "id_scheme": "DOI"
 },
 "abstract": "Digital possibilities and the presence of large image collections urged art history to reassess existing methods to study artworks. Big data facilitate new research—allowing to analyze millions of images—but also revealed the insufficiency of existing methods. The collaboration between computer vision and art history has provided tools to access and evaluate large image collections. This article elaborates on the potentials of a collaboration and presents work by the Computer Vision group of Heidelberg University. The group uses computational methods to study art data and performs automatic visual searches to find recurrences and organize data according to notions of similarity. It will be shown that large image collections can be studied efficiently with computer-based methods to assist art historians with iconographic research and that similar approaches already existed in art history at the beginning of the twentieth century.",
 "article_title": "Attesting similarity: Supporting the organization and study of art image collections with computer vision",
 "authors": [
 {
 "given": " Sabine",
 "family": "Lang",
 "affiliation": [
 {
 "original_name": "Heidelberg Collaboratory for Image Processing, Ruprecht-Karls-University Heidelberg, Germany",
 "normalized_name": "Heidelberg University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/038t36y30",
 "GRID": "grid.7700.0"
 }
 }
 ]
 },
 {
 "given": " Björn",
 "family": "Ommer",
 "affiliation": [
 {
 "original_name": "Heidelberg Collaboratory for Image Processing, Ruprecht-Karls-University Heidelberg, Germany",
 "normalized_name": "Heidelberg University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/038t36y30",
 "GRID": "grid.7700.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-04-09",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy008",
 "identifier": {
 "string_id": "10.1093/llc/fqy008",
 "id_scheme": "DOI"
 },
 "abstract": "The article presents the achievements of digital humanities in Poland, draws attention to the needs related to the development of digitization, and points to possible future undertakings aimed to popularize the accomplishments in this field. Apart from digitization, issues such as methods of sharing historic and linguistic sources in the digital form are covered. These sources include historic and scientific dictionaries of the Polish language, records, and texts dating back to before 1945. Additionally, linguistic corpora of historic Polish are presented, both those completed and those underway. The article emphasizes the imperative to create constellations of linguistic data warehouses. The last part, dedicated to the concept of the platform Diachronic Corpora of Polish, constitutes an attempt to catalog, disseminate, and made public the results of activities pertaining to works on the Polish corpora.",
 "article_title": "Digital Humanities in Poland from the Perspective of the Historical Linguist of the Polish Language: Achievements, Needs, Demands",
 "authors": [
 {
 "given": " Magdalena",
 "family": "Pastuch",
 "affiliation": [
 {
 "original_name": "Department of Philology, University of Silesia in Katowice, Poland",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Beata",
 "family": "Duda",
 "affiliation": [
 {
 "original_name": "Department of Philology, University of Silesia in Katowice, Poland",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Karolina",
 "family": "Lisczyk",
 "affiliation": [
 {
 "original_name": "Department of Philology, University of Silesia in Katowice, Poland",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Barbara",
 "family": "Mitrenga",
 "affiliation": [
 {
 "original_name": "Department of Philology, University of Silesia in Katowice, Poland",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Joanna",
 "family": "Przyklenk",
 "affiliation": [
 {
 "original_name": "Department of Philology, University of Silesia in Katowice, Poland",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Katarzyna",
 "family": "Sujkowska-Sobisz",
 "affiliation": [
 {
 "original_name": "Department of Philology, University of Silesia in Katowice, Poland",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-10-11",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy007",
 "identifier": {
 "string_id": "10.1093/llc/fqy007",
 "id_scheme": "DOI"
 },
 "abstract": "The article explores the uses of quantitative approaches used in textual scholarship in studying large amounts of medieval hand-written calendars. Calendars are exceedingly numerous among medieval manuscript sources but have been studied surprisingly little in spite of the insights they offer into the values and ideals of the communities using and updating them. Moreover, the study of a large number of calendars helps shape patterns of cultural contacts, for instance. The constant copying and modifying of a medieval calendar is analogous to copying of other manuscripts by hand in the Middle Ages. However, the overall pattern of influences was much more complex than in traditional copying, and new quantitative methods are called for. In this article, we propose three different quantitative methods for the analysis of medieval calendars. They provide a scholar with sound hypotheses on the relationships between a large number of calendars, on the broader context of an individual calendar’s contents as well as on the single feasts that can be indicative of the origin of one or several calendars.",
 "article_title": "Quantitative methods for the analysis of medieval calendars",
 "authors": [
 {
 "given": " Tuomas",
 "family": "Heikkilä",
 "affiliation": [
 {
 "original_name": "Institutum Romanum Finlandiae, Italy",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 }
 ]
 },
 {
 "given": " Teemu",
 "family": "Roos",
 "affiliation": [
 {
 "original_name": "Institutum Romanum Finlandiae, Italy",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-10-11",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy016",
 "identifier": {
 "string_id": "10.1093/llc/fqy016",
 "id_scheme": "DOI"
 },
 "abstract": "Elena Ferrante is a pen name known worldwide, authoring novels such as the bestseller My Brilliant Friend. A recent study indicates that the true author behind these books is probably Domenico Starnone. This study aims to select a set of approved authorship methods and appropriate feature sets to prove, with as much certainty as possible, that this conclusion is correct. To achieve this, a corpus of contemporary Italian novels has been generated, containing 150 books written by forty authors (including seven by Ferrante). Six authorship identification models have been applied to this data set (Delta, Labbé’s distance, nearest shrunken centroids (NSC), naïve Bayes, k-nearest neighbors, and character n-grams). Using either an instance- or profile-based matching technique, the same result (Starnone) appears very often in first place. Modifying the feature set to include between 50 and 2,000 of the most frequent tokens or lemmas does not change this result. When removing Starnone’s novels from the corpus, all approved attribution methods tend to indicate different names as the most probable author. This result confirms not only that the outputs of these methods are independent but also that the true author is certainly Starnone. Finally, a lexical analysis reveals the reasons justifying this conclusion.",
 "article_title": "Is Starnone really the author behind Ferrante?",
 "authors": [
 {
 "given": " Jacques",
 "family": "Savoy",
 "affiliation": [
 {
 "original_name": "University of Neuchatel, Switzerland",
 "normalized_name": "University of Neuchâtel",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/00vasag41",
 "GRID": "grid.10711.36"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-07-02",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy011",
 "identifier": {
 "string_id": "10.1093/llc/fqy011",
 "id_scheme": "DOI"
 },
 "abstract": "This research examines and contributes to recent work by Matthew Jockers and Gabi Kirilloff on the relationship between gender and action in the nineteenth-century novel. Jockers and Kirilloff use dependency parsing to extract verb and gendered pronoun pairs (‘he said’, ‘she walked’, etc.). They then build a classification model to predict the gender of a pronoun based on the verb being performed. This present study examines the novels that were categorized as outliers by the classification model to gain a better understanding of the way the observed trends function at the level of individual narratives. We argue that while the classifier successfully categorized and identified novels in which characters behave unconventionally—that is, in ways not typical to the corpus as a whole—the rhetorical effects of these unconventional novels (and the extent to which their authors openly question nineteenth-century gender norms) vary based on other factors of characterization and narration. We propose that the combination of machine and human reading that this essay utilizes provides a productive model for allowing distant reading to guide and provoke traditional humanities scholarship.",
 "article_title": "From a distance ‘You might mistake her for a man’: A closer reading of gender and character action in Jane Eyre, The Law and the Lady, and A Brilliant Woman1",
 "authors": [
 {
 "given": " Gabi",
 "family": "Kirilloff",
 "affiliation": [
 {
 "original_name": "Texas Christian University, USA",
 "normalized_name": "Texas Christian University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/054b0b564",
 "GRID": "grid.264766.7"
 }
 }
 ]
 },
 {
 "given": " Peter J",
 "family": "Capuano",
 "affiliation": [
 {
 "original_name": "University of Nebraska, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Julius",
 "family": "Fredrick",
 "affiliation": [
 {
 "original_name": "University of Nebraska, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Matthew L",
 "family": "Jockers",
 "affiliation": [
 {
 "original_name": "University of Nebraska, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-05-25",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqy015",
 "identifier": {
 "string_id": "10.1093/llc/fqy015",
 "id_scheme": "DOI"
 },
 "abstract": "The widespread use of English in science and scholarship has stressed the increasing need for reference tools which provide non-native, especially junior, researchers with useful information about the collocational patterns as well as conventionalized phraseology of non-technical words prototypical of specialized discourses. Within this lexicographic trend, the GRELIC research group research (GRELIC) has developed SciE-Lex, a lexicographic tool which includes morphosyntactic and contextual information about the combinatory potential of general words commonly used in biomedical discourse. This article serves the purpose of checking the validity of SciE-Lex by means of a qualitative survey distributed among a group of experts who were asked to explore and rate the dictionary by highlighting its weaknesses and strengths. The analysis of their reports have revealed interesting findings with respect to the adequacy of SciE-Lex as a lexicographic tool addressed to the biomedical community as well as to the appropriateness of the inclusion of contextual information of non-specialized terms prototypical of biomedical discourse. This pre-evaluation has informed the revision process of the dictionary and thus has greatly contributed to verifying its usefulness.",
 "article_title": "Research report on the adequacy of SciE-Lex as a lexicographic tool for the writing of biomedical papers in English",
 "authors": [
 {
 "given": " Natalia Judith",
 "family": "Laso",
 "affiliation": [
 {
 "original_name": "Department of Modern Languages and Literatures and of English Studies, University of Barcelona, Spain",
 "normalized_name": "University of Barcelona",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/021018s57",
 "GRID": "grid.5841.8"
 }
 }
 ]
 },
 {
 "given": " Elisabet",
 "family": "Comelles",
 "affiliation": [
 {
 "original_name": "Department of Modern Languages and Literatures and of English Studies, University of Barcelona, Spain",
 "normalized_name": "University of Barcelona",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/021018s57",
 "GRID": "grid.5841.8"
 }
 }
 ]
 },
 {
 "given": " Isabel",
 "family": "Verdaguer",
 "affiliation": [
 {
 "original_name": "Department of Modern Languages and Literatures and of English Studies, University of Barcelona, Spain",
 "normalized_name": "University of Barcelona",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/021018s57",
 "GRID": "grid.5841.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "34",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx027",
 "identifier": {
 "string_id": "10.1093/llc/fqx027",
 "id_scheme": "DOI"
 },
 "abstract": "The article describes First We Feel Then We Fall, a multichannel, interactive video application, which is a multimedia adaptation of James Joyce’s Finnegans Wake. It offers the viewers a portmanteau-like audiovisual experience resembling the experience of reading Joyce’s enigmatic, multilingual dream-like narrative. Through an audiovisual format consisting of simultaneously running streams, it proposes an intermedial translation of hypertextuality and simultaneity of Finnegans Wake. The Wakean imagery, euphonies, rhythms, and polyphonic contexts are rendered into four narrative strands, or ‘plots’. Networks of linguistic, historical, symbolic, and mathematical meanings entailed in Wakean puns are transposed into a dynamic audiovisual structure that the audience can co-shape in the process of interactive viewing. They can switch at will between four simultaneous streams of film clips accompanied by sound (and optional captions with the Finnegans Wake text). The interactive and immersive nature of First We Feel Then We Fall goes beyond previous cinematic adaptations of Joyce’s novel. It is the advance of digital technologies that have enabled us to approach complexity of Finnegans Wake in this novel way.",
 "article_title": "First We Feel Then We Fall: James Joyce’s Finnegans Wake as an interactive video application",
 "authors": [
 {
 "given": " Katarzyna",
 "family": "Bazarnik",
 "affiliation": [
 {
 "original_name": "Institute of English Studies, Jagiellonian University in Kraków, Poland",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Jakub",
 "family": "Wróblewski",
 "affiliation": [
 {
 "original_name": "Academy of Fine Arts in Warsaw, Poland",
 "normalized_name": "Academy of Fine Arts in Warsaw",
 "country": "Poland",
 "identifiers": {
 "ror": "https://ror.org/036d1w285",
 "GRID": "grid.445468.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-01-21",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "32",
 "issue": "suppl_2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx046",
 "identifier": {
 "string_id": "10.1093/llc/fqx046",
 "id_scheme": "DOI"
 },
 "abstract": "Distributed language representation (deep learning) has been applied successfully in different applications in natural language processing. Using this model, we propose and implement two new authorship attribution classifiers. In this perspective, a vector-space representation can be generated for each author or disputed text according to words and their nearby context. To determine the authorship of a disputed text, the cosine similarity between vector representations can be applied. The proposed strategies can be adapted without any difficulty to different languages (such as English and Italian) or genres (essays, political speeches, and newspaper articles). Evaluations using the k-nearest neighbors (k-NNs))and based on four test collections (the Federalist Papers, the State of the Union addresses, the Glasgow Herald, and La Stampa newspapers) indicate that the distributed language representation preforms well, providing sometimes better effectiveness than state-of-the-art methods such as k-NN, nearest shrunken centroids, chi-square, Delta, latent Dirichlet allocation, or multi-layer perceptron classifier.",
 "article_title": "Distributed language representation for authorship attribution",
 "authors": [
 {
 "given": " Mirco",
 "family": "Kocher",
 "affiliation": [
 {
 "original_name": "University of Neuchatel, Switzerland",
 "normalized_name": "University of Neuchâtel",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/00vasag41",
 "GRID": "grid.10711.36"
 }
 }
 ]
 },
 {
 "given": " Jacques",
 "family": "Savoy",
 "affiliation": [
 {
 "original_name": "University of Neuchatel, Switzerland",
 "normalized_name": "University of Neuchâtel",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/00vasag41",
 "GRID": "grid.10711.36"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-02-07",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx047",
 "identifier": {
 "string_id": "10.1093/llc/fqx047",
 "id_scheme": "DOI"
 },
 "abstract": "In our research, we study mechanisms of knowledge dissemination based on the structural and social networks surrounding the edition history of a single text: the Tractatus de sphaera by Johannes de Sacrobosco. By applying methods from network analysis, we investigate how specific commentaries on the text circulated, which actors were responsible for them and what factors supported or hindered the spread of specific kinds of knowledge. The basis of this investigation is represented by CorpusTracer, a database that stores the required data in a suitable format and with the required level of expressivity. In this article, we present the design of our database and our data model based on CIDOC-CRM and FRBRoo. We discuss the implementation and suitability of the conceptual and technical realization for our research question. We conclude that FRBRoo fits well to the task at hand. We found that the comparatively complex data structure it requires can be sufficiently abstracted through current implementation methods. As the research continues, our data model will have to grow and we expect that the presented methods will be sufficient to accommodate our future requirements.",
 "article_title": "CorpusTracer: A CIDOC database for tracing knowledge networks",
 "authors": [
 {
 "given": " Florian",
 "family": "Kräutli",
 "affiliation": [
 {
 "original_name": "Max Planck Institute for the History of Science, Germany",
 "normalized_name": "Max Planck Institute for the History of Science",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/0492sjc74",
 "GRID": "grid.419556.a"
 }
 }
 ]
 },
 {
 "given": " Matteo",
 "family": "Valleriani",
 "affiliation": [
 {
 "original_name": "Max Planck Institute for the History of Science, Germany",
 "normalized_name": "Max Planck Institute for the History of Science",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/0492sjc74",
 "GRID": "grid.419556.a"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-02-07",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx041",
 "identifier": {
 "string_id": "10.1093/llc/fqx041",
 "id_scheme": "DOI"
 },
 "abstract": "While Gallo-Italic varieties clearly belong to the Romance language family, their subgrouping as either Gallo-Romance or Italo-Romance has been the source of disagreement in the classificatory literature. While earlier analyses tended to classify Gallo-Italic as Gallo-Romance (notably Schmid, 1956; Bec, 1970–1971), later work has either argued for or tacitly assumed a classification of Gallo-Italic as part of the Italo-Romance branch, a view that is both different from as well as irreconcilable with the earlier Gallo-Romance classifications. In this article, we aim to contribute to the development of an empirically based classification of Gallo-Italic through the use of dialectometry applied to atlas corpora, and specifically through the measurement of Levenshtein distance. Using three wordlists (Swadesh 100, Swadesh 200, Leipzig–Jakarta) and comparing twenty-six linguistic varieties across Italy and south-eastern France, we show that Gallo-Italic is best classified as a third subgroup within the Gallo-Romance branch. Our results also clearly identify all the major bundles of isoglosses established through traditional dialectological methods and confirm Gallo-Italic as a relatively homogenous group distinct from Italo-Romance.",
 "article_title": "Revisiting the classification of Gallo-Italic: a dialectometric approach",
 "authors": [
 {
 "given": " Marco",
 "family": "Tamburelli",
 "affiliation": [
 {
 "original_name": "School of Linguistics and English Language, Bangor University, Bangor, UK",
 "normalized_name": "Bangor University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/006jb1a24",
 "GRID": "grid.7362.0"
 }
 }
 ]
 },
 {
 "given": " Lissander",
 "family": "Brasca",
 "affiliation": [
 {
 "original_name": "School of Linguistics and English Language, Bangor University, Bangor, UK",
 "normalized_name": "Bangor University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/006jb1a24",
 "GRID": "grid.7362.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-05-16",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx050",
 "identifier": {
 "string_id": "10.1093/llc/fqx050",
 "id_scheme": "DOI"
 },
 "abstract": "This article reports a study that compared how Portuguese and Brazilian newspapers covered Japan in the 90s. The research was based on 9,152 texts related to Japan published in a Portuguese and a Brazilian newspaper from that era. This is a much larger sample than what was used in existing text content analysis studies for Portuguese. To treat this large sample, selected concordances and distributions obtained from the corpora were semi-automatically analyzed. Results revealed that the most referred Japanese personalities were politicians. Additionally, in general, there are more texts related to Japan (and naming Japanese personalities) in the Portuguese newspaper than in the Brazilian newspaper. The study focused on personalities for which there are statistically significant frequency differences in the Portuguese and the Brazilian newspapers. A detailed analysis of the texts where these personalities were named revealed events related to Japan with different impact in Portugal and Brazil.",
 "article_title": "A method for content analysis applied to newspaper coverage of Japanese personalities in Brazil and Portugal",
 "authors": [
 {
 "given": " Luís Fernando",
 "family": "Costa",
 "affiliation": [
 {
 "original_name": "Faculty of Engineering, Yamaguchi University, Japan",
 "normalized_name": "Yamaguchi University",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/03cxys317",
 "GRID": "grid.268397.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-02-07",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx045",
 "identifier": {
 "string_id": "10.1093/llc/fqx045",
 "id_scheme": "DOI"
 },
 "abstract": "‘Authorship attribution’, the problem of determining the author (or the author's attributes, such as gender, age, native language, or other characteristics) by examining the writing style of an unknown work, is an important problem in applied linguistics. The theory of authorship attribution is relatively straightforward: language is an underspecified system, and people can pick and choose among several different ways to describe the same thing. These choices, in turn, become habituated and can be identified as persistent patterns of an individual or group of writers.One important psycholinguistic underpinning to this solution is the universal existence (in natural languages) of so-called “marker words” or ‘function words,’–little, closed-class words that do not carry much semantics but instead denote relationships between content words. Because these words are so lightly processed, writers/speakers can choose among many different near-synonymous forms, and implicitly express their identity in doing so.Do constructed languages have this same degree of near-synonymity? We present the results of a study of authorship attribution using an ad-hoc corpus of fan-written documents in various constructed languages, and show that even artificial languages constructed for artistic purposes, such as Klingon, Na'vi, and Elvish, permit this type of analysis. This indicates that even constructed languages tend to be psycholinguistically plausible.",
 "article_title": "Authorship attribution, constructed languages, and the psycholinguistics of individual variation",
 "authors": [
 {
 "given": " Patrick",
 "family": "Juola",
 "affiliation": [
 {
 "original_name": "Duquesne University, USA",
 "normalized_name": "Duquesne University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/02336z538",
 "GRID": "grid.255272.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-09-07",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx049",
 "identifier": {
 "string_id": "10.1093/llc/fqx049",
 "id_scheme": "DOI"
 },
 "abstract": "The article outlines the rationale of the born-digital dossier génétique from a digital forensic perspective in the light of the recent discussion about digital materiality. In its first part, the study addresses theoretical, conceptual, and methodological questions that arise from the specific materiality of the born-digital avant-texte, namely, the dualism of ‘forensic materiality’ and ‘formal materiality’ (M. Kirschenbaum) and the role of distributed materiality (J.-F. Blanchette). The article argues that the born-digital record, consisting of digital objects, temporary files, metadata, and fragmented traces of the writing process scattered across multiple system locations, has to be analyzed with regard to the specific historical computing context, its distributed materiality ensemble of hardware, operating system, and application (multi-evidential perspective, J. L. John). Current challenges for born-digital preservation and philological analysis will be discussed. In the second part, the exemplary analysis of several digital drafts and text fragments found on the hard drives of German poet Thomas Kling (1957–2005) sheds light on digital materiality from a practical digital forensic and critique génétique perspective. The following methods will be demonstrated: analysis of fast save artifacts in Microsoft Word documents; draft text recovery from CHK files; file carving and verification of recovery results (true, false positives); recovery of text fragments from drive slack. Digital forensic methodology is in the focus of this article as a tool in the context of archival studies, philology, genetic criticism, and scholarly editing of born-digital material. As born-digital primary records of cultural, social, and political history (private storage media, cloud storage, world wide web content as well as public and semi-public social media posts) come to the archives in increasing numbers and volumes, the forensic perspective on born-digital material, questions of authentic preservation and analysis, bibliographic citability and stability, materiality and their status as a document and evidence as well as legal and ethical issues of preservation, curation and access in the archives become crucial for all humanities disciplines.",
 "article_title": "The rationale of the born-digital dossier génétique: Digital forensics and the writing process: With examples from the Thomas Kling Archive",
 "authors": [
 {
 "given": " Thorsten",
 "family": "Ries",
 "affiliation": [
 {
 "original_name": "Ghent University, Belgium",
 "normalized_name": "Ghent University",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/00cv9y106",
 "GRID": "grid.5342.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-02-07",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx033",
 "identifier": {
 "string_id": "10.1093/llc/fqx033",
 "id_scheme": "DOI"
 },
 "abstract": "Medieval literary traditions provide a particularly challenging test case for textual alignment and the visualization of variance. Whereas the editors of medieval traditions working with the printed page struggle to illustrate the complex phenomena of textual instability, research in screen-based visualization has made significant progress, allowing for complex textual situations to be captured at the micro- and the macro-level. This article uses visualization and a computational approach to identifying variance to allow the analysis of different medieval poetic works using the transcriptions of how they are found in particular manuscripts. It introduces the notion of a meso-level visualization, a visual representation of aligned text providing for comparative reading on the screen, all the while assembling non-contradictory, intuitive solutions for the visual exploration of multi-scalar variance. Building upon the literary notion of mouvance, it delves into medieval French literature and, in particular, different visualizations of three versions of the Chanson de Roland (the Oxford, the Châteauroux, and the Venice 4 manuscripts). The article presents experimental prototypes for such meso-level visualization and explores how they can advance our understanding of formulaically rich medieval poetry.",
 "article_title": "Visualizing Mouvance: Toward a visual analysis of variant medieval text traditions",
 "authors": [
 {
 "given": " Stefan",
 "family": "Jänicke",
 "affiliation": [
 {
 "original_name": "Institut für Informatik, Leipzig University, Germany",
 "normalized_name": "Leipzig University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/03s7gtk40",
 "GRID": "grid.9647.c"
 }
 }
 ]
 },
 {
 "given": " David",
 "family": "Joseph Wrisley",
 "affiliation": [
 {
 "original_name": "Digital Humanities, New York University Abu Dhabi, UAE",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-01-21",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "32",
 "issue": "suppl_2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx042",
 "identifier": {
 "string_id": "10.1093/llc/fqx042",
 "id_scheme": "DOI"
 },
 "abstract": "Compared to the epistemic traditions digital palaeography builds on, how is it transformative? In this article I will outline the emergent meanings and possible research directions of digital palaeography by reflecting on the past 15 years of approaches and conceptualizations in the field. By departing from a contextualized take of the term digital coupled with humanities and palaeography, I will show how digital approaches relate to the scholarly tradition of the study of handwriting and writing systems as a whole and how recent approaches of digital palaeography can be defined as critical, self-reflective, multidisciplinary and interdisciplinary. Moving between a formal and a historically situated analysis, I will relate practices of modelling of handwriting in digital palaeography to modelling in digital humanities more generally. Digital palaeography will emerge well positioned to represent the complexity of handwritten objects from the unfamiliar perspective of the substance of the expression of handwriting (text as shape).",
 "article_title": "Digital palaeography: What is digital about it?",
 "authors": [
 {
 "given": " Arianna",
 "family": "Ciula",
 "affiliation": [
 {
 "original_name": "King's Digital Lab, King's College London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-10-14",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "32",
 "issue": "suppl_2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx051",
 "identifier": {
 "string_id": "10.1093/llc/fqx051",
 "id_scheme": "DOI"
 },
 "abstract": "Digitization has changed the concept of dictionaries from merely alphabetically ordered reference works into lexical databases providing flexible search systems with interconnected lemmas. This article investigates ensuing opportunities and useful design options of digitized historical dictionaries as research tools for the study of texts. It appears that we have arrived at an interesting intersection of digital humanities and historical lexicography. The 14th-century ‘seemly play of Winter and Summer’ serves as a research case.",
 "article_title": "At the crossroads of digital humanities and historical lexicography: The Middle Dutch ‘seemly play (abel spel) of Winter and Summer’ as a research case",
 "authors": [
 {
 "given": " Dirk C J",
 "family": "Kinable",
 "affiliation": [
 {
 "original_name": "Dutch Language Institute, Instituut voor de Nederlandse Taal, Leiden, The Netherlands",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-11-06",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx057",
 "identifier": {
 "string_id": "10.1093/llc/fqx057",
 "id_scheme": "DOI"
 },
 "abstract": "Searching for articles of interest in a digital archive need not be through a free-form text search. In fact, many authors have suggested that the best way to find relevant items in an archive is to browse its contents rather than to search for specific keywords. The University of Central Florida’s Regional Initiative for Collecting Histories, Experiences and Stories (RICHES) project uses a multi-criteria Connections algorithm to make item selection recommendations and browse through the RICHES Mosaic Interface (RICHES MI)—an archive of digitized historical documents, imagery, and audio. The Connections algorithm allows researchers to examine a selected artifact and nearest related items in the archive based on multiple criteria from the metadata contained in the artifact of interest. To determine how effective the Connections algorithm was at presenting relevant material, it was compared to random selections and single criteria keyword searches. In this article we will show that the multi-criteria approach is not only better than randomly selected results it also selects more relevant items than single criteria keyword searches. In addition, the multi-criteria algorithm achieves a secondary benefit: it returns unanticipated relevant results that potentially yield new insights for the researcher.",
 "article_title": "Evaluating multi-criteria Connection mechanisms: A new algorithm for browsing digital archives",
 "authors": [
 {
 "given": " Amy Larner",
 "family": "Giroux",
 "affiliation": [
 {
 "original_name": "Center for Humanities and Digital Research, University of Central Florida (UCF), Orlando, FL, USA",
 "normalized_name": "University of Central Florida",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/036nfer12",
 "GRID": "grid.170430.1"
 }
 }
 ]
 },
 {
 "given": " Connie",
 "family": "Harper",
 "affiliation": [
 {
 "original_name": "RICHES, Department of History, University of Central Florida (UCF), Orlando, FL, USA",
 "normalized_name": "University of Central Florida",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/036nfer12",
 "GRID": "grid.170430.1"
 }
 }
 ]
 },
 {
 "given": " R Paul",
 "family": "Wiegand",
 "affiliation": [
 {
 "original_name": "Institute for Simulation and Training, University of Central Florida (UCF)), Orlando, FL, USA",
 "normalized_name": "University of Central Florida",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/036nfer12",
 "GRID": "grid.170430.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-02-07",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx054",
 "identifier": {
 "string_id": "10.1093/llc/fqx054",
 "id_scheme": "DOI"
 },
 "abstract": "Spelling correction is one of the main tasks in the field of Natural Language Processing. Contrary to common spelling errors, real-word errors cannot be detected by conventional spelling correction methods. The real-word correction model proposed by Mays, Damerau, and Mercer showed a great performance in different evaluations. In this research, however, a new hybrid approach is proposed which relies on statistical and syntactic knowledge to detect and correct real-word errors. In this model, Constraint Grammar is used to discriminate among sets of correction candidates in the search space. Mays, Damerau, and Mercer’s trigram approach is manipulated to estimate the probability of syntactically well-formed correction candidates. The approach proposed here is tested on the Wall Street Journal corpus. The model can prove to be more practical than some other models, such as WordNet-based method of Hirst and Budanitsky and fixed windows size method of Wilcox-O’Hearn and Hirst.",
 "article_title": "Correcting real-word spelling errors: A new hybrid approach",
 "authors": [
 {
 "given": " Seyed MohammadSadegh",
 "family": "Dashti",
 "affiliation": [
 {
 "original_name": "Islamic Azad University, Iran",
 "normalized_name": "Qom Islamic Azad University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/0283g3v77",
 "GRID": "grid.472325.5"
 }
 }
 ]
 },
 {
 "given": " Amid",
 "family": "Khatibi Bardsiri",
 "affiliation": [
 {
 "original_name": "Islamic Azad University, Iran",
 "normalized_name": "Qom Islamic Azad University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/0283g3v77",
 "GRID": "grid.472325.5"
 }
 }
 ]
 },
 {
 "given": " Vahid",
 "family": "Khatibi Bardsiri",
 "affiliation": [
 {
 "original_name": "Islamic Azad University, Iran",
 "normalized_name": "Qom Islamic Azad University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/0283g3v77",
 "GRID": "grid.472325.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-02-07",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx055",
 "identifier": {
 "string_id": "10.1093/llc/fqx055",
 "id_scheme": "DOI"
 },
 "abstract": "Text mining techniques were applied to a corpus consisting in the titles of 2,454 documents on Mudejar art, a style unique to Spanish art history. Probabilistic topic modelling was used to analyse the semantic structure underlying the suite of documents studied. Two classifications were obtained, an initial, generic division into five topics followed by a second more refined division into ten. These were compared to the preliminary subject categories found for the corpus with the guidance of an area specialist. The classifications delivered by the automatic and manual procedures were observed to be compatible. The conclusion drawn was that the deployment of digitized data affords the opportunity to conduct humanities studies from new perspectives.",
 "article_title": "Topic modelling characterization of Mudejar art based on document titles",
 "authors": [
 {
 "given": " Carlos",
 "family": "Garcia-Zorita",
 "affiliation": [
 {
 "original_name": "Departamento de Biblioteconomía y Documentación, Universidad Carlos III de Madrid, Spain",
 "normalized_name": "Carlos III University of Madrid",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/03ths8210",
 "GRID": "grid.7840.b"
 }
 }
 ]
 },
 {
 "given": " Ana R",
 "family": "Pacios",
 "affiliation": [
 {
 "original_name": "Departamento de Biblioteconomía y Documentación, Universidad Carlos III de Madrid, Spain",
 "normalized_name": "Carlos III University of Madrid",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/03ths8210",
 "GRID": "grid.7840.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-02-07",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx058",
 "identifier": {
 "string_id": "10.1093/llc/fqx058",
 "id_scheme": "DOI"
 },
 "abstract": "The article gives a brief outline of the fruitless attempts in the past at finding the author(s) of the Parnassus Plays, an anonymous trilogy performed between 1597 and 1601 at St. John’s College in Cambridge as part of the Christmas festivities, and then moves on to employ the R Stylo features Rolling Delta and Rolling Classify, which in various approaches confirm John Marston and Thomas Nashe as the authors. As collaborative scenarios count among the assets of these relatively new stylometric tools, it became possible to tip the scales towards Glatzer’s view that the plays have two authors, and Leishman’s advocacy of one author, based on the manuscript prologue of Part 2 of The Return, gave way to a ‘battle of the plays’ between Marston and Nashe.",
 "article_title": "Stylometry approaching Parnassus",
 "authors": [
 {
 "given": " Hartmut",
 "family": "Ilsemann",
 "affiliation": [
 {
 "original_name": "English Department, Leibniz Universität Hannover, Germany",
 "normalized_name": "University of Hannover",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/0304hq317",
 "GRID": "grid.9122.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-02-07",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx052",
 "identifier": {
 "string_id": "10.1093/llc/fqx052",
 "id_scheme": "DOI"
 },
 "abstract": "Normally, software documentations are produced, informally. They are written in the unnatural and non-structural form of the language, such as user manuals, user requirements, design documentation, tutorials, support documentation, and so on. Recent studies show that 61% of software projects are subject to failure or challenges due to an increase in the costs and production time. Various factors may lead to this issue, and one of the major contributing factors is the lack of links between the software's source code and its related documents. The significance of software development and the possibility of making prospective changes by the development team necessitate an understanding of the links between various sections of codes and documentations. Therefore, it is crucial to design a system to link the software codes to their corresponding textual documentation. This article proposes a model for recovering the latent, but traceable links between software source codes and existing documents based on word extraction and function name separation. The contributions in this article include: (1) a model based on word extraction from document and source codes; (2) the proposal of an algorithm for splitting compound words and words that are connected to one another and completing abbreviations used in the names of functions, variables, and output commands; and (3) a new algorithm that is proposed for retrieving traceable latent links between the source code and documents. Two data sets are used in this research and the achieved results will be reported in terms of recall, precision, and F-measure. The experimental results are promising and indicate that the proposed approach significantly outperforms its counterparts.",
 "article_title": "Mining and discovery of hidden relationships between software source codes and related textual documents",
 "authors": [
 {
 "given": " Amir Hossein",
 "family": "Rasekh",
 "affiliation": [
 {
 "original_name": "Shiraz University, Iran",
 "normalized_name": "Shiraz University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/028qtbk54",
 "GRID": "grid.412573.6"
 }
 }
 ]
 },
 {
 "given": " Amir Hossein",
 "family": "Arshia",
 "affiliation": [
 {
 "original_name": "Shiraz University, Iran",
 "normalized_name": "Shiraz University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/028qtbk54",
 "GRID": "grid.412573.6"
 }
 }
 ]
 },
 {
 "given": " Seyed Mostafa",
 "family": "Fakhrahmad",
 "affiliation": [
 {
 "original_name": "Shiraz University, Iran",
 "normalized_name": "Shiraz University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/028qtbk54",
 "GRID": "grid.412573.6"
 }
 }
 ]
 },
 {
 "given": " Mohammad Hadi",
 "family": "Sadreddini",
 "affiliation": [
 {
 "original_name": "Shiraz University, Iran",
 "normalized_name": "Shiraz University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/028qtbk54",
 "GRID": "grid.412573.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-10-31",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx053",
 "identifier": {
 "string_id": "10.1093/llc/fqx053",
 "id_scheme": "DOI"
 },
 "abstract": "Dr Anne Luther is a researcher, curator, and software developer whose work examines the contemporary art market and data visualization in qualitative research. She received her PhD from Central Saint Martins College of Art and Design, London, and is currently a researcher at the Department for Modern Art History at the Institute of Art Studies and Historical Urban Studies at TU Berlin and at The Center for Data Arts at The New School in New York. Her PhD research presents a cultural analysis of contemporary art collecting and art production with an illustration of patterns that overlap in collecting and art production practices in contemporary art. The analysis shows how institutions, local context, social strategies, and prestige overlap in their influences on art production as a cause for collecting contemporary art. Her research in data visualization, qualitative methods, and data analysis emerged into the successful implementation of new software for qualitative research, The Entity Mapper.anneluther.info@AnneLutherahttps://github.com/lutheranne",
 "article_title": "Visual meta-data in qualitative analysis",
 "authors": [
 {
 "given": " Anne K",
 "family": "Luther",
 "affiliation": [
 {
 "original_name": "Center for Data Arts, The New School, New York",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-02-07",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx024",
 "identifier": {
 "string_id": "10.1093/llc/fqx024",
 "id_scheme": "DOI"
 },
 "abstract": "Text reuse in early Chinese transmitted texts is extensive and widespread, often reflecting complex textual histories involving repeated transcription, compilation, and editing spanning many centuries and involving the work of multiple authors and editors. In this study, a fully automated method of identifying and representing complex text reuse patterns is presented, and the results evaluated by comparison to a manually compiled reference work. The resultant data are integrated into a widely used and publicly available online database system with browse, search, and visualization functionality. These same results are then aggregated to create a model of text reuse relationships at a corpus level, revealing patterns of systematic reuse among groups of texts. Lastly, the large number of reuse instances identified make possible the analysis of frequently observed string substitutions, which are observed to be strongly indicative of partial synonymy between strings.",
 "article_title": "Unsupervised identification of text reuse in early Chinese literature",
 "authors": [
 {
 "given": " Donald",
 "family": "Sturgeon",
 "affiliation": [
 {
 "original_name": "Fairbank Center for Chinese Studies, Harvard University, USA",
 "normalized_name": "Harvard University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/03vek6s52",
 "GRID": "grid.38142.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-11-06",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx014",
 "identifier": {
 "string_id": "10.1093/llc/fqx014",
 "id_scheme": "DOI"
 },
 "abstract": "For several decades, Geographic Information Systems (GISs) have held center stage in archaeological studies of ancient landscapes. Recently, three-dimensional (3D) technologies such as airborne LiDAR and aerial photogrammetry are allowing us to acquire inordinate amounts of georeferenced 3D data to locate, map, and visualize archaeological sites within their surrounding landscapes. GIS offers locational precision, data overlay, and complex spatial analysis. Three-dimensionality adds a ground-based perspective lacking in two-dimensional GIS maps to provide archaeologists a sense of mass and space more closely attuned with human perception. This article uses comparative and iterative approaches ‘tacking back and forth’ between GIS and 3D visualization to explore the role of visibility in conveying sociopolitical and ideological messages at ancient Copan—today a UNESCO World Heritage Site in Honduras. A two-prong approach comprising computational and experiential components explores the potential role of visibility in sending messages that participate in the shaping of social interaction on a daily basis. The organization of built forms within the natural landscape created spatial configurations that sent visual messages targeting specific different groups, subsequently influencing how people negotiated their physical surroundings and the frequency and intensity of social interactions. The ancient Maya belief that sight played a key role in structuring everyday experiences because it triggered perception in the other senses thus serves to bridge the computational and experiential results in this case study.",
 "article_title": "An iterative 3D GIS analysis of the role of visibility in ancient Maya landscapes: A case study from Copan, Honduras",
 "authors": [
 {
 "given": " Heather",
 "family": "Richards-Rissetto",
 "affiliation": [
 {
 "original_name": "Department of Anthropology, University of Nebraska-Lincoln, USA",
 "normalized_name": "University of Nebraska–Lincoln",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/043mer456",
 "GRID": "grid.24434.35"
 }
 },
 {
 "original_name": "Center for Digital Research in the Humanities, University of Nebraska-Lincoln, USA",
 "normalized_name": "University of Nebraska–Lincoln",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/043mer456",
 "GRID": "grid.24434.35"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-03-27",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "32",
 "issue": "suppl_2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx017",
 "identifier": {
 "string_id": "10.1093/llc/fqx017",
 "id_scheme": "DOI"
 },
 "abstract": "The ongoing dispute in literary studies concerned with gender and writing style is wide and varied. Our preliminary analyses lend evidence to the claims that such gender differences are evident in writing across periods. While we follow in the methodological footsteps of such studies, particular those completed by Hoover (Textual analysis. In Price, K. M. and Siemens, R. (eds), Literary Studies in the Digital Age. Modern Language Association of America, 2013) and Rybicki (2016), we have shifted the focus of our investigation away from style, in the macro-analytical sense, to period and its relation to gender-differentiable terminology. Doing so recognizes the limitations of approaches like Zeta and Delta, while simultaneously benefiting from their affordances. Accepting that one can never have too large or robust a data set for this type of macro-analytic case study, we attempt to build on the foundations set down by Hoover and Rybicki, analyzing gender markers across a selection of male and female authors, and doing so crucially with a concern for the evolution of gender markers over specified canonical literary periods.",
 "article_title": "The limits of distinctive words: Re-evaluating literature’s gender marker debate",
 "authors": [
 {
 "given": " Sean G",
 "family": "Weidman",
 "affiliation": [
 {
 "original_name": "Pennsylvania State University, USA",
 "normalized_name": "Pennsylvania State University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/04p491231",
 "GRID": "grid.29857.31"
 }
 }
 ]
 },
 {
 "given": " James",
 "family": "O’Sullivan",
 "affiliation": [
 {
 "original_name": "University of Sheffield, UK",
 "normalized_name": "University of Sheffield",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05krs5044",
 "GRID": "grid.11835.3e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-02-01",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx012",
 "identifier": {
 "string_id": "10.1093/llc/fqx012",
 "id_scheme": "DOI"
 },
 "abstract": "Historical documents usually have a complex layout, making them one of the most challenging types of documents for automatic image analysis. In the pipeline of automatic document image analysis (DIA), layout analysis is an important prerequisite for further steps including optical character recognition, script analysis, and image recognition. It aims at splitting a document image into regions of interest such as text lines, background, and decorations. To train a layout analysis system, an essential prerequisite is a set of pages with corresponding ground truth (GT), i.e. existing labels (e.g. text line and decoration) annotated by human experts. Although there exist many methods and tools in GT generation, most of them are not suitable on our specific data sets. In this article, we propose to use Gabor features to generate GT, and based on Gabor features, we developed a web-based interface called DivaDiaWI. DivaDiaWI applies automatic functions using Gabor features to generate GT of text lines. For other region types such as background and decorations, users can manually draw their GT with user-friendly operations. The evaluation shows that (1) DivaDiaWI has two advantages when bringing it into context with state-of-the-art tools, (2) the automatic functions of DivaDiaWI greatly accelerate the GT generation, and (3) DivaDiaWI obtains a high score in a system usability test.",
 "article_title": "The use of Gabor features for semi-automatically generated polyon-based ground truth of historical document images",
 "authors": [
 {
 "given": " Hao",
 "family": "Wei",
 "affiliation": [
 {
 "original_name": "DIVA Group, Department of Informatics, University of Fribourg, Switzerland",
 "normalized_name": "University of Fribourg",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/022fs9h90",
 "GRID": "grid.8534.a"
 }
 }
 ]
 },
 {
 "given": " Mathias",
 "family": "Seuret",
 "affiliation": [
 {
 "original_name": "DIVA Group, Department of Informatics, University of Fribourg, Switzerland",
 "normalized_name": "University of Fribourg",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/022fs9h90",
 "GRID": "grid.8534.a"
 }
 }
 ]
 },
 {
 "given": " Marcus",
 "family": "Liwicki",
 "affiliation": [
 {
 "original_name": "DIVA Group, Department of Informatics, University of Fribourg, Switzerland",
 "normalized_name": "University of Fribourg",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/022fs9h90",
 "GRID": "grid.8534.a"
 }
 }
 ]
 },
 {
 "given": " Rolf",
 "family": "Ingold",
 "affiliation": [
 {
 "original_name": "DIVA Group, Department of Informatics, University of Fribourg, Switzerland",
 "normalized_name": "University of Fribourg",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/022fs9h90",
 "GRID": "grid.8534.a"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-06-08",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "32",
 "issue": "suppl_1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx008",
 "identifier": {
 "string_id": "10.1093/llc/fqx008",
 "id_scheme": "DOI"
 },
 "abstract": "Universities around the world have increasingly turned to digital infrastructures as a way to revamp the arts and humanities. This article contributes a fresh understanding by examining the material development of HumlabX, a research laboratory for digital humanities at Umeå University, Sweden. Specifically, we approach the empirical case as a timeline of research funding, projects, events, and deliverables to examine how the research laboratory as an organizational and material space developed and evolved in relation to new technology investments. Based on our analysis, we argue that while digital research infrastructures can, indeed, stimulate innovation in and around research, aimed to produce new knowledge, digital technologies carry social and material implications that affect organizational processes. We show that while knowledge production processes at HumlabX were highly influenced by the infrastructural legacy of the past, they indeed directed scholars toward innovation. By discussing these implications in detail, we move beyond the debate of humanities qua digital, and demonstrate the need for scholars of digital humanities to engage in the development of policies for digital research infrastructures. Using a Swedish case study, we argue that research laboratories for the digital humanities must be scrutinized and should be fully exposed as socio-material organizations that develop, and should develop, over time. In particular, we stress the need to ensure that digital humanities laboratories are sustainable and open for redevelopment.",
 "article_title": "Beyond humanities qua digital: Spatial and material development for digital research infrastructures in HumlabX1",
 "authors": [
 {
 "given": " Anna",
 "family": "Foka",
 "affiliation": [
 {
 "original_name": "Humlab, Umeå University, Sweden",
 "normalized_name": "Umeå University",
 "country": "Sweden",
 "identifiers": {
 "ror": "https://ror.org/05kb8h459",
 "GRID": "grid.12650.30"
 }
 },
 {
 "original_name": "Pufendorf Institute, Lund University, Sweden",
 "normalized_name": "Lund University",
 "country": "Sweden",
 "identifiers": {
 "ror": "https://ror.org/012a77v79",
 "GRID": "grid.4514.4"
 }
 }
 ]
 },
 {
 "given": " Anna",
 "family": "Misharina",
 "affiliation": [
 {
 "original_name": "Humlab, Umeå University, Sweden",
 "normalized_name": "Umeå University",
 "country": "Sweden",
 "identifiers": {
 "ror": "https://ror.org/05kb8h459",
 "GRID": "grid.12650.30"
 }
 }
 ]
 },
 {
 "given": " Viktor",
 "family": "Arvidsson",
 "affiliation": [
 {
 "original_name": "Department of Informatics, University of Oslo, Norway",
 "normalized_name": "University of Oslo",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/01xtthb56",
 "GRID": "grid.5510.1"
 }
 }
 ]
 },
 {
 "given": " Stefan",
 "family": "Gelfgren",
 "affiliation": [
 {
 "original_name": "Humlab, Umeå University, Sweden",
 "normalized_name": "Umeå University",
 "country": "Sweden",
 "identifiers": {
 "ror": "https://ror.org/05kb8h459",
 "GRID": "grid.12650.30"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-05-16",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx021",
 "identifier": {
 "string_id": "10.1093/llc/fqx021",
 "id_scheme": "DOI"
 },
 "abstract": "In recent years, one of the two fully preserved ancient Greek tragic plays of disputed authorship, Rhesus, traditionally attributed to Euripides, has been the object of a quite lively scholarly interest. The rather extreme number, for the standards of classical philology, of four published commentaries in 10 years, by Athanasios D. Stefanis, [Euripides’]: Rhesus, Athens: Academy of Athens, 2004, Arne Feickert, Euripidis: Rhesus, Frankfurt: Lang, 2005, Vayos Liapis, A Commentary on the Rhesus Attributed to Euripides, Oxford: Oxford University Press, 2012, and Almut Fries, Pseudo-Euripides: Rhesus, Berlin: De Gruyter, 2014 (two of them in English), and one forthcoming by Marco Fantuzzi (also in English), tangibly prove the great vogue this drama enjoys nowadays. Its doubtful nature, as far as the fusion of tragic and comic elements is concerned (see further Burnett, Directions in Euripidean Criticism: A Collection of Essays, Durham: Duke University Press, pp. 13–51, 177–88, 1985), and, most of all, its controversial authorship and date still render it a riddle—even though its non-Euripidean origin is widely accepted. Our research is an attempt to unveil the authorial status of this play, employing traditional and non-traditional authorship attribution techniques. In fact, as it will become clear in the course of this work, the latter kind of methodology allows us to approach the author of Rhesus in a way that was not even thought possible until the present day.",
 "article_title": "Devising Rhesus: A strange ‘collaboration’ between Aeschylus and Euripides",
 "authors": [
 {
 "given": " Nikos",
 "family": "Manousakis",
 "affiliation": [
 {
 "original_name": "National and Kapodistrian University of Athens, Greece",
 "normalized_name": "National and Kapodistrian University of Athens",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/04gnjpq42",
 "GRID": "grid.5216.0"
 }
 }
 ]
 },
 {
 "given": " Efstathios",
 "family": "Stamatatos",
 "affiliation": [
 {
 "original_name": "University of the Aegean, Greece",
 "normalized_name": "University of the Aegean",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/03zsp3p94",
 "GRID": "grid.7144.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-05-16",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx022",
 "identifier": {
 "string_id": "10.1093/llc/fqx022",
 "id_scheme": "DOI"
 },
 "abstract": "Computational stylistics has often analyzed variations in the style of a single author or text, including chronological change, the dialogue or narration of multiple characters or narrators in a single novel, and other perceived shifts in style. Here, I examine intra-textual style variation from a different perspective, and suggest circumstances under which it is appropriate and beneficial to omit some parts of texts from an analysis to eliminate sources of predictable and intrusive variation that would render other kinds of variation or consistency of style invisible. In other cases it may be appropriate to randomize a text to mask a kind of variation that would otherwise disrupt an analysis. One way to do this is by sorting the lines of the text in random order before analyzing it in sections. In analyses in which texts of very different lengths must be compared, it is also beneficial to randomize the longer parts, cut them all to approximately the length of the shortest one, and use the equalized amounts of text to create a word frequency list that is not biased in favor of the longer parts. These techniques can lead to a deeper understanding of style variation.",
 "article_title": "The microanalysis of style variation",
 "authors": [
 {
 "given": " David L",
 "family": "Hoover",
 "affiliation": [
 {
 "original_name": "Department of English, New York University, USA",
 "normalized_name": "New York University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0190ak572",
 "GRID": "grid.137628.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-04-28",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "32",
 "issue": "suppl_2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx020",
 "identifier": {
 "string_id": "10.1093/llc/fqx020",
 "id_scheme": "DOI"
 },
 "abstract": "Although there has been a drive in the cultural heritage sector to provide large-scale, open data sets for researchers, we have not seen a commensurate rise in humanities researchers undertaking complex analysis of these data sets for their own research purposes. This article reports on a pilot project at University College London, working in collaboration with the British Library, to scope out how best high-performance computing facilities can be used to facilitate the needs of researchers in the humanities. Using institutional data-processing frameworks routinely used to support scientific research, we assisted four humanities researchers in analysing 60,000 digitized books, and we present two resulting case studies here. This research allowed us to identify infrastructural and procedural barriers and make recommendations on resource allocation to best support non-computational researchers in undertaking ‘big data’ research. We recommend that research software engineer capacity can be most efficiently deployed in maintaining and supporting data sets, while librarians can provide an essential service in running initial, routine queries for humanities scholars. At present there are too many technical hurdles for most individuals in the humanities to consider analysing at scale these increasingly available open data sets, and by building on existing frameworks of support from research computing and library services, we can best support humanities scholars in developing methods and approaches to take advantage of these research opportunities.",
 "article_title": "Enabling complex analysis of large-scale digital collections: humanities research, high-performance computing, and transforming access to British Library digital collections",
 "authors": [
 {
 "given": " Melissa",
 "family": "Terras",
 "affiliation": [
 {
 "original_name": "Department of Information Studies, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 },
 {
 "original_name": "UCL Centre for Digital Humanities, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " James",
 "family": "Baker",
 "affiliation": [
 {
 "original_name": "School of History, Art History and Philosophy, University of Sussex, UK",
 "normalized_name": "University of Sussex",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/00ayhx656",
 "GRID": "grid.12082.39"
 }
 }
 ]
 },
 {
 "given": " James",
 "family": "Hetherington",
 "affiliation": [
 {
 "original_name": "Research Software Development Group, Research IT Services, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " David",
 "family": "Beavan",
 "affiliation": [
 {
 "original_name": "UCL Centre for Digital Humanities, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Martin",
 "family": "Zaltz Austwick",
 "affiliation": [
 {
 "original_name": "Centre for Advanced Spatial Analysis, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Anne",
 "family": "Welsh",
 "affiliation": [
 {
 "original_name": "Department of Information Studies, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Helen",
 "family": "O'Neill",
 "affiliation": [
 {
 "original_name": "Department of Information Studies, University College London, UK, The London Library, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Will",
 "family": "Finley",
 "affiliation": [
 {
 "original_name": "Department of History, University of Sheffield, UK",
 "normalized_name": "University of Sheffield",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05krs5044",
 "GRID": "grid.11835.3e"
 }
 }
 ]
 },
 {
 "given": " Oliver",
 "family": "Duke-Williams",
 "affiliation": [
 {
 "original_name": "Department of Information Studies, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Adam",
 "family": "Farquhar",
 "affiliation": [
 {
 "original_name": "Digital Scholarship, British Library, UK",
 "normalized_name": "British Library",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05dhe8b71",
 "GRID": "grid.36212.34"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-02-01",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx023",
 "identifier": {
 "string_id": "10.1093/llc/fqx023",
 "id_scheme": "DOI"
 },
 "abstract": "This article builds on a mathematical explanation of one the most prominent stylometric measures, Burrows’s Delta (and its variants), to understand and explain its working. Starting with the conceptual separation between feature selection, feature scaling, and distance measures, we have designed a series of controlled experiments in which we used the kind of feature scaling (various types of standardization and normalization) and the type of distance measures (notably Manhattan, Euclidean, and Cosine) as independent variables and the correct authorship attributions as the dependent variable indicative of the performance of each of the methods proposed. In this way, we are able to describe in some detail how each of these two variables interact with each other and how they influence the results. Thus we can show that feature vector normalization, that is, the transformation of the feature vectors to a uniform length of 1 (implicit in the cosine measure), is the decisive factor for the improvement of Delta proposed recently. We are also able to show that the information particularly relevant to the identification of the author of a text lies in the profile of deviation across the most frequent words rather than in the extent of the deviation or in the deviation of specific words only.",
 "article_title": "Understanding and explaining Delta measures for authorship attribution",
 "authors": [
 {
 "given": " Stefan",
 "family": "Evert",
 "affiliation": [
 {
 "original_name": "Friedrich-Alexander-Universität Erlangen-Nürnberg, Germany",
 "normalized_name": "University of Erlangen-Nuremberg",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/00f7hpc57",
 "GRID": "grid.5330.5"
 }
 }
 ]
 },
 {
 "given": " Thomas",
 "family": "Proisl",
 "affiliation": [
 {
 "original_name": "Friedrich-Alexander-Universität Erlangen-Nürnberg, Germany",
 "normalized_name": "University of Erlangen-Nuremberg",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/00f7hpc57",
 "GRID": "grid.5330.5"
 }
 }
 ]
 },
 {
 "given": " Fotis",
 "family": "Jannidis",
 "affiliation": [
 {
 "original_name": "Julius-Maximilians-Universität Würzburg, Germany",
 "normalized_name": "University of Würzburg",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/00fbnyb24",
 "GRID": "grid.8379.5"
 }
 }
 ]
 },
 {
 "given": " Isabella",
 "family": "Reger",
 "affiliation": [
 {
 "original_name": "Julius-Maximilians-Universität Würzburg, Germany",
 "normalized_name": "University of Würzburg",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/00fbnyb24",
 "GRID": "grid.8379.5"
 }
 }
 ]
 },
 {
 "given": " Steffen",
 "family": "Pielström",
 "affiliation": [
 {
 "original_name": "Julius-Maximilians-Universität Würzburg, Germany",
 "normalized_name": "University of Würzburg",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/00fbnyb24",
 "GRID": "grid.8379.5"
 }
 }
 ]
 },
 {
 "given": " Christof",
 "family": "Schöch",
 "affiliation": [
 {
 "original_name": "Julius-Maximilians-Universität Würzburg, Germany",
 "normalized_name": "University of Würzburg",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/00fbnyb24",
 "GRID": "grid.8379.5"
 }
 }
 ]
 },
 {
 "given": " Thorsten",
 "family": "Vitt",
 "affiliation": [
 {
 "original_name": "Julius-Maximilians-Universität Würzburg, Germany",
 "normalized_name": "University of Würzburg",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/00fbnyb24",
 "GRID": "grid.8379.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-01-21",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "32",
 "issue": "suppl_2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx029",
 "identifier": {
 "string_id": "10.1093/llc/fqx029",
 "id_scheme": "DOI"
 },
 "abstract": "We present two new measures of syntactic distance between languages. First, we present the ‘movement measure’ which measures the average number of words that has moved in sentences of one language compared to the corresponding sentences in another language. Secondly, we introduce the ‘indel measure’ which measures the average number of words being inserted or deleted in sentences of one language compared to the corresponding sentences in another language. The two measures were compared to the ‘trigram measure’ which was introduced by Nerbonne & Wiersma (2006, A Measure of Aggregate Syntactic Distance. In Nerbonne, J. and Hinrichs, E. (eds.) Linguistic Distances Workshop at the joint conference of International Committee on Computational Linguistics and the Association for Computational Linguistics, Sydney, July, 2006, pp. 82–90.). We correlated the results of the three measures and found a low correlation between the results of the movement and indel measure, indicating that the two measures represent different kinds of linguistic variation. We found a high correlation between the results of the movement measure and the trigram measure. The results of all of the three measures suggest that English is syntactically a Scandinavian language. Because of our unique database design we were able to detect asymmetric relationships between the languages. All three measures suggest that asymmetric syntactical distances could be part of the explanation why native speakers of Dutch more easily understand German texts than native speakers of German understand Dutch texts (Swarte 2016).",
 "article_title": "Measuring syntactical variation in Germanic texts",
 "authors": [
 {
 "given": " Wilbert",
 "family": "Heeringa",
 "affiliation": [
 {
 "original_name": "Fryske Akademy, The Netherlands",
 "normalized_name": "Fryske Akademy",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/05fcmfe52",
 "GRID": "grid.450022.1"
 }
 }
 ]
 },
 {
 "given": " Femke",
 "family": "Swarte",
 "affiliation": [
 {
 "original_name": "Faculty of Arts, Applied Linguistics, University of Groningen, The Netherlands",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 }
 ]
 },
 {
 "given": " Anja",
 "family": "Schüppert",
 "affiliation": [
 {
 "original_name": "Faculty of Arts, European Languages and Cultures, University of Groningen, The Netherlands",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 }
 ]
 },
 {
 "given": " Charlotte",
 "family": "Gooskens",
 "affiliation": [
 {
 "original_name": "Faculty of Arts, Applied Linguistics, University of Groningen, The Netherlands",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 },
 {
 "original_name": "School of Behavioural, Cognitive and Social Sciences, University of New England, Australia",
 "normalized_name": "University of New England",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/02n2ava60",
 "GRID": "grid.266826.e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-02-01",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx026",
 "identifier": {
 "string_id": "10.1093/llc/fqx026",
 "id_scheme": "DOI"
 },
 "abstract": "Through the prism of the comparison, this study examines the dialogism characterizing the discourse of French literary critics in the second half of the 19th century. Using an automatic method, a set of comparisons relying on terms belonging to eleven predetermined hard sciences (anatomy, biology, physics, chemistry, botany, zoology, astronomy, surgery, medicine, geology, and mathematics) was extracted in a corpus of 249 French critical texts as well as in novels, philosophical texts, scientific texts, and texts from the social and human sciences. Apart from confirming the separation of literary critics into two tendencies, one which distances itself from sciences, and the other which wants to emulate it, the retrieved comparative constructions show that despite this division, some sciences such as mathematics are mostly depicted negatively in relation to literature. Furthermore, the comparison plays a crucial role in conferring a scientific dimension to literary criticism, especially because it enables to create an analogical system around some scientific concepts such as ‘espèce’ and therefore, to classify, discuss, and scrutinize literary forms more rigorously. In this literary discourse, the comparison does not merely borrow terms from scientific disciplines but also imbue them with new meaning, so that literary criticism can acquire the same legitimacy as sciences without losing its intrinsic features.",
 "article_title": "At the crossroads between the scientific and the literary discourse: Comparison as a figure of dialogism",
 "authors": [
 {
 "given": " Marine",
 "family": "Riguet",
 "affiliation": [
 {
 "original_name": "Université Paris-Sorbonne, France",
 "normalized_name": "University of Paris-Sud",
 "country": "France",
 "identifiers": {
 "ror": "https://ror.org/028rypz17",
 "GRID": "grid.5842.b"
 }
 }
 ]
 },
 {
 "given": " Suzanne",
 "family": "Mpouli",
 "affiliation": [
 {
 "original_name": "Université Pierre et Marie Curie, France",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-01-21",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "32",
 "issue": "suppl_2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx030",
 "identifier": {
 "string_id": "10.1093/llc/fqx030",
 "id_scheme": "DOI"
 },
 "abstract": "Understanding people’s online behaviour has traditionally been a field of interest of commercial research agencies. However, academic researchers in a variety of fields are interested in the same type of data to gain insights in the Web behaviour of users. Digital Humanities scholars interested in the use of digital collections are, e.g., interested in the navigation paths of users to these collections. In our case we wanted (1) to analyse the way news consumers visit news websites and (2) understand how these websites fit in their daily news consumption patterns. Until now most common applied scholarly research methods to analyse online user behaviour focus on analyses of log files provided by website owners or recalled user behaviour by survey, diary, or interview methods. Only recently scholars started to experiment with gathering real-world data of Web behaviour by monitoring a group of respondents. In this article we describe the set-up of ‘The Newstracker’, a tool that primarily allowed us to analyse online news consumption of a group of young Dutch news users on their desktop and laptop computers. We demonstrate the workflow of the Newstracker and how we designed the data collection and pre-processing phase. By reflecting on the technical, methodological, and analytical challenges we encountered, we illustrate the potential of online monitoring tools such as the Newstracker. We end our article with discussing its limitations by stressing the need for a multimethod study design when aiming not only to analyse but also to understand online user behaviour.",
 "article_title": "Analysing and understanding news consumption patterns by tracking online user behaviour with a multimodal research design",
 "authors": [
 {
 "given": " Martijn",
 "family": "Kleppe",
 "affiliation": [
 {
 "original_name": "National Library of the Netherlands (KB), The Netherlands and Vrije Universiteit Amsterdam, The Netherlands",
 "normalized_name": "VU Amsterdam",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/008xxew50",
 "GRID": "grid.12380.38"
 }
 }
 ]
 },
 {
 "given": " Marco",
 "family": "Otte",
 "affiliation": [
 {
 "original_name": "National Library of the Netherlands (KB), The Netherlands and Vrije Universiteit Amsterdam, The Netherlands",
 "normalized_name": "VU Amsterdam",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/008xxew50",
 "GRID": "grid.12380.38"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-10-14",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "32",
 "issue": "suppl_2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx034",
 "identifier": {
 "string_id": "10.1093/llc/fqx034",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents an epistemological rationale, intellectual justification, and design outline for a non-representational approach to modeling interpretation in a graphical environment. It begins with a brief critical discussion of the representational approaches that are the common form of information visualizations and suggests that the less familiar non-representational approach could be used to augment these existing visualizations by supporting interpretative work that is closer to the practice of humanistic hermeneutic traditions. Representational display, based on large-scale processing, surrogates, and conventional visualizations, and non-representational modeling at the level of the individual interpretative act operate at very different scales to support intellectual work. In a representational approach, data precede display. Display is a surrogate produced according to automated protocols and algorithms. These cannot be altered or intervened except through rewriting their code, and the display, though interpretative and subject to interpretation, cannot be used as a means by which interpretation is actually modeled. While all visualizations express a model, they do not all provide a modeling environment. In the non-representational approach proposed here, graphical input serves as a primary means of interpretative work. More significantly, a graphical environment that supports direct modeling of interpretation allows traditional humanistic approaches, close reading, and marking of texts, documents, artifacts, or images, to be integrated with computationally produced visualizations. This research was developed as part of the 3DH (three-dimensional/digital humanities) project hosted at the University of Hamburg, between April and June 2016.",
 "article_title": "Non-representational approaches to modeling interpretation in a graphical environment",
 "authors": [
 {
 "given": " Johanna",
 "family": "Drucker",
 "affiliation": [
 {
 "original_name": "University of California, Los Angeles, USA",
 "normalized_name": "California Coast University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05t99sp05",
 "GRID": "grid.468726.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-11-06",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx028",
 "identifier": {
 "string_id": "10.1093/llc/fqx028",
 "id_scheme": "DOI"
 },
 "abstract": "Maya hieroglyphic analysis requires epigraphers to spend a significant amount of time browsing existing catalogs to identify individual glyphs. Automatic Maya glyph analysis provides an efficient way to assist scholars’ daily work. We introduce the Histogram of Orientation Shape Context (HOOSC) shape descriptor to the Digital Humanities community. We discuss key issues for practitioners and study the effect that certain parameters have on the performance of the descriptor. Different HOOSC parameters are tested in an automatic ancient Maya hieroglyph retrieval system with two different settings, namely, when shape alone is considered and when glyph co-occurrence information is incorporated. Additionally, we developed a graph-based glyph visualization interface to facilitate efficient exploration and analysis of hieroglyphs. Specifically, a force-directed graph prototype is applied to visualize Maya glyphs based on their visual similarity. Each node in the graph represents a glyph image; the width of an edge indicates the visual similarity between the two according glyphs. The HOOSC descriptor is used to represent glyph shape, based on which pairwise glyph similarity scores are computed. To evaluate our tool, we designed evaluation tasks and questionnaires for two separate user groups, namely, a general public user group and an epigrapher scholar group. Evaluation results and feedback from both groups show that our tool provides intuitive access to explore and discover the Maya hieroglyphic writing, and could potentially facilitate epigraphy work. The positive evaluation results and feedback further hint the practical value of the HOOSC descriptor.",
 "article_title": "Analyzing and visualizing ancient Maya hieroglyphics using shape: From computer vision to Digital Humanities",
 "authors": [
 {
 "given": " Rui",
 "family": "Hu",
 "affiliation": [
 {
 "original_name": "Idiap Research Institute, École Polytechnique Fédérale de Lausanne (EPFL), Switzerland",
 "normalized_name": "Idiap Research Institute",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/05932h694",
 "GRID": "grid.482253.a"
 }
 }
 ]
 },
 {
 "given": " Carlos Pallán",
 "family": "Gayol",
 "affiliation": [
 {
 "original_name": "University of Bonn, Germany",
 "normalized_name": "University of Bonn",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/041nas322",
 "GRID": "grid.10388.32"
 }
 }
 ]
 },
 {
 "given": " Jean-Marc",
 "family": "Odobez",
 "affiliation": [
 {
 "original_name": "Idiap Research Institute, École Polytechnique Fédérale de Lausanne (EPFL), Switzerland",
 "normalized_name": "Idiap Research Institute",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/05932h694",
 "GRID": "grid.482253.a"
 }
 }
 ]
 },
 {
 "given": " Daniel",
 "family": "Gatica-Perez",
 "affiliation": [
 {
 "original_name": "Idiap Research Institute, École Polytechnique Fédérale de Lausanne (EPFL), Switzerland",
 "normalized_name": "Idiap Research Institute",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/05932h694",
 "GRID": "grid.482253.a"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-01-21",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "32",
 "issue": "suppl_2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx037",
 "identifier": {
 "string_id": "10.1093/llc/fqx037",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents a model of author dictionary in the field of Latin lexicography. It proposes an organization of the microstructure of its entries following S. C. Dik’s Functionalist Grammar linguistic principles, especially when describing the predicative frameworks. The objective of this article is to provide the user of the lexicon with a suitable tool to disambiguate meanings, thanks to the description of the predicative frameworks and the relationships the different lemmatized units keep. To proceed so, an XML file has been used as the support of the dictionary which is contrasted with its correspondent DTD. This guarantees the adequacy of the principle of hierarchic representation of this metalanguage as well as its lexicographic exploitation in computational linguistics.",
 "article_title": "A lexicographical model based on the predicative framework theory (functional grammar) for sense disambiguation. An application to Latin author dictionaries",
 "authors": [
 {
 "given": " Manuel Márquez",
 "family": "Cruz",
 "affiliation": [
 {
 "original_name": "Department of Latin Philology, Universidad Complutense de Madrid, Spain",
 "normalized_name": "Complutense University of Madrid",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/02p0gd045",
 "GRID": "grid.4795.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-05-16",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx036",
 "identifier": {
 "string_id": "10.1093/llc/fqx036",
 "id_scheme": "DOI"
 },
 "abstract": "Certain problems in the design of digital systems for use in cultural heritage and the humanities have proved to be unexpectedly difficult to solve. For example, Why is it difficult to locate ourselves and understand the extent and shape of digital information resources? Why is digital serendipity still so unusual? Why do users persist in making notes on paper rather than using digital annotation systems? Why do we like to visit and work in a library, and browse open stacks, even though we could access digital information remotely? Why do we still love printed books, but feel little affection for digital e-readers? Why are vinyl records so popular? Why is the experience of visiting a museum still relatively unaffected by digital interaction? The article argues that the reasons these problems persist may be due to the very complex relationship between physical and digital information and information resources. I will discuss the importance of spatial orientation, memory, pleasure, and multi-sensory input, especially touch, in making sense of, and connections between physical and digital information. I will also argue that, in this context, we have much to learn from the designers of early printed books and libraries, such as the Priory Library and that of John Cosin, a seventeenth-century bishop of Durham, which is part of the collections of Durham University library.",
 "article_title": "Beauty is truth: Multi-sensory input and the challenge of designing aesthetically pleasing digital resources",
 "authors": [
 {
 "given": " Claire",
 "family": "Warwick",
 "affiliation": [
 {
 "original_name": "Department of English Studies, Durham University, UK",
 "normalized_name": "Durham University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01v29qb04",
 "GRID": "grid.8250.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-10-14",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "32",
 "issue": "suppl_2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx039",
 "identifier": {
 "string_id": "10.1093/llc/fqx039",
 "id_scheme": "DOI"
 },
 "abstract": "In this article we aim to provide a minimally sufficient theoretical framework to argue that it is time for a re-conception of the notion of text in the field of digital textual scholarship. This should allow us to reconsider the ontological status of digital text, and that will ground future work discussing the specific analytical affordances offered by digital texts understood as digital texts. Following from the argument of Suzanne Briet regarding documentation, referring to Eco’s understanding of ‘infinite semiosis’, and accounting for the reciprocal effects between carrier technology and meaning observed by McLuhan, we argue that the functions of document and text are realized primarily by their fluid nature and by the dynamic character of their interpretation. To define the purpose of textual scholarship as a ‘stabilisation’ of text is therefore fallacious. The delusive focus on ‘stability’ and discrete ‘philological fact’ gives rise to a widespread belief in textual scholarship that digital texts can be treated simply as representations of print or manuscript texts. On the contrary—digital texts are texts in and of themselves in numerous digital models and data structures which may include, but is not limited to, text meant for graphical display on a screen. We conclude with the observation that philological treatment of these texts demands an adequate digital and/or computational literacy.",
 "article_title": "Qu’est-ce qu’un texte numérique?—A new rationale for the digital representation of text",
 "authors": [
 {
 "given": " Joris J",
 "family": "van Zundert",
 "affiliation": [
 {
 "original_name": "Royal Netherlands Academy of Arts and Sciences, The Netherlands",
 "normalized_name": "Royal Netherlands Academy of Arts and Sciences",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/043c0p156",
 "GRID": "grid.418101.d"
 }
 }
 ]
 },
 {
 "given": " Tara L",
 "family": "Andrews",
 "affiliation": [
 {
 "original_name": "University of Vienna, Austria",
 "normalized_name": "University of Vienna",
 "country": "Austria",
 "identifiers": {
 "ror": "https://ror.org/03prydq77",
 "GRID": "grid.10420.37"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-01-21",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "32",
 "issue": "suppl_2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw056",
 "identifier": {
 "string_id": "10.1093/llc/fqw056",
 "id_scheme": "DOI"
 },
 "abstract": "This essay considers both the promise and perils of \"social editing,\" a term strongly associated with user-generated content. The idea of user-contributed content has been greeted with enthusiasm in some quarters and with skepticism and anxiety in others. We can learn from the crowdsourcing efforts undertaken thus far and can glimpse some of the new possibilities on the horizon. To what extent might users of electronic editions help projects such as the Walt Whitman Archive address the extensive and costly work that stands in the way of the realization of a digital scholarly edition? How can the Archive best negotiate the roles of scholarly specialists and interested users, and in particular, how can quality control be established without discouraging user involvement?",
 "article_title": "The Walt Whitman Archiveand the prospects for social editing",
 "authors": [
 {
 "given": " Kenneth M.",
 "family": "Price",
 "affiliation": [
 {
 "original_name": "University of Nebraska—Lincoln, USA",
 "normalized_name": "University of Nebraska–Lincoln",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/043mer456",
 "GRID": "grid.24434.35"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-12-11",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw060",
 "identifier": {
 "string_id": "10.1093/llc/fqw060",
 "id_scheme": "DOI"
 },
 "abstract": "At certain points in history, certain words take on a positive aura that makes it difficult to openly express dissenting or sceptical views about the objects, processes, or qualities they denote. Right now, social has this aura. This word’s role as a modifier to make the noun after it refer to society and other kinds of human association—as in social law and social life—emerged at the end of the sixteenth century (OED ‘social’ adj. 5a, 5b). Most recently, the word has attached itself to a relatively new word, media—first used to denote mass communication in 1927 (OED ‘media’ n.2)—to denote a new kind of technology of communication. Whereas the ordinary media provided only one-way, one-to-many, communication, the social media allow ‘users to create and share...",
 "article_title": "Afterword",
 "authors": [
 {
 "given": " Gabriel",
 "family": "Egan",
 "affiliation": [
 {
 "original_name": "School of Humanities, De Montfort University, Leicester, England",
 "normalized_name": "De Montfort University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0312pnr83",
 "GRID": "grid.48815.30"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-12-28",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw052",
 "identifier": {
 "string_id": "10.1093/llc/fqw052",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents a study of Leo Tolstoy’s War and Peace by means of automatic syntactic and semantic analysis. Using a parser that extracts syntactic dependencies and semantic roles we were able to compare different characters of the novel in terms of the semantic roles they tend to occupy. Our data show that there are certain dependencies between the apparent personal traits of a character and his or her positions within the predicate structures. We hope that further research will help us gain more insights into the ‘literary technique’ of Tolstoy and enable us to create a semantic mark-up of his works.",
 "article_title": "Text miningWar and Peace: Automatic extraction of character traits from literary pieces",
 "authors": [
 {
 "given": " Anastasia",
 "family": "Bonch-Osmolovskaya",
 "affiliation": [
 {
 "original_name": "National Research University ‘Higher School of Economics’, Russia",
 "normalized_name": "National Research University Higher School of Economics",
 "country": "Russia",
 "identifiers": {
 "ror": "https://ror.org/055f7t516",
 "GRID": "grid.410682.9"
 }
 }
 ]
 },
 {
 "given": " Daniil",
 "family": "Skorinkin",
 "affiliation": [
 {
 "original_name": "National Research University ‘Higher School of Economics’, Russia",
 "normalized_name": "National Research University Higher School of Economics",
 "country": "Russia",
 "identifiers": {
 "ror": "https://ror.org/055f7t516",
 "GRID": "grid.410682.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-01-01",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw062",
 "identifier": {
 "string_id": "10.1093/llc/fqw062",
 "id_scheme": "DOI"
 },
 "abstract": "AustLit is a major Australian cultural heritage database and the most comprehensive record of a nation’s literary history in the world. In this article we will present the successful results of a project addressing the challenge of discovering and recording creative writing published in digitized historical Australian newspapers, provided by the National Library of Australia’s Trove service. As a first step in identifying creative writing, we developed an automated method for identifying articles that are likely to be poems by searching for a number of signals embedded in articles. When this work began, AustLit contained more than 10,200 bibliographical records for poems published between 1803 and 1954 (75% prior to 1900) with links to the full text in 115 different newspapers. The aim of the project was to expand this number of bibliographical records in AustLit and provide a foundation for analysing the importance of poetry in newspaper publishing of the period. Taking advantage of Ted Underwood’s (Getting Everything you Want from HathiTrust http://tedunderwood.com/2012/07/27/getting-everything-you-want-from-hathitrust/, and Open Data (http://tedunderwood.com/open-data/): The Stone and the Shell, Underwood blog posts (Both accessed 27 October 2015), 2012) work with seventeenth- and eighteenth-century full text in the HathiTrust collection, we trained a naive Bayesian classifier, modifying code from Daniel Shiffman (Bayesian Filtering. http://shiffman.net/teaching/a2z_2008/bayesian/ (accessed 27 October 2015), 2008) and Paul Graham (A Plan for Spam. http://www.paulgraham.com/spam.html (accessed 27 October 2015), 2002) and improving the quality of Optical Character Recognition (OCR) by using the overProof correction algorithm. We have been able to successfully identify large numbers of poems in the newspapers database, greatly expanding AustLit’s coverage of this important literary form. After suitable training of the classifier, we were able to successfully identify 88% of the newspaper articles that a knowledgeable human would classify as ‘poetry’. Our results have encouraged us to consider enhancing and extending the techniques to aid the identification of other forms of literature and criticism.",
 "article_title": "‘Searching for My Lady’s Bonnet: discovering poetry in the National Library of Australia’s newspapers database’",
 "authors": [
 {
 "given": " Kerry",
 "family": "Kilner",
 "affiliation": [
 {
 "original_name": "The School of Communication and Arts, The University of Queensland, Australia",
 "normalized_name": "University of Queensland",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00rqy9422",
 "GRID": "grid.1003.2"
 }
 }
 ]
 },
 {
 "given": " Kent",
 "family": "Fitch",
 "affiliation": [
 {
 "original_name": "The School of Communication and Arts, The University of Queensland, Australia",
 "normalized_name": "University of Queensland",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00rqy9422",
 "GRID": "grid.1003.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-01-08",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw059",
 "identifier": {
 "string_id": "10.1093/llc/fqw059",
 "id_scheme": "DOI"
 },
 "abstract": "It is widely believed that different parts of a classical Chinese poem vary in syntactic properties. The middle part is usually parallel, i.e. the two lines in a couplet have similar sentence structure and part of speech; in contrast, the beginning and final parts tend to be non-parallel. Imagistic language, dominated by noun phrases evoking images, is concentrated in the middle; propositional language, with more complex grammatical structures, is more often found at the end. We present the first quantitative analysis on these linguistic phenomena—syntactic parallelism, imagistic language, and propositional language—on a treebank of selected poems from the Complete Tang Poems. Written during the Tang Dynasty between the 7th and 9th centuries CE, these poems are often considered the pinnacle of classical Chinese poetry. Our analysis affirms the traditional observation that the final couplet is rarely parallel; the middle couplets are more frequently parallel, especially at the phrase rather than the word level. Further, the final couplet more often takes a non-declarative mood, uses function words, and adopts propositional language. In contrast, the beginning and middle couplets employ more content words and tend toward imagistic language.",
 "article_title": "Syntactic patterns in classical Chinese poems: A quantitative study",
 "authors": [
 {
 "given": " John",
 "family": "Lee",
 "affiliation": [
 {
 "original_name": "Department of Linguistics and Translation, City University of Hong Kong, Hong Kong SAR, China",
 "normalized_name": "City University of Hong Kong",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/03q8dnn23",
 "GRID": "grid.35030.35"
 }
 }
 ]
 },
 {
 "given": " Yin Hei",
 "family": "Kong",
 "affiliation": [
 {
 "original_name": "Department of Linguistics and Translation, City University of Hong Kong, Hong Kong SAR, China",
 "normalized_name": "City University of Hong Kong",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/03q8dnn23",
 "GRID": "grid.35030.35"
 }
 }
 ]
 },
 {
 "given": " Mengqi",
 "family": "Luo",
 "affiliation": [
 {
 "original_name": "Information Retrieval and Knowledge Mining Laboratory, Wuhan University, Wuhan, China",
 "normalized_name": "Wuhan University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/033vjfk17",
 "GRID": "grid.49470.3e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-01-08",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw063",
 "identifier": {
 "string_id": "10.1093/llc/fqw063",
 "id_scheme": "DOI"
 },
 "abstract": "This article describes the research and development (R&D) work done as an extension to the multilingual cross-domain client application prototype for UNL-ization and NL-ization for natural language processing (NLP) application developed by Agarwal and Kumar (A multilingual cross-domain client application prototype for UNL-ization and NL-ization for NLP applications. Digital Scholarship in the Humanities, 2016)1. A common platform has been developed and made live for worldwide users where they can share their Interactive Analyzer and EUGENE (dEep-to-sUrface GENErator) resources and exploit already shared resources by other users for UNL-ization and NL-ization. This article also highlights that how the existing platform can be used by other researchers and developers to make their UNL-based Web applications language-independent and can make it available to computational linguists, researchers, developers, and general audience globally. Such kind of platform is definitely useful for all UNL-based R&D activities being done throughout the geography. The platform gives 100% accuracy. However, the correctness depends on the F-measure of the respective Analysis and Generation module being used.",
 "article_title": "A public platform for developing language-independent applications",
 "authors": [
 {
 "given": " Vaibhav",
 "family": "Agarwal",
 "affiliation": [
 {
 "original_name": "Thapar University, CSED, India",
 "normalized_name": "Thapar University",
 "country": "India",
 "identifiers": {
 "ror": "https://ror.org/00wdq3744",
 "GRID": "grid.412436.6"
 }
 }
 ]
 },
 {
 "given": " Parteek",
 "family": "Kumar",
 "affiliation": [
 {
 "original_name": "Thapar University, CSED, India",
 "normalized_name": "Thapar University",
 "country": "India",
 "identifiers": {
 "ror": "https://ror.org/00wdq3744",
 "GRID": "grid.412436.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-02-04",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx007",
 "identifier": {
 "string_id": "10.1093/llc/fqx007",
 "id_scheme": "DOI"
 },
 "abstract": "This present article examines the verbal style and rhetoric of the candidates of the 2016 US presidential primary elections. To achieve this objective, this study analyzes the oral communication forms used by the candidates during the TV debates. When considering the most frequent lemmas, the candidates can be split into two groups, one using more frequently the pronoun ‘I’, and the second favoring more the ‘we’ (which corresponds to candidates leaving the presidential run sooner). According to several overall stylistic indicators, candidate Trump clearly adopted a simple and direct communication style, avoiding complex formulation and vocabulary. From a topical perspective, our analysis generates a map showing the affinities between candidates. This investigation results in the presence of three distinct groups of candidates, the first one with the Democrats (Clinton, O’Malley, and Sanders), the second with three Republicans (Bush, Cruz, Rubio), and the last with the duo Trump and Kasich, with, at a small distance, Paul. The over-used terms and typical sentences associated with each candidate reveal their specific topics such as ‘simple flat tax’ for Cruz, ‘balanced budget’ for Kasich, negativity with Trump, or critiques against large corporations and Wall Street for Sanders.",
 "article_title": "Analysis of the style and the rhetoric of the 2016 US presidential primaries",
 "authors": [
 {
 "given": " Jacques",
 "family": "Savoy",
 "affiliation": [
 {
 "original_name": "University of Neuchatel, Switzerland",
 "normalized_name": "University of Neuchâtel",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/00vasag41",
 "GRID": "grid.10711.36"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-03-20",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx004",
 "identifier": {
 "string_id": "10.1093/llc/fqx004",
 "id_scheme": "DOI"
 },
 "abstract": "This article explains some aspects of the verbal polysemy of Old English by means of the concept of semantic pole, an area of semantic space that represents a core meaning. It draws on the semantic primes of the natural semantic metalanguage, the theoretical constructs of semantic space, and force dynamics as well as semantic maps based on graph theory. In the semantic map, graphs link poles to definiens and lexical nodes, in such a way that the centrality of the poles is indicated, quantitatively, by the number of edges and, qualitatively, by the distance between the pole that exerts the centrifugal force and the pole to which such a force is directed. The conclusion is reached that the semantic poles MOVE, BE, and SAY constitute the core of the verbal lexicon of Old English, considering the semantic space that they occupy and the centrifugal and centripetal forces that produce polysemy originating in these semantic poles.",
 "article_title": "The semantic poles of Old English: Toward the 3D representation of complex polysemy",
 "authors": [
 {
 "given": " Javier ",
 "family": "Martín Arista",
 "affiliation": [
 {
 "original_name": "Universidad de La Rioja",
 "normalized_name": "University of La Rioja",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/0553yr311",
 "GRID": "grid.119021.a"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-03-20",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx001",
 "identifier": {
 "string_id": "10.1093/llc/fqx001",
 "id_scheme": "DOI"
 },
 "abstract": "Translating poetry is a very complex process. The paradoxical nature of untranslatability and translatability of poetry has been noticed by Hai An (The translation of poetry by the translator-cum-poet. Chinese Translator Journals 2005; 6: 27–30), citing two famous scholars who are holding totally different opinions toward poetry translation. Robert Frost purports that ‘poetry is what gets lost in translation’, and Susan Bassnet advocates ‘poetry is what we gain in translation’. However, the common ground between these two drastic opinions is that poetry translation is no more a repetition of the original works than a reproduction. There are both similarities and discrepancies between the translated works and the original pieces, or in another word: ‘harmony in diversity’. This study aims to testify the above-mentioned proposal in a clear and objective manner, by comparing the original poetry texts (twenty randomly selected poems from Shakespearean sonnets) with their translated versions (the corresponding Chinese-translated versions by four different translators) from the perspective of vocabulary, word frequency distribution and part-of-speech (POS) frequency distribution. The results have corroborated the previous proposal: first, there is no significant difference in terms of vocabulary size and the text management styles between the translated poems and the original ones. Second, there is a significant difference in the word frequency distribution and POS frequency distribution between translated poems and the original ones. Third, there are also differences in the POS frequency distribution in poems translated by different authors. Furthermore, the translation style could distinguish professional translators from professional poets.",
 "article_title": "Harmony in diversity: The language codes in English–Chinese poetry translation",
 "authors": [
 {
 "given": " Xiaxing",
 "family": "Pan",
 "affiliation": [
 {
 "original_name": "Chinese Language and Culture College, National Huaqiao University, China",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Xinying",
 "family": "Chen",
 "affiliation": [
 {
 "original_name": "School of Foreign Studies, Xi’an Jiaotong University, China",
 "normalized_name": "Xi'an Jiaotong University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/017zhmm22",
 "GRID": "grid.43169.39"
 }
 }
 ]
 },
 {
 "given": " Haitao",
 "family": "Liu",
 "affiliation": [
 {
 "original_name": "Department of Linguistics, Zhejiang University, China",
 "normalized_name": "Zhejiang University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/00a2xv884",
 "GRID": "grid.13402.34"
 }
 },
 {
 "original_name": "Centre for Linguistics and Applied Linguistics, Guangdong University of Foreign Studies, Guangzhou, China",
 "normalized_name": "Guangdong University of Foreign Studies",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/00fhc9y79",
 "GRID": "grid.440718.e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-03-20",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw064",
 "identifier": {
 "string_id": "10.1093/llc/fqw064",
 "id_scheme": "DOI"
 },
 "abstract": "We present a process for cost-effective transcription of cursive handwritten text images that has been tested on a 1,000-page 17th-century book about botanical species. The process comprised two main tasks, namely: (1) preprocessing: page layout analysis, text line detection, and extraction; and (2) transcription of the extracted text line images. Both tasks were carried out with semiautomatic procedures, aimed at incrementally minimizing user correction effort, by means of computer-assisted line detection and interactive handwritten text recognition technologies. The contribution derived from this work is three-fold. First, we provide a detailed human-supervised transcription of a relatively large historical handwritten book, ready to be searchable, indexable, and accessible to cultural heritage scholars as well as the general public. Second, we have conducted the first longitudinal study to date on interactive handwriting text recognition, for which we provide a very comprehensive user assessment of the real-world performance of the technologies involved in this work. Third, as a result of this process, we have produced a detailed transcription and document layout information (i.e. high-quality labeled data) ready to be used by researchers working on automated technologies for document analysis and recognition.",
 "article_title": "Transcribing a 17th-century botanical manuscript: Longitudinal evaluation of document layout detection and interactive transcription",
 "authors": [
 {
 "given": " Alejandro H",
 "family": "Toselli",
 "affiliation": [
 {
 "original_name": "PRHLT Research Center, Universitat Politècnica de València, Spain",
 "normalized_name": "Universitat Politècnica de València",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01460j859",
 "GRID": "grid.157927.f"
 }
 }
 ]
 },
 {
 "given": " Luis A",
 "family": "Leiva",
 "affiliation": [
 {
 "original_name": "PRHLT Research Center, Universitat Politècnica de València, Spain",
 "normalized_name": "Universitat Politècnica de València",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01460j859",
 "GRID": "grid.157927.f"
 }
 }
 ]
 },
 {
 "given": " Isabel",
 "family": "Bordes-Cabrera",
 "affiliation": [
 {
 "original_name": "Biblioteca Nacional de España, Spain",
 "normalized_name": "Biblioteca Nacional de España",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/02cr20t12",
 "GRID": "grid.432858.0"
 }
 }
 ]
 },
 {
 "given": " Celio",
 "family": "Hernández-Tornero",
 "affiliation": [
 {
 "original_name": "PRHLT Research Center, Universitat Politècnica de València, Spain",
 "normalized_name": "Universitat Politècnica de València",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01460j859",
 "GRID": "grid.157927.f"
 }
 }
 ]
 },
 {
 "given": " Vicent",
 "family": "Bosch",
 "affiliation": [
 {
 "original_name": "PRHLT Research Center, Universitat Politècnica de València, Spain",
 "normalized_name": "Universitat Politècnica de València",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01460j859",
 "GRID": "grid.157927.f"
 }
 }
 ]
 },
 {
 "given": " Enrique",
 "family": "Vidal",
 "affiliation": [
 {
 "original_name": "PRHLT Research Center, Universitat Politècnica de València, Spain",
 "normalized_name": "Universitat Politècnica de València",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01460j859",
 "GRID": "grid.157927.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-02-01",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx009",
 "identifier": {
 "string_id": "10.1093/llc/fqx009",
 "id_scheme": "DOI"
 },
 "abstract": "In this article an automatic scansion model for fixed-metre Spanish poetry is presented. It is a hybrid model that combines hand-made rules with probabilistic information. Through the set of rules, the model is able to extract the syllabic structure of each word, to classify them as stressed or unstressed and to resolve metrical phenomena such as synaloephas or diaereses. The article is mainly focused on the metrical ambiguities produced by synaloephas: verse lines from which it is possible to derive two or more metrical patterns. This metrical ambiguity is resolved through probabilities, assuming a relation between high probabilities and metricality. The system has been evaluated through more than 1,000 lines extracted from a corpus of Golden-Age Spanish sonnets. An accuracy of 95% has been achieved, resulting in not only considerable progress if we compare it to previous proposals, but also in an adequate way of performing the task when compared to human performance.",
 "article_title": "A metrical scansion system for fixed-metre Spanish poetry",
 "authors": [
 {
 "given": " Borja",
 "family": "Navarro-Colorado",
 "affiliation": [
 {
 "original_name": "Department of Software and Computing Systems, University of Alicante",
 "normalized_name": "University of Alicante",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/05t8bcz72",
 "GRID": "grid.5268.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-03-09",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx003",
 "identifier": {
 "string_id": "10.1093/llc/fqx003",
 "id_scheme": "DOI"
 },
 "abstract": "English historical linguists have often complained about the scholarly neglect of the phonology of the Late Modern English period; yet, the value of pronouncing dictionaries as rich and reliable evidence has been demonstrated (Beal, J. C., 1999, English Pronunciation in the Eighteenth Century: Thomas Spence’s Grand Repository of the English Language (1775). Oxford: Clarendon Press; Jones, C., 2006, English Pronunciation in the Eighteenth and Nineteenth Centuries. Basingstoke: Palgrave Macmillan). This article presents a new electronic, searchable database of ‘Eighteenth-Century English Phonology’ (ECEP) which aims to facilitate research on the social, regional, and lexical distribution of phonological variants in 18th-century English, as documented in contemporary pronouncing dictionaries. Taking Wells’ (1982, Accents of English. Cambridge: Cambridge University Press) lexical sets for the vowel system of present-day varieties of English as its reference, the database provides unicode IPA transcriptions for the relevant segment of each word given as an example of lexical (sub)set in his account of standard lexical sets, to which we have added some complementary consonant sets. These will be of use for comparative studies with 19th-century and present-day English. First, we describe the methodology and contents of ECEP: primary source selection, data input and annotation, the web-based interface. Second, we report on two case studies that demonstrate the value of evidence that can be systematically extracted from ECEP for the analysis of segmental and suprasegmental phonology; these are variations in the pronunciation of ‘wh’ in the set whale (/hw/∼/w/∼/h/), and the palatalization of alveolar consonants before /uː/. Thus, this article will demonstrate the viability of ECEP for historical phonology, dialectology, and sociolinguistics, and will help to promote the use of databases as key resources in historical linguistics.",
 "article_title": "‘Proper’ pro-nun-ʃha-ʃhun1 in Eighteenth-Century English: ECEP as a New Tool for the Study of Historical Phonology and Dialectology",
 "authors": [
 {
 "given": " Nuria",
 "family": "Yáñez-Bouza",
 "affiliation": [
 {
 "original_name": "Universidade de Vigo, Department of Filoloxia Inglesa, Vigo, Spain",
 "normalized_name": "Universidade de Vigo",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/05rdf8595",
 "GRID": "grid.6312.6"
 }
 }
 ]
 },
 {
 "given": " Joan C",
 "family": "Beal",
 "affiliation": [
 {
 "original_name": "University of Sheffield, School of English, Sheffield, UK",
 "normalized_name": "University of Sheffield",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05krs5044",
 "GRID": "grid.11835.3e"
 }
 }
 ]
 },
 {
 "given": " Ranjan",
 "family": "Sen",
 "affiliation": [
 {
 "original_name": "University of Sheffield, School of English, Sheffield, UK",
 "normalized_name": "University of Sheffield",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05krs5044",
 "GRID": "grid.11835.3e"
 }
 }
 ]
 },
 {
 "given": " Christine",
 "family": "Wallis",
 "affiliation": [
 {
 "original_name": "University of Sheffield, School of English, Sheffield, UK",
 "normalized_name": "University of Sheffield",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05krs5044",
 "GRID": "grid.11835.3e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-03-20",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx010",
 "identifier": {
 "string_id": "10.1093/llc/fqx010",
 "id_scheme": "DOI"
 },
 "abstract": "The point of departure for this article is the Renderings project (http://trope-tank.mit.edu/renderings/) established in 2014 and developed at the Massachusetts Institute of Technology in a laboratory called the Trope Tank. The goal of the project is to translate highly computational and otherwise unusual digital literature into English. Translating digital works that are implemented as computer programs presents new challenges that go beyond the already difficult ones tackled by translators of more typical forms of literature. It is a type of translation akin to the translation of experimental, conceptual, or constrained works. It is not unusual for this task to require the translator or translators to reinvent the work in a new linguistic and cultural context, and sometimes also to port the original program to another programming language. This article describes an undertaking related to the broadly understood discipline of creative computing and studies the work of the translator as taking place both in code and language, drawing from the methodologies developed by the fields of code studies, platform studies, and expressive processing.",
 "article_title": "Renderings: Translating literary works in the digital age",
 "authors": [
 {
 "given": " Piotr",
 "family": "Marecki",
 "affiliation": [
 {
 "original_name": "Jagiellonian University, Poland",
 "normalized_name": "Jagiellonian University",
 "country": "Poland",
 "identifiers": {
 "ror": "https://ror.org/03bqmcz70",
 "GRID": "grid.5522.0"
 }
 }
 ]
 },
 {
 "given": " Nick",
 "family": "Montfort",
 "affiliation": [
 {
 "original_name": "Massachusetts Institute of Technology, USA",
 "normalized_name": "Massachusetts Institute of Technology",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/042nb2s44",
 "GRID": "grid.116068.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-01-21",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "32",
 "issue": "suppl_1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx011",
 "identifier": {
 "string_id": "10.1093/llc/fqx011",
 "id_scheme": "DOI"
 },
 "abstract": "The identification of pseudepigraphic texts—texts not written by the authors to which they are attributed—has important historical, forensic, and commercial applications. Any method for identifying such pseudepigrapha must ultimately depend on some measure of a given document’s similarity to the other documents in a corpus. We show that for this purpose, second-order document similarity measures taken from the authorship verification literature strongly outperform standard document similarity measures commonly used for outlier identification. We apply these improved methods to two famous corpora suspected of including pseudepigrapha: Shakespeare’s plays and Pauline epistles.",
 "article_title": "Detecting pseudepigraphic texts using novel similarity measures",
 "authors": [
 {
 "given": " Moshe",
 "family": "Koppel",
 "affiliation": [
 {
 "original_name": "Department of Computer, Bar Ilan University, Israel",
 "normalized_name": "Bar-Ilan University",
 "country": "Israel",
 "identifiers": {
 "ror": "https://ror.org/03kgsv495",
 "GRID": "grid.22098.31"
 }
 }
 ]
 },
 {
 "given": " Shachar",
 "family": "Seidman",
 "affiliation": [
 {
 "original_name": "Department of Computer, Bar Ilan University, Israel",
 "normalized_name": "Bar-Ilan University",
 "country": "Israel",
 "identifiers": {
 "ror": "https://ror.org/03kgsv495",
 "GRID": "grid.22098.31"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-03-20",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx002",
 "identifier": {
 "string_id": "10.1093/llc/fqx002",
 "id_scheme": "DOI"
 },
 "abstract": "A mediator invited 101 academics from around the world to work together by email, over three rounds, to author a manuscript, in an attempt to establish the first ‘crowd-authored’ paper. Once the paper was finalized, it was submitted for publication to fifty-one accredited journals. However, the journals rejected the paper. The current article offers a critique of this negative experience, in reference to previous research and in consultation with the 101 authors. This critique highlights possible factors that may encourage journals to decline manuscripts authored by a large number of people. An awareness of such possible factors would be beneficial for other academics undertaking crowd-authoring projects. A main contribution of the present article is that it provides a debate about the cultural and political ramifications of crowd-authoring, a phenomenon that is expected to soon enter the academic discourse.",
 "article_title": "Crowd-authoring versus peer-reviewing: An epistemic clash in the field of educational technology",
 "authors": [
 {
 "given": " Abdulrahman Essa",
 "family": "Al Lily",
 "affiliation": [
 {
 "original_name": "Department of Educational Technologies, King Faisal University, Saudi Arabia",
 "normalized_name": "King Faisal University",
 "country": "Saudi Arabia",
 "identifiers": {
 "ror": "https://ror.org/00dn43547",
 "GRID": "grid.412140.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-03-20",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx005",
 "identifier": {
 "string_id": "10.1093/llc/fqx005",
 "id_scheme": "DOI"
 },
 "abstract": "This article highlights shared methods, questions, and challenges between Research Through Design (RtD) and Digital Humanities (DH) through the discussion of an archival research project. In DH, debates continue e.g. in (Gold, Debates in the Digital Humanities. University of Minnesota Press, 2012) regarding the impact of digital technologies on epistemology, methodology, and our professional identities as researchers, scholars, academics, and teachers. Our reading of this debate is that there is a tripartite relationship between the kind of work we should call DH (and aspire to produce), the nature of DH knowledge, research and scholarship (particularly regarding the role of artefacts produced), and issues of disciplinary orientation or professional identity. We could phrase these as the what, how, and who of DH and, of course, RtD. The discussion of our project is in no sense intended to provide an exclusive answer to those questions, but to give one snapshot of what DH and RtD may look like when they come together. We emphasize that this relationship can and will be productive for both disciplines and point to the lack of significant discussion hereto.",
 "article_title": "Research through design and digital humanities in practice: What, how and who in an archive research project",
 "authors": [
 {
 "given": " Tom",
 "family": "Schofield",
 "affiliation": [
 {
 "original_name": "Culture Lab, School of Arts and Cultures, Newcastle University, UK",
 "normalized_name": "University of Newcastle Australia",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00eae9z71",
 "GRID": "grid.266842.c"
 }
 }
 ]
 },
 {
 "given": " Mitchell",
 "family": "Whitelaw",
 "affiliation": [
 {
 "original_name": "School of Art and Design, Australian National University, Canberra, Australia",
 "normalized_name": "Australian National University",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/019wvm592",
 "GRID": "grid.1001.0"
 }
 }
 ]
 },
 {
 "given": " David",
 "family": "Kirk",
 "affiliation": [
 {
 "original_name": "Faculty of Engineering and Environment, Northumbria University, UK",
 "normalized_name": "Northumbria University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/049e6bc10",
 "GRID": "grid.42629.3b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-01-21",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "32",
 "issue": "suppl_1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx015",
 "identifier": {
 "string_id": "10.1093/llc/fqx015",
 "id_scheme": "DOI"
 },
 "abstract": "As society continues to embrace advances in digital technologies, a major question that arises is the impact which such technologies have on the concept of an ‘author’ under copyright law. Prior to the advent of the user-generated content (UGC) technology, creative works on the Internet were produced by one or several identifiable authors. The advent of the UGC technology has enabled the active authorial participation of Internet users. This has made it possible for massively collaborative works on the Internet to mushroom where numerous authors’ contributions are incrementally merged into an extensive single work. The concept of an ‘author’ under copyright law is premised on the basis that a work has one or several finite authors. Many UGC works defy this traditional mode of creating works. Taking Malaysian copyright law as the focal point of this study, the research examines whether the concept of an ‘author’ as defined in the Malaysian Copyright Act 1987 is sufficient to address the authorship issue in the light of the UGC technology. It concludes that the current concept of an ‘author’ in the Act is ill-equipped to accommodate Internet-based collaborations. It recommends the introduction of the concept of a ‘deemed author’ in copyright law and suggests that the status of a ‘deemed author’ be conferred on the entity who controls and determines the configuration of the resulting work.",
 "article_title": "Rethinking the concept of an ‘Author’ in the face of digital technology advances: A perspective from the copyright law of a commonwealth country",
 "authors": [
 {
 "given": " Pek San",
 "family": "Tay",
 "affiliation": [
 {
 "original_name": "Faculty of Law, University of Malaya, Malaysia",
 "normalized_name": "University of Malaya",
 "country": "Malaysia",
 "identifiers": {
 "ror": "https://ror.org/00rzspn62",
 "GRID": "grid.10347.31"
 }
 }
 ]
 },
 {
 "given": " Cheng Peng",
 "family": "Sik",
 "affiliation": [
 {
 "original_name": "Faculty of Law, University of Malaya, Malaysia",
 "normalized_name": "University of Malaya",
 "country": "Malaysia",
 "identifiers": {
 "ror": "https://ror.org/00rzspn62",
 "GRID": "grid.10347.31"
 }
 }
 ]
 },
 {
 "given": " Wai Meng",
 "family": "Chan",
 "affiliation": [
 {
 "original_name": "Department of Business Strategy and Policy, Faculty of Business and Accountancy, University of Malaya, Malaysia",
 "normalized_name": "University of Malaya",
 "country": "Malaysia",
 "identifiers": {
 "ror": "https://ror.org/00rzspn62",
 "GRID": "grid.10347.31"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2018-03-20",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx006",
 "identifier": {
 "string_id": "10.1093/llc/fqx006",
 "id_scheme": "DOI"
 },
 "abstract": "What is the scholarly nature of code and how do we evaluate the scholarship involved with coding? Our claim is that the humanities need an urgent answer to these questions given the increasing softwarization of both society and scholarship that pushes the boundaries of the methods and objects of study of the humanities. We argue that, as a result, there is a need to develop code criticism as a critical and reflexive tool within the humanities. Code criticism is described and positioned with respect to critical code studies, textual criticism, literary criticism, tool, and interface critique. Finally we outline an approach to code criticism based on ideas of reciprocal inquiry and of a continuum of literacies that connects code, code criticism, textual criticism, and literature.",
 "article_title": "Code, scholarship, and criticism: When is code scholarship and when is it not?",
 "authors": [
 {
 "given": " Joris J.",
 "family": "van Zundert",
 "affiliation": [
 {
 "original_name": "Huygens Institute for the History of the Netherlands, Royal Netherlands Academy of Arts and Sciences, The Netherlands",
 "normalized_name": "Royal Netherlands Academy of Arts and Sciences",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/043c0p156",
 "GRID": "grid.418101.d"
 }
 }
 ]
 },
 {
 "given": " Ronald",
 "family": "Haentjens Dekker",
 "affiliation": [
 {
 "original_name": "Huygens Institute for the History of the Netherlands, Royal Netherlands Academy of Arts and Sciences, The Netherlands",
 "normalized_name": "Royal Netherlands Academy of Arts and Sciences",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/043c0p156",
 "GRID": "grid.418101.d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-06-08",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "32",
 "issue": "suppl_1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqx013",
 "identifier": {
 "string_id": "10.1093/llc/fqx013",
 "id_scheme": "DOI"
 },
 "abstract": "This article deals with Rolling Delta and Rolling Classify authorship attributions in the apocryphal play Sir Thomas More. Conflicting results were overcome by extracting stable information from the tested range of diverse parameter results of Rolling Delta, and by establishing majority attributions of the text chunks with Rolling Classify. Both approaches were applied to the well-recognized 1911 edition of the play, prepared by W. Greg. This followed the given folio sequence 3a–22a and then made the various additions. Each of the additions was not long enough to establish convincing results as to its authorship, but the folio sequences of the original text could be analysed with larger and reliable window sizes, revealing Samuel Rowley and William Shakespeare as authors. The long-standing claim that Munday or Chettle is the author of the original text of the play proved to be unsustainable. As far as the conventional dating is concerned, an earlier analysis of Thomas of Woodstock, largely written by Rowley, and in part by Shakespeare, points, if later revisions are disregarded, to the period 1592–93.",
 "article_title": "More news on Sir Thomas More",
 "authors": [
 {
 "given": " Hartmut",
 "family": "Ilsemann",
 "affiliation": [
 {
 "original_name": "English Department, Leibniz Universität Hannover, Germany",
 "normalized_name": "University of Hannover",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/0304hq317",
 "GRID": "grid.9122.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-03-27",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "33",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw028",
 "identifier": {
 "string_id": "10.1093/llc/fqw028",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents a new theoretical framework for computer-assisted decipherment of ancient alphabetic inscriptions. This framework is based on regular expressions, a widely used computer science formalism for encoding text strings with partially unknown characters. We then present a new software called Scrypt, which applies our framework to the Khirbet Qeiyafa ostracon, an important Proto-Canaanite inscription recently discovered in Israel, as a first case study. Several new anthroponymic readings for the Qeiyafa ostracon, found with the help of our software, are presented as part of that case study. The software, freely available online (www.ScryptApp.com), enables users to encode all possible readings for a given grapheme in the ostracon and provides fast automated dictionary searches for lexemes.",
 "article_title": "Computer experiments on the Khirbet Qeiyafa ostracon",
 "authors": [
 {
 "given": " Eythan",
 "family": "Levy",
 "affiliation": [
 {
 "original_name": "École supérieure d’informatique (HEB – ESI), Belgium and Centre de Recherches en Archéologie et Patrimoine, Université libre de Bruxelles, Belgium",
 "normalized_name": "Université Libre de Bruxelles",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/01r9htc13",
 "GRID": "grid.4989.c"
 }
 }
 ]
 },
 {
 "given": " Frédéric",
 "family": "Pluquet",
 "affiliation": [
 {
 "original_name": "École supérieure d’informatique (HEB – ESI), Belgium",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-09-02",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw039",
 "identifier": {
 "string_id": "10.1093/llc/fqw039",
 "id_scheme": "DOI"
 },
 "abstract": "Various features of R Stylo were applied to quartos Q1 (1600) and Q2 (1619) of Sir John Oldcastle, a play performed by the Lord Admiral’s Men in November 1599 and written by Anthony Munday, Michael Drayton, Robert Wilson, and Richard Hathwaye, according to Henslowe’s diary. Reference texts by Drayton and Hathwaye were not available, but those of Munday and Wilson did not surface stylistically anywhere in the texts. Instead, stylistic features of Shakespeare’s reference texts were abundant and explain why Q2 was subtitled ‘written by William Shakespeare’. Likewise, Dekker’s ‘additions’ were absent. As the Lord Chamberlain’s Men also performed a play that was referred to as Sir John Old Castell, the assumption is that Shakespeare’s play somehow crossed over to Henslowe’s theatrical company. Multiple approaches (rolling delta, rolling classify, bootstrap consensus tree, Craig’s zeta) all come to the same conclusions.",
 "article_title": "The Two Oldcastles of London",
 "authors": [
 {
 "given": " Hartmut",
 "family": "Ilsemann",
 "affiliation": [
 {
 "original_name": "English Department, Leibniz Universität Hannover, Germany",
 "normalized_name": "University of Hannover",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/0304hq317",
 "GRID": "grid.9122.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-09-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw044",
 "identifier": {
 "string_id": "10.1093/llc/fqw044",
 "id_scheme": "DOI"
 },
 "abstract": "If Scholarly Editing means the exercise of textual criticism for the production of digital archives and editions, then crowdsourcing may produce more problems than solutions because a digital archive is a surrogate for material documents and a digital scholarly edition is a precise argument about the archive. But the analysis of the materials in the archive is truly a crowdsourcing task, for which adequate software design is still wanted and careful monitoring and vetting required.",
 "article_title": "Reliable social scholarly editing",
 "authors": [
 {
 "given": " Peter",
 "family": "Shillingsburg",
 "affiliation": [
 {
 "original_name": "Loyola University Chicago, Chicago, IL, USA",
 "normalized_name": "Loyola University Chicago",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/04b6x2g63",
 "GRID": "grid.164971.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-09-23",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw042",
 "identifier": {
 "string_id": "10.1093/llc/fqw042",
 "id_scheme": "DOI"
 },
 "abstract": "Machine translation (MT) has become increasingly important and popular in the past decade, leading to the development of MT evaluation metrics aiming at automatically assessing MT output. Most of these metrics use reference translations to compare systems output, therefore, they should not only detect MT errors but also be able to identify correct equivalent expressions so as not to penalize them when those are not displayed in the reference translations. With the aim of improving MT evaluation metrics a study has been carried out of a wide panorama of linguistic features and their implications. For that purpose a Spanish and an English corpora containing hypothesis and reference translations have been analysed from a linguistic point of view, so that common errors can be detected and positive equivalencies highlighted. This article focuses on this qualitative analysis describing the linguistic phenomena that should be considered when developing an automatic MT evaluation metric. The results of this analysis have been used to develop an automatic MT evaluation metric that takes into account different dimensions of language. A brief review of the metric and its evaluation are also provided.",
 "article_title": "Guiding automatic MT evaluation by means of linguistic features",
 "authors": [
 {
 "given": " Elisabet",
 "family": "Comelles",
 "affiliation": [
 {
 "original_name": "Universitat de Barcelona, Spain",
 "normalized_name": "University of Barcelona",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/021018s57",
 "GRID": "grid.5841.8"
 }
 }
 ]
 },
 {
 "given": " Victoria",
 "family": "Arranz",
 "affiliation": [
 {
 "original_name": "ELDA/ELRA, France",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Irene",
 "family": "Castellón",
 "affiliation": [
 {
 "original_name": "Universitat de Barcelona, Spain",
 "normalized_name": "University of Barcelona",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/021018s57",
 "GRID": "grid.5841.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-09-26",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw045",
 "identifier": {
 "string_id": "10.1093/llc/fqw045",
 "id_scheme": "DOI"
 },
 "abstract": "In this paper we focus on modelling as a creative process to gain new knowledge about material and immaterial objects by generating and manipulating external representations of them. We aim at enriching the current theoretical understanding by contextualising digital humanities practices within a semiotic conceptualisation of modelling. A semiotic approach enables us to contextualise modelling in a scholarly framework well suited to humanistic enquiries, forcing us to investigate how models function as signs within specific contexts of production and use. Kralemann and Lattmann’s semiotic model of modelling complemented by Elleström's theories on iconicity are some of the tools we use to inform this semiotic perspective on modelling. We contextualise Kralemann and Lattmann’s theory within modelling practices in digital humanities by using three examples of models representing components and structure of historical artefacts. We show how their model of models can be used to understand and contextualise the models we study and how their classification of model types clarify important aspects of digital humanities modelling practice.",
 "article_title": "Modelling in digital humanities: Signs in context",
 "authors": [
 {
 "given": " Arianna",
 "family": "Ciula",
 "affiliation": [
 {
 "original_name": "Department of Humanities, University of Roehampton, London, UK",
 "normalized_name": "University of Roehampton",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/043071f54",
 "GRID": "grid.35349.38"
 }
 }
 ]
 },
 {
 "given": " Øyvind",
 "family": "Eide",
 "affiliation": [
 {
 "original_name": "Historisch-Kulturwissenschaftliche Informationsverarbeitung, Universität zu KölnGermany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-09-30",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw043",
 "identifier": {
 "string_id": "10.1093/llc/fqw043",
 "id_scheme": "DOI"
 },
 "abstract": "Recent attempts to computer-model the scholarly edition so as to permit the crowd-sourcing of its production have misunderstood its nature. Scholarly editions are, in their methodology and form, not unchanging, nor are their underlying conceptions simple. This essay is, in response, a reflection on the opportunities that the digital form potentially offers editors about how they may gain traction by taking advantage of the capacities and logic of the new medium. The main proposal stems from leaving the representational question on hold (how the edition represents the work and the methodologies used to achieve that) and instead considering the edition primarily as a transaction with its readers—those print-counterparts of the digital crowd. The history of post-war scholarly editions is reviewed for its evolving understandings of the reader-user. Then a conceptual separation between the archive and the edition is proposed so that a new, more reader-oriented definition of editorial responsibilities can be envisaged for digital scholarly editions—something that the logic of the print medium forbade.",
 "article_title": "The reader-oriented scholarly edition",
 "authors": [
 {
 "given": " Paul",
 "family": "Eggert",
 "affiliation": [
 {
 "original_name": "Loyola University Chicago, USA",
 "normalized_name": "Loyola University Chicago",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/04b6x2g63",
 "GRID": "grid.164971.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-09-30",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw046",
 "identifier": {
 "string_id": "10.1093/llc/fqw046",
 "id_scheme": "DOI"
 },
 "abstract": "Zipf’s law is an important linguistics law. In 1940s, Zipf found power law in the distribution of the word frequencies. The word rankings are in descending order of their occurrence frequencies. Through a series of experiments of random input letter sequences, the results show that the power law distribution has existed in not only natural language utterances but also random symbolic sequences.",
 "article_title": "Pow law in random symbolic sequences",
 "authors": [
 {
 "given": " Yong",
 "family": "Cao",
 "affiliation": [
 {
 "original_name": "School of Computer and Information, Southwest Forestry University, China",
 "normalized_name": "Southwest Forestry University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/03dfa9f06",
 "GRID": "grid.412720.2"
 }
 }
 ]
 },
 {
 "given": " Fei",
 "family": "Xiong",
 "affiliation": [
 {
 "original_name": "School of Computer and Information, Southwest Forestry University, China",
 "normalized_name": "Southwest Forestry University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/03dfa9f06",
 "GRID": "grid.412720.2"
 }
 }
 ]
 },
 {
 "given": " Youjie",
 "family": "Zhao",
 "affiliation": [
 {
 "original_name": "School of Computer and Information, Southwest Forestry University, China",
 "normalized_name": "Southwest Forestry University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/03dfa9f06",
 "GRID": "grid.412720.2"
 }
 }
 ]
 },
 {
 "given": " Yongke",
 "family": "Sun",
 "affiliation": [
 {
 "original_name": "School of Computer and Information, Southwest Forestry University, China",
 "normalized_name": "Southwest Forestry University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/03dfa9f06",
 "GRID": "grid.412720.2"
 }
 }
 ]
 },
 {
 "given": " Xiaoguang",
 "family": "Yue",
 "affiliation": [
 {
 "original_name": "School of Civil Engineering, Wuhan University, China",
 "normalized_name": "Wuhan University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/033vjfk17",
 "GRID": "grid.49470.3e"
 }
 }
 ]
 },
 {
 "given": " Xin",
 "family": "He",
 "affiliation": [
 {
 "original_name": "School of Computer and Information, Southwest Forestry University, China",
 "normalized_name": "Southwest Forestry University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/03dfa9f06",
 "GRID": "grid.412720.2"
 }
 }
 ]
 },
 {
 "given": " Lichao",
 "family": "Wang",
 "affiliation": [
 {
 "original_name": "School of Computer and Information, Southwest Forestry University, China",
 "normalized_name": "Southwest Forestry University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/03dfa9f06",
 "GRID": "grid.412720.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-10-05",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw041",
 "identifier": {
 "string_id": "10.1093/llc/fqw041",
 "id_scheme": "DOI"
 },
 "abstract": "In recent years, public engagement is increasingly viewed as more than an ‘additional extra’ in academia. In the UK, it is becoming more common for research projects to embrace public engagement with the belief that it informs research, enhances teaching and learning, and increases research impact on society. Therefore, it is becoming increasingly important to consider ways of incorporating public engagement activities into digital humanities research. This article discusses public engagement and digital humanities in practice, highlighting how museums are utilizing digital technology to engage the public. This article describes the development and presents the results of a case study: The QRator project, an application for digital interpretation in the museum and cultural heritage sector. The QRator project took an innovative, multidisciplinary approach to creating new ways for museum visitors to engage with museum objects and discussions. The objective was to understand how digital technologies, such as interactive labels and smartphones, create new ways for users to engage with museum objects; investigate the value and constraints of digital sources and methods involving cultural content; and demonstrate how crowdsourced digital interpretation may be utilized as a research source. This article will use the QRator project as a case study to explore how mobile devices and interactive digital labels can create new models for public engagement, visitor meaning-making (Silverman, L. H. Visitor meaning-making in museums for a new age. Curator, 1995;38(3):161–70), and the construction of multiple interpretations inside museum spaces. This article will also put emphasis on how public engagement can and should be a core consideration of digital humanities projects.",
 "article_title": "Engaging the museum space: Mobilizing visitor engagement with digital content creation",
 "authors": [
 {
 "given": " Claire",
 "family": "Bailey-Ross",
 "affiliation": [
 {
 "original_name": "Department of English Studies, Durham University, Durham, UK",
 "normalized_name": "Durham University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01v29qb04",
 "GRID": "grid.8250.f"
 }
 }
 ]
 },
 {
 "given": " Steven",
 "family": "Gray",
 "affiliation": [
 {
 "original_name": "The Bartlett Centre for Advanced Spatial Analysis, University College London, London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Jack",
 "family": "Ashby",
 "affiliation": [
 {
 "original_name": "Grant Museum of Zoology, University College London, London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Melissa",
 "family": "Terras",
 "affiliation": [
 {
 "original_name": "Department of Information Studies, University College London, London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Andrew",
 "family": "Hudson-Smith",
 "affiliation": [
 {
 "original_name": "The Bartlett Centre for Advanced Spatial Analysis, University College London, London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Claire",
 "family": "Warwick",
 "affiliation": [
 {
 "original_name": "Department of English Studies, Durham University, Durham, UK",
 "normalized_name": "Durham University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01v29qb04",
 "GRID": "grid.8250.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-10-06",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw047",
 "identifier": {
 "string_id": "10.1093/llc/fqw047",
 "id_scheme": "DOI"
 },
 "abstract": "In this article we discuss the heuristic capabilities that the process of generating, processing, and integrating cultural heritage linked data may afford, including its potential for enhancing arts and humanities research. More specifically, we report on our current work on detecting and assigning gender properties to person entities and semantically enriching a set of Linked Open Data (LOD) in the domain of history of jazz. Linked Jazz—an ongoing project that experiments with the application of LOD principles and techniques to cultural heritage materials—provided the context for this research. Linked Jazz aims to uncover meaningful connections between data and documents from digital archives of jazz history. It employs oral histories as the main source of named entities to be represented as linked data. The entities are then semantically connected and visualized as social graphs. Using the assignment of gender properties, this article describes how the data development process itself offers new and unanticipated paths of research inquiry and engagement with heritage data.",
 "article_title": "Accidental discovery, intentional inquiry: Leveraging linked data to uncover the women of jazz",
 "authors": [
 {
 "given": " M Cristina",
 "family": "Pattuelli",
 "affiliation": [
 {
 "original_name": "Pratt Institute, School of Information, USA",
 "normalized_name": "Pratt Institute",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/007m3p006",
 "GRID": "grid.262107.0"
 }
 }
 ]
 },
 {
 "given": " Karen",
 "family": "Hwang",
 "affiliation": [
 {
 "original_name": "New York Public Library, USA",
 "normalized_name": "New York Public Library",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/02eysy271",
 "GRID": "grid.429888.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-10-11",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw054",
 "identifier": {
 "string_id": "10.1093/llc/fqw054",
 "id_scheme": "DOI"
 },
 "abstract": "Traduco is a web-based collaborative tool aimed at supporting the translation of texts that pose particular challenging interpretative issues. Nowadays, Computer-Assisted Translation (CAT) tools are mainly applied to the translation of technical manuals or legislative texts and are aimed at speeding up the translation process. Traduco extends most of the standard components of a traditional CAT tool with specific features necessary to support the interpretation and translation of complex texts (like the Babylonian Talmud, that we here present as a case study), which pose particular comprehension issues. Traduco goes beyond the translation and its printing: it includes features for the addition of notes and annotations and the creation of glossaries. Translators, editors, supervisors, and end-users accessing Traduco are able to use components that can ease the translation process through the use of CAT technologies, the supervision and managing of the whole process of translation and publishing, the exporting of translations and notes in standard formats for desktop publishing software and TEI format, and, soon, the possibility to perform automatic linguistic analysis of the text. Moreover, Traduco allows the users to insert notes, comments, annotations, and bibliographical references. The design and development of Traduco required the adoption of a multidisciplinary approach, leveraging on advances in software engineering, computational linguistics, knowledge engineering, and publishing.",
 "article_title": "Traduco: A collaborative web-based CAT environment for the interpretation and translation of texts",
 "authors": [
 {
 "given": " Emiliano",
 "family": "Giovannetti",
 "affiliation": [
 {
 "original_name": "Istituto di Linguistica Computazionale ‘A. Zampolli’, Consiglio Nazionale delle Ricerche, Pisa, Italy",
 "normalized_name": "Institute for Computational Linguistics “A. Zampolli”",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/028g3pe33",
 "GRID": "grid.503055.6"
 }
 }
 ]
 },
 {
 "given": " Davide",
 "family": "Albanesi",
 "affiliation": [
 {
 "original_name": "Istituto di Linguistica Computazionale ‘A. Zampolli’, Consiglio Nazionale delle Ricerche, Pisa, Italy",
 "normalized_name": "Institute for Computational Linguistics “A. Zampolli”",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/028g3pe33",
 "GRID": "grid.503055.6"
 }
 }
 ]
 },
 {
 "given": " Andrea",
 "family": "Bellandi",
 "affiliation": [
 {
 "original_name": "Istituto di Linguistica Computazionale ‘A. Zampolli’, Consiglio Nazionale delle Ricerche, Pisa, Italy",
 "normalized_name": "Institute for Computational Linguistics “A. Zampolli”",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/028g3pe33",
 "GRID": "grid.503055.6"
 }
 }
 ]
 },
 {
 "given": " Giulia",
 "family": "Benotto",
 "affiliation": [
 {
 "original_name": "Istituto di Linguistica Computazionale ‘A. Zampolli’, Consiglio Nazionale delle Ricerche, Pisa, Italy",
 "normalized_name": "Institute for Computational Linguistics “A. Zampolli”",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/028g3pe33",
 "GRID": "grid.503055.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-10-28",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw053",
 "identifier": {
 "string_id": "10.1093/llc/fqw053",
 "id_scheme": "DOI"
 },
 "abstract": "This article examines the question of whether Digital Humanities has given too much focus to text over non-text media and provides four major reasons to encourage more non-text-focused research under the umbrella of Digital Humanities. How could Digital Humanities engage in more humanities-oriented rhetorical and critical visualization, and not only in the development of scientific visualization and information visualization?",
 "article_title": "Digital humanities is text heavy, visualization light, and simulation poor",
 "authors": [
 {
 "given": " Erik Malcolm",
 "family": "Champion",
 "affiliation": [
 {
 "original_name": "CIC, AAPI, School of Media Culture and Creative Arts, Curtin University, Australia",
 "normalized_name": "Curtin University",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/02n415q13",
 "GRID": "grid.1032.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw048",
 "identifier": {
 "string_id": "10.1093/llc/fqw048",
 "id_scheme": "DOI"
 },
 "abstract": "The adoption of XML and encoding standards such as those developed by the Text Encoding Initiative was accompanied by expectations of easy interoperability which are now widely seen as unfulfilled. The related but distinct concept of ‘interchange’ has received much less attention. This article argues that, particularly for sophisticated digital edition projects using XML, interchange is a more practical goal, and that approached in a specific way, it is highly beneficial not only to potential end users of the project’s data but also to the project itself.The article illustrates specific strategies and approaches to enabling and facilitating interchange, using work undertaken on the Map of Early Modern London (MoEML) project as a case study.",
 "article_title": "Whatever happened to interchange?",
 "authors": [
 {
 "given": " Martin",
 "family": "Holmes",
 "affiliation": [
 {
 "original_name": "University of Victoria, Canada",
 "normalized_name": "University of Victoria",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04s5mat29",
 "GRID": "grid.143640.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw051",
 "identifier": {
 "string_id": "10.1093/llc/fqw051",
 "id_scheme": "DOI"
 },
 "abstract": "In this article we present a web service framework providing automatic document processing methods to the public. Furthermore, an assessment environment and sample applications using this framework are briefly described. Research on Document Image Analysis (DIA) focuses mainly on developing and refining automatic processing steps, e.g. text line extraction, binarization, and layout analysis. While many state-of-the-art methods perform satisfactorily, the algorithms applied to obtain the results are not easily accessible for other researchers. Making the source code available is often not sufficient as it typically requires a cumbersome installation of required libraries and reading long manuals about the usage. We present a new approach for making methods available to researchers in the digital humanities without detailed knowledge of the algorithms.For our approach we propose a RESTful web service architecture, the current state of the art in online web communication. For a developer this reduces the steps needed to access a method to sending and receiving HTTP requests with Java Script Object Notification data, removing all installation steps. We will build on standards such as the Text Encoding Initiative and the International Image Interoperability Framework. Thus, methods hosted on DivaServices can be integrated easily into document processing workflows by any software engineer in computer science, but also the digital humanities without specific knowledge of the mathematical and algorithmic details of DIA.",
 "article_title": "DivaServices—A RESTful web service for Document Image Analysis methods",
 "authors": [
 {
 "given": " Marcel",
 "family": "Würsch",
 "affiliation": [
 {
 "original_name": "Diva group, Department of Informatics, University of Fribourg, Switzerland",
 "normalized_name": "University of Fribourg",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/022fs9h90",
 "GRID": "grid.8534.a"
 }
 }
 ]
 },
 {
 "given": " Rolf",
 "family": "Ingold",
 "affiliation": [
 {
 "original_name": "Diva group, Department of Informatics, University of Fribourg, Switzerland",
 "normalized_name": "University of Fribourg",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/022fs9h90",
 "GRID": "grid.8534.a"
 }
 }
 ]
 },
 {
 "given": " Marcus",
 "family": "Liwicki",
 "affiliation": [
 {
 "original_name": "Diva group, Department of Informatics, University of Fribourg, Switzerland",
 "normalized_name": "University of Fribourg",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/022fs9h90",
 "GRID": "grid.8534.a"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw050",
 "identifier": {
 "string_id": "10.1093/llc/fqw050",
 "id_scheme": "DOI"
 },
 "abstract": "Text mining and information visualization techniques applied to large-scale historical and literary document collections have enabled new types of humanities research. The assumption behind such efforts is often that trends will emerge from the analysis despite errors for individual data points and that noise will be dominated by the signal in the data. However, for some text analysis tasks, the technology is unable to perform as well as domain experts, perhaps because it does not have sufficient world knowledge or metadata available. Yet, the advantage of language processing technology is that it can process at scale, even if not perfectly accurately. Geo-locating literary works is one example where human expert knowledge is invaluable when it comes to distinguishing between candidate works. This was the underlying assumption in Palimpsest, an interdisciplinary digital humanities research project on mining literary Edinburgh. From the outset, the project adopted an assisted curation process whereby the automatic processing of large data collections was combined with manual checking to identify literary works set in Edinburgh. In this article, we introduce the assisted curation process and evaluate how the feedback from literary scholars helped to improve the technology, thereby highlighting the importance of placing humanities research at the core of digital humanities projects.",
 "article_title": "Palimpsest: Improving assisted curation of loco-specific literature",
 "authors": [
 {
 "given": " Beatrice",
 "family": "Alex",
 "affiliation": [
 {
 "original_name": "ILCC, School of Informatics, University of Edinburgh, Scotland",
 "normalized_name": "University of Edinburgh",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01nrxwf90",
 "GRID": "grid.4305.2"
 }
 }
 ]
 },
 {
 "given": " Claire",
 "family": "Grover",
 "affiliation": [
 {
 "original_name": "ILCC, School of Informatics, University of Edinburgh, Scotland",
 "normalized_name": "University of Edinburgh",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01nrxwf90",
 "GRID": "grid.4305.2"
 }
 }
 ]
 },
 {
 "given": " Jon",
 "family": "Oberlander",
 "affiliation": [
 {
 "original_name": "ILCC, School of Informatics, University of Edinburgh, Scotland",
 "normalized_name": "University of Edinburgh",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01nrxwf90",
 "GRID": "grid.4305.2"
 }
 }
 ]
 },
 {
 "given": " Tara",
 "family": "Thomson",
 "affiliation": [
 {
 "original_name": "School of Arts and Creative Industries, Edinburgh Napier University, Scotland",
 "normalized_name": "Edinburgh Napier University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/03zjvnn91",
 "GRID": "grid.20409.3f"
 }
 }
 ]
 },
 {
 "given": " Miranda",
 "family": "Anderson",
 "affiliation": [
 {
 "original_name": "School of Literature, Languages and Cultures, University of Edinburgh, Scotland",
 "normalized_name": "University of Edinburgh",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01nrxwf90",
 "GRID": "grid.4305.2"
 }
 }
 ]
 },
 {
 "given": " James",
 "family": "Loxley",
 "affiliation": [
 {
 "original_name": "School of Literature, Languages and Cultures, University of Edinburgh, Scotland",
 "normalized_name": "University of Edinburgh",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01nrxwf90",
 "GRID": "grid.4305.2"
 }
 }
 ]
 },
 {
 "given": " Uta",
 "family": "Hinrichs",
 "affiliation": [
 {
 "original_name": "SACHI Group, School of Computer Science, University of St Andrews, Scotland",
 "normalized_name": "University of St Andrews",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02wn5qz54",
 "GRID": "grid.11914.3c"
 }
 }
 ]
 },
 {
 "given": " Ke",
 "family": "Zhou",
 "affiliation": [
 {
 "original_name": "School of Computer Science, University of Nottingham1, England",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-11-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw049",
 "identifier": {
 "string_id": "10.1093/llc/fqw049",
 "id_scheme": "DOI"
 },
 "abstract": "In 2011, six academics gathered over 90,000 authentic text messages (SMS) in French from the general public, in compliance with French law (http://sud4science.org,Panckhurst et al., 2013). The SMS ‘donors’ were also invited to fill out a sociolinguistic questionnaire (see Figure A1, Moïse, 2013, Panckhurst and Moïse, 2014). The ‘sud4science’ project is part of a vast international initiative, entitled ‘sms4science’ (http://www.sms4science.org/, Fairon et al., 2006, Cougnon and Fairon, 2014, Cougnon, 2015), which aims to build a worldwide database and analyse authentic text messages in different languages. After the ‘sud4science’ SMS data collection, a pre-processing phase of checking and eliminating any spurious information and a three-step semi-automatic anonymization phase were conducted (Accorsi et al., 2014, Patel et al., 2013). Two extracts were transcoded into standardized French (1,000 SMS) and annotated (100 SMS). The finalized digital resource of 88,000 anonymized French text messages, the ‘88milSMS’ corpus, the extracts and the sociolinguistic questionnaire data are currently available for all to download, from the Huma-Num web service (http://88milsms.huma-num.fr, Panckhurst et al., 2014). The 88milSMS corpus has also recently become available via a Creative Commons Attribution 4.0 International licence on the ‘Ortolang’ platform (https://hdl.handle.net/11403/comere/cmr-88milsms/cmr-88milsms-tei-v1, Panckhurst et al., in Chanier (ed), 2016). In this paper, first the authors briefly situate the project and describe the anonymization process. Then, they focus on why they decided to exclude full ‘transcoding’ and linguistic annotation in the first version of the final corpus.",
 "article_title": "A digital corpus resource of authentic anonymized French text messages: 88milSMS—What about transcoding and linguistic annotation?",
 "authors": [
 {
 "given": " Rachel",
 "family": "Panckhurst",
 "affiliation": [
 {
 "original_name": "Praxiling, Université Paul-Valéry Montpellier 3, France",
 "normalized_name": "Université Paul-Valéry Montpellier",
 "country": "France",
 "identifiers": {
 "ror": "https://ror.org/00qhdy563",
 "GRID": "grid.440910.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-11-19",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw057",
 "identifier": {
 "string_id": "10.1093/llc/fqw057",
 "id_scheme": "DOI"
 },
 "abstract": "The Great Parchment Book of the Honourable the Irish Society is a major surviving historical record of the estates of the county of Londonderry (in modern day Northern Ireland). It contains key data about landholding and population in the Irish province of Ulster and the city of Londonderry and its environs in the mid-17th century, at a time of social, religious, and political upheaval. Compiled in 1639, it was severely damaged in a fire in 1786, and due to the fragile state of the parchment, its contents have been mostly inaccessible since. We describe here a long-term, interdisciplinary, international partnership involving conservators, archivists, computer scientists, and digital humanists that developed a low-cost pipeline for conserving, digitizing, 3D-reconstructing, and virtually flattening the fire-damaged, buckled parchment, enabling new readings and understanding of the text to be created. For the first time, this article presents a complete overview of the project, detailing the conservation, digital acquisition, and digital reconstruction methods used, resulting in a new transcription and digital edition of the text in time for the 400th anniversary celebrations of the building of Londonderry’s city walls in 2013. We concentrate on the digital reconstruction pipeline that will be of interest to custodians of similarly fire-damaged historical parchment, whilst highlighting how working together on this project has produced an online resource that has focussed community reflection upon an important, but previously inaccessible, historical text.",
 "article_title": "Digitally reconstructing the Great Parchment Book: 3D recovery of fire-damaged historical documents",
 "authors": [
 {
 "given": " Kazim",
 "family": "Pal",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Nicola",
 "family": "Avery",
 "affiliation": [
 {
 "original_name": "London Metropolitan Archives, UK",
 "normalized_name": "London Metropolitan Archives",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/028pagn69",
 "GRID": "grid.450982.2"
 }
 }
 ]
 },
 {
 "given": " Pete",
 "family": "Boston",
 "affiliation": [
 {
 "original_name": "Headscape Ltd, UK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Alberto",
 "family": "Campagnolo",
 "affiliation": [
 {
 "original_name": "Ligatus Research Centre, University of the Arts, UK",
 "normalized_name": "University of the Arts",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/040w1dr55",
 "GRID": "grid.441309.b"
 }
 }
 ]
 },
 {
 "given": " Caroline",
 "family": "De Stefani",
 "affiliation": [
 {
 "original_name": "London Metropolitan Archives, UK",
 "normalized_name": "London Metropolitan Archives",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/028pagn69",
 "GRID": "grid.450982.2"
 }
 }
 ]
 },
 {
 "given": " Helen",
 "family": "Matheson-Pollock",
 "affiliation": [
 {
 "original_name": "University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Daniele",
 "family": "Panozzo",
 "affiliation": [
 {
 "original_name": "Courant Institute of Mathematical Sciences, New York University, USA",
 "normalized_name": "New York University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0190ak572",
 "GRID": "grid.137628.9"
 }
 }
 ]
 },
 {
 "given": " Matthew",
 "family": "Payne",
 "affiliation": [
 {
 "original_name": "Muniment Room, Westminster Abbey, UK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Christian",
 "family": "Schüller",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, ETH Zurich, Switzerland",
 "normalized_name": "ETH Zurich",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/05a28rw58",
 "GRID": "grid.5801.c"
 }
 }
 ]
 },
 {
 "given": " Chris",
 "family": "Sanderson",
 "affiliation": [
 {
 "original_name": "Headscape Ltd, UK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Chris",
 "family": "Scott",
 "affiliation": [
 {
 "original_name": "Headscape Ltd, UK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Philippa",
 "family": "Smith",
 "affiliation": [
 {
 "original_name": "London Metropolitan Archives, UK",
 "normalized_name": "London Metropolitan Archives",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/028pagn69",
 "GRID": "grid.450982.2"
 }
 }
 ]
 },
 {
 "given": " Rachael",
 "family": "Smither",
 "affiliation": [
 {
 "original_name": "London Metropolitan Archives, UK",
 "normalized_name": "London Metropolitan Archives",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/028pagn69",
 "GRID": "grid.450982.2"
 }
 }
 ]
 },
 {
 "given": " Olga",
 "family": "Sorkine-Hornung",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, ETH Zurich, Switzerland",
 "normalized_name": "ETH Zurich",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/05a28rw58",
 "GRID": "grid.5801.c"
 }
 }
 ]
 },
 {
 "given": " Ann",
 "family": "Stewart",
 "affiliation": [
 {
 "original_name": "National Museums Liverpool, UK",
 "normalized_name": "National Museums Liverpool",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05vqfs419",
 "GRID": "grid.422298.7"
 }
 }
 ]
 },
 {
 "given": " Emma",
 "family": "Stewart",
 "affiliation": [
 {
 "original_name": "London Metropolitan Archives, UK",
 "normalized_name": "London Metropolitan Archives",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/028pagn69",
 "GRID": "grid.450982.2"
 }
 }
 ]
 },
 {
 "given": " Patricia",
 "family": "Stewart",
 "affiliation": [
 {
 "original_name": "Oxford English Dictionary, Oxford University Press, UK",
 "normalized_name": "Oxford University Press (United Kingdom)",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0336mm561",
 "GRID": "grid.470899.b"
 }
 }
 ]
 },
 {
 "given": " Melissa",
 "family": "Terras",
 "affiliation": [
 {
 "original_name": "UCL Department of Information Studies, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 },
 {
 "original_name": "UCL Centre for Digital Humanities, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Bernadette",
 "family": "Walsh",
 "affiliation": [
 {
 "original_name": "Museum and Visitor Service, Derry City and Strabane District Council, Northern Ireland",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Laurence",
 "family": "Ward",
 "affiliation": [
 {
 "original_name": "London Metropolitan Archives, UK",
 "normalized_name": "London Metropolitan Archives",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/028pagn69",
 "GRID": "grid.450982.2"
 }
 }
 ]
 },
 {
 "given": " Liz",
 "family": "Yamada",
 "affiliation": [
 {
 "original_name": "Freelance Paper Conservator",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Tim",
 "family": "Weyrich",
 "affiliation": [
 {
 "original_name": "UCL Department of Computer Science, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 },
 {
 "original_name": "UCL Centre for Digital Humanities, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-12-13",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw061",
 "identifier": {
 "string_id": "10.1093/llc/fqw061",
 "id_scheme": "DOI"
 },
 "abstract": "Digitizing Lefebvre’s Spatial Triad is conceived as a seed project for an interdisciplinary analysis of the built environment via digital media. Two social housing projects in İzmir are chosen as case studies as an initial step to be developed toward a potentially international digital platform. The theoretical premises of the project are based on the renowned cultural theorist Henri Lefebvre’s Spatial Triad, which distinguishes between representations of space, representational spaces or spaces of representation, and spatial practices. Following this framework, the collected data are organized in three sections, which are reflected in the digital interface. These are respectively titled, ‘implementations’, which contains architectural drawings and visual recordings of interviews with the chief architect of the projects; ‘perceptions’, which includes related texts that are scanned from Web sites, newspapers, journals, and conference proceedings; and ‘lived experiences’, which contains photographs and visual records of on-site interviews with the users of the two housing estates. Users of the digital interface are enabled access to data in each category by means of choosing one of eighty-three related keywords. The latter are derived from the digital analyses of discursive material. By enabling the comparison of the sections of spatial data for each settlement and between the two settlements, the digital platform has the potential to inform decision-making processes in future social housing projects.",
 "article_title": "Digitizing Lefebvre’s Spatial Triad",
 "authors": [
 {
 "given": " Gülsüm",
 "family": "Baydar",
 "affiliation": [
 {
 "original_name": "Department of Architecture, Yaşar University, Turkey",
 "normalized_name": "Yaşar University",
 "country": "Turkey",
 "identifiers": {
 "ror": "https://ror.org/00dz1eb96",
 "GRID": "grid.439251.8"
 }
 }
 ]
 },
 {
 "given": " Murat",
 "family": "Komesli",
 "affiliation": [
 {
 "original_name": "Department of Software Engineering, Yaşar University, Turkey",
 "normalized_name": "Yaşar University",
 "country": "Turkey",
 "identifiers": {
 "ror": "https://ror.org/00dz1eb96",
 "GRID": "grid.439251.8"
 }
 }
 ]
 },
 {
 "given": " Ahenk",
 "family": "Yılmaz",
 "affiliation": [
 {
 "original_name": "Department of Architecture, Yaşar University, Turkey",
 "normalized_name": "Yaşar University",
 "country": "Turkey",
 "identifiers": {
 "ror": "https://ror.org/00dz1eb96",
 "GRID": "grid.439251.8"
 }
 }
 ]
 },
 {
 "given": " Kıvanç",
 "family": "Kılınç",
 "affiliation": [
 {
 "original_name": "Department of Architecture, Yaşar University, Turkey",
 "normalized_name": "Yaşar University",
 "country": "Turkey",
 "identifiers": {
 "ror": "https://ror.org/00dz1eb96",
 "GRID": "grid.439251.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-12-26",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw015",
 "identifier": {
 "string_id": "10.1093/llc/fqw015",
 "id_scheme": "DOI"
 },
 "abstract": "Due to the special features of Persian, developing natural language processing tools for it involves an array of challenges. Lack of efficient Persian knowledge sources is another obstacle to research this language. The goal of this article was to overcome these problems by implementing spelling correction task. The main outputs of this study included a parallel corpus, an N-gram language model for Persian, and a semantic-based spelling correction system named Perspell, which made use of extracted language model. Compared to its rival software (including Vafa spellchecker), Perspell could detect and correct nonword and real word errors more successfully. The rate of real word error detection in Perspell was 95%. In fact, its outstanding ability to detect real word errors as well as its significant improvement in terms of F-measure were the two advantages of the proposed system.",
 "article_title": "Perspell: A New Persian Semantic-Based Spelling Correction System",
 "authors": [
 {
 "given": " Mohammad Bagher",
 "family": "Dastgheib",
 "affiliation": [
 {
 "original_name": "Department of Computer Science and Engineering, School of Electrical and Computer Engineering, Shiraz University",
 "normalized_name": "Shiraz University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/028qtbk54",
 "GRID": "grid.412573.6"
 }
 }
 ]
 },
 {
 "given": " Seyed Mostafa",
 "family": "Fakhrahmad",
 "affiliation": [
 {
 "original_name": "Department of Computer Science and Engineering, School of Electrical and Computer Engineering, Shiraz University",
 "normalized_name": "Shiraz University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/028qtbk54",
 "GRID": "grid.412573.6"
 }
 }
 ]
 },
 {
 "given": " Mansoor Zolghadri",
 "family": "Jahromi",
 "affiliation": [
 {
 "original_name": "Department of Computer Science and Engineering, School of Electrical and Computer Engineering, Shiraz University",
 "normalized_name": "Shiraz University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/028qtbk54",
 "GRID": "grid.412573.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-03-28",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw008",
 "identifier": {
 "string_id": "10.1093/llc/fqw008",
 "id_scheme": "DOI"
 },
 "abstract": "The present investigation is an attempt to investigate how the unique linguistic profile of different text types can be reflected in their respective entropy characteristics. With samples from the Lancaster Corpus of Mandarin Chinese and the Freiburg–Brown corpus of American English, the research investigates entropy performances in two dimensions: the relative entropy of words and their part-of-speech (POS) on different sentential positions, and entropy of aspect markers. Our research yields the following results: First, it shows a strikingly similar distribution pattern in Chinese and English concerning the relative entropy of word-forms and POS-forms on different sentential positions. The relative entropy of word-forms in descending order yields: news > essays > official > academic > fiction, and the POS-forms yields: fiction > essays > news > academic > official. The relative entropy of POS-forms may be a more reliable indicator of syntactical differences, which helps to distinguish dichotomous ‘narrative vs. expository’ text types in both Chinese and English. Second, there exists a cross-linguistic difference concerning entropy of aspect markers, namely, Chinese displays higher relative entropy than English. This indicates that aspect-marking in terms of variation is more prominent in Chinese grammar than in English. The ‘narrative vs. expository distinction’ is also identified by entropy of aspect markers in both Chinese and English, though more obviously in Chinese.",
 "article_title": "Entropy in Different Text Types",
 "authors": [
 {
 "given": " Ruina",
 "family": "Chen",
 "affiliation": [
 {
 "original_name": "Department of Foreign Languages, Guizhou University, China",
 "normalized_name": "Guizhou University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/02wmsc916",
 "GRID": "grid.443382.a"
 }
 },
 {
 "original_name": "Department of Linguistics, Zhejiang University, China",
 "normalized_name": "Zhejiang University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/00a2xv884",
 "GRID": "grid.13402.34"
 }
 }
 ]
 },
 {
 "given": " Haitao",
 "family": "Liu",
 "affiliation": [
 {
 "original_name": "Department of Linguistics, Zhejiang University, China",
 "normalized_name": "Zhejiang University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/00a2xv884",
 "GRID": "grid.13402.34"
 }
 },
 {
 "original_name": "Ningbo Institute of Technology, Zhejiang University, China",
 "normalized_name": "Zhejiang University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/00a2xv884",
 "GRID": "grid.13402.34"
 }
 }
 ]
 },
 {
 "given": " Gabriel",
 "family": "Altmann",
 "affiliation": [
 {
 "original_name": "Ruhr University Bochum, Germany",
 "normalized_name": "Ruhr University Bochum",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/04tsk2644",
 "GRID": "grid.5570.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-03-30",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw021",
 "identifier": {
 "string_id": "10.1093/llc/fqw021",
 "id_scheme": "DOI"
 },
 "abstract": "Relying on the analysis of a Latin historical corpus, our research aims to study the markers structuring literary texts in general, and focuses on methods which, by extension, should be valid for any text of some length. Our basic assumption is the following: such texts include complex multilevel structures (i.e. those calling upon lexis, semantics, morphology, syntax, etc) which function as heterogeneity indicators (progression to a new episode, focalization on a new point of view, insertion of reported speech, etc.). Additionally, the recurrence of these structures is a factor in textual cohesion. Under certain conditions, they function as topological ‘motifs’, marking the linear progression of the text and ensuring textual unity. We are developing new methods to detect and analyse the distributions of such ‘motifs’ and to support structural comparisons with the objective of contrastive corpus studies (contrasts between genres, authorial styles, etc.). Our methods are based on mathematical models (neighbourhoods, bursts) and combine a qualitative approach with a sequential quantitative analysis to comprehend language in a linear fashion.",
 "article_title": "A Text Structure Indicator and two Topological Methods: New Ways for Studying Latin Historic Narratives",
 "authors": [
 {
 "given": " Dominique",
 "family": "Longrée",
 "affiliation": [
 {
 "original_name": "LASLA, University of Liège, Liège",
 "normalized_name": "University of Liège",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/00afp2z80",
 "GRID": "grid.4861.b"
 }
 }
 ]
 },
 {
 "given": " Sylvie",
 "family": "Mellet",
 "affiliation": [
 {
 "original_name": "BCL, University Nice Sophia Antipolis, CNRS, France",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-04-29",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw022",
 "identifier": {
 "string_id": "10.1093/llc/fqw022",
 "id_scheme": "DOI"
 },
 "abstract": "Ever since the Universal Networking Language (UNL) programme started in 1996, researchers and computational linguists across the globe have actively participated in this. English, Chinese, Georgian, Greek, Hindi, Punjabi, Portuguese, Russian, Ukrainian, Vietnamese, Slovenian, etc., are some of the languages which are part of the UNL programme. Although previous years have witnessed significant interest and application development in UNL, UNL can be exploited for several different tasks in natural language engineering, such as multilingual document generation, summarization, text simplification, information retrieval, and semantic reasoning. Although UNL is language-independent artificial language, yet, existing UNL-based applications are standalone in the sense that they are language specific which supports the local natural language of the application developer. This article illustrates the cross-domain client application prototype that has been built to support the development of multilingual UNL-based applications where researchers, developers, or computational linguists across the globe can use this common application for UNL-ization and NL-ization. Output of the proposed system can further be utilized by any other UNL-based application. The proposed system is evaluated on the basis of two measures, i.e. accuracy and correctness. The accuracy of the proposed system is 100%. However, correctness of the proposed system depends upon the F-Measure of UNL-ization and NL-ization modules which has been consistently greater than 0.95 (on a scale of 0–1) for Punjabi language.",
 "article_title": "A Multilingual Cross-Domain Client Application Prototype for UNL-ization and NL-ization for NLP Applications",
 "authors": [
 {
 "given": "Vaibhav",
 "family": "Agarwal",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Parteek",
 "family": "Kumar",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-05-01",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw023",
 "identifier": {
 "string_id": "10.1093/llc/fqw023",
 "id_scheme": "DOI"
 },
 "abstract": "Over the past decade large, searchable collections of primary texts have been embraced by virtually all literary scholars and this has led to changes in how scholarship is conducted. This article offers a partial history of the introduction of search to large collections of primary texts, and explores its effects. It did not come automatically or easily, but when it did search broke down barriers to access (no longer requiring background knowledge in history and bibliography), offering a new means of discovering and selecting texts to read. This change was more than a convenience. It was transformative. Database represents a new form of textuality, and scholars have come to rely on database's affordances to develop new ways of reading. In addition to content analysis of claims made about database in various fora, modest bibliometric analysis of two journals (American Literature and English Literary History) suggests trends: more and more diverse primary texts are being read and cited. Interviews with authors of journal articles and journal editors are used to characterize how the databases are used and the effect on scholarship.",
 "article_title": "Search, Reading, and the Rise of Database: Table 1",
 "authors": [
 {
 "given": " Alan",
 "family": "Bilansky",
 "affiliation": [
 {
 "original_name": "Graduate School of Library and Information Science, University of Illinois at Urbana-Champaign, USA",
 "normalized_name": "University of Illinois at Urbana-Champaign",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047426m28",
 "GRID": "grid.35403.31"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-05-10",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw018",
 "identifier": {
 "string_id": "10.1093/llc/fqw018",
 "id_scheme": "DOI"
 },
 "abstract": "One of Shakespeare’s least performed plays is King John, a drama indicted by E. K. Chambers for being an ‘incoherent patchwork’. Stylometric evidence over an extended period suggests a division of authorship that sheds light on the play’s ambiguous allegiance to its eponymous hero. The play displays a distinctive cross pattern, both contextually and linguistically. A variety of methods are described here. They include the use of the relative frequency of most common words, the distribution of irregular lines (feminine endings), and the average length of all words in modern spelling. There is also a two-fold cluster analysis with R Stylo, a programme which combines variable extraction with statistical analysis in a single process. This is a promising and accessible means for independent replication. The authorship of King John is a question that can progress towards a solution with modern methods.",
 "article_title": "Is It Time to Re-thinkKing John?",
 "authors": [
 {
 "given": "Thomas",
 "family": "Merriam",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-05-14",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw024",
 "identifier": {
 "string_id": "10.1093/llc/fqw024",
 "id_scheme": "DOI"
 },
 "abstract": "Analytic interest in comics, graphic novels and similarly visual media is currently experiencing considerable growth. In order to pursue empirical investigation of such media, it is useful to explore how data of this kind can be made accessible for the application of established empirical methods, such as linguistic corpus analysis. Many forms of communication have already benefited from data-driven analytic procedures, and it is logical to consider how this might also be the case for visual media. However, comics and graphic novels raise some unique challenges for this endeavor because a substantial component of their communicative effect is achieved by variations in their visual appearance and spatial organization. Schemes capable of capturing the spatial organization of visual media are to date limited largely to geometric descriptions and so are of limited value for more interpretative analyses. In this article, we set out a detailed classification scheme for the visual appearance of comics, graphic novels, and similar media that focuses particularly on their spatial ‘layout’ to make this facet of their meaning accessible to corpus-based quantitative and qualitative analyses.",
 "article_title": "An Open Multilevel Classification Scheme for the Visual Layout of Comics and Graphic Novels: Motivation and Design",
 "authors": [
 {
 "given": " John A.",
 "family": "Bateman",
 "affiliation": [
 {
 "original_name": "Department of Linguistics, Bremen University, Germany",
 "normalized_name": "University of Bremen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/04ers2y35",
 "GRID": "grid.7704.4"
 }
 }
 ]
 },
 {
 "given": " Francisco O. D.",
 "family": "Veloso",
 "affiliation": [
 {
 "original_name": "Department of English, Hong Kong Polytechnic University, Hong Kong",
 "normalized_name": "Hong Kong Polytechnic University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/0030zas98",
 "GRID": "grid.16890.36"
 }
 }
 ]
 },
 {
 "given": " Janina",
 "family": "Wildfeuer",
 "affiliation": [
 {
 "original_name": "Department of Linguistics, Bremen University, Germany",
 "normalized_name": "University of Bremen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/04ers2y35",
 "GRID": "grid.7704.4"
 }
 }
 ]
 },
 {
 "given": " Felix HiuLaam",
 "family": "Cheung",
 "affiliation": [
 {
 "original_name": "Department of English, Hong Kong Polytechnic University, Hong Kong",
 "normalized_name": "Hong Kong Polytechnic University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/0030zas98",
 "GRID": "grid.16890.36"
 }
 }
 ]
 },
 {
 "given": " Nancy Songdan",
 "family": "Guo",
 "affiliation": [
 {
 "original_name": "School of Professional Education and Executive Development, Hong Kong Polytechnic University, Hong Kong",
 "normalized_name": "Hong Kong Polytechnic University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/0030zas98",
 "GRID": "grid.16890.36"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-06-02",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw025",
 "identifier": {
 "string_id": "10.1093/llc/fqw025",
 "id_scheme": "DOI"
 },
 "abstract": "The aim of this paper is to present both the main parts of the designing and the implementation of a useful and user-friendly electronic tool, the Greek grammar checker. This tool carries out the function of analyzing morphologically and syntactically sentences, phrases, and words in order to correct syntactic, grammatical, and stylistic errors (Iordanidou, 1999, 2004). Our premise in order to deal with all these issues is the settings of Grammar (adaptation of Little Modern Grammar of Manolis Triantafyllidis), which is the formal grammatical codification of Modern Greek, since 1976 (Triantafyllidis, 1991). This paper also presents the formalism used (the Mnemosyne), a formalism that handles with the particularities of the Greek language that hinder the computational processing. This formalism has already been used to identify multi-word terms and to phrase grammars, aiming to automatically extract information. We tested the Greek grammar checker by giving texts that were to be evaluated both to the grammar checker and to a person. In the majority of cases, the human corrector accuracy is almost equal to the grammar checker one. As far as mistakes that have to do with the coherence of the text or with meaning are concerned, the human corrector was the only accurate corrector, not the grammar checker one (Gakis, 2015).",
 "article_title": "Design and construction of the Greek grammar checker",
 "authors": [
 {
 "given": " Panagiotis",
 "family": "Gakis",
 "affiliation": [
 {
 "original_name": "Department of Primary Education, University of Patras, Greece",
 "normalized_name": "University of Patras",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/017wvtq80",
 "GRID": "grid.11047.33"
 }
 }
 ]
 },
 {
 "given": " Christos",
 "family": "Panagiotakopoulos",
 "affiliation": [
 {
 "original_name": "Department of Primary Education, University of Patras, Greece",
 "normalized_name": "University of Patras",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/017wvtq80",
 "GRID": "grid.11047.33"
 }
 }
 ]
 },
 {
 "given": " Kyriakos",
 "family": "Sgarbas",
 "affiliation": [
 {
 "original_name": "Department of Electrical and Computer Engineering, University of Patras, Greece",
 "normalized_name": "University of Patras",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/017wvtq80",
 "GRID": "grid.11047.33"
 }
 }
 ]
 },
 {
 "given": " Christos",
 "family": "Tsalidis",
 "affiliation": [
 {
 "original_name": "Neurolingo Language Technology Applications, Athens, Greece",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Vassilios",
 "family": "Verykios",
 "affiliation": [
 {
 "original_name": "School of Science and Technology, Hellenic Open University, Patras, Greece",
 "normalized_name": "Hellenic Open University",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/02kq26x23",
 "GRID": "grid.55939.33"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-07-16",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw017",
 "identifier": {
 "string_id": "10.1093/llc/fqw017",
 "id_scheme": "DOI"
 },
 "abstract": "FarsiTag is a tagging system capable of assigning the most probable part-of-speech (POS) tags to Persian words in a text. In this system, some linguistic rules have been used to select the best POS tag for every Persian word. The present study aims to report the processes during which a robust tagging system—FarsiTag—was designed and implemented on Persian texts. A POS-tagged parallel corpus of English–Persian containing about 5,000,000 words has also been developed as a side-product of the mentioned tagger. An experiment has been conducted to evaluate the performance of the system while tagging unrestricted Persian texts. The highest rate of error traces back to medical and religious genres, while the lowest system error type is related to the scientific texts. The total error rate considering all domains is as low as 1.4%, with the overall system accuracy of 98.6% which is very promising for a language like Persian.",
 "article_title": "FarsiTag: A Part-of-Speech Tagging System for Persian",
 "authors": [
 {
 "given": " Mohammad Javad",
 "family": "Rezai",
 "affiliation": [
 {
 "original_name": "Yazd University, Islamic Republic of Iran",
 "normalized_name": "Yazd University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/02x99ac45",
 "GRID": "grid.413021.5"
 }
 }
 ]
 },
 {
 "given": " Tayebeh",
 "family": "Mosavi Miangah",
 "affiliation": [
 {
 "original_name": "Payame Noor University, Islamic Republic of Iran",
 "normalized_name": "Payame Noor University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/031699d98",
 "GRID": "grid.412462.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-07-16",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw019",
 "identifier": {
 "string_id": "10.1093/llc/fqw019",
 "id_scheme": "DOI"
 },
 "abstract": "Edgar Allan Poe has left us with a literary legacy that in part lacks a definitive stamp of authenticity. While some of the ‘possible Poes’ that have been discovered after his death have generated heated discussion among scholars, many others have quickly slipped into obscurity. This paper reevaluates thirty-two of such prose texts as well as ten poems that have been tenuously attributed to Poe in the past, using the ‘classify’ function (employing Nearest Shrunken Centroid, Burrows’ Delta and Support Vector Machines) of the stylo-toolkit for R. It also sheds new light (with the help of rolling Delta) on Poe’s possible contribution to the so-called Paulding-Drayton review, infamous in Poe criticism for its defense of slavery. By contrasting and comparing the ‘author signal’ behind these pieces with unclear authorship, this analysis is able to answer with a high degree of accuracy the question: Poe or not Poe?",
 "article_title": "Poe or Not Poe? A Stylometric Analysis of Edgar Allan Poe’s Disputed Writings",
 "authors": [
 {
 "given": "Stefan",
 "family": "Schöberlein",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-07-25",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw031",
 "identifier": {
 "string_id": "10.1093/llc/fqw031",
 "id_scheme": "DOI"
 },
 "abstract": "All-words sense tagging is the task of determining the correct senses of all content words in a given text. Many methods utilizing various language resources, such as a machine readable dictionary (MRD), sense tagged corpus, and WordNet, have been proposed for tagging senses to all words rather than a small number of sample words. However, sense tagging methods that require vast resources cannot be used for resource-deficient languages. The conventional sense tagging method for resource-deficient languages, which utilizes only an MRD, suffers from low recall and low precision because it determines senses only when a gloss word in the dictionary exactly matches a context word. In this study, we propose an all-words sense tagging method that is effective for resource-deficient languages in particular. It requires an MRD, which is the essential resource for all-words sense tagging, and a raw corpus, which is easily acquired and freely available. The proposed sense tagging method attempts to find semantically related context words based on the co-occurrence information extracted from the raw corpus and utilizes these words for tagging the senses of the target word. The experimental results of an evaluation of the proposed sense tagging algorithm on a Korean test corpus consisting of approximately 15 million words show that it can tag senses to all contents words automatically with high precision. Furthermore, we also show that a semantic concordancer can be developed based on the automatic sense tagged corpus.",
 "article_title": "An All-Words Sense Tagging Method for Resource-Deficient Languages",
 "authors": [
 {
 "given": " Bong-Jun",
 "family": "Yi",
 "affiliation": [
 {
 "original_name": "Department of Computer Science and Engineering, Korea University, Republic of Korea",
 "normalized_name": "Korea University",
 "country": "South Korea",
 "identifiers": {
 "ror": "https://ror.org/047dqcg40",
 "GRID": "grid.222754.4"
 }
 }
 ]
 },
 {
 "given": " Do-Gil",
 "family": "Lee",
 "affiliation": [
 {
 "original_name": "Research Institute of Korean Studies, Korea University, Republic of Korea",
 "normalized_name": "Korea University",
 "country": "South Korea",
 "identifiers": {
 "ror": "https://ror.org/047dqcg40",
 "GRID": "grid.222754.4"
 }
 }
 ]
 },
 {
 "given": " Hae-Chang",
 "family": "Rim",
 "affiliation": [
 {
 "original_name": "Department of Computer Science and Engineering, Korea University, Republic of Korea",
 "normalized_name": "Korea University",
 "country": "South Korea",
 "identifiers": {
 "ror": "https://ror.org/047dqcg40",
 "GRID": "grid.222754.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-08-14",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw038",
 "identifier": {
 "string_id": "10.1093/llc/fqw038",
 "id_scheme": "DOI"
 },
 "abstract": "Stemmatology aims at gaining understanding of the development and copying history of a textual tradition, based on the surviving witnesses of the text. Typically, this includes the task of identifying for each witness the source text from which it was copied. In a textual tradition, every copyist makes alterations, errors, and corrections (that can be either correct or not), which gradually mutate the contents of the text. When the extant versions are placed in a stemma, i.e. a graph representing the copying relationships, a scholar can attempt to reconstruct the earlier textual versions by reversing the process along the branches of the stemma. Anyone who has attempted such a task is well aware of the fact that it is subject to uncertainty arising from a number of sources, and...",
 "article_title": "Thematic Section on Studia Stemmatologica",
 "authors": [
 {
 "given": " Tuomas",
 "family": "Heikkilä",
 "affiliation": [
 {
 "original_name": "Institutum Romanum Finlandiae, Italy",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Teemu",
 "family": "Roos",
 "affiliation": [
 {
 "original_name": "Helsinki Institute for Information Technology HIIT, University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-08-24",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw027",
 "identifier": {
 "string_id": "10.1093/llc/fqw027",
 "id_scheme": "DOI"
 },
 "abstract": "Variation among human translations is usually invisible, little understood, and under-valued. Previous statistical research finds that translations vary most where the source items are most semantically significant or express most ‘attitude’ (affect, evaluation, ideology). Understanding how and why translations vary is important for translator training and translation quality assessment, for cultural research, and for machine translation development. Our experimental project began with the intuition that quantitative variation in a corpus of historical retranslations might be used to project quasi-qualitative annotations onto the translated text. We present a web-based system which enables users to create parallel, segment-aligned multi-version corpora, and provides visual interfaces for exploring multiple translations, with their variation projected onto a base text. The system can support any corpus of variant versions. We report experiments using our tools (and stylometric analysis) to investigate a corpus of forty German versions of a work by Shakespeare. Initial findings lead to more questions than answers.",
 "article_title": "Multi-Retranslation Corpora: Visibility, Variation, Value, and Virtue",
 "authors": [
 {
 "given": " Tom",
 "family": "Cheesman",
 "affiliation": [
 {
 "original_name": "Department of Languages, Swansea University, UK",
 "normalized_name": "Swansea University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/053fq8t95",
 "GRID": "grid.4827.9"
 }
 }
 ]
 },
 {
 "given": " Kevin",
 "family": "Flanagan",
 "affiliation": [
 {
 "original_name": "Department of Languages, Swansea University, UK and SDL Research, Bristol, UK",
 "normalized_name": "Swansea University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/053fq8t95",
 "GRID": "grid.4827.9"
 }
 }
 ]
 },
 {
 "given": " Stephan",
 "family": "Thiel",
 "affiliation": [
 {
 "original_name": "Bauhaus University Weimar, Germany and Studio Nand, Berlin",
 "normalized_name": "Bauhaus University, Weimar",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/033bb5z47",
 "GRID": "grid.41315.32"
 }
 }
 ]
 },
 {
 "given": " Jan",
 "family": "Rybicki",
 "affiliation": [
 {
 "original_name": "Institute of English Studies, Jagiellonian University, Poland",
 "normalized_name": "Jagiellonian University",
 "country": "Poland",
 "identifiers": {
 "ror": "https://ror.org/03bqmcz70",
 "GRID": "grid.5522.0"
 }
 }
 ]
 },
 {
 "given": " Robert S.",
 "family": "Laramee",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, Swansea University, UK",
 "normalized_name": "Swansea University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/053fq8t95",
 "GRID": "grid.4827.9"
 }
 }
 ]
 },
 {
 "given": " Jonathan",
 "family": "Hope",
 "affiliation": [
 {
 "original_name": "Department of English, Strathclyde University, UK",
 "normalized_name": "University of Strathclyde",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/00n3w3b69",
 "GRID": "grid.11984.35"
 }
 }
 ]
 },
 {
 "given": " Avraham",
 "family": "Roos",
 "affiliation": [
 {
 "original_name": "Amsterdam School of Culture and History, University of Amsterdam, the Netherlands",
 "normalized_name": "University of Amsterdam",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/04dkp9463",
 "GRID": "grid.7177.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-05-08",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw037",
 "identifier": {
 "string_id": "10.1093/llc/fqw037",
 "id_scheme": "DOI"
 },
 "abstract": "This article makes an argument for an open-workshop editorial process for scholarly editions, in which preliminary research products such as manuscript transcriptions are published to the Web, as they are completed. A publicly accessible online working environment for scholarly editions would allow research assistants to receive proper credit for their intellectual labor, and would reach out to the worldwide audience of scholars, students, and amateur enthusiasts, potentially building public support for a kind of scholarly activity that is threatened within the academy. Two ongoing projects in which the author is involved are used as illustrations of the way this can work, the Online Corpus of Old English Poetry and the Cotton Nero A.x. Project.",
 "article_title": "‘Why don’t we do it in the road?’: The case for scholarly editing as a public intellectual activity",
 "authors": [
 {
 "given": " Murray",
 "family": "McGillivray",
 "affiliation": [
 {
 "original_name": "University of Calgary, Calgary, Alberta, Canada",
 "normalized_name": "University of Calgary",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03yjb2x39",
 "GRID": "grid.22072.35"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-08-25",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw035",
 "identifier": {
 "string_id": "10.1093/llc/fqw035",
 "id_scheme": "DOI"
 },
 "abstract": "This article describes and demonstrates a named entity similarity metric developed for, and currently in use by, the FuzzyPhoto project. The presented metric is effective at comparing named entity data in and across syntaxless data schemas such as are often encountered in Gallery, Library, Archive, and Museum collections. The efficiency of the approach was compared to an existing named entity similarity metric and is shown to be a significant improvement when comparing messy named entity data.",
 "article_title": "An effective named entity similarity metric for comparing data from multiple sources with varying syntax",
 "authors": [
 {
 "given": " David",
 "family": "Croft",
 "affiliation": [
 {
 "original_name": "School of Computing, Electronics and Maths, Coventry University, UK",
 "normalized_name": "Coventry University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01tgmhj36",
 "GRID": "grid.8096.7"
 }
 }
 ]
 },
 {
 "given": " Stephen",
 "family": "Brown",
 "affiliation": [
 {
 "original_name": "Knowledge Media and Design, De Montfort University, UK",
 "normalized_name": "De Montfort University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0312pnr83",
 "GRID": "grid.48815.30"
 }
 }
 ]
 },
 {
 "given": " Simon",
 "family": "Coupland",
 "affiliation": [
 {
 "original_name": "Centre for Computational Intelligence, De Montfort University, UK",
 "normalized_name": "De Montfort University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0312pnr83",
 "GRID": "grid.48815.30"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-08-28",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw029",
 "identifier": {
 "string_id": "10.1093/llc/fqw029",
 "id_scheme": "DOI"
 },
 "abstract": "Why are Romeo and Juliet prominent characters in Shakespeare’s play of the same name? Contrary to what common sense might suggest, the academic literature does not provide a unique answer to this question. Indeed, there is little agreement on who the main character is and which elements of a script contribute to establishing a character’s leading role. The objective of this article is to explore and compare the prominence of characters in Romeo and Juliet by using social network analysis. To this end, we calculate the centralities of several characters in Romeo and Juliet using a method based on Social Network Analysis. Comparing the scores generated by this analysis, we found that Romeo’s centrality is more stable than Juliet’s while hers is lower and supported by the ‘strength of the bonds’ she develops with other characters. Thus, the comparison of different centrality rankings and clusters provides new knowledge about the plays of Shakespeare. We show that the ‘strength’ of the relationships affects the prominence of the characters. This finding opens new directions for analyzing Shakespeare’s scripts and determining who the main character is using weighted centrality measures. Finally, we discuss some theoretical and practical implications of the method used in this study.",
 "article_title": "Exploring the prominence ofRomeo and Juliet’s characters using weighted centrality measures",
 "authors": [
 {
 "given": " Víctor Hugo",
 "family": "Masías",
 "affiliation": [
 {
 "original_name": "Department of Management Control and Information Systems, Universidad de Chile, Chile",
 "normalized_name": "University of Chile",
 "country": "Chile",
 "identifiers": {
 "ror": "https://ror.org/047gc3g35",
 "GRID": "grid.443909.3"
 }
 }
 ]
 },
 {
 "given": " Paula",
 "family": "Baldwin",
 "affiliation": [
 {
 "original_name": "Institute of Literature, Universidad de Los Andes, Chile",
 "normalized_name": "University of the Andes",
 "country": "Venezuela",
 "identifiers": {
 "ror": "https://ror.org/02h1b1x27",
 "GRID": "grid.267525.1"
 }
 }
 ]
 },
 {
 "given": " Sigifredo",
 "family": "Laengle",
 "affiliation": [
 {
 "original_name": "Department of Management Control and Information Systems, Universidad de Chile, Chile",
 "normalized_name": "University of Chile",
 "country": "Chile",
 "identifiers": {
 "ror": "https://ror.org/047gc3g35",
 "GRID": "grid.443909.3"
 }
 }
 ]
 },
 {
 "given": " Augusto",
 "family": "Vargas",
 "affiliation": [
 {
 "original_name": "Departamento de Diseño y Manufactura (DIMA), Universidad Técnica Federico Santa María, Chile",
 "normalized_name": "Universidad Técnica Federico Santa María",
 "country": "Ecuador",
 "identifiers": {
 "ror": "https://ror.org/02zbepj77",
 "GRID": "grid.472425.2"
 }
 }
 ]
 },
 {
 "given": " Fernando A.",
 "family": "Crespo",
 "affiliation": [
 {
 "original_name": "Universidad Bernardo OHiggins, Centro de Desarrollo y Transferencia Tecnológica (CEDYTEC), Dirección de Investigación, y Facultad de Ingeniería y Administración, Chile",
 "normalized_name": "Universidad Bernardo O'Higgins",
 "country": "Chile",
 "identifiers": {
 "ror": "https://ror.org/00x0xhn70",
 "GRID": "grid.440625.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-08-31",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw036",
 "identifier": {
 "string_id": "10.1093/llc/fqw036",
 "id_scheme": "DOI"
 },
 "abstract": "This study uses information gleaned from the front matter, or preliminaries, of Spanish Golden Age texts to model the social networks underpinning the early modern publication industry. Using a data-driven approach, we examine the historical and political conditions that influenced the process of approval, censorship, and publication in the Spanish Empire, with a particular focus on the concept of geography, as it relates to the process of community formation and composition. We find that the literary publishing scene was dominated by a small group of authors, generally tied to Madrid, but highly published across Iberian cultural and political capitals. These authors, together with the powerful literary patrons who they relied upon for support, served as local bridges between communities that formed primarily at the local level. Regionally, we find groups of literate bureaucrats, clergymen, printers, and booksellers working together to fulfill the legal requirements for publication as dictated by the Spanish crown. Finally, we see how certain individuals tend to stand out at the regional level as gatekeepers to the publication industry, interacting equally with high- and low-profile individuals to approve and publish texts.",
 "article_title": "The preliminaries project: Geography, networks, and publication in the Spanish Golden Age",
 "authors": [
 {
 "given": " David M",
 "family": "Brown",
 "affiliation": [
 {
 "original_name": "CulturePlex Lab, Western University, Canada",
 "normalized_name": "Western University",
 "country": "Cambodia",
 "identifiers": {
 "ror": "https://ror.org/02agqkc58",
 "GRID": "grid.443228.b"
 }
 }
 ]
 },
 {
 "given": " Adriana",
 "family": "Soto-Corominas",
 "affiliation": [
 {
 "original_name": "CulturePlex Lab, Western University, Canada",
 "normalized_name": "Western University",
 "country": "Cambodia",
 "identifiers": {
 "ror": "https://ror.org/02agqkc58",
 "GRID": "grid.443228.b"
 }
 }
 ]
 },
 {
 "given": " Juan Luis",
 "family": "Suárez",
 "affiliation": [
 {
 "original_name": "CulturePlex Lab, Western University, Canada",
 "normalized_name": "Western University",
 "country": "Cambodia",
 "identifiers": {
 "ror": "https://ror.org/02agqkc58",
 "GRID": "grid.443228.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-08-31",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv062",
 "identifier": {
 "string_id": "10.1093/llc/fqv062",
 "id_scheme": "DOI"
 },
 "abstract": "This article discusses two major initiatives tasked with developing tools to improve optical character recognition (OCR) or the mechanical keying of texts that are digitally available only as page images. The two initiatives are the IMProving ACcess to Text Project in Europe and the Early Modern OCR Project in the USA. Because of dealing with a multilayered problem like OCR technologies and having to collaborate with radically interdisciplinary and international team members, the two projects developed techniques that we call Agile Project Management, outlined in this essay with rationales for their use.",
 "article_title": "Navigating the Storm: IMPACT, eMOP, and Agile Steering Standards",
 "authors": [
 {
 "given": "Laura C.",
 "family": "Mandell",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Clemens",
 "family": "Neudecker",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Apostolos",
 "family": "Antonacopoulos",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Elizabeth",
 "family": "Grumbach",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Loretta",
 "family": "Auvil",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Matthew J.",
 "family": "Christy",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Jacob A.",
 "family": "Heil",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Todd",
 "family": "Samuelson",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-12-17",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv068",
 "identifier": {
 "string_id": "10.1093/llc/fqv068",
 "id_scheme": "DOI"
 },
 "abstract": "The contribution presents an ongoing research project that aims at designing a dynamic grammar of Ancient Greek. Relying on a Drupal-based solution, students will be trained to move between the language’s formal, semantic, and syntactic levels, so as to overcome the static character of a traditional grammar. A short description of the shortcomings of traditional Ancient Greek grammars is followed by a description of both the micro-structure and the macro-structure of the grammar. The final section focuses on the implementation of the tool in classes.Benefiting from recent developments and insights in the fields of technology, linguistics, and language didactics alike, the Greek grammar Pedalion (http://www.pedalion.org/—Ancient Greek πηδάλιον means ‘rudder’) seeks to offer a ‘contemporary’ instrument that is tailored to mastering and understanding ‘ancient’ languages.",
 "article_title": "Reconciling the Dynamics of Language with a Grammar Handbook: The Ongoing Pedalion Grammar Project",
 "authors": [
 {
 "given": " Toon",
 "family": "Van Hal",
 "affiliation": [
 {
 "original_name": "University of Leuven, Belgium.",
 "normalized_name": "KU Leuven",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/05f950310",
 "GRID": "grid.5596.f"
 }
 }
 ]
 },
 {
 "given": " Yannick",
 "family": "Anné",
 "affiliation": [
 {
 "original_name": "University of Leuven, Belgium.",
 "normalized_name": "KU Leuven",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/05f950310",
 "GRID": "grid.5596.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-01-26",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv072",
 "identifier": {
 "string_id": "10.1093/llc/fqv072",
 "id_scheme": "DOI"
 },
 "abstract": "Modernist authors such as Virginia Woolf and James Joyce greatly expanded the use of ‘free indirect discourse’, a form of third-person narration that is strongly influenced by the language of a viewpoint character. Unlike traditional approaches to analyzing characterization using common words, such as those based on Burrows (1987), the nature of free indirect discourse and the sparseness of our data require that we understand the stylistic connotations of rarer words and expressions which cannot be gleaned directly from our target texts. To this end, we apply methods introduced in our recent work to derive information with regards to six stylistic aspects from a large corpus of texts from Project Gutenberg. We thus build high-coverage, finely grained lexicons that include common multiword collocations. Using this information along with student annotations of two modernist texts, Woolf’s To The Lighthouse and Joyce’s The Dead, we confirm that free indirect discourse does, at a stylistic level, reflect a mixture of narration and direct speech, and we investigate the extent to which social attributes of the various characters (in particular age, class, and gender) are reflected in their lexical stylistic profile.",
 "article_title": "Using Models of Lexical Style to Quantify Free Indirect Discourse in Modernist Fiction",
 "authors": [
 {
 "given": " Julian",
 "family": "Brooke",
 "affiliation": [
 {
 "original_name": "Department of Computing and Information Systems, University of Melbourne, Australia",
 "normalized_name": "University of Melbourne",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/01ej9dk98",
 "GRID": "grid.1008.9"
 }
 }
 ]
 },
 {
 "given": " Adam",
 "family": "Hammond",
 "affiliation": [
 {
 "original_name": "Department of English and Comparative Literature, San Diego State University, USA",
 "normalized_name": "San Diego State University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0264fdx42",
 "GRID": "grid.263081.e"
 }
 }
 ]
 },
 {
 "given": " Graeme",
 "family": "Hirst",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, University of Toronto, Canada",
 "normalized_name": "University of Toronto",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03dbr7087",
 "GRID": "grid.17063.33"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-02-04",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv063",
 "identifier": {
 "string_id": "10.1093/llc/fqv063",
 "id_scheme": "DOI"
 },
 "abstract": "As digital humanities (DH) continues to embrace its global dimensions, community members struggle to ascertain frames of reference for understanding and interpreting local contexts for scholarship. This article intervenes in that effort by distinguishing between the local and global contours of DH. It analyzes two projects that map the geographies of DH and identifies the challenge of recognizing DH work. Drawing on postcolonial and linguistic theories of language, this article then proposes that the concept of a ‘DH accent’ provides a lens for mediating between local and global definitions of DH and resolving the ethical challenge of misrecognition. In seeking a global vision, the article suggests, the DH community must begin with the question, ‘What is your DH accent?’",
 "article_title": "Other Worlds, Other DHs: Notes towards a DH Accent",
 "authors": [
 {
 "given": " Roopika",
 "family": "Risam",
 "affiliation": [
 {
 "original_name": "Salem State University, English, Salem, MA, USA",
 "normalized_name": "Salem State University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/023qmza96",
 "GRID": "grid.419433.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-02-06",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv070",
 "identifier": {
 "string_id": "10.1093/llc/fqv070",
 "id_scheme": "DOI"
 },
 "abstract": "This article will describe social networks and the concepts of social network analysis. It will then move on to describe some of the uses social network analysis has been put to in historical research. This will be followed by a description of the People of Medieval Scotland database, which provides the data for this research. Finally, the social network analysis techniques used in this research will be described and the preliminary results that reveal findings that traditional historical methods had not will be discussed, including identifying an additional role played by Duncan II Earl of Fife, and using network density model for the diffusion of innovations to identify opinion leaders in medieval Scotland.",
 "article_title": "Using Social Network Analysis to Reveal Unseen Relationships in Medieval Scotland",
 "authors": [
 {
 "given": " Cornell",
 "family": "Jackson",
 "affiliation": [
 {
 "original_name": "Digital Humanities, Kings College London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-02-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv071",
 "identifier": {
 "string_id": "10.1093/llc/fqv071",
 "id_scheme": "DOI"
 },
 "abstract": "The concept of dramatic situation is important in dramaturgy and narratology. In the domain of story generation and interactive digital storytelling, this concept is particularly powerful in creating meaningful story variations from a single core model. Nevertheless, dramatic situations and the related notion of deep narrative structures have been overlooked in the domain of computational models of narrative. This article presents a computational model of dramatic situations. Designed with creative authors in mind, the model consists of a small set of building blocks that, when assembled with specific relations, create narrative structures. Some structures that are described are of particular interest from a dramatic point of view, for they embed a fundamental paradox. These structures are generalized and formalized to allow an exhaustive search and to establish an initial list of dramatic situations that share this property.",
 "article_title": "Modeling and Representing Dramatic Situations as Paradoxical Structures",
 "authors": [
 {
 "given": " Nicolas",
 "family": "Szilas",
 "affiliation": [
 {
 "original_name": "TECFA, FPSE, University of Geneva, Switzerland",
 "normalized_name": "University of Geneva",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/01swzsf04",
 "GRID": "grid.8591.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-02-13",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw001",
 "identifier": {
 "string_id": "10.1093/llc/fqw001",
 "id_scheme": "DOI"
 },
 "abstract": "Pliny the Younger's letter to Trajan regarding the Christians is a crucial subject for the studies on early Christianity. A serious quarrel among scholars concerning its genuineness arose between the end of the 19th century and the beginning of the 20th; per contra, Plinian authorship has not been seriously questioned in the last few decades. After analysing various kinds of internal and external evidence in favour of and against the authenticity of the letter, a modern stylometric method is applied in order to examine whether internal linguistic evidence allows one to definitely settle the debate.The findings of this analysis tend to contradict received opinion among modern scholars, affirming the authenticity of Pliny’s letter, and suggest instead the presence of large amounts of interpolation inside the text of the letter, since its stylistic behaviour appears highly different from that of the rest of Book X.",
 "article_title": "An Application of a Profile-Based Method for Authorship Verification: Investigating the Authenticity of Pliny the Younger’s Letter to Trajan Concerning the Christians",
 "authors": [
 {
 "given": "Enrico",
 "family": "Tuccinardi",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-02-16",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw005",
 "identifier": {
 "string_id": "10.1093/llc/fqw005",
 "id_scheme": "DOI"
 },
 "abstract": "Many complex systems are naturally described through graph theory, and different kinds of systems described as networks present certain important characteristics in common. One of these features is the so-called scale-free distribution for its node’s connectivity, which means that the degree distribution for the network’s nodes follows a power law. Scale-free networks are usually referred to as small-world because the average distance between their nodes do not scale linearly with the size of the network, but logarithmically. Here we present a mathematical analysis on linguistics: the word frequency effect for different translations of the ‘Le Petit Prince’ in different languages. Comparison of word association networks with random networks makes evident the discrepancy between the random Erdös-Rény model for graphs and real-world networks.",
 "article_title": "The Small-World of ‘Le Petit Prince’: Revisiting the Word Frequency Distribution",
 "authors": [
 {
 "given": " Daniel",
 "family": "Gamermann",
 "affiliation": [
 {
 "original_name": "Department of Physics, Universidade Federal do Rio Grande do Sul (UFRGS), Instituto de Física Av. Bento Gonçalves 9500, Brasil",
 "normalized_name": "Federal University of Rio Grande do Sul",
 "country": "Brazil",
 "identifiers": {
 "ror": "https://ror.org/041yk2d64",
 "GRID": "grid.8532.c"
 }
 }
 ]
 },
 {
 "given": " Carmen",
 "family": "Moret-Tatay",
 "affiliation": [
 {
 "original_name": "Departamento de Neuropsicobiología, Metodología y Psicología Social, Universidad Católica de Valencia (San Vicente Mártir), Spain",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Esperanza",
 "family": "Navarro-Pardo",
 "affiliation": [
 {
 "original_name": "Department of Developmental and Educational Psychology, Universitat de València. Av. Blasco Ibáñez, Spain",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Pedro",
 "family": "Fernandez de Córdoba Castellá",
 "affiliation": [
 {
 "original_name": "Instituto Universitario de Matemática Pura y Aplicada, Universitat Politècnica de València, Spain",
 "normalized_name": "Universitat Politècnica de València",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01460j859",
 "GRID": "grid.157927.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-02-27",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw013",
 "identifier": {
 "string_id": "10.1093/llc/fqw013",
 "id_scheme": "DOI"
 },
 "abstract": "This essay presents a case study that considers the motivations and needs of a scholarly edition of Joseph Furphy’s Australian novel Such is Life in conjunction with the requirements for the development of the Australian Electronic Scholarly Editing Workbench. The latter integrates a suite of eResearch tools to support the collaborative authoring and management of electronic scholarly editions. The discussion focuses on the theoretical and practical implications of building an electronic edition in such an environment and considers the ways in which the product of these activities begins to move beyond the model of the book. Central to the discussion is the idea of an ontology-based electronic edition, not as an end in itself, but as the ongoing activity of one or more human beings contributing to the creation and assembly of constituent parts with digital tools.",
 "article_title": "Archiving, editing, and reading on the AustESE Workbench: Assembling and theorizing an ontology-based electronic scholarly edition of Joseph Furphy’sSuch is Life",
 "authors": [
 {
 "given": " Roger",
 "family": "Osborne",
 "affiliation": [
 {
 "original_name": "School of Communication and Arts, University of Queensland",
 "normalized_name": "University of Queensland",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00rqy9422",
 "GRID": "grid.1003.2"
 }
 }
 ]
 },
 {
 "given": " Anna",
 "family": "Gerber",
 "affiliation": [
 {
 "original_name": "eResearch Group, University of Queensland",
 "normalized_name": "University of Queensland",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00rqy9422",
 "GRID": "grid.1003.2"
 }
 }
 ]
 },
 {
 "given": " Jane",
 "family": "Hunter",
 "affiliation": [
 {
 "original_name": "eResearch Group, University of Queensland",
 "normalized_name": "University of Queensland",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00rqy9422",
 "GRID": "grid.1003.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-12-28",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw009",
 "identifier": {
 "string_id": "10.1093/llc/fqw009",
 "id_scheme": "DOI"
 },
 "abstract": "As digital literary collections continue to expand their scope and to broaden their audience, documenting the collaborative editorial work involved in creating these collections—and rendering that documentation transparent for its users—ensures that scholars continue to develop the idea (and reality) of the ‘social text’ envisioned by D. F. McKenzie. By documenting their collaborative editorial practices in a digital environment, scholarly editors help instantiate both the material history and the authorial, literary, and social contexts of a particular text. By rendering these collaborative practices visible, they make digital collections dynamic and usable for a wide range of individuals. The Walt Whitman Archive (WWA) serves as an ideal case study for examining the ways this particular collection intermediates scholarly editorial practices within a collaborative digital environment, as well as conventions of a scholarly edition and an archive. Through its collaborative editorial practices and guidelines, its layout and design, and its detailed documentation about its conditions of use for the general public, the WWA at once renders more visible the iterative process involved in editorial work, and makes the publicly accessible documentation of that process part of its infrastructure.",
 "article_title": "Documentation for the public: Social editing inThe Walt Whitman Archive",
 "authors": [
 {
 "given": " Meg",
 "family": "Meiman",
 "affiliation": [
 {
 "original_name": "University of Delaware, USA",
 "normalized_name": "University of Delaware",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/01sbq1a82",
 "GRID": "grid.33489.35"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-03-03",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw003",
 "identifier": {
 "string_id": "10.1093/llc/fqw003",
 "id_scheme": "DOI"
 },
 "abstract": "This article suggests that Jerome McGann’s proposal for social text editing can be applied to editions understood not as one author’s works, but rather as networks of publications by many authors and editors. The ability to create such an edition has been hampered in the past by the inability of HTML to express the semantic richness of TEI XML. However, by adopting the new semantic tags, custom data attributes, and schema.org microdata introduced with HTML5, an interoperable digital social edition can be feasible. The Grub Street Project, an edition of books, pamphlets, and data from 18th-century London, is a test of this premise.",
 "article_title": "The Grub Street Project: A digital social edition of London in the long 18th century",
 "authors": [
 {
 "given": " Allison",
 "family": "Muri",
 "affiliation": [
 {
 "original_name": "University of Saskatchewan",
 "normalized_name": "University of Saskatchewan",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/010x8gc63",
 "GRID": "grid.25152.31"
 }
 }
 ]
 },
 {
 "given": " Catherine",
 "family": "Nygren",
 "affiliation": [
 {
 "original_name": "McGill University, Canada",
 "normalized_name": "McGill University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/01pxwe438",
 "GRID": "grid.14709.3b"
 }
 }
 ]
 },
 {
 "given": " Benjamin",
 "family": "Neudorf",
 "affiliation": [
 {
 "original_name": "University of Alberta, Canada",
 "normalized_name": "University of Alberta",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/0160cpw27",
 "GRID": "grid.17089.37"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-03-05",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw011",
 "identifier": {
 "string_id": "10.1093/llc/fqw011",
 "id_scheme": "DOI"
 },
 "abstract": "One of the great advantages the digital medium has to offer the field of scholarly editing is that it makes its products much easier to distribute. No longer bound to a shelf, the Digital Scholarly Edition has the potential to reach a much wider audience than a printed edition could. To a certain extent, however, the nature of the materials textual scholars are working with dictates the perimeters within which this dissemination can take place. When working with modern manuscripts, for instance, copyright restrictions may limit the extent to which a project can distribute its resources. In an academic climate where open access is not only becoming a standard, but in some cases even a requirement for receiving funding, such limitations may be perceived as problematic. In this article, we argue that even within the boundaries of copyright restrictions there can still be room to produce and distribute the results of textual scholarship. Therefore, the article zooms in on the way in which different Digital Scholarly Editions of copyrighted materials deal with this issue, using the Beckett Digital Manuscript Project (BDMP; www.beckettarchive.org) and Woolf Online (www.woolfonline.com) as case studies. To conclude, we investigate other strategies that may be used to share as much research data as we are allowed to, e.g. by sharing metadata and ancillary data, or by using the fair use doctrine to circumvent the problem. Case studies used for this aspect of the article include ModNets (www.modnets.org), the BDMP Encoding Manual (www.beckettarchive.org/encodingmanual), the Lexicon of Scholarly Editing (http://uahost.uantwerpen.be/lse), and the Finnegans Wake Extensible Elucidation Treasury (FWEET; www.fweet.org).",
 "article_title": "Digital scholarly editing within the boundaries of copyright restrictions",
 "authors": [
 {
 "given": " Wout",
 "family": "Dillen",
 "affiliation": [
 {
 "original_name": "Centre for Manuscript Genetics, University of Antwerp, Belgium",
 "normalized_name": "University of Antwerp",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/008x57b05",
 "GRID": "grid.5284.b"
 }
 }
 ]
 },
 {
 "given": " Vincent",
 "family": "Neyt",
 "affiliation": [
 {
 "original_name": "Centre for Manuscript Genetics, University of Antwerp, Belgium",
 "normalized_name": "University of Antwerp",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/008x57b05",
 "GRID": "grid.5284.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-03-06",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw002",
 "identifier": {
 "string_id": "10.1093/llc/fqw002",
 "id_scheme": "DOI"
 },
 "abstract": "Presented here is a geovisual reading of all three volumes of Karl Marx's Capital. Marx's seminal treatise on political economy is normally treated as a work of abstract conceptualization. However, Marx names hundreds of geographic locations in Capital, usually in a highly relational and dynamic fashion. It seemed to me there was enough geographic information contained in the volumes to produce a geovisually rich map, presenting the themes, places, and relationships in this text in a new and revealing way.",
 "article_title": "Mapping the Geography of Karl Marx’s Capital",
 "authors": [
 {
 "given": " Jacob",
 "family": "Shell",
 "affiliation": [
 {
 "original_name": "Department of Geography and Urban Studies, Temple University, USA",
 "normalized_name": "Temple University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00kx1jb78",
 "GRID": "grid.264727.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-05-08",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "32",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw012",
 "identifier": {
 "string_id": "10.1093/llc/fqw012",
 "id_scheme": "DOI"
 },
 "abstract": "The role and usage of a certain technology is not imparted wholesale on the intended user community—technology is not deterministic. Rather, a negotiation between users and the designers of the technology will result in its particular form and function. This article considers a side effect of these negotiations. When a certain known technology is used to convey a new technological concept or model, there is a risk that the paradigm associated by the users with the known technology will eclipse the new model and its affordances in part or in whole. The article presents a case study of this ‘paradigmatic regression’ centering on a transcription tool of the Huygens Institute in the Netherlands. It is argued that similar effects also come into play at a larger scale within the field of textual scholarship, inhibiting the exploration of the affordances of new models that do not adhere to the pervasive digital metaphor of the codex. An example of such an innovative model, the knowledge graph model, is briefly introduced to illustrate the point.",
 "article_title": "The case of the bold button: Social shaping of technology and the digital scholarly edition",
 "authors": [
 {
 "given": " Joris J.",
 "family": "van Zundert",
 "affiliation": [
 {
 "original_name": "Huygens Institute for the History of the Netherlands, Royal Netherlands Academy of Arts and Sciences, The Hague, The Netherlands",
 "normalized_name": "Royal Netherlands Academy of Arts and Sciences",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/043c0p156",
 "GRID": "grid.418101.d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-03-09",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw004",
 "identifier": {
 "string_id": "10.1093/llc/fqw004",
 "id_scheme": "DOI"
 },
 "abstract": "Semi-automated extraction of details corresponding to narratological fabula from a corpus of narrative interviews on a single event provides decontextualized building blocks for transversal, or cross-document, narratives. With information extracted from 503 World Trade Center Task Force Interviews comprising 12,000 pages of testimony and novel visualization techniques, this article proposes a computational method for the emergence of narratives that cross beyond the boundaries of one interview. These assembled narratives, in cases like that of Chief Ganci, can document those who did not survive to tell their own story.",
 "article_title": "Visualizing Computational, Transversal Narratives from the World Trade Towers",
 "authors": [
 {
 "given": " Ben",
 "family": "Miller",
 "affiliation": [
 {
 "original_name": "Departments of English and Communication, Georgia State University",
 "normalized_name": "Georgia State University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/03qt6ba18",
 "GRID": "grid.256304.6"
 }
 }
 ]
 },
 {
 "given": " Ayush",
 "family": "Shrestha",
 "affiliation": [
 {
 "original_name": "IEEE Member",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Jennifer",
 "family": "Olive",
 "affiliation": [
 {
 "original_name": "Department of English, Georgia State University",
 "normalized_name": "Georgia State University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/03qt6ba18",
 "GRID": "grid.256304.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-05-08",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw006",
 "identifier": {
 "string_id": "10.1093/llc/fqw006",
 "id_scheme": "DOI"
 },
 "abstract": "For most of the world’s 7,000 languages, there are few records available via the Internet. Recognizing this digital divide and the consequential underrepresentation of most languages in any linked open data efforts is a motivation for some solutions offered in this article. Efforts to increase the documentation of the world’s small languages have led to the development of tools and repositories over the past decade. However, as not all digital language archives currently provide metadata in standard formats, their collections are invisible to aggregated searches. Other repositories (including many institutional repositories—national libraries and archives, mission archives, and so on) have language content that is not noted in the collection’s catalog, so is impossible to locate at all via a search based on language names. Finally, there are collections still held by their creators and not in a repository at all, completely hidden from other potential users. This article suggests that it is a digital humanities project to make more information about the world’s small languages more freely available, and identifies several means by which this could be accomplished, including a survey to locate more collections; a register to announce their existence; and a documentation index to provide an overview of what is known for each language.",
 "article_title": "What Remains to be Done—Exposing Invisible Collections in the other 7,000 Languages and Why it is a DH Enterprise",
 "authors": [
 {
 "given": " Nick",
 "family": "Thieberger",
 "affiliation": [
 {
 "original_name": "School of Languages and Linguistics, University of Melbourne, Australia",
 "normalized_name": "University of Melbourne",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/01ej9dk98",
 "GRID": "grid.1008.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-03-10",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw014",
 "identifier": {
 "string_id": "10.1093/llc/fqw014",
 "id_scheme": "DOI"
 },
 "abstract": " By comparing the results obtained through traditional qualitative stemmatics with those obtained through computer-assisted quantitative stemmatology, when both approaches are applied to two authentic data sets (the Old English Anglo-Saxon Chronicle and a Latin epitome of Marco Polo’s Devisement dou Monde ), this study aims at bringing to the fore the advantages and the disadvantages of some recent methods for the automatic grouping of witnesses, most of which are based on phylogenetic models. The analysis will show that not all the methods provide results which can be considered reliable in light of the evidence offered by a thorough scrutiny of the documentary history of the texts under inspection. In particular, the majority of computer-assisted methods succeed in providing very good information for detecting the grouping of witnesses, as well as for a preliminary evaluation of their variant readings. Yet, few offer some valuable guidance as to define the sub-groups. This limitation becomes crucial when the existence of more than one codex interpositus has to be postulated, i.e. when the historical evidence makes it clear that the actual textual transmission cannot conform to the mathematical ideal of cladistic parsimony. The latter case is particularly evident with ‘closed’ recensions, where mechanical reconstruction plays a heavier role, and the choice of variants follows rigorous stemmatic steps. On the other hand, the application of computer-assisted methods to ‘open’ recensions seems to give better results. ",
 "article_title": "Open versus closed recensions (Pasquali): Pros and cons of some methods for computer-assisted stemmatology",
 "authors": [
 {
 "given": " Marina",
 "family": "Buzzoni",
 "affiliation": [
 {
 "original_name": "Department of Linguistics and Comparative Cultural Studies, Ca’ Foscari University of Venice, Italy",
 "normalized_name": "Ca Foscari University of Venice",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/04yzxz566",
 "GRID": "grid.7240.1"
 }
 }
 ]
 },
 {
 "given": " Eugenio",
 "family": "Burgio",
 "affiliation": [
 {
 "original_name": "Department of Humanities, Ca’ Foscari University of Venice, Italy",
 "normalized_name": "Ca Foscari University of Venice",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/04yzxz566",
 "GRID": "grid.7240.1"
 }
 }
 ]
 },
 {
 "given": " Martina",
 "family": "Modena",
 "affiliation": [
 {
 "original_name": "Department of Humanities, Ca’ Foscari University of Venice, Italy",
 "normalized_name": "Ca Foscari University of Venice",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/04yzxz566",
 "GRID": "grid.7240.1"
 }
 }
 ]
 },
 {
 "given": " Samuela",
 "family": "Simion",
 "affiliation": [
 {
 "original_name": "Department of Humanities, Ca’ Foscari University of Venice, Italy",
 "normalized_name": "Ca Foscari University of Venice",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/04yzxz566",
 "GRID": "grid.7240.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-03-18",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw007",
 "identifier": {
 "string_id": "10.1093/llc/fqw007",
 "id_scheme": "DOI"
 },
 "abstract": "Deliberate differences in how authors represent characters has been a core area of literary investigation since the dawn of literary theory. Here, we focus on epistolary literature, where authors consciously attempt to create different character styles through series of documents like letters. Previous studies suggest that the linguistic gestalt of an author’s style—the author’s ‘writeprint’—can be extracted from the various characters of an epistolary novel, but it is unclear whether individual characters themselves also have distinct writeprints. We examine Samuel Richardson’s Clarissa, lauded as a watershed example of the epistolary novel, using a recently developed and highly successful authorship attribution technique to determine (1) whether Richardson can construct distinct character writeprints, and (2) if so, which linguistic features he manipulated to do so. We find that while there are not as many distinct character writeprints as characters, Richardson does appear to have signature features he alters to create distinct character styles—and few of these features are the function word or abstract syntactic features typically comprising author writeprints. We discuss implications for other questions about character identity in Clarissa and character writeprint analysis more generally.",
 "article_title": "The Character in the Letter: Epistolary Attribution in Samuel Richardson’sClarissa",
 "authors": [
 {
 "given": " Lisa",
 "family": "Pearl",
 "affiliation": [
 {
 "original_name": "Department of Cognitive Sciences, 3151 Social Science Plaza, University of California",
 "normalized_name": "California Coast University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05t99sp05",
 "GRID": "grid.468726.9"
 }
 }
 ]
 },
 {
 "given": " Kristine",
 "family": "Lu",
 "affiliation": [
 {
 "original_name": "Department of Cognitive Sciences, 3151 Social Science Plaza, University of California",
 "normalized_name": "California Coast University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05t99sp05",
 "GRID": "grid.468726.9"
 }
 }
 ]
 },
 {
 "given": " Anousheh",
 "family": "Haghighi",
 "affiliation": [
 {
 "original_name": "Department of Cognitive Sciences, 3151 Social Science Plaza, University of California",
 "normalized_name": "California Coast University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05t99sp05",
 "GRID": "grid.468726.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-03-19",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqw016",
 "identifier": {
 "string_id": "10.1093/llc/fqw016",
 "id_scheme": "DOI"
 },
 "abstract": "This essay discusses the methodological problems faced by researchers in the humanities, and more especially so those in literature. Its aim is to advance the field of telematics research of literary texts. As it is, literary research is already in checkmate for its high degree of subjectivity and lack of an approach to ensure the effectiveness of its results as it happens in the so-called Hard Sciences. Therefore, when a literato launches him/herself to do research with the use of text analysis software, he/she has to learn from science how to report his/her search so that his/her peers can reproduce the experiment and come to similar results.",
 "article_title": "On the Path to a Methodology for the Critique of Digital Literature",
 "authors": [
 {
 "given": " Saulo Cunha de Serpa",
 "family": "Brandão",
 "affiliation": [
 {
 "original_name": "Universidade Federal do Piauí, Brazil",
 "normalized_name": "Federal University of Piauí",
 "country": "Brazil",
 "identifiers": {
 "ror": "https://ror.org/00kwnx126",
 "GRID": "grid.412380.c"
 }
 }
 ]
 },
 {
 "given": " Wander Nunes",
 "family": "Frota",
 "affiliation": [
 {
 "original_name": "Universidade Federal do Piauí, Brazil",
 "normalized_name": "Federal University of Piauí",
 "country": "Brazil",
 "identifiers": {
 "ror": "https://ror.org/00kwnx126",
 "GRID": "grid.412380.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2016-03-25",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv067",
 "identifier": {
 "string_id": "10.1093/llc/fqv067",
 "id_scheme": "DOI"
 },
 "abstract": "I describe the collection and deep annotation of the semantics of a corpus of Russian folktales. This corpus, which I call the ‘ProppLearner’ corpus, was assembled to provide data for an algorithm designed to learn Vladimir Propp’s morphology of Russian hero tales. The corpus is the most deeply annotated narrative corpus available at this time. The algorithm and learning results are described elsewhere; here, I provide detail on the layers of annotation and how they were chosen, novel layers of annotation required for successful learning, the selection of the texts for annotation, the annotation process itself, and the resulting inter-annotator agreement measures. In particular, the corpus comprised fifteen texts totaling 18,862 words. There were eighteen layers of annotation, five of which were developed specifically to support learning Propp’s morphology: referent attributes, context relationships, event valences, Propp’s ‘dramatis personae’, and Propp’s functions. All annotations were created by trained annotators with the Story Workbench annotation tool, following a double-annotation paradigm. I discuss lessons learned from this effort and what they mean for future digital humanities efforts when working with the semantics of natural language text.",
 "article_title": "ProppLearner: Deeply Annotating a Corpus of Russian Folktales to Enable the Machine Learning of a Russian Formalist Theory",
 "authors": [
 {
 "given": " Mark A.",
 "family": "Finlayson",
 "affiliation": [
 {
 "original_name": "Florida International University, Miami, FL, USA",
 "normalized_name": "Florida International University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/02gz6gg07",
 "GRID": "grid.65456.34"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-12-17",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv047",
 "identifier": {
 "string_id": "10.1093/llc/fqv047",
 "id_scheme": "DOI"
 },
 "abstract": "There are many ways to model relationships between texts and objects. Creating statements with RDF triples is one of them. In the project ‘Semantic Blumenbach', we have endeavoured to discover and render visible the innate connections of Johann Friedrich Blumenbach's (1752–1840) writings on natural history with the physical objects studied and collected by him. After a careful evaluation of existing frameworks for describing objects and texts, we decided to test the Scientific Communication Infrastructure (WissKI) for this purpose. During the project, new modules have been developed, and a workflow to connect extracted knowledge from Blumenbach’s texts with metadata of objects has been established. The data modelling, the ingest workflow, and project evaluation in the context of the on-going discussion about Linking TEI and CIDOC Conceptual Reference Model are subjects of this article.",
 "article_title": "Semantic Blumenbach: Exploration of Text–Object Relationships with Semantic Web Technology in the History of Science",
 "authors": [
 {
 "given": " Jörg",
 "family": "Wettlaufer",
 "affiliation": [
 {
 "original_name": "Göttingen Academy of Sciences and Humanities, Germany",
 "normalized_name": "Göttingen Academy of Sciences and Humanities",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/04hsa7a08",
 "GRID": "grid.461599.6"
 }
 }
 ]
 },
 {
 "given": " Christopher",
 "family": "Johnson",
 "affiliation": [
 {
 "original_name": "Wikimedia Germany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Martin",
 "family": "Scholz",
 "affiliation": [
 {
 "original_name": "Friedrich-Alexander-Universität Erlangen-Nürnberg, Germany",
 "normalized_name": "University of Erlangen-Nuremberg",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/00f7hpc57",
 "GRID": "grid.5330.5"
 }
 }
 ]
 },
 {
 "given": " Mark",
 "family": "Fichtner",
 "affiliation": [
 {
 "original_name": "Germanisches Nationalmuseum Nürnberg, Germany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Sree Ganesh",
 "family": "Thotempudi",
 "affiliation": [
 {
 "original_name": "Digital Humanities Research Collaboration, Germany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-10-07",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv036",
 "identifier": {
 "string_id": "10.1093/llc/fqv036",
 "id_scheme": "DOI"
 },
 "abstract": "Multispectral imaging—a method for acquiring image data over a series of wavelengths across the light spectrum—is becoming a valuable tool within the cultural and heritage sector for the recovery and enhancement of information contained within primary historical texts. However, most applications of this technique, to date, have been bespoke: analysing particular documents of historic importance. There has been little prior work done on evaluating this technique in a structured fashion, to provide recommendations on how best to capture and process images when working with damaged and abraded textual material. This article introduces a new approach for evaluating the efficacy of image processing algorithms in recovering information from multispectral images of deteriorated primary historical texts. We present a series of experiments that deliberately degrade samples cut from a real historical document to provide a set of images acquired before and after damage. These images then allow us to compare, both objectively and quantitatively, the effectiveness of multispectral imaging and image processing for recovering information from damaged text. We develop a methodological framework for the continuing study of the techniques involved in the analysis and processing of multispectral images of primary historical texts, and a dataset which will be of use to others interested in advanced digitisation techniques within the cultural heritage sector.",
 "article_title": "The value of critical destruction: Evaluating multispectral image processing methods for the analysis of primary historical texts",
 "authors": [
 {
 "given": "Alejandro",
 "family": "Giacometti",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Alberto",
 "family": "Campagnolo",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Lindsay",
 "family": "MacDonald",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Simon",
 "family": "Mahony",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Stuart",
 "family": "Robson",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Tim",
 "family": "Weyrich",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Melissa",
 "family": "Terras",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Adam",
 "family": "Gibson",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-10-08",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv051",
 "identifier": {
 "string_id": "10.1093/llc/fqv051",
 "id_scheme": "DOI"
 },
 "abstract": "Research data in the humanities needs to be sustainable, and access to digital resources must be possible over a long period. Only if these prerequisites are fulfilled can research data be used as a source for other projects. In addition, reliability is a fundamental requirement so that digital sources can be cited, reused, and quoted. To address this problem, we present our solution: the Data and Service Center for the Humanities located in Switzerland. The centralized infrastructure is based on flexible and extendable software that is in turn reliant on modern technologies. Such an approach allows for the straightforward migration of existing research project databases with limited life spans in the humanities. We will demonstrate the basic concepts behind this proposed solution and our first experiences in the application thereof.",
 "article_title": "DASCH: Data and Service Center for the Humanities",
 "authors": [
 {
 "given": " Lukas",
 "family": "Rosenthaler",
 "affiliation": [
 {
 "original_name": "Digital Humanities Lab, University of Basel, Basel, Switzerland",
 "normalized_name": "University of Basel",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/02s6k3f65",
 "GRID": "grid.6612.3"
 }
 }
 ]
 },
 {
 "given": " Peter",
 "family": "Fornaro",
 "affiliation": [
 {
 "original_name": "Digital Humanities Lab, University of Basel, Basel, Switzerland",
 "normalized_name": "University of Basel",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/02s6k3f65",
 "GRID": "grid.6612.3"
 }
 }
 ]
 },
 {
 "given": " Claire",
 "family": "Clivaz",
 "affiliation": [
 {
 "original_name": "University of Lausanne, Ladhul, Faculty of Social and Political Sciences, Swiss Institute of Bioinformatics, VITAL-IT, Lausanne (CH), Switzerland ",
 "normalized_name": "University of Lausanne",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/019whta54",
 "GRID": "grid.9851.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-10-10",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv042",
 "identifier": {
 "string_id": "10.1093/llc/fqv042",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents a selection of findings from a survey-based study on the role of software development and programming in the Digital Humanities, disseminated to researchers, teachers, and practitioners from across the community.",
 "article_title": "Programming in the Digital Humanities",
 "authors": [
 {
 "given": " James",
 "family": "O’Sullivan",
 "affiliation": [
 {
 "original_name": "Pennsylvania State University, USA",
 "normalized_name": "Pennsylvania State University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/04p491231",
 "GRID": "grid.29857.31"
 }
 }
 ]
 },
 {
 "given": " Diane",
 "family": "Jakacki",
 "affiliation": [
 {
 "original_name": "Bucknell University, USA",
 "normalized_name": "Bucknell University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00fc1qt65",
 "GRID": "grid.253363.2"
 }
 }
 ]
 },
 {
 "given": " Mary",
 "family": "Galvin",
 "affiliation": [
 {
 "original_name": "University College Cork, Ireland",
 "normalized_name": "University College Cork",
 "country": "Ireland",
 "identifiers": {
 "ror": "https://ror.org/03265fv13",
 "GRID": "grid.7872.a"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-10-10",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv049",
 "identifier": {
 "string_id": "10.1093/llc/fqv049",
 "id_scheme": "DOI"
 },
 "abstract": "This article describes the development and application of an innovative tool, Text Re-use Alignment Visualization (TRAViz), whose aim is to visualize variation between editions of both historical and modern texts. Reading different editions of a text empowers research in literary studies and linguistics, where one can study a text’s reception or follow the development of its language over time. One of the purposes of a text edition is to trace or reconstruct a possible archetype or something that might be considered to be an original version of the text in order to better understand its evolution over time. To do so, the textual scholar examines and records the similarities and the differences between a number of exemplars in what is known as a ‘critical apparatus’. The result of this variant analysis can be visually represented as a ‘Variant Graph’, where the relationships between these exemplars can be more easily studied. Variant Graphs can be, in turn, visualized in order to facilitate reading and interaction with the source data. Borrowing from existing digital tools, TRAViz assists the scholar in the collation process by specifically focusing on design and user engagement, concurrently seeking to simplify interaction as a means of encouraging humanists to adopt the tool. The article will describe the needs and rationale behind the creation of TRAViz by exploring existing research, describing its functionality through examples, and by finally discussing how its application can influence future development of this tool in particular and of the field in general.",
 "article_title": "TRAViz: A Visualization for Variant Graphs",
 "authors": [
 {
 "given": " Stefan",
 "family": "Jänicke",
 "affiliation": [
 {
 "original_name": "Leipzig University, Germany",
 "normalized_name": "Leipzig University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/03s7gtk40",
 "GRID": "grid.9647.c"
 }
 }
 ]
 },
 {
 "given": " Annette",
 "family": "Geßner",
 "affiliation": [
 {
 "original_name": "Göttingen Centre for Digital Humanities (GCDH), Germany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Greta",
 "family": "Franzini",
 "affiliation": [
 {
 "original_name": "UCL Centre for Digital Humanities (UCLDH), UK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Melissa",
 "family": "Terras",
 "affiliation": [
 {
 "original_name": "UCL Centre for Digital Humanities (UCLDH), UK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Simon",
 "family": "Mahony",
 "affiliation": [
 {
 "original_name": "UCL Centre for Digital Humanities (UCLDH), UK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Gerik",
 "family": "Scheuermann",
 "affiliation": [
 {
 "original_name": "Leipzig University, Germany",
 "normalized_name": "Leipzig University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/03s7gtk40",
 "GRID": "grid.9647.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-10-10",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv046",
 "identifier": {
 "string_id": "10.1093/llc/fqv046",
 "id_scheme": "DOI"
 },
 "abstract": "Large-scale digitization efforts and the availability of computational methods, including text mining and information visualization, have enabled new approaches to historical research. However, we lack case studies of how these methods can be applied in practice and what their potential impact may be. Trading Consequences is an interdisciplinary research project between environmental historians, computational linguists, and visualization specialists. It combines text mining and information visualization alongside traditional research methods in environmental history to explore commodity trade in the 19th century from a global perspective. Along with a unique data corpus, this project developed three visual interfaces to enable the exploration and analysis of four historical document collections, consisting of approximately 200,000 documents and 11 million pages related to commodity trading. In this article, we discuss the potential and limitations of our approach based on feedback from historians we elicited over the course of this project. Informing the design of such tools in the larger context of digital humanities projects, our findings show that visualization-based interfaces are a valuable starting point to large-scale explorations in historical research. Besides providing multiple visual perspectives on the document collection to highlight general patterns, it is important to provide a context in which these patterns occur and offer analytical tools for more in-depth investigations.",
 "article_title": "Trading Consequences: A Case Study of Combining Text Mining and Visualization to Facilitate Document Exploration",
 "authors": [
 {
 "given": " Uta",
 "family": "Hinrichs",
 "affiliation": [
 {
 "original_name": "SACHI Group, School of Computer Science, University of St Andrews, UK",
 "normalized_name": "University of St Andrews",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02wn5qz54",
 "GRID": "grid.11914.3c"
 }
 }
 ]
 },
 {
 "given": " Beatrice",
 "family": "Alex",
 "affiliation": [
 {
 "original_name": "ILCC, School of Informatics, University of Edinburgh, UK",
 "normalized_name": "University of Edinburgh",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01nrxwf90",
 "GRID": "grid.4305.2"
 }
 }
 ]
 },
 {
 "given": " Jim",
 "family": "Clifford",
 "affiliation": [
 {
 "original_name": "Department of History, University of Saskatchewan, Canada",
 "normalized_name": "University of Saskatchewan",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/010x8gc63",
 "GRID": "grid.25152.31"
 }
 }
 ]
 },
 {
 "given": " Andrew",
 "family": "Watson",
 "affiliation": [
 {
 "original_name": "Robarts Centre for Canadian Studies, York University, Canada",
 "normalized_name": "York University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/05fq50484",
 "GRID": "grid.21100.32"
 }
 }
 ]
 },
 {
 "given": " Aaron",
 "family": "Quigley",
 "affiliation": [
 {
 "original_name": "SACHI Group, School of Computer Science, University of St Andrews, UK",
 "normalized_name": "University of St Andrews",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02wn5qz54",
 "GRID": "grid.11914.3c"
 }
 }
 ]
 },
 {
 "given": " Ewan",
 "family": "Klein",
 "affiliation": [
 {
 "original_name": "ILCC, School of Informatics, University of Edinburgh, UK",
 "normalized_name": "University of Edinburgh",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01nrxwf90",
 "GRID": "grid.4305.2"
 }
 }
 ]
 },
 {
 "given": " Colin M.",
 "family": "Coates",
 "affiliation": [
 {
 "original_name": "Robarts Centre for Canadian Studies, York University, Canada",
 "normalized_name": "York University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/05fq50484",
 "GRID": "grid.21100.32"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-10-13",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv050",
 "identifier": {
 "string_id": "10.1093/llc/fqv050",
 "id_scheme": "DOI"
 },
 "abstract": "In this essay, the authors present a case study of how an ongoing, multi-faculty, interdisciplinary DH project focused on the Susquehanna Valley in Pennsylvania has created, and continues to explore, ways in which students can excel both inside the classroom and outside. These DH projects involve undergraduates working with faculty on an unfolding expansive research project that affords otherwise unachievable opportunities for undergraduate student engagement, the development of new skills, and meaningful ongoing interaction between the institution and community that have, in turn, furthered the scope and scale of the project.",
 "article_title": "Digital Learning in an Undergraduate Context: Promoting Long-Term Student–Faculty Place-Based Collaboration",
 "authors": [
 {
 "given": " Katherine M.",
 "family": "Faull",
 "affiliation": [
 {
 "original_name": "Bucknell University, USA",
 "normalized_name": "Bucknell University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00fc1qt65",
 "GRID": "grid.253363.2"
 }
 }
 ]
 },
 {
 "given": " Diane K.",
 "family": "Jakacki",
 "affiliation": [
 {
 "original_name": "Bucknell University, USA",
 "normalized_name": "Bucknell University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00fc1qt65",
 "GRID": "grid.253363.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-10-13",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv038",
 "identifier": {
 "string_id": "10.1093/llc/fqv038",
 "id_scheme": "DOI"
 },
 "abstract": " For some time, scholars have been using computer-assisted methods to produce graphic representations of the relationships between witnesses within a textual tradition. 1 The use of methods originally developed by evolutionary biologists has been called into question on account of the perceived lack of identity between two different disciplines. This view arises from a misunderstanding about how the methods work in relation to texts and how the resulting stemmata should be interpreted. This article refines textual critical terminology, particularly the distinction between textual traditions and manuscript traditions, in the context of the use of computer-assisted stemmatological methods to further our understanding of how these fit within the wider theoretical framework of textual criticism and scholarly editing, and makes explicit the way in which stemmata produced by using evolutionary biology software should be read. ",
 "article_title": "The genealogy of texts: Manuscript traditions and textual traditions",
 "authors": [
 {
 "given": " Barbara",
 "family": "Bordalejo",
 "affiliation": [
 {
 "original_name": "KU Leuven, Faculteit Letteren, Belgium",
 "normalized_name": "KU Leuven",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/05f950310",
 "GRID": "grid.5596.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-10-14",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv040",
 "identifier": {
 "string_id": "10.1093/llc/fqv040",
 "id_scheme": "DOI"
 },
 "abstract": "We propose a possible solution to one of the major weaknesses in the application of authorship attribution—the absence of clear-cut standards for accurate analytic practice. To address this, we propose a specific practice as a possible standard and present four recent cases applying this standard. The key elements of this protocol are the use of an ad hoc distractor set in conjunction with multiple analyses structured as a set of elimination tests. This protocol (or close variants of it) has been used in at least four separate cases across a wide variety of documents and consumers. It is mathematically supported while still being easy to understand. We are confident that the proposed protocol will provide a relatively straightforward and understandable way to reduce controversy regarding stylometric authorship attribution, and thereby increase its uptake and credibility.",
 "article_title": "The Rowling Case: A Proposed Standard Analytic Protocol for Authorship Questions",
 "authors": [
 {
 "given": " Patrick",
 "family": "Juola",
 "affiliation": [
 {
 "original_name": "Evaluating Variations in Language Lab, Duquesne University, Pittsburgh, PA, USA and Juola & Associates, Pittsburgh, PA, USA",
 "normalized_name": "Duquesne University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/02336z538",
 "GRID": "grid.255272.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-10-20",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv041",
 "identifier": {
 "string_id": "10.1093/llc/fqv041",
 "id_scheme": "DOI"
 },
 "abstract": "This research began in a class taught by Matthew Jockers and has continued under his direction as a project of the newly formed Nebraska Literary Lab. Our work focused on mining the fiction and non-fiction works of Willa Cather that are housed in the Willa Cather Archive at the University of Nebraska-Lincoln (Jewell, Andrew. The Willa Cather Archive. University of Nebraska-Lincoln, 2004–2013. Web). Largely regarded as a private person, Cather forbade the publication of her correspondence; only recently have her letters finally been published. With the publication of these letters comes the unique opportunity for scholars to research Cather’s personal thoughts and voice. Our research focused on using stylometrics to explore the ways in which the voice Cather used in her correspondence differs from the voice she used in her public writing; our conclusions point to similarities between Cather’s novel My Mortal Enemy, a work noted for both its economy of style and autobiographical features, and her recently published letters.",
 "article_title": "Exploring the Intersection of Personal and Public Authorial Voice in the Works of Willa Cather",
 "authors": [
 {
 "given": " Laura",
 "family": "Dimmit",
 "affiliation": [
 {
 "original_name": "Department of English, University of Nebraska-Lincoln, Lincoln, NE, USA",
 "normalized_name": "University of Nebraska–Lincoln",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/043mer456",
 "GRID": "grid.24434.35"
 }
 }
 ]
 },
 {
 "given": " Gabrielle",
 "family": "Kirilloff",
 "affiliation": [
 {
 "original_name": "Department of English, University of Nebraska-Lincoln, Lincoln, NE, USA",
 "normalized_name": "University of Nebraska–Lincoln",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/043mer456",
 "GRID": "grid.24434.35"
 }
 }
 ]
 },
 {
 "given": " Chandler",
 "family": "Warren",
 "affiliation": [
 {
 "original_name": "Department of English, University of Nebraska-Lincoln, Lincoln, NE, USA",
 "normalized_name": "University of Nebraska–Lincoln",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/043mer456",
 "GRID": "grid.24434.35"
 }
 }
 ]
 },
 {
 "given": " James",
 "family": "Wehrwein",
 "affiliation": [
 {
 "original_name": "Department of English, University of Nebraska-Lincoln, Lincoln, NE, USA",
 "normalized_name": "University of Nebraska–Lincoln",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/043mer456",
 "GRID": "grid.24434.35"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-11-18",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "suppl 1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv043",
 "identifier": {
 "string_id": "10.1093/llc/fqv043",
 "id_scheme": "DOI"
 },
 "abstract": "This article motivates and details the first implementation of a freely available part of speech tag set and tagger for Coptic. Coptic is the last phase of the Egyptian language family and a descendant of the hieroglyphs of ancient Egypt. Unlike classical Greek and Latin, few resources for digital and computational work have existed for ancient Egyptian language and literature until now. We evaluate our tag set in an inter-annotator agreement experiment and examine some of the difficulties in tagging Coptic data. Using an existing digital lexicon and a small training corpus taken from several genres of literary Sahidic Coptic in the first half of the first millennium, we evaluate the performance of a stochastic tagger applying a fine-grained and coarse-grained set of tags within and outside the domain of literary texts. Our results show that a relatively high accuracy of 94–95% correct automatic tag assignment can be reached for literary texts, with substantially worse performance on documentary papyrus data. We also present some preliminary applications of natural language processing to the study of genre, style, and authorship attribution in Coptic and discuss future directions in applying computational linguistics methods to the analysis of Coptic texts.",
 "article_title": "Computational Methods for Coptic: Developing and Using Part-of-Speech Tagging for Digital Scholarship in the Humanities",
 "authors": [
 {
 "given": " Amir",
 "family": "Zeldes",
 "affiliation": [
 {
 "original_name": "Department of Linguistics, Georgetown University, USA",
 "normalized_name": "Georgetown University",
 "country": "Qatar",
 "identifiers": {
 "ror": "https://ror.org/029e47x73",
 "GRID": "grid.452129.9"
 }
 }
 ]
 },
 {
 "given": " Caroline T.",
 "family": "Schroeder",
 "affiliation": [
 {
 "original_name": "University of the Pacific, USA",
 "normalized_name": "University of the Pacific",
 "country": "Chile",
 "identifiers": {
 "ror": "https://ror.org/005gk0s47",
 "GRID": "grid.441817.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-11-18",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "suppl 1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv053",
 "identifier": {
 "string_id": "10.1093/llc/fqv053",
 "id_scheme": "DOI"
 },
 "abstract": "One of the important issues in natural language processing and information retrieval is the automatic extraction of the word’s stem. Both statistical and rule-based approaches for stemming have their own advantages and limitations. The statistical stemmers are not accurate and fail to take advantage of some language phenomenon which can be easily expressed by simple rules. On the other hand, handcrafting the stemming rules in the rule-based stemmers is a time-consuming, tedious, and impractical task. In this regard, we propose a new hybrid stemming method based on a combination of affix stripping and statistical techniques for Persian language. The proposed method combines cues from the orthography, word frequency, and syntactic distributions to induce the stemming rules. In general, the proposed method is divided into two main parts. In the first part, all words of the annotated text corpus are used to automatically induce the stemming rules; while in the second part, the rule-based stemmer uses the induced stemming rules to discover the word's stem. We test the performance of the proposed scheme on two different data sets. The encouraging results indicate the superior performance of the proposed method compared with its counterparts.",
 "article_title": "A New Hybrid Stemming Method for Persian Language",
 "authors": [
 {
 "given": "Hossein",
 "family": "Taghi-Zadeh",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Mohammad Hadi",
 "family": "Sadreddini",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Mohammad Hasan",
 "family": "Diyanati",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Amir Hossein",
 "family": "Rasekh",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-11-07",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv061",
 "identifier": {
 "string_id": "10.1093/llc/fqv061",
 "id_scheme": "DOI"
 },
 "abstract": "The aim of this article is to discuss reliability issues of a few visual techniques used in stylometry, and to introduce a new method that enhances the explanatory power of visualization with a procedure of validation inspired by advanced statistical methods. A promising way of extending cluster analysis dendrograms with a self-validating procedure involves producing numerous particular ‘snapshots’, or dendrograms produced using different input parameters, and combining them all into the form of a consensus tree. Significantly better results, however, can be obtained using a new visualization technique, which combines the idea of nearest neighborhood derived from cluster analysis, the idea of hammering out a clustering consensus from bootstrap consensus trees, with the idea of mapping textual similarities onto a form of a network. Additionally, network analysis seems to be a good solution for large data sets.",
 "article_title": "Visualization in stylometry: Cluster analysis using networks",
 "authors": [
 {
 "given": "Maciej",
 "family": "Eder",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-02-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "32",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv058",
 "identifier": {
 "string_id": "10.1093/llc/fqv058",
 "id_scheme": "DOI"
 },
 "abstract": "Over 100 years after the publication of Mark Twain’s The Adventures of Huckleberry Finn, it still remains a highly reputed classic not only in America but also elsewhere around the globe. However, Twain’s representation of linguistic diversity in his native Missouri region has given rise to a heated dispute, still ongoing, over his, according to some detractors, vaudeville-like characterization of Jim. Such controversy has been further spurred by recent voices lampooning Twain for, allegedly, having portrayed Jim as one more ethnic caricature. Translators seem to have paid no heed to Twain’s cautionary words in his preface, stating that he was using several dialects from his region and that his recording of these dialects had not been done in a ‘haphazard fashion’ but ‘painstakingly’. Unfortunately, many translations have either rendered a standardized version in which all characters speak alike or, worse still, a twisted mirror in which Jim appears speaking in the dialect of a far remote region, say Andalusia or Naples. The effect in the target culture is a considerable distortion, and yet, translators still keep claiming that it is utterly impossible to do otherwise. Given the current state of affairs, one may ask, is there a way to legitimize the translation of dialect? Was Twain’s intention parody or was it, on the contrary, authenticity? Determining this is of paramount importance prior to undertaking a translation of this work into a foreign culture. Corpus linguistics, as I would like to prove heretofore, can greatly contribute to gauging whether dialect has been transcribed consistently or accurately. A thorough linguistic inquiry into Jim’s corpus and a comparison with the corpora of other characters can yield very interesting results. As some Chinese translations of this work have shown, drawing from linguistically oriented data can be very helpful in using the right translation strategies.",
 "article_title": "The Adventures of Huckleberry Finn and Jim in China: A Case of what Corpus Pragmatics can do for the Translation of Dialect",
 "authors": [
 {
 "given": " José Manuel ",
 "family": "Rodríguez Herrera",
 "affiliation": [
 {
 "original_name": "Departamento de Filología Moderna, Universidad de Las Palmas de Gran Canaria, Spain",
 "normalized_name": "University of Las Palmas de Gran Canaria",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01teme464",
 "GRID": "grid.4521.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-12-03",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv066",
 "identifier": {
 "string_id": "10.1093/llc/fqv066",
 "id_scheme": "DOI"
 },
 "abstract": "Historians of the English language and students of literary style alike have long agreed that a key change took place in American prose style at the end of the late 19th century, when a more informal, ‘democratic' register came to dominate fictional prose. However, despite its historical and critical importance, neither the features nor the precise historical development of this shift has been the subject of systematic analysis. In this essay, we undertake an in-depth analysis of one key feature of what became known as the colloquial style: patterns of linguistic repetition. With the aid of quantitative analysis, we demonstrate that the use of repetition is in itself a reliable metric for automatically detecting the presence of colloquial discourse. We find that colloquial repetition does indeed increase in American fiction over the course of the 19th and early 20th century, but, via comparative analysis, that this phenomenon may not be limited to American prose. Finally, we explore the semantics of these patterns of repetition, demonstrating first that repetition is broadly characteristic of represented speech in writing, and secondly that changes over time in the semantic contents of repetitions demonstrate a clear increase in colloquial, informal language.",
 "article_title": "Operationalizing the Colloquial Style: Repetition in 19th-Century American Fiction",
 "authors": [
 {
 "given": " Marissa",
 "family": "Gemma",
 "affiliation": [
 {
 "original_name": "Max Planck Institute for Empirical Aesthetics, Sorbonne University,Paris-Sorbonne University-Paris 4",
 "normalized_name": "Sorbonne University",
 "country": "France",
 "identifiers": {
 "ror": "https://ror.org/02en5vm52",
 "GRID": "grid.462844.8"
 }
 },
 {
 "original_name": "UPMC-Paris 6",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "Labex OBVIL",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Frédéric",
 "family": "Glorieux",
 "affiliation": [
 {
 "original_name": "Max Planck Institute for Empirical Aesthetics, Sorbonne University,Paris-Sorbonne University-Paris 4",
 "normalized_name": "Sorbonne University",
 "country": "France",
 "identifiers": {
 "ror": "https://ror.org/02en5vm52",
 "GRID": "grid.462844.8"
 }
 },
 {
 "original_name": "UPMC-Paris 6",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "Labex OBVIL",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Jean-Gabriel",
 "family": "Ganascia",
 "affiliation": [
 {
 "original_name": "Max Planck Institute for Empirical Aesthetics, Sorbonne University,Paris-Sorbonne University-Paris 4",
 "normalized_name": "Sorbonne University",
 "country": "France",
 "identifiers": {
 "ror": "https://ror.org/02en5vm52",
 "GRID": "grid.462844.8"
 }
 },
 {
 "original_name": "UPMC-Paris 6",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "Labex OBVIL",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-12-10",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv065",
 "identifier": {
 "string_id": "10.1093/llc/fqv065",
 "id_scheme": "DOI"
 },
 "abstract": "This article surveys how phylogenetics may be applied effectively and productively to the analysis of textual traditions—and, by implication, how it might not be. Examples from two very different traditions (the artificial Julius Caesar ‘Orange Branch’, and Chaucer’s Wife of Bath’s Prologue) are deployed to support four central premises. First, it is an error to understand the results of any quantitative analysis of textual traditions as if they represent exactly what happened in the actual making of these copies. Second, phylogenetic methods can give useful results on uncorrected, unregularized data for vernacular and other traditions, where the spelling of individual words is relatively stable across copies. Third, before any collation, any transcription, any data preparation is started toward investigation of a textual tradition, and before analysis commences, the editor must develop an explicit model of the variation he or she expects to find in the copies which constitute that tradition. Fourth, one can only be as certain, in any reconstruction of any textual tradition, as the data, the model of variation, the methods applied, and other evidence allow. The discussion leads to a final conclusion that scholars should use both traditional qualitative analysis and the new quantitative methods to complement, correct, and complete each other.",
 "article_title": "Four rules for the application of phylogenetics in the analysis of textual traditions",
 "authors": [
 {
 "given": " Peter",
 "family": "Robinson",
 "affiliation": [
 {
 "original_name": "University of Saskatchewan, Canada",
 "normalized_name": "University of Saskatchewan",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/010x8gc63",
 "GRID": "grid.25152.31"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-12-11",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv022",
 "identifier": {
 "string_id": "10.1093/llc/fqv022",
 "id_scheme": "DOI"
 },
 "abstract": "The article describes methodology of zonal text processing based on interpretation of Bradford's law in terms of geometric progression. The methodology involves dividing the text into three zones (J0, J1, J2) and finding their composition. To verify the value of Bradford multiplier two methods that evaluate distribution of stop words across the three zones are used. The concept of zonal-correlational processing that implies contrastive analysis of J1 zones of two or more texts for the purpose of authorship attribution and classification is formulated and tested. To address the problem of difference in text sizes the concept of logarithmic equalizing is proposed.",
 "article_title": "Zonal text processing",
 "authors": [
 {
 "given": " Viatcheslav",
 "family": "Yatsko",
 "affiliation": [
 {
 "original_name": "Department of Software for Automated and Computer Systems, Katanov State University of Khakasia",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-06-24",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv018",
 "identifier": {
 "string_id": "10.1093/llc/fqv018",
 "id_scheme": "DOI"
 },
 "abstract": "This article describes a Recommendation System to help photographic historians make connections between widely dispersed and previously unrelated records of photographs held in different heritage institutions, and demonstrates how it has been used to rediscover images of exhibits from the Royal Photographic Society annual exhibitions of over 120 years ago. While the surviving exhibition catalogues are a rich information source, they are largely devoid of illustrations of the exhibits. The FuzzyPhoto project has developed techniques for analyzing a corpus of more than 1.4 million historical photographic records across different galleries, libraries, archives, and museums, in order to identify similarities between them and used the results to offer visitors to those sites links to potentially related items at other sites, thus creating a web of interconnections between them. The article describes techniques used for data acquisition, cleaning, integration, semantic-based data mining, approximate reasoning, and fuzzy algorithm-based similarity metrics. It compares the approach described here with manual searches and more sophisticated computational methods such as linked data and concludes that FuzzyPhoto is an effective method for dealing with the realities of messy collection records that could be extended to other types of archival objects such as paintings, maps, and textiles where record matching is required.",
 "article_title": "Words, words. They’re all we have to go on: Image finding without the pictures",
 "authors": [
 {
 "given": "Stephen",
 "family": "Brown",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-06-24",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv017",
 "identifier": {
 "string_id": "10.1093/llc/fqv017",
 "id_scheme": "DOI"
 },
 "abstract": "After the sudden occurrence of East Japan Great Earthquake on 11 March 2011, triple disasters crippled the regular life of citizens of East Japan. A lot of people were affected, especially women victims suffered from different problems and worries: they had to care for elders, raise children, and find new jobs. Women also had specific needs of commodities for everyday life. Administrative authorities wanted to recognize women victims’ specific problems and provide them appropriate supports. However, it was difficult to grasp women victims’ requirements properly, because they were really patient and their needs were sometimes neglected under the environmental pressure. Conducting interviews and taking questionnaire from women victims is one way to gauge their needs, but it is time-consuming and labor intensive. This work proposes a framework for the development of an advisory message board for women victims on the web in which women victims can post their messages freely. The computational technologies are used here for analyzing digital media data in order to improve the lives of underserved or underprivileged people in case of disasters like earthquake. Text mining technologies are developed for automatic analysis of the messages to find out the specific needs of the victims and the change of needs with time and support them with proper advice. The proposed method uses latent semantic analysis (LSA) to extract the hidden topics and change of topics over time. As a case study, text messages from several on-line social media over a period of 2 years after the East Japan Great earthquake are collected and analyzed. It has been found that LSA-based technique is more effective in extracting the change of needs over time than graph-based topic extraction method. The final aim of this work is to develop the framework of advisory message board for women which will help the authority to find out the special needs of women victims after any future disaster and support them.",
 "article_title": "Developing a framework for an advisory message board for female victims after disasters: A case study after east Japan great earthquake",
 "authors": [
 {
 "given": " Takako",
 "family": "Hashimoto",
 "affiliation": [
 {
 "original_name": "Department of Commerce and Economics, Chiba University of Commerce, Japan",
 "normalized_name": "Chiba University of Commerce",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/02qn0vb48",
 "GRID": "grid.443770.3"
 }
 }
 ]
 },
 {
 "given": " Yukari",
 "family": "Shirota",
 "affiliation": [
 {
 "original_name": "Department of Management, Faculty of Economics, Gakushuin University, Japan",
 "normalized_name": "Gakushuin University",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/037s2db26",
 "GRID": "grid.256169.f"
 }
 }
 ]
 },
 {
 "given": " Basabi",
 "family": "Chakraborty",
 "affiliation": [
 {
 "original_name": "Faculty of Software and Information Science, Iwate Prefectural University, Japan",
 "normalized_name": "Iwate Prefectural University",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/054dx8336",
 "GRID": "grid.443998.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-06-23",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv021",
 "identifier": {
 "string_id": "10.1093/llc/fqv021",
 "id_scheme": "DOI"
 },
 "abstract": "We look to unlock the verbal code of President Putin and NATO Secretary-General Rasmussen during the Ukrainian crisis. On 18 March 2014, referring to the medieval history of Russia, Putin expressed a vision that invites to explore the role of ancestral mental images as an instance of people with a direct knowledge of spiritual truth. Looking for spiritual truth is often at the edge of words, forcing the speaker to resort to poetic language to convey an inspired message beyond common understanding. Using a fragment of Martindale’s creativity model, we look for indicators of insight (regressive thought, metaphors, dual-coding of images and emotions) in Putin’s and NATO’s speeches over a short take of recent history, December 2013–September 2014. Among obvious results, the annexing of Crimea to the Russian Federation (18 March 2014) sparked new words in both Putin’s and NATO’s speeches. The May 9 ‘Great Victory Day’ also affected Putin’s speeches. After May 9, a visible discontinuity marks the speeches of both Putin and NATO, but in opposite directions. Higher scores of metaphoric thought in Putin contrasts with lower scores in NATO. Finally, the threat index increases moderately in both cases, yet bears no strong relation to the ups or downs of visionary metaphoric thought in either Putin or NATO. The two corpuses contain the words ‘value’ and ‘border’ in plenty, pushing linguistic detection scholars to explore new frontiers.",
 "article_title": "Deaf sentences1over Ukraine: Mysticism versus ethics",
 "authors": [
 {
 "given": " Robert L.",
 "family": "Hogenraad",
 "affiliation": [
 {
 "original_name": "Université Catholique de Louvain, Louvain-la-Neuve, Belgium",
 "normalized_name": "Université Catholique de Louvain",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/02495e989",
 "GRID": "grid.7942.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-06-24",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv019",
 "identifier": {
 "string_id": "10.1093/llc/fqv019",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents a profile-based authorship analysis method which first categorizes texts according to social and conceptual characteristics of their author (e.g. Sex and Political Ideology) and then combines these profiles for two authorship analysis tasks: (1) determining shared authorship of pairs of texts without a set of candidate authors and (2) clustering texts according to characteristics of their authors in order to provide an analysis of the types of individuals represented in the data set. The first task outperforms Burrows’ Delta by a wide margin on short texts and a small margin on long texts. The second task has no such benchmark with existing methods. The data set for evaluating the method consists of speeches from the US House and Senate from 1995 to 2013. This data set contains both a large number of texts (42,000 in the test sets) and a large number of speakers (over 800). The article shows that this approach to authorship analysis is more accurate than existing approaches given a data set with hundreds of authors. Further, this profile-based method makes new types of analysis possible by looking at types of individuals as well as at specific individuals.",
 "article_title": "Profile-based authorship analysis",
 "authors": [
 {
 "given": " Jonathan",
 "family": "Dunn",
 "affiliation": [
 {
 "original_name": "Illinois Institute of Technology, Chicago, IL, USA",
 "normalized_name": "Illinois Institute of Technology",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/037t3ry66",
 "GRID": "grid.62813.3e"
 }
 }
 ]
 },
 {
 "given": " Shlomo",
 "family": "Argamon",
 "affiliation": [
 {
 "original_name": "Illinois Institute of Technology, Chicago, IL, USA",
 "normalized_name": "Illinois Institute of Technology",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/037t3ry66",
 "GRID": "grid.62813.3e"
 }
 }
 ]
 },
 {
 "given": " Amin",
 "family": "Rasooli",
 "affiliation": [
 {
 "original_name": "Illinois Institute of Technology, Chicago, IL, USA",
 "normalized_name": "Illinois Institute of Technology",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/037t3ry66",
 "GRID": "grid.62813.3e"
 }
 }
 ]
 },
 {
 "given": " Geet",
 "family": "Kumar",
 "affiliation": [
 {
 "original_name": "Illinois Institute of Technology, Chicago, IL, USA",
 "normalized_name": "Illinois Institute of Technology",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/037t3ry66",
 "GRID": "grid.62813.3e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-06-24",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv028",
 "identifier": {
 "string_id": "10.1093/llc/fqv028",
 "id_scheme": "DOI"
 },
 "abstract": "The relationship between two important semantic properties (polysemy and synonymy) of language and one of the most fundamental syntactic network properties (a degree of the node) is observed. Based on the synergetic theory of language, it is hypothesized that a word which occurs in more syntactic contexts, i.e. it has a higher degree, should be more polysemous and have more synonyms than a word which occurs in less syntactic contexts, i.e. it has a lesser degree. Six languages are used for hypotheses testing and, tentatively, the hypotheses are corroborated. The analysis of syntactic dependency networks presented in this study brings a new interpretation of the well-known relationship between frequency and polysemy (or synonymy).",
 "article_title": "Polysemy and Synonymy in Syntactic Dependency Networks",
 "authors": [
 {
 "given": "Radek",
 "family": "Čech",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Ján",
 "family": "Mačutek",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Zdeněk",
 "family": "Žabokrtský",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Aleš",
 "family": "Horák",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-07-26",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv026",
 "identifier": {
 "string_id": "10.1093/llc/fqv026",
 "id_scheme": "DOI"
 },
 "abstract": "The authorship of the 1924 short story ‘The Loved Dead’ has been contested by family members of Clifford Martin Eddy, Jr. and Sunand Tryambak Joshi, a leading scholar on Howard Phillips Lovecraft. The authors of this article use stylometric methods to provide evidence for a claim about the authorship of the story and to analyze the nature of Eddy’s collaboration with Lovecraft. Further, we extend Rybicki, Hoover, and Kestemont’s (Collaborative authorship: Conrad, Ford, and rolling delta. Literary and Linguistic Computing, 2014; 29, 422–31) analysis of stylometry as it relates to collaborations in order to reveal the necessary considerations for employing a stylometric approach to authorial collaboration.",
 "article_title": "Stylometry and collaborative authorship: Eddy, Lovecraft, and ‘The Loved Dead’",
 "authors": [
 {
 "given": "Alexander A. G.",
 "family": "Gladwin",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Matthew J.",
 "family": "Lavin",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Daniel M.",
 "family": "Look",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2017-02-15",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "32",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv027",
 "identifier": {
 "string_id": "10.1093/llc/fqv027",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents the integration of sentiment analysis in ALCIDE, an online platform for historical content analysis. A prior polarity approach has been applied to a corpus of Italian historical texts, and a new lexical resource has been developed with a semi-automatic mapping starting from two English lexica. This article also reports on a first experiment on contextual polarity using both expert annotators and crowdsourced contributors. The long-term goal of our research is to create a system to support historical studies, which is able to analyse the sentiment in historical texts and to discover the opinion about a topic and its change over time.",
 "article_title": "Towards sentiment analysis for historical texts",
 "authors": [
 {
 "given": " Rachele",
 "family": "Sprugnoli",
 "affiliation": [
 {
 "original_name": "Fondazione Bruno Kessler, Trento, Italy",
 "normalized_name": "Fondazione Bruno Kessler",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/01j33xk10",
 "GRID": "grid.11469.3b"
 }
 },
 {
 "original_name": "Department of Information and Communication Technology, University of Trento, Trento, Italy",
 "normalized_name": "University of Trento",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/05trd4x28",
 "GRID": "grid.11696.39"
 }
 }
 ]
 },
 {
 "given": " Sara",
 "family": "Tonelli",
 "affiliation": [
 {
 "original_name": "Fondazione Bruno Kessler, Trento, Italy",
 "normalized_name": "Fondazione Bruno Kessler",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/01j33xk10",
 "GRID": "grid.11469.3b"
 }
 }
 ]
 },
 {
 "given": " Alessandro",
 "family": "Marchetti",
 "affiliation": [
 {
 "original_name": "Department of Information and Communication Technology, University of Trento, Trento, Italy",
 "normalized_name": "University of Trento",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/05trd4x28",
 "GRID": "grid.11696.39"
 }
 }
 ]
 },
 {
 "given": " Giovanni",
 "family": "Moretti",
 "affiliation": [
 {
 "original_name": "Fondazione Bruno Kessler, Trento, Italy",
 "normalized_name": "Fondazione Bruno Kessler",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/01j33xk10",
 "GRID": "grid.11469.3b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-07-30",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv032",
 "identifier": {
 "string_id": "10.1093/llc/fqv032",
 "id_scheme": "DOI"
 },
 "abstract": "Word reordering is one of the fundamental problems of machine translation. It is an important factor in the quality and efficiency of machine translations. Tackling the reordering problem can lead to significant improvements in translation quality. A new method is introduced with the objective of solving the reordering problem. It exploits sophisticated syntactic-based features for re-ranking the n-best translation candidates provided by a phrase-based statistical machine translation system. These sophisticated reordering features are based on an innovative structure named the phrasal dependency tree, which is inspired from target-side dependency relations among contiguous non-syntactic phrases. The features benefit from phrase dependencies, translation orientation, and distance. A translation candidate is modelled as a directed and weighted graph built from information provided by the reordering features and is re-scored by the proposed re-ranking system. This system markedly improves the outputs of the machine translation of two syntactically divergent language pairs. The performance is evaluated for Persian→English and German→English translation tasks using the WMT07 benchmark. The results report 0.566/0.95/0.011- and 0.75/0.97/0.024-point improvements in terms of BLEU/TER/LRSCORE metrics on Persian→English and German→English translation tasks, respectively. The superiority of the proposed system in terms of precision and recall measures is demonstrated as well.",
 "article_title": "Improving Statistical Machine Translation using Syntax-based Learning-to-Rank System",
 "authors": [
 {
 "given": "Saeed",
 "family": "Farzi",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Heshaam",
 "family": "Faili",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-08-13",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv030",
 "identifier": {
 "string_id": "10.1093/llc/fqv030",
 "id_scheme": "DOI"
 },
 "abstract": "Recently, a claim was made, on the basis of the German Google Books 1-gram corpus (Michel et al., Quantitative Analysis of Culture Using Millions of Digitized Books. Science 2010; 331: 176–82), that there was a linear relationship between six non-technical non-Nazi words and three ‘explicitly Nazi words’ in times of World War II (Caruana-Galizia. 2015. Politics and the German language: Testing Orwell’s hypothesis using the Google N-Gram corpus. Digital Scholarship in the Humanities [Online]. http://dsh.oxfordjournals.org/cgi/doi/10.1093/llc/fqv011 (accessed 15 April 2015)). Here, I try to show that apparent relationships like this are the result of misspecified models that do not take into account the temporal aspect of time-series data. The main point of this article is to demonstrate why such analyses run the risk of incorrect statistical inference, where potential effects are both meaningless and can potentially lead to wrong conclusions.",
 "article_title": "Why the quantitative analysis of diachronic corpora that does not consider the temporal aspect of time-series can lead to wrong conclusions",
 "authors": [
 {
 "given": "Alexander",
 "family": "Koplenig",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-08-13",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv031",
 "identifier": {
 "string_id": "10.1093/llc/fqv031",
 "id_scheme": "DOI"
 },
 "abstract": "A Systematic Literature Review (SLR) identifies, evaluates, and synthesizes the literature available for a given topic. This generally requires a significant human workload and has subjectivity bias that could affect the results of such a review. Automated document classification can be a valuable tool for recommending the selection of studies. In this article, we propose an automated pre-selection approach based on text mining and semantic enrichment techniques. Each document is firstly processed by a named entity extractor. The DBpedia URIs coming from the entity linking process are used as external sources of information. Our system collects the bag of words of those sources and it adds them to the initial document. A Multinomial Naive Bayes classifier discriminates whether the enriched document belongs to the positive example set or not. We used an existing manually performed SLR as benchmark data set. We trained our system with different configurations of relevant documents and we tested the goodness of our approach with an empirical assessment. Results show a reduction of the manual workload of 18% that a human researcher has to spend, while holding a remarkable 95% of recall, important condition for the nature itself of SLRs. We measure the effect of the enrichment process to the precision of the classifier and we observed a gain up to 5%.",
 "article_title": "Semantic Enrichment for Recommendation of Primary Studies in a Systematic Literature Review",
 "authors": [
 {
 "given": "Giuseppe",
 "family": "Rizzo",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Federico",
 "family": "Tomassetti",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Antonio",
 "family": "Vetrò",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Luca",
 "family": "Ardito",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Marco",
 "family": "Torchiano",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Maurizio",
 "family": "Morisio",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Raphaël",
 "family": "Troncy",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-08-13",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv035",
 "identifier": {
 "string_id": "10.1093/llc/fqv035",
 "id_scheme": "DOI"
 },
 "abstract": "Two graphical methods of exploring aspects of cutting structure in film using shot-length data are presented. The first of these converts the cumulative frequencies of shot-lengths to tabular form that can be displayed in various ways, including the use of correspondence analysis. The method is used to investigate the differences in cutting rates used by Mack Sennett and Charlie Chaplin while directing films for the Keystone Company in 1912–14. Results suggest that previous analyses based on the average shot-length may over-simplify the contrast, and some evidence for the evolution of Sennett’s style in 1913 is also suggested. The methods used, like much of the literature, do not take into account the time-series structure of the shot-lengths. In the second approach presented, this is allowed for by smoothing the time-series of shot-lengths using non-parametric regression. A computer-intensive way of presenting results graphically is developed, that does not commit the analyst to a particular choice of smoothing level, and is used to investigate an ‘hypothesis’ about D. W. Griffith’s cutting style suggested by a ‘prescription’ for pacing implied in comments made in an article published under his name in the 1920s. It is shown that his major feature films between 1914 and 1921 conform to the prescription, but there is not much evidence for it in his earlier and later work.",
 "article_title": "Exploring Cutting Structure in Film, with Applications to the Films of D. W. Griffith, Mack Sennett, and Charlie Chaplin",
 "authors": [
 {
 "given": "Mike",
 "family": "Baxter",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Daria",
 "family": "Khitrova",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Yuri",
 "family": "Tsivian",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-08-29",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv037",
 "identifier": {
 "string_id": "10.1093/llc/fqv037",
 "id_scheme": "DOI"
 },
 "abstract": "The Google Ngram Corpora seem to offer a unique opportunity to study linguistic and cultural change in quantitative terms. To avoid breaking any copyright laws, the data sets are not accompanied by any metadata regarding the texts the corpora consist of. Some of the consequences of this strategy are analyzed in this article. I chose the example of measuring censorship in Nazi Germany, which received widespread attention and was published in a paper that accompanied the release of the Google Ngram data (Michel et al. (2010): Quantitative analysis of culture using millions of digitized books. Science, 331(6014): 176–82). I show that without proper metadata, it is unclear whether the results actually reflect any kind of censorship at all. Collectively, the findings imply that observed changes in this period of time can only be linked directly to World War II to a certain extent. Therefore, instead of speaking about general linguistic or cultural change, it seems to be preferable to explicitly restrict the results to linguistic or cultural change ‘as it is represented in the Google Ngram data’. On a more general level, the analysis demonstrates the importance of metadata, the availability of which is not just a nice add-on, but a powerful source of information for the digital humanities.",
 "article_title": "The Impact of Lacking Metadata for the Measurement of Cultural and Linguistic Change Using the Google Ngram Data Sets—Reconstructing the Composition of the German Corpus in Times of WWII",
 "authors": [
 {
 "given": "Alexander",
 "family": "Koplenig",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-09-03",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv034",
 "identifier": {
 "string_id": "10.1093/llc/fqv034",
 "id_scheme": "DOI"
 },
 "abstract": "Weighted Gene Co-Expression Network Analysis (WGCNA) is a technique developed for analysing gene co-expression microarray data. This article demonstrates the adaption of WGCNA to mine an entire genre of literature, describing its dominant features, exposing its evolution through time, and dissecting its plot structures. WGCNA not only finds these large-scale structures, but exposes the fine-grained contribution of individual words. Romance accounts for 16.7% of all novels sold in the USA, and is the most popular form of genre literature (Romance Writers of America, 2013; Industry Statistics. http://www.rwa.org/p/cm/ld/fid=580 (accessed 13 June 2013)). Selling into 111 different markets and thirty-one languages, Harlequin is the largest publisher of romance worldwide, and its most successful category line, Harlequin Presents, offers the reader ‘pure romantic fantasy’ (Harlequin Presents Writing Guidelines)—romance in an almost archetypal sense. Despite the popularity, ubiquity and profitability of category romance, there is relatively little study to date on the phenomenon. Using WGCNA together with all electronically available Harlequin Presents novels—some 1,400 from 1999 to 2013—this article demonstrates that the genre’s fundamental architecture is a choir of authorial voices, that its evolution is dominated by sudden shifts due to financial pressures on the publisher, and that the order in which elements appear—the plot—is largely fixed.",
 "article_title": "Whole Genre Sequencing",
 "authors": [
 {
 "given": "Jack",
 "family": "Elliott",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-09-04",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv033",
 "identifier": {
 "string_id": "10.1093/llc/fqv033",
 "id_scheme": "DOI"
 },
 "abstract": "This article reports on a Digital Humanities research project which is concerned with the automated linguistic and visual analysis of political discourses with a particular focus on the concept of deliberative communication. According to the theory of deliberative communication as discussed within political science, political debates should be inclusive and stakeholders participating in these debates are required to justify their positions rationally and respectfully and should eventually defer to the better argument. The focus of the article is on the novel interactive visualizations that combine linguistic and statistical cues to analyze the deliberative quality of communication automatically. In particular, we quantify the degree of deliberation for four dimensions of communication: Participation, Respect, Argumentation and Justification, and Persuasiveness. Yet, these four dimensions have not been linked within a combined linguistic and visual framework, but each single dimension helps determining the degree of deliberation independently from each other. Since at its core, deliberation requires sustained and appropriate modes of communication, our main contribution is the automatic annotation and disambiguation of causal connectors and discourse particles.",
 "article_title": "Visual Linguistic Analysis of Political Discussions: Measuring Deliberative Quality",
 "authors": [
 {
 "given": "Valentin",
 "family": "Gold",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Mennatallah",
 "family": "El-Assady",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Tina",
 "family": "Bögel",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Christian",
 "family": "Rohrdantz",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Miriam",
 "family": "Butt",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Katharina",
 "family": "Holzinger",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Daniel",
 "family": "Keim",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-09-11",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv045",
 "identifier": {
 "string_id": "10.1093/llc/fqv045",
 "id_scheme": "DOI"
 },
 "abstract": "The use of metaphor in popular science is widespread to aid readers’ conceptions of the scientific concepts under discussion. Almost all research in this area has been done by careful close reading of the text(s) in question, but this article describes—for the first time—a digital ‘distant reading’ analysis of popular science, using a system created by a team from Glasgow and Lancaster. This team, as part of the SAMUELS project, has developed semantic tagging software which is based upon the UCREL Semantic Analysis System developed by Lancaster University’s University Centre for Computer Corpus Research on Language, but using the uniquely comprehensive Historical Thesaurus of English (published in 2009 as The Historical Thesaurus of the Oxford English Dictionary) as its knowledge base, in order to provide fine-grained meaning distinctions for use in word-sense disambiguation. In addition to analyzing metaphors in highly abstract book-length popular science texts from physics and mathematics, this article describes the technical underpinning to the system and the methods employed to hone the word-sense disambiguation procedure.",
 "article_title": "Metaphor, Popular Science, and Semantic Tagging: Distant reading with theHistorical Thesaurus of English",
 "authors": [
 {
 "given": " Marc",
 "family": "Alexander",
 "affiliation": [
 {
 "original_name": "University of Glasgow, UK",
 "normalized_name": "University of Glasgow",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/00vtgdb53",
 "GRID": "grid.8756.c"
 }
 }
 ]
 },
 {
 "given": " Fraser",
 "family": "Dallachy",
 "affiliation": [
 {
 "original_name": "University of Glasgow, UK",
 "normalized_name": "University of Glasgow",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/00vtgdb53",
 "GRID": "grid.8756.c"
 }
 }
 ]
 },
 {
 "given": " Scott",
 "family": "Piao",
 "affiliation": [
 {
 "original_name": "Lancaster University, UK",
 "normalized_name": "Lancaster University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04f2nsd36",
 "GRID": "grid.9835.7"
 }
 }
 ]
 },
 {
 "given": " Alistair",
 "family": "Baron",
 "affiliation": [
 {
 "original_name": "Lancaster University, UK",
 "normalized_name": "Lancaster University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04f2nsd36",
 "GRID": "grid.9835.7"
 }
 }
 ]
 },
 {
 "given": " Paul",
 "family": "Rayson",
 "affiliation": [
 {
 "original_name": "Lancaster University, UK",
 "normalized_name": "Lancaster University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04f2nsd36",
 "GRID": "grid.9835.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-10-01",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv039",
 "identifier": {
 "string_id": "10.1093/llc/fqv039",
 "id_scheme": "DOI"
 },
 "abstract": "Our hypothesis was simple enough: undergraduates would better understand a historic document online if, instead of having a traditional textual introduction, the same information was made available in bite-size balloons invoked by the users clicking on pins distributed throughout the document. Half the students had a pinned edition and half a more traditional one, while they all had several hours to explore the same eight-page crew agreement from the late 19th century. They then filled out quizzes, short answer tests, and went through an extensive debriefing. The results surprised us. Form made no difference whatsoever, none of the students understood the document’s content. We concluded their difficulty stemmed from living in the immediate, rather than in a temporally informed present, and so they could not fathom the profundity of the past. Seeking to understand this dramatic foreshortening of the analytics of existence, an issue of general interest to humanists, we searched for guidance in the digital humanities and educational literatures with little success. Borrowing from more progressive writings on academic literacy, our solution is a Friere-inspired approach that privileges points of entry for our undergraduates that build on their already-existing knowledge, rather than requiring them to acquire a canonical and frankly out-dated learned past. We argue this critical approach allows our students a democratizing experience that permits them to more fully engage the world as informed citizens.",
 "article_title": "Realizing the Democratic Potential of Online Sources in the Classroom",
 "authors": [
 {
 "given": " Valerie",
 "family": "Burton",
 "affiliation": [
 {
 "original_name": "Memorial University of Newfoundland, NL, Canada",
 "normalized_name": "Memorial University of Newfoundland",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04haebc03",
 "GRID": "grid.25055.37"
 }
 }
 ]
 },
 {
 "given": " Robert C. H.",
 "family": "Sweeny",
 "affiliation": [
 {
 "original_name": "Memorial University of Newfoundland, NL, Canada",
 "normalized_name": "Memorial University of Newfoundland",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04haebc03",
 "GRID": "grid.25055.37"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-10-02",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "",
 "issue": "",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv052",
 "identifier": {
 "string_id": "10.1093/llc/fqv052",
 "id_scheme": "DOI"
 },
 "abstract": "How do humanities scholars make sense of new or otherwise unfamiliar archives? Is there a role for computational text analysis in the process of sensemaking? We propose that topic modeling, when conceived as a process of thematic exploration, can provide a new entry point into this process. To this end, we present research on a new software tool called TOME: Interactive TOpic Model and MEtadata Visualization, designed to support the exploratory thematic analysis of digitized archival collections. TOME is centered around a set of visualizations intended to facilitate the interpretation of the topic model and its incorporation into extant humanities research practices. In contrast to other topic model browsers, which present the model on its own terms, ours is informed by the process of conducting early-stage humanities research. Our article thus also demonstrates the conceptual conversions—in terms of both design and process—that interdisciplinary collaboration necessarily entails. In making these conversions explicit, and exploring the implications of their successes and failures, we take up the call, as voiced by Johanna Drucker (Humanities approaches to graphical display. Digital Humanities Quarterly, 5(1), 2011), to resist the ‘intellectual Trojan horse’ of visualization. We seek to model a new mode of interdisciplinary inquiry, one that brings the methodological emphasis of the digital humanities to bear on the practices of humanities research and computer science alike.",
 "article_title": "Exploratory Thematic Analysis for Digitized Archival Collections",
 "authors": [
 {
 "given": " Lauren F.",
 "family": "Klein",
 "affiliation": [
 {
 "original_name": "Georgia Institute of Technology, School of Literature, Media, and Communication, USA",
 "normalized_name": "Georgia Institute of Technology",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/01zkghx44",
 "GRID": "grid.213917.f"
 }
 }
 ]
 },
 {
 "given": " Jacob",
 "family": "Eisenstein",
 "affiliation": [
 {
 "original_name": "Georgia Institute of Technology, School of Interactive Computing, USA",
 "normalized_name": "Georgia Institute of Technology",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/01zkghx44",
 "GRID": "grid.213917.f"
 }
 }
 ]
 },
 {
 "given": " Iris",
 "family": "Sun",
 "affiliation": [
 {
 "original_name": "Georgia Institute of Technology, School of Literature, Media, and Communication, USA",
 "normalized_name": "Georgia Institute of Technology",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/01zkghx44",
 "GRID": "grid.213917.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-11-18",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "suppl 1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu066",
 "identifier": {
 "string_id": "10.1093/llc/fqu066",
 "id_scheme": "DOI"
 },
 "abstract": "In recent years, social networks, microblogs, and short message service have deeply penetrated peoples lives, and thus, chat-style text is a common phenomenon. This chat-style text has many unknown features for linguists, which can be discovered by analyzing a chat-style corpus. The process of constructing a corpus conforms to specific corpus criteria, such as representativeness, sampling, variety, and chronology. Up to now, literature does not provide specific corpus criteria for creating a chat-style-text corpus. In contrast to related work, corpus criteria for creating a chat-style corpus are provided. An exhaustive and reliable Malay chat-style text corpus is still lacking. Thus, the provided criteria are used to demonstrate the process of constructing a Twitter corpus known as the Malay Chat-style Corpus (MCC). The MCC, which has 1 million twitter messages, consists of 14,484,384 word instances, 646,807 terms and metadata, such as posting time, used twitter client application, and type of Twitter message (simple Tweet, Retweet, Reply). Furthermore, the results of the analysis of the MCC reveal characteristics of the corpus including the most frequent terms and collocations, Zipf law diagram, Twitter peak hours, and percentages of message types. Finally, representativeness of the corpus is evaluated by employing cartography and automatic language identification methods. This corpus and the process of corpus creating are valuable for researchers working in linguistics, natural language processing, and data mining.",
 "article_title": "Twitter corpus creation: The case of a Malay Chat-style-text Corpus (MCC)",
 "authors": [
 {
 "given": " Mohammad",
 "family": "Arshi Saloot",
 "affiliation": [
 {
 "original_name": "University of Malaya, Malaysia",
 "normalized_name": "University of Malaya",
 "country": "Malaysia",
 "identifiers": {
 "ror": "https://ror.org/00rzspn62",
 "GRID": "grid.10347.31"
 }
 },
 {
 "original_name": "Institute for Infocomm Research (I2R), A*STAR, Singapore",
 "normalized_name": "Institute for Infocomm Research",
 "country": "Singapore",
 "identifiers": {
 "ror": "https://ror.org/053rfa017",
 "GRID": "grid.418705.f"
 }
 }
 ]
 },
 {
 "given": " Norisma",
 "family": "Idris",
 "affiliation": [
 {
 "original_name": "University of Malaya, Malaysia",
 "normalized_name": "University of Malaya",
 "country": "Malaysia",
 "identifiers": {
 "ror": "https://ror.org/00rzspn62",
 "GRID": "grid.10347.31"
 }
 }
 ]
 },
 {
 "given": " AiTi",
 "family": "Aw",
 "affiliation": [
 {
 "original_name": "Institute for Infocomm Research (I2R), A*STAR, Singapore",
 "normalized_name": "Institute for Infocomm Research",
 "country": "Singapore",
 "identifiers": {
 "ror": "https://ror.org/053rfa017",
 "GRID": "grid.418705.f"
 }
 }
 ]
 },
 {
 "given": " Dirk",
 "family": "Thorleuchter",
 "affiliation": [
 {
 "original_name": "Fraunhofer INT, Euskirchen, Appelsgarten 2, Germany",
 "normalized_name": "Fraunhofer Institute for Technological Trend Analysis",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/02sm4kj57",
 "GRID": "grid.469856.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-12-15",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu062",
 "identifier": {
 "string_id": "10.1093/llc/fqu062",
 "id_scheme": "DOI"
 },
 "abstract": "Nowadays, a large amount of documents is generated daily. These documents may contain some spelling errors which should be detected and corrected by using a proofreading tool. Therefore, the existence of automatic writing assistance tools such as spell-checkers/correctors could help to improve their quality. Spelling errors could be categorized into five categories. One of them is real-word errors, which are misspelled words that have been wrongly converted into another word in the language. Detection of such errors requires discourse analysis rather than just checking the word in a dictionary. We propose a discourse-aware discriminative model to improve the results of context-sensitive spell-checkers by reranking their resulted n-best list. We augment the proposed reranker into two existing context-sensitive spell-checker systems; one of them is based on statistical machine translation and the other one is based on language model. We choose the keywords of the whole document as contextual features of the model and improve the results of both systems by employing the features in a log-linear reranker system. We evaluated the system on two different languages: English and Persian. The results of the experiments in English language on the Wall street journal test set show improvements of 4.5% and 5.2% in detection and correction recall, respectively, in comparison to the baseline method. The mentioned improvement on recall metric was achieved with comparable precision. We also achieve state-of-the-art performance on the Persian language.",
 "article_title": "Discriminative reranking for context-sensitive spell–checker",
 "authors": [
 {
 "given": " Behzad",
 "family": "Mirzababaei",
 "affiliation": [
 {
 "original_name": "School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Tehran, Iran",
 "normalized_name": "University of Tehran",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/05vf56z40",
 "GRID": "grid.46072.37"
 }
 },
 {
 "original_name": "Natural Language Processing Laboratory, School of Electrical and Computer Engineering, College of Engineering, Campus no. 2, North Kargar Ave. P. O. Box 14395/515, Tehran, Iran",
 "normalized_name": "Maharaj Vijayaram Gajapathi Raj College of Engineering",
 "country": "India",
 "identifiers": {
 "ror": "https://ror.org/00hvk3c79",
 "GRID": "grid.454300.6"
 }
 },
 {
 "original_name": "School of Computer Science, Institute for Research in Fundamental Science (IPM), P. O. Box 19395-5746, Tehran, Iran",
 "normalized_name": "Institute for Research in Fundamental Sciences",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/04xreqs31",
 "GRID": "grid.418744.a"
 }
 }
 ]
 },
 {
 "given": " Heshaam",
 "family": "Faili",
 "affiliation": [
 {
 "original_name": "School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Tehran, Iran",
 "normalized_name": "University of Tehran",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/05vf56z40",
 "GRID": "grid.46072.37"
 }
 },
 {
 "original_name": "Natural Language Processing Laboratory, School of Electrical and Computer Engineering, College of Engineering, Campus no. 2, North Kargar Ave. P. O. Box 14395/515, Tehran, Iran",
 "normalized_name": "Maharaj Vijayaram Gajapathi Raj College of Engineering",
 "country": "India",
 "identifiers": {
 "ror": "https://ror.org/00hvk3c79",
 "GRID": "grid.454300.6"
 }
 },
 {
 "original_name": "School of Computer Science, Institute for Research in Fundamental Science (IPM), P. O. Box 19395-5746, Tehran, Iran",
 "normalized_name": "Institute for Research in Fundamental Sciences",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/04xreqs31",
 "GRID": "grid.418744.a"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-01-01",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu072",
 "identifier": {
 "string_id": "10.1093/llc/fqu072",
 "id_scheme": "DOI"
 },
 "abstract": "The role of human philological judgement in textual criticism, and particularly in stemmatics, has been at times hotly debated and in computational stemmatology tends to be carefully circumscribed. In this context philological judgement is deployed to distinguish ‘significant’ from ‘insignificant’ textual variation—that is, to select those variants that are more or less likely to betray information about the exemplar from which a given text was copied. This article reports on an experiment performed to assess the accuracy of human philological judgement on a set of three artificial traditions, using tools for stemma analysis developed for a prior project and available to the public as the Stemmaweb online service. We show that for most of the artificial traditions, human judgement was not significantly better than random selection for choosing the variant readings that fit the stemma in a text-genealogical pattern, and we discuss some of the implications of these findings.",
 "article_title": "Analysis of variation significance in artificial traditions using Stemmaweb",
 "authors": [
 {
 "given": " Tara L.",
 "family": "Andrews",
 "affiliation": [
 {
 "original_name": "Digital Humanities, Universität Bern, Switzerland",
 "normalized_name": "University of Bern",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/02k7v4d05",
 "GRID": "grid.5734.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-01-01",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu063",
 "identifier": {
 "string_id": "10.1093/llc/fqu063",
 "id_scheme": "DOI"
 },
 "abstract": "Theorists of technology adoption have demonstrated that successful technologies rely on social resources. This article takes up social tensions involved in designing digital resources for scholarship, at the centre of which stand editing tools. These are (1) individualism versus collaboration in relation to credit; (2) the shift towards dynamism versus stability in resources; (3) simplicity versus complexity in data models and interfaces; (4) swift dissemination versus scholarly quality control; and (5) the benefits of standards versus disciplinary resistance to systematization. With particular reference to editing and publication software, it argues that interfaces are the contact zones within which such tensions will necessarily be mediated. The onus is on the scholarly community to address the social implications of new editing environments, but we can navigate future possibilities only through a deep respect for the embodied and socially situated experience of the user or subject of textuality and a profound recognition of the power of our printed past.",
 "article_title": "Tensions and tenets of socialized scholarship",
 "authors": [
 {
 "given": " Susan",
 "family": "Brown",
 "affiliation": [
 {
 "original_name": "School of English and Theatre Studies, University of Guelph, Canada",
 "normalized_name": "University of Guelph",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/01r7awg59",
 "GRID": "grid.34429.38"
 }
 },
 {
 "original_name": "Department of English and Film Studies, University of Alberta, Canada",
 "normalized_name": "University of Alberta",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/0160cpw27",
 "GRID": "grid.17089.37"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-01-09",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu073",
 "identifier": {
 "string_id": "10.1093/llc/fqu073",
 "id_scheme": "DOI"
 },
 "abstract": "There was one trending topic on Twitter in December 2012 that we could have seen coming for a few years now: the New Age prophecy of the End of Times on 21 December 2012—all because some Mayan calendar supposedly ended on this date. For 2 weeks long—a week before the Apocalypse and a week after—we monitored Twitter for Dutch words concerning the End of the World. We caught 52,000 tweets in 2 weeks. When did the stream of rumours peek? How many retweets were involved? Was there much micro-variation? What was the overall content of the tweets? What emotions were expressed in the tweets? How did religious people respond? And finally, how many people confessed they were truly scared because of the prophecy? These are intriguing questions that we can answer by using a few basic computational tools. Although the Apocalypse got a lot of attention in the news media, it turned out most Dutch people on Twitter took the End of Days with a grain of salt.",
 "article_title": "The apocalypse on Twitter",
 "authors": [
 {
 "given": " Theo",
 "family": "Meder",
 "affiliation": [
 {
 "original_name": "Meertens Institute, University of Twente",
 "normalized_name": "University of Twente",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/006hf6230",
 "GRID": "grid.6214.1"
 }
 },
 {
 "original_name": "University of Leiden",
 "normalized_name": "Leiden University",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/027bh9e22",
 "GRID": "grid.5132.5"
 }
 }
 ]
 },
 {
 "given": " Dong",
 "family": "Nguyen",
 "affiliation": [
 {
 "original_name": "Meertens Institute, University of Twente",
 "normalized_name": "University of Twente",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/006hf6230",
 "GRID": "grid.6214.1"
 }
 },
 {
 "original_name": "University of Leiden",
 "normalized_name": "Leiden University",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/027bh9e22",
 "GRID": "grid.5132.5"
 }
 }
 ]
 },
 {
 "given": " Rilana",
 "family": "Gravel",
 "affiliation": [
 {
 "original_name": "Meertens Institute, University of Twente",
 "normalized_name": "University of Twente",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/006hf6230",
 "GRID": "grid.6214.1"
 }
 },
 {
 "original_name": "University of Leiden",
 "normalized_name": "Leiden University",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/027bh9e22",
 "GRID": "grid.5132.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-02-01",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv004",
 "identifier": {
 "string_id": "10.1093/llc/fqv004",
 "id_scheme": "DOI"
 },
 "abstract": " Medieval chronicles offer valuable source material for historians studying the Middle Ages. Like all medieval books, also chronicles were written and copied by hand, causing both unintentional errors and intentional alterations to the text. Stemmatologists are trying to recreate the family tree of the different copies. In recent years, many computer-assisted methods have emerged which several editors have already used. Computer-assisted stemmatology can offer valuable tools not only for editors but also for historians. They can also help to test traditional methods of textual criticism, point out errors in earlier historiography and create possibilities for studying cultural links and the history of books. In this article it is demonstrated how the use of different computer-assisted stemmatological methods can reveal new information concerning the manuscript tradition of a Finnish 16th-century chronicle, Paulus Juusten’s Catalogus et ordinaria successio Episcoporum Finlandensium . With the help of these methods, it can also be shown that the stemma put forward in the latest edition of the chronicle should be reconsidered. Using PAUP, RHM, and SplitsTree, it is pointed out that these methods create similar results as traditional textual criticism. These results can be obtained considerably more quickly than with traditional methods and without the subjective decision by a stemmatologist between ‘original readings and errors’. ",
 "article_title": "Computer-assisted stemmatology in studying Paulus Juusten's 16th-century chronicleCatalogus et ordinaria successio Episcoporum Finlandensium",
 "authors": [
 {
 "given": " Marko",
 "family": "Halonen",
 "affiliation": [
 {
 "original_name": "University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-03-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv002",
 "identifier": {
 "string_id": "10.1093/llc/fqv002",
 "id_scheme": "DOI"
 },
 "abstract": " After his first edition of the Old French text Lai de l’Ombre in 1890, the Romance scholar Joseph Bédier returned to the text in a revised edition in 1913. In the introduction to this edition, he claimed that he had become aware of a strange law: the great majority of stemmata proposed for Old French texts were bifurcating, i.e. they had two main branches. When he once more returned to this question in 1928, he claimed that of 110 stemmata he had encountered, 105 were bifurcating. Arrigo Castellani, another Romance scholar, revised this material in 1957, and came to somewhat lower numbers, but confirmed in general Bédier’s conclusion—of 86 stemmata, Castellani found that 71 were bifurcating. This article is an investigation into another vernacular tradition, the Old Norse one, i.e. Old Icelandic and Old Norwegian. The material presented here is based on the two major series published in Copenhagen, Bibliotheca Arnamagnæana and Editiones Arnamagnæanæ , and it comes very close to the findings of Castellani—of 89 stemmata, 74 turned out to be bifurcating. The two main hypotheses of Bédier are evaluated, and the conclusion is that the most likely explanation for the preponderance of bifurcating stemmata is the force of dichotomy inherent in the procedure of the stemmatic recension. ",
 "article_title": "Thesilva portentosaof stemmatology: Bifurcation in the recension of Old Norse manuscripts",
 "authors": [
 {
 "given": " Odd Einar",
 "family": "Haugen",
 "affiliation": [
 {
 "original_name": "University of Bergen, Norway",
 "normalized_name": "University of Bergen",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/03zga2b32",
 "GRID": "grid.7914.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-03-22",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv003",
 "identifier": {
 "string_id": "10.1093/llc/fqv003",
 "id_scheme": "DOI"
 },
 "abstract": " This article combines bibliography, book history, literary and traditional textual criticism with phylogenetic analysis to infer the publishing history and textual descent of a short printed ballad history of England— The Wandering Jew’s Chronicle . Probably first published in 1634, The Wandering Jew’s Chronicle most commonly survives as a ‘broadside ballad’—a cheaply-printed song-sheet—illustrated with woodcut portraits of kings and queens of England. It remained in print until ca.1830, its text and illustrations updated to the present. Although in partial synchrony with English history, much of its publishing history and textual descent is uncertain. This article demonstrates how historical evidence, taken in particular from book trade history, may be usefully combined with textual and bibliographical evidence, and that it is at times essential for understanding the descent of the text. The textual descent of the ballad is visualized in a stemma that summarizes key findings from both traditional and phylogenetic analyses. ",
 "article_title": "Lines of succession in an English ballad tradition: The publishing history and textual descent ofThe Wandering Jew’s Chronicle",
 "authors": [
 {
 "given": " Giles",
 "family": "Bergel",
 "affiliation": [
 {
 "original_name": "Faculty of English Language and Literature, University of Oxford, Oxford, UK",
 "normalized_name": "University of Oxford",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/052gg0110",
 "GRID": "grid.4991.5"
 }
 }
 ]
 },
 {
 "given": " Christopher J.",
 "family": "Howe",
 "affiliation": [
 {
 "original_name": "Department of Biochemistry, University of Cambridge, Cambridge, UK",
 "normalized_name": "University of Cambridge",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/013meh722",
 "GRID": "grid.5335.0"
 }
 }
 ]
 },
 {
 "given": " Heather F.",
 "family": "Windram",
 "affiliation": [
 {
 "original_name": "Department of Biochemistry, University of Cambridge, Cambridge, UK",
 "normalized_name": "University of Cambridge",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/013meh722",
 "GRID": "grid.5335.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-03-26",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv006",
 "identifier": {
 "string_id": "10.1093/llc/fqv006",
 "id_scheme": "DOI"
 },
 "abstract": "Recent contributions have highlighted that the advent of digital technologies in the humanities is the object of different and even polarized narratives, which frame the effects of digitization either in utopian or dystopian terms. In this light, technology-centred narratives should be complemented by an intellectual history of technology-related «myths and dystopias», in order to increase our understanding of how digital technologies are presented in the disciplinary and public debates. Whereas this type of analysis has taken its start from library science and the digital humanities, however, it is still in its infancy within the field of museum computing. To this purpose, the article provides an interpretive and critical review of the debate on the automated cataloguing and digitization of museum collections. It highlights a sequence of discursive shifts in time since the 1960s to the present decade are identified and discussed: namely, a phase of «standardization», followed by «the museum of the Information Society» and, most recently, a «post-modernist utopia» which dominates the current debate. Each new paradigm tends at the same time to reverse and «re-mediate» some characteristics of former phases, generating controversies that are likely to proceed until more empirical knowledge is collected about the actual impacts of digital media on museums.",
 "article_title": "Towards an intellectual history of digitization: Myths, dystopias, and discursive shifts in museum computing",
 "authors": [
 {
 "given": " Andrea",
 "family": "Sartori",
 "affiliation": [
 {
 "original_name": "University of Florence, Italy",
 "normalized_name": "University of Florence",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/04jr1s763",
 "GRID": "grid.8404.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-03-26",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv005",
 "identifier": {
 "string_id": "10.1093/llc/fqv005",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents a novel architecture using a hybrid model for developing a Sindhi spellchecker system which has yet not been developed prior to this work. The compound textual forms and glyphs of Sindhi language presents a substantial challenge for developing a Sindhi spellchecker system and generating a similar suggestion list for misspelled words. In order to implement such a system, phonetic-based Sindhi language rules and patterns must be taken into account for increasing the accuracy and efficiency. In this research work, a simple and efficient combinational hybrid system is proposed, using three different algorithms, the Edit Distance algorithm to find the measure of similarity between two Sindhi strings. The phonetic-based SoundEx and ShapeEx algorithms are developed for pattern or glyph matching, generating accurate and an efficient suggestion list for incorrect or misspelled Sindhi words. The proposed system is established with a blend between Phonetic-based SoundEx algorithm and ShapeEx algorithm for pattern or glyph matching, generating accurate and efficient suggestion list for incorrect or misspelled Sindhi words. In this article, a table of phonetically similar-sounding Sindhi characters is presented which are grouped together along with another table containing similar glyph or shape-based character groups. The system has been successfully integrated into a pre-developed Sindhi word processer application. The Sindhi word segmentation methodology and algorithms required for the spellchecker has already been published and so are not discussed in detail in this article.",
 "article_title": "Phonetic-based Sindhi spellchecker system using a hybrid model",
 "authors": [
 {
 "given": " Zeeshan",
 "family": "Bhatti",
 "affiliation": [
 {
 "original_name": "Institute of Information and Communication Technology, University of Sindh, Jamshoro, Pakistan",
 "normalized_name": "University of Sindh",
 "country": "Pakistan",
 "identifiers": {
 "ror": "https://ror.org/01d692d57",
 "GRID": "grid.412795.c"
 }
 }
 ]
 },
 {
 "given": " Imdad",
 "family": "Ali Ismaili",
 "affiliation": [
 {
 "original_name": "Institute of Information and Communication Technology, University of Sindh, Jamshoro, Pakistan",
 "normalized_name": "University of Sindh",
 "country": "Pakistan",
 "identifiers": {
 "ror": "https://ror.org/01d692d57",
 "GRID": "grid.412795.c"
 }
 }
 ]
 },
 {
 "given": " Dil",
 "family": "Nawaz Hakro",
 "affiliation": [
 {
 "original_name": "School of Computer Sciences, University Sains Malaysia, Malaysia",
 "normalized_name": "Universiti Sains Malaysia",
 "country": "Malaysia",
 "identifiers": {
 "ror": "https://ror.org/02rgb2k63",
 "GRID": "grid.11875.3a"
 }
 }
 ]
 },
 {
 "given": " Waseem",
 "family": "Javid Soomro",
 "affiliation": [
 {
 "original_name": "Institute of Information and Communication Technology, University of Sindh, Jamshoro, Pakistan",
 "normalized_name": "University of Sindh",
 "country": "Pakistan",
 "identifiers": {
 "ror": "https://ror.org/01d692d57",
 "GRID": "grid.412795.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-04-01",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv008",
 "identifier": {
 "string_id": "10.1093/llc/fqv008",
 "id_scheme": "DOI"
 },
 "abstract": "This article demonstrates how to automatically build a Latin word stemmer to transform words into their grammatical roots. By using the Wiktionary database as source data, it becomes possible to build such a tool with several hundreds of thousands of words. Our experiments demonstrate that it can then be used to correctly find the root of 78% of the words of Martial’s Epigrams, and can be combined with other linguistic tools such as the Latin WordNet to greatly enhance their language coverage. While our research focuses on the Latin language, the same methodology could be used to build stemmers and other linguistic tools for many other ancient languages represented in Wiktionary, such as Ancient Greek or Old Armenian.",
 "article_title": "Latin word stemming using Wiktionary:",
 "authors": [
 {
 "given": " Richard",
 "family": "Khoury",
 "affiliation": [
 {
 "original_name": "Lakehead University, Canada",
 "normalized_name": "Lakehead University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/023p7mg82",
 "GRID": "grid.258900.6"
 }
 }
 ]
 },
 {
 "given": " Francesca",
 "family": "Sapsford",
 "affiliation": [
 {
 "original_name": "Birmingham, UK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-04-01",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv011",
 "identifier": {
 "string_id": "10.1093/llc/fqv011",
 "id_scheme": "DOI"
 },
 "abstract": " Understanding the relationship between political regimes and language, while a popular theme among historians and linguists, is empirically difficult. This study suggests a preliminary empirical framework. A quantitative analysis of the Google Books 1-Gram German corpus from the year 1870 to 1945 provides empirical evidence consistent with George Orwell’s hypothesis that everyday language deteriorates under dictatorships, through the inversion of words’ underlying meanings. More specifically, this article shows that six non-technical non-Nazi words— Demokratie (democracy), Freiheit (freedom), Frieden (peace), Herrlichkeit (glory), Gerechtigkeit (justice), and Heldentumd (heroism)—are (1) highly correlated with explicitly Nazi words; (2) negatively correlated with Germany’s level of democracy; and (3) negatively correlated with the count of riots, anti-government protests, and government crises, implying that these words were not used as a form of protest. The use of these words increased sharply under the Nazi government, which banned all publications that were critical of the government. These correlations cannot tell us whether the relationship is causal, and we cannot be sure whether the corpus under study is truly representative. Replicating this empirical framework on other corpora, pushing the period under study further back in time, or using 2-gram data sets can all help assess this study’s findings. ",
 "article_title": "Politics and the German language: Testing Orwell’s hypothesis using the Google N-Gram corpus",
 "authors": [
 {
 "given": " Paul",
 "family": "Caruana-Galizia",
 "affiliation": [
 {
 "original_name": "Institute of Economic History, Humboldt University Berlin, Berlin, Germany",
 "normalized_name": "Humboldt University of Berlin",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/01hcx6992",
 "GRID": "grid.7468.d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-04-02",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv009",
 "identifier": {
 "string_id": "10.1093/llc/fqv009",
 "id_scheme": "DOI"
 },
 "abstract": " The present article reports on a corpus-based study that explores the relationship between English dual quantifier both and its Spanish equivalents, especially dual quantifier ambos/as , which is perceived as being functionally similar. The aim of this research is to shed some light on the causes of Spanish students’ underuse of both in their writing by analyzing and classifying the translation solutions for each different use of both and by comparing the use of both and its Spanish counterparts in fictional discourse and in non-fictional discourse to search for any possible cross-register differences. A parallel English–Spanish corpus, P-ACTRES, an ad hoc corpus of contemporary English texts and their corresponding translations into Spanish, has been used for the purpose of this study. ",
 "article_title": "Translation as an aid to ELT: Using an English–Spanish parallel corpus (P-ACTRES) to study Englishbothand its Spanish counterparts",
 "authors": [
 {
 "given": " Belen",
 "family": "Labrador",
 "affiliation": [
 {
 "original_name": "University of León, Spain",
 "normalized_name": "University of Leon",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/02tzt0b78",
 "GRID": "grid.4807.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-04-02",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv010",
 "identifier": {
 "string_id": "10.1093/llc/fqv010",
 "id_scheme": "DOI"
 },
 "abstract": " This article introduces a new stylometric method that combines supervised machine-learning classification with the idea of sequential analysis. Unlike standard procedures, aimed at assessing style differentiation between discrete text samples, the new method, supported with compact visualization, tries to look inside a text represented as a set of linearly sliced chunks, in order to test their stylistic consistency. Three flavors of the method have been introduced: (1) Rolling SVM, relying on the support vector machines (SVM) classifier, (2) Rolling NSC, based on the nearest shrunken centroids method, and (3) Rolling Delta, using the classic Burrowsian measure of similarity. The technique is primarily intended to assess mixed authorship; however, it can be also used as a magnifying glass to inspect works with unclear stylometric signal. To demonstrate its applicability, three different examples of collaborative work have been briefly discussed: (1) the 13th-century French allegorical poem Roman de la Rose , (2) a 15th-century translation of the Bible into Polish known as Queen Sophia’s Bible , and (3) The Inheritors , a novel collaboratively written by Joseph Conrad and Ford Madox Ford in 1901. ",
 "article_title": "Rolling stylometry",
 "authors": [
 {
 "given": " Maciej",
 "family": "Eder",
 "affiliation": [
 {
 "original_name": "Polish Academy of Sciences, Institute of Polish Language, and Pedagogical University of Kraków, Kraków, Poland",
 "normalized_name": "Pedagogical University of Kraków",
 "country": "Poland",
 "identifiers": {
 "ror": "https://ror.org/030mz2444",
 "GRID": "grid.412464.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-04-08",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv012",
 "identifier": {
 "string_id": "10.1093/llc/fqv012",
 "id_scheme": "DOI"
 },
 "abstract": "Drawing on Digital Humanities as a specific, reflexive way of using new information technology to enhance learning, teaching, and research, this article describes a tool whose development began in 2011 with the goal of helping students, teachers, and researchers to share, transcribe, and comment on audio/video data without having to experience complicated software installation, regular overlap of windows, or strong versioning. From the definition of the requirements to the evaluation of the impact on teaching and research, the article stresses the importance of conceiving of techno-pedagogical tools as dynamic products, whose plasticity is a way to offset teething problems and apparent weaknesses.",
 "article_title": "IMPACT: A tool for transcribing and commenting on oral data, for teaching, learning, and research",
 "authors": [
 {
 "given": " Jérôme",
 "family": "Jacquin",
 "affiliation": [
 {
 "original_name": "University of Lausanne, Switzerland",
 "normalized_name": "University of Lausanne",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/019whta54",
 "GRID": "grid.9851.5"
 }
 },
 {
 "original_name": "Victoria University of Wellington, New Zealand",
 "normalized_name": "Victoria University of Wellington",
 "country": "New Zealand",
 "identifiers": {
 "ror": "https://ror.org/0040r6f76",
 "GRID": "grid.267827.e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-06-18",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv001",
 "identifier": {
 "string_id": "10.1093/llc/fqv001",
 "id_scheme": "DOI"
 },
 "abstract": "In this article we describe the methodology developed for the semiautomatic annotation of EPEC-RolSem, a Basque corpus labeled at predicate level that follows the PropBank-VerbNet model. The methodology presented is the product of detailed theoretical study of the semantic nature of verbs in Basque and of their similarities and differences with verbs in other languages. As part of the proposed methodology, we are creating a Basque lexicon on the PropBank-VerbNet model that we have named the Basque Verb Index (BVI). Our work thus dovetails with the general trend toward building lexicons from tagged corpora that is clear in work conducted for other languages. EPEC-RolSem and BVI are two important resources for the computational semantic processing of Basque; as far as the authors are aware, they are also the first resources of their kind developed for Basque. In addition, each entry in BVI is linked to the corresponding verb-entry in well-known resources like PropBank, VerbNet, WordNet, FrameNet, and Levin’s classification. We have also implemented several automatic processes to aid in creating and annotating the BVI, including processes designed to facilitate the task of manual annotation.",
 "article_title": "A methodology for the semiautomatic annotation of EPEC-RolSem, a Basque corpus labeled at predicate level following the PropBank-VerbNet model",
 "authors": [
 {
 "given": " Ainara",
 "family": "Estarrona",
 "affiliation": [
 {
 "original_name": "IXA NLP Group, University of the Basque Country, UPV/EHU, Spain",
 "normalized_name": "University of the Basque Country",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/000xsnr85",
 "GRID": "grid.11480.3c"
 }
 }
 ]
 },
 {
 "given": " Izaskun",
 "family": "Aldezabal",
 "affiliation": [
 {
 "original_name": "IXA NLP Group, University of the Basque Country, UPV/EHU, Spain",
 "normalized_name": "University of the Basque Country",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/000xsnr85",
 "GRID": "grid.11480.3c"
 }
 }
 ]
 },
 {
 "given": " Arantza",
 "family": "Díaz de Ilarraza",
 "affiliation": [
 {
 "original_name": "IXA NLP Group, University of the Basque Country, UPV/EHU, Spain",
 "normalized_name": "University of the Basque Country",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/000xsnr85",
 "GRID": "grid.11480.3c"
 }
 }
 ]
 },
 {
 "given": " María Jesús",
 "family": "Aranzabe",
 "affiliation": [
 {
 "original_name": "IXA NLP Group, University of the Basque Country, UPV/EHU, Spain",
 "normalized_name": "University of the Basque Country",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/000xsnr85",
 "GRID": "grid.11480.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-06-18",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv013",
 "identifier": {
 "string_id": "10.1093/llc/fqv013",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents the ‘Roman City Ruleset’, a suite of procedural rules for creating 3D models of Roman and Hellenistic architecture and urban environments. Unlike traditional 3D modeling software, in which the user directly manipulates polygons to simulate form, procedural modeling entails the use of computer programming languages to write a semantic description of a building that then generates a polygonal model. Procedural modeling has the potential to address a number of issues related to 3D archaeological reconstructions which are of concern to digital humanists. Of particular interest for archaeologists and architectural historians is the ability to test hypothetical reconstructions of ancient architecture in a fully realized urban context. The procedural rules link each iteration of a model to its source material, allowing the degree of certainty present in each model to be accurately defined through the documentation of each step in the process of interpreting a given data set. Procedural modeling enhances the scholarly value of architectural reconstructions by providing a platform for the comparison and refutation of 3D visualizations, and advances the methodology of 3D modeling toward becoming an essential part of the digital humanist’s toolkit.",
 "article_title": "An Integrated Approach to the Procedural Modeling of Ancient Cities and Buildings",
 "authors": [
 {
 "given": " Marie",
 "family": "Saldaña",
 "affiliation": [
 {
 "original_name": "UCLA, Los Angeles, California",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-06-18",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "suppl 1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv015",
 "identifier": {
 "string_id": "10.1093/llc/fqv015",
 "id_scheme": "DOI"
 },
 "abstract": "This keynote address for the 2014 Digital Humanities conference is a practitioner’s talk, and—though the abstract belies it—an optimistic one. I take as given the evidence that human beings are irrevocably altering the conditions for life on Earth and that, despite certain unpredictabilities, we live at the cusp of a mass extinction. What is the place of digital humanities (DH) practice in the new social and geological era of the Anthropocene? What are the DH community’s most significant responsibilities, and to whom? This talk positions itself in deep time, but strives for a foothold in the vital here-and-now of service to broad publics. From the presentist, emotional aesthetics of Dark Mountain to the arms-length futurism of the Long Now, I dwell on concepts of graceful degradation, preservation, memorialization, apocalypse, ephemerality, and minimal computing. I discuss digital recovery and close reading of texts and artifacts once thought lost forever, and the ways that prosopography, graphesis, and distant reading open new vistas on the longue durée. Can DH develop a practical ethics of resilience and repair? Can it become more humane while working at inhuman scales? Can we resist narratives of progress, and still progress? I wish to open community discussion about the practice of DH, and what to give, in the face of a great hiatus or the end of it all.",
 "article_title": "Digital Humanities in the Anthropocene",
 "authors": [
 {
 "given": " Bethany",
 "family": "Nowviskie",
 "affiliation": [
 {
 "original_name": "University of Virginia Library, VA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-06-18",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "suppl 1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv014",
 "identifier": {
 "string_id": "10.1093/llc/fqv014",
 "id_scheme": "DOI"
 },
 "abstract": "There exist about 150,000 premodern Arabic documents on papyrus and paper, of which about 2,500 have been edited. Another 10,000 unpublished documents are described or mentioned in papyrological publications. It is the aim of the Arabic Papyrology Database (APD) to give access to published texts and descriptions. For the APD, an entirely new approach of organizing Arabic text was developed. The APD presents texts in five levels that account for the peculiarities of the Arabic script system and the scribal practices. The first level provides a faithful diplomatic edition of the text as found in the document. The following levels document four steps of editorial interventions. On the second level, lines of characters are broken into single words. On the third level, lacking diacritical dots are supplied. On the fourth level, Arabic vowel signs are added, providing a full phonological representation. On the fifth level, a scientific Latin transliteration is given. Each element of the fifth level is connected to a lexicon and a list of grammatical forms. All levels contain variant readings and editorial remarks. At present, the APD contains 1,806 full-text documents and is freely accessible (http://www.naher-osten.lmu.de/apd).",
 "article_title": "The Arabic Papyrology Database",
 "authors": [
 {
 "given": " Johannes",
 "family": "Thomann",
 "affiliation": [
 {
 "original_name": "University of Zurich, Switzerland",
 "normalized_name": "University of Zurich",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/02crff812",
 "GRID": "grid.7400.3"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-06-18",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "suppl 1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqv016",
 "identifier": {
 "string_id": "10.1093/llc/fqv016",
 "id_scheme": "DOI"
 },
 "abstract": "The evolution of fairy tales often involves complex interactions between oral and literary traditions, which can be difficult to tease apart when investigating their origins. Here, we show how computer-assisted stemmatology can be productively applied to this problem, focusing on a long-standing controversy in fairy tale scholarship: did Little Red Riding Hood originate as an oral tale that was adapted by Perrault and the Brothers Grimm, or is the oral tradition in fact derived from literary texts? We address this question by analysing a sample of twenty-four literal and oral versions of the fairy tale Little Red Riding Hood using several methods of phylogenetic analysis, including maximum parsimony and two network-based approaches (NeighbourNet and TRex). While the results of these analyses are more compatible with the oral origins hypothesis than the alternative literary origins hypothesis, their interpretation is problematized by the fact that none of them explicitly model lineal (i.e. ancestor-descendent) relationships among taxa. We therefore present a new likelihood-based method, PhyloDAG, which was specifically developed to model lineal as well as collateral and reticulate relationships. A comparison of different structures derived from PhyloDAG provided a much clearer result than the maximum parsimony, NeighbourNet or TRex analyses, and strongly favoured the hypothesis that literary versions of Little Red Riding Hood were originally based on oral folktales, rather than vice versa.",
 "article_title": "Oral fairy tale or literary fake? Investigating the origins ofLittle Red Riding Hoodusing phylogenetic network analysis",
 "authors": [
 {
 "given": " Jamshid",
 "family": "Tehrani",
 "affiliation": [
 {
 "original_name": "Department of Anthropology, Durham University, Durham, UK",
 "normalized_name": "Durham University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01v29qb04",
 "GRID": "grid.8250.f"
 }
 }
 ]
 },
 {
 "given": " Quan",
 "family": "Nguyen",
 "affiliation": [
 {
 "original_name": "Department of Computer Science and Helsinki Institute for Information Technology, FI-0014 University of Helsinki, Helsinki",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 }
 ]
 },
 {
 "given": " Teemu",
 "family": "Roos",
 "affiliation": [
 {
 "original_name": "Department of Computer Science and Helsinki Institute for Information Technology, FI-0014 University of Helsinki, Helsinki",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2015-06-24",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu069",
 "identifier": {
 "string_id": "10.1093/llc/fqu069",
 "id_scheme": "DOI"
 },
 "abstract": "Writers of a best-selling category romance imprint share a common tendency to decrease their deployment of unique words over the span of their novels—a phenomenon of ‘vocabulary decay’. This tendency cannot be found in the novels of Jane Austen, suggesting this drop is not intrinsic to the romance genre itself, and is unlikely to have any true narrative purpose. A study of Charles Dickens shows that vocabulary decay extends beyond the romance genre. Closer examination reveals vocabulary decay is a result of progressive amounts of linguistic chunking—due to author fatigue or a desire to produce a more readable narrative.",
 "article_title": "Vocabulary decay in category romance",
 "authors": [
 {
 "given": " Jack",
 "family": "Elliott",
 "affiliation": [
 {
 "original_name": "Centre for Literary and Linquistic Computing, University of Newcastle, Australia",
 "normalized_name": "University of Newcastle Australia",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00eae9z71",
 "GRID": "grid.266842.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-12-10",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu061",
 "identifier": {
 "string_id": "10.1093/llc/fqu061",
 "id_scheme": "DOI"
 },
 "abstract": " This article presents an approach to citation segmentation that addresses special challenges as typically found in Digital Humanities applications. We perform citation segmentation from Optical Character Recognition (OCR) input obtained from volumes of a printed bibliography, the Turkology Annual . This showcase application features serious difficulties for state-of-the-art techniques in citation segmentation: multilingual citation entries , lack of data redundancy , inconsistencies , and noise from OCR input . Our approach is based on Markov logic networks (MLN) (Richardson and Domingos, Markov logic networks. Machine Learning , 62 (1): 107–36, 2006), a framework of statistical relational learning that combines first-order logic with probabilistic modeling. Formalization in first-order logic offers high expressivity and flexibility, and makes it possible to tailor segmentation to specific conventions of a given bibliography. We show that in face of the specific difficulties found with segmenting references from a digitized bibliography, our MLN formalizations outperform state-of-the-art statistical methods. We obtain 88% F 1 -score for exact field match, a 24.8% increase over a conditional random fields-based system baseline. In contrast to prior work, we address a data set featuring sparse and noisy data. Our method extends Poon and Domingos (Joint Inference in information extraction. In Proceedings of the Twenty-Second National Conference on Artificial Intelligence . Vancouver, Canada: AAAI Press, 2007)’s approach by applying joint inference at the field level . By this move, we are able to cope with the lack of citation redundancy and noise in the data. Our approach can be characterized as knowledge-based and hence does not rely on annotated training data. The rule sets we designed can be adapted to other bibliographies, or further types of digitized sources, such as historical dictionaries or encyclopedias. ",
 "article_title": "Citation segmentation from sparse & noisy data: A joint inference approach with Markov logic networks",
 "authors": [
 {
 "given": " Dustin",
 "family": "Heckmann",
 "affiliation": [
 {
 "original_name": "Department of Computational Linguistics, Heidelberg University, Germany",
 "normalized_name": "Heidelberg University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/038t36y30",
 "GRID": "grid.7700.0"
 }
 }
 ]
 },
 {
 "given": " Anette",
 "family": "Frank",
 "affiliation": [
 {
 "original_name": "Department of Computational Linguistics, Heidelberg University, Germany",
 "normalized_name": "Heidelberg University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/038t36y30",
 "GRID": "grid.7700.0"
 }
 }
 ]
 },
 {
 "given": " Matthias",
 "family": "Arnold",
 "affiliation": [
 {
 "original_name": "Cluster of Excellence “Asia and Europe”, Heidelberg University, Germany",
 "normalized_name": "Heidelberg University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/038t36y30",
 "GRID": "grid.7700.0"
 }
 }
 ]
 },
 {
 "given": " Peter",
 "family": "Gietz",
 "affiliation": [
 {
 "original_name": "Cluster of Excellence “Asia and Europe”, Heidelberg University, Germany",
 "normalized_name": "Heidelberg University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/038t36y30",
 "GRID": "grid.7700.0"
 }
 }
 ]
 },
 {
 "given": " Christian",
 "family": "Roth",
 "affiliation": [
 {
 "original_name": "Cluster of Excellence “Asia and Europe”, Heidelberg University, Germany",
 "normalized_name": "Heidelberg University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/038t36y30",
 "GRID": "grid.7700.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-12-10",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "31",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu054",
 "identifier": {
 "string_id": "10.1093/llc/fqu054",
 "id_scheme": "DOI"
 },
 "abstract": "We often try to teach people through stories and narratives instead of giving them explicit facts and rules. But how do these stories influence us, how do they persuade us to change our attitudes? In this paper, we aim to answer these questions by providing a computational model that offers an internal perspective on character motives in stories. This model allows us to represent the deliberations of the main characters and how they weighed their values and motives given their attitudes. We illustrate out model by discussing the well known fable of the Ant and the Grasshopper and the parable of the Prodigal Son.",
 "article_title": "Arguments as a new perspective on character motive in stories",
 "authors": [
 {
 "given": " Floris",
 "family": "Bex",
 "affiliation": [
 {
 "original_name": "Department of Information and Computing Sciences, Utrecht University, The Netherlands",
 "normalized_name": "Utrecht University",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/04pp8hn57",
 "GRID": "grid.5477.1"
 }
 },
 {
 "original_name": "Department of Computer Science, University of Liverpool, UK",
 "normalized_name": "University of Liverpool",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04xs57h96",
 "GRID": "grid.10025.36"
 }
 }
 ]
 },
 {
 "given": " Katie",
 "family": "Atkinson",
 "affiliation": [
 {
 "original_name": "Department of Information and Computing Sciences, Utrecht University, The Netherlands",
 "normalized_name": "Utrecht University",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/04pp8hn57",
 "GRID": "grid.5477.1"
 }
 },
 {
 "original_name": "Department of Computer Science, University of Liverpool, UK",
 "normalized_name": "University of Liverpool",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04xs57h96",
 "GRID": "grid.10025.36"
 }
 }
 ]
 },
 {
 "given": " Trevor",
 "family": "Bench-Capon",
 "affiliation": [
 {
 "original_name": "Department of Information and Computing Sciences, Utrecht University, The Netherlands",
 "normalized_name": "Utrecht University",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/04pp8hn57",
 "GRID": "grid.5477.1"
 }
 },
 {
 "original_name": "Department of Computer Science, University of Liverpool, UK",
 "normalized_name": "University of Liverpool",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04xs57h96",
 "GRID": "grid.10025.36"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-10-15",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu056",
 "identifier": {
 "string_id": "10.1093/llc/fqu056",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents an approach to using cognitive models of narrative discourse comprehension to define an explicit computational model of a reader’s comprehension process during reading, predicting aspects of narrative focus and inferencing with precision. This computational model is employed in a narrative discourse generation system to select and sequence content from a partial plan representing story world facts, objects, and events, creating discourses that satisfy comprehension criteria. Cognitive theories of narrative discourse comprehension define explicit models of a reader’s mental state during reading. These cognitive models are created to test hypotheses and explain empirical results about reader comprehension, but do not often contain sufficient precision for implementation on a computer. Therefore, they have not previously been suitable for computational narrative generation. The results of three experiments are presented and discussed, exhibiting empirical support for the approach presented. This work makes a number of contributions that advance the state-of-the-art in narrative discourse generation: a formal model of narrative focus, a formal model of online inferencing in narrative, a method of selecting narrative discourse content to satisfy comprehension criteria, and both implementation and evaluation of these models.",
 "article_title": "Cognitive models of discourse comprehension for narrative generation",
 "authors": [
 {
 "given": " James",
 "family": "Niehaus",
 "affiliation": [
 {
 "original_name": "Charles River Analytics Inc, USA",
 "normalized_name": "Charles River Analytics (United States)",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/03z47zw42",
 "GRID": "grid.455283.d"
 }
 }
 ]
 },
 {
 "given": " R. Michael",
 "family": "Young",
 "affiliation": [
 {
 "original_name": "North Carolina State University, USA",
 "normalized_name": "North Carolina State University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/04tj63d06",
 "GRID": "grid.40803.3f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-10-14",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu046",
 "identifier": {
 "string_id": "10.1093/llc/fqu046",
 "id_scheme": "DOI"
 },
 "abstract": "One of the main efforts of recent computational linguistics is to formalize the process of identifying and evaluating similarity between narratives, which is argued to be a key concept for all human behavior. Analyses of the data of 52 adults that participated in our empirical study offered evidence that supports the position that narrative similarity can be equated to the existence of a common summary between the narratives involved. As a further step for applying the above hypothesis, we introduced our own methods for measuring similarity of narratives through the notion of summary and compared them with some of the existing lexical-matching similarity measures. Comparisons of each computational measure with the actual similarity judgments of human participants revealed that methods that merely measure the number of shared words between two stories were unable to capture human similarity judgments, especially for stories of moderate similarity levels. However, the summary-based methods of our approach managed to reproduce human ratings for story pairs across all the range of similarity (from high similarity to low similarity).",
 "article_title": "Narrative similarity as common summary: Evaluation of behavioral and computational aspects",
 "authors": [
 {
 "given": " Elektra",
 "family": "Kypridemou",
 "affiliation": [
 {
 "original_name": "Open University of Cyprus, Cyprus",
 "normalized_name": "Open University of Cyprus",
 "country": "Cyprus",
 "identifiers": {
 "ror": "https://ror.org/033sm2k57",
 "GRID": "grid.440846.a"
 }
 }
 ]
 },
 {
 "given": " Loizos",
 "family": "Michael",
 "affiliation": [
 {
 "original_name": "Open University of Cyprus, Cyprus",
 "normalized_name": "Open University of Cyprus",
 "country": "Cyprus",
 "identifiers": {
 "ror": "https://ror.org/033sm2k57",
 "GRID": "grid.440846.a"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-10-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu055",
 "identifier": {
 "string_id": "10.1093/llc/fqu055",
 "id_scheme": "DOI"
 },
 "abstract": "Structural similarities across narratives play an important role in many areas of humanities research. In this article, we describe a methodology and an implementation to uncover such similarities automatically in two application scenarios. In both scenarios—ritual and folktale studies—existing research examines similarities of narratives on a structural level and discusses structural principles that govern the combination of individual events to tales or rituals. We present a largely unsupervised and fully automated alignment-based approach for the detection of structural similarities of narratives that allows for data-driven quantitative studies of narrative structure. Our approach makes use of an adaptable, computational linguistic processing architecture that creates integrated discourse representations of events, participants, and their relations. Our contributions are twofold and crucially build on the automatically constructed discourse representations: (1) We examine different ‘semantics-driven cross-document alignment’ algorithms that determine (sequences of) events shared between narratives, to support the search for recurrent elements in their structure. The alignment algorithms are evaluated in two experiments. (2) We develop ‘tools for exploration and interpretation’ that we offer to humanities researchers for investigation of the analyzed data. These include search facilities, visualizations, statistical overviews, and a graph-based algorithm that identifies densely aligned regions across documents for targeted inspection.",
 "article_title": "An NLP-based cross-document approach to narrative structure discovery",
 "authors": [
 {
 "given": " Nils",
 "family": "Reiter",
 "affiliation": [
 {
 "original_name": "Heidelberg University, Germany",
 "normalized_name": "Heidelberg University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/038t36y30",
 "GRID": "grid.7700.0"
 }
 }
 ]
 },
 {
 "given": " Anette",
 "family": "Frank",
 "affiliation": [
 {
 "original_name": "Heidelberg University, Germany",
 "normalized_name": "Heidelberg University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/038t36y30",
 "GRID": "grid.7700.0"
 }
 }
 ]
 },
 {
 "given": " Oliver",
 "family": "Hellwig",
 "affiliation": [
 {
 "original_name": "Heidelberg University, Germany",
 "normalized_name": "Heidelberg University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/038t36y30",
 "GRID": "grid.7700.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-10-02",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu050",
 "identifier": {
 "string_id": "10.1093/llc/fqu050",
 "id_scheme": "DOI"
 },
 "abstract": "We continue the study of the reproducibility of Propp’s annotations from Bod et al. (2012). We present four experiments in which test subjects were taught Propp’s annotation system; we conclude that Propp’s system needs a significant amount of training, but that with sufficient time investment, it can be reliably trained for simple tales.",
 "article_title": "Annotating with Propp’sMorphology of the Folktale: reproducibility and trainability",
 "authors": [
 {
 "given": " Bernhard",
 "family": "Fisseni",
 "affiliation": [
 {
 "original_name": "Fachbereich Mathematik, Universität Hamburg, Hamburg, Germany",
 "normalized_name": "Universität Hamburg",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/00g30e956",
 "GRID": "grid.9026.d"
 }
 },
 {
 "original_name": "Fakultät für Geisteswissenschaften, Universität Duisburg-Essen, Essen, Germany",
 "normalized_name": "University of Duisburg-Essen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/04mz5ra38",
 "GRID": "grid.5718.b"
 }
 }
 ]
 },
 {
 "given": " Aadil",
 "family": "Kurji",
 "affiliation": [
 {
 "original_name": "Department of Philosophy, University of Bristol, Bristol, UK",
 "normalized_name": "University of Bristol",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0524sp257",
 "GRID": "grid.5337.2"
 }
 }
 ]
 },
 {
 "given": " Benedikt",
 "family": "Löwe",
 "affiliation": [
 {
 "original_name": "Fachbereich Mathematik, Universität Hamburg, Hamburg, Germany",
 "normalized_name": "Universität Hamburg",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/00g30e956",
 "GRID": "grid.9026.d"
 }
 },
 {
 "original_name": "Institute for Logic, Language and Computation, Universiteit van Amsterdam, Amsterdam, The Netherlands",
 "normalized_name": "University of Amsterdam",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/04dkp9463",
 "GRID": "grid.7177.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-10-02",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu051",
 "identifier": {
 "string_id": "10.1093/llc/fqu051",
 "id_scheme": "DOI"
 },
 "abstract": "This research studies the effect of language orthographic characteristics on the performance of digital word recognition in degraded documents such as historical documents. We provide a rigorous scheme for quantifying the statistical influence of the orthographic characteristics on the quality of word recognition in such documents. We study and compare several orthographic characteristics for four natural languages and measure the effect of each individual characteristic on the digital word recognition process. To this end, we create synthetic languages, for which all characteristics, except the one we examine, are identical, and measure the performance of two word recognition algorithms on synthetic documents of these languages. We examine and summarize the influence of the values of each characteristic on the performance of these word recognition methods.",
 "article_title": "The influence of language orthographic characteristics on digital word recognition",
 "authors": [
 {
 "given": " Ofer",
 "family": "Biller",
 "affiliation": [
 {
 "original_name": "Ben-Gurion University of the Negev, Israel",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Jihad",
 "family": "El-Sana",
 "affiliation": [
 {
 "original_name": "Ben-Gurion University of the Negev, Israel",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Klara",
 "family": "Kedem",
 "affiliation": [
 {
 "original_name": "Ben-Gurion University of the Negev, Israel",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-10-02",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu049",
 "identifier": {
 "string_id": "10.1093/llc/fqu049",
 "id_scheme": "DOI"
 },
 "abstract": "In this article, we focus on the problem of verifying Saikaku Ihara’s authorship, especially for Yorozu no humihougu (万の文反古), a posthumous work. Saikaku Ihara (井原西鶴) (c. 1642–93) is one of the most famous writers of the Edo period (1603–1868) in Japan. Saikaku's works are known for their significance for developing Japanese novels today. For a long time, researchers have tried to identify Saikaku’s works by investigating the history, content, format, and other features. However, it remained unclear which works were really written by Saikaku. Meanwhile, the potential of quantitative analysis of textual data has dramatically advanced. To resolve Saikaku’s authorship problem, our laboratory worked with Saikaku researchers to develop a database of works attributed to Saikaku. Based on these new capabilities, we examined Yorozu no humihougu (万の文反古) using quantitative analysis. In this study, we compared Yorozu no humihougu (万の文反古) and Kousyoku ichidai otoko (好色一代男), which has been verified to be a work of Saikaku. We examined six grammatical categories using principal component analysis where significant differences were found. Yorozu no humihougu (万の文反古) was revealed to be characterized as having a higher frequency of verbs and a lower frequency of particles than in Kousyoku ichidai otoko (好色一代男).",
 "article_title": "Verifying the authorship of Saikaku Ihara’s work in early modern Japanese literature; a quantitative approach",
 "authors": [
 {
 "given": " Ayaka",
 "family": "Uesaka",
 "affiliation": [
 {
 "original_name": "Graduate School of Culture and Information Science, Doshisha University, Kyoto City, Japan",
 "normalized_name": "Doshisha University",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/01fxdkm29",
 "GRID": "grid.255178.c"
 }
 }
 ]
 },
 {
 "given": " Masakatsu",
 "family": "Murakami",
 "affiliation": [
 {
 "original_name": "Faculty of Culture and Information science, Doshisha University, Kyoto City, Japan",
 "normalized_name": "Doshisha University",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/01fxdkm29",
 "GRID": "grid.255178.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-10-01",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu041",
 "identifier": {
 "string_id": "10.1093/llc/fqu041",
 "id_scheme": "DOI"
 },
 "abstract": "The article aims to model the verbal and prosodic features of emotional expression in interviews to investigate the potential for synergy between scholarly fields that have the narrative as object of study. Using a digital collection of oral history interviews that contains narrative aspects addressing war and violence in Croatia, we analyzed emotional expression through the words spoken, and through the pitch, vocal effort, and pause duration in the speech signal. The findings were correlated with the linear structure of interviews as well as question type. Our analysis indicates that the weight of emotion words for the overall expressed emotion is stronger in later interview parts as well as after open questions and meaning questions. Similar patterns were found for pitch and pause duration, but not for vocal effort. Although the verbal expression of emotions was somewhat correlated to pause duration, the hypothesized correlation between the verbal and nonverbal features was not confirmed. The research also shows that the various expressive layers in the interviews as well as the relations between them are a suited basis for computational modeling that may help track emotional personal narratives in interview collections. Additional research is needed to further develop the framework for the automated analysis of verbal and nonverbal cues to automatically generate annotations to be used for exploring spoken word collections.",
 "article_title": "Towards modeling expressed emotions in oral history interviews: Using verbal and nonverbal signals to track personal narratives",
 "authors": [
 {
 "given": " Khiet P.",
 "family": "Truong",
 "affiliation": [
 {
 "original_name": "Human Media Interaction, University of Twente, The Netherlands",
 "normalized_name": "University of Twente",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/006hf6230",
 "GRID": "grid.6214.1"
 }
 }
 ]
 },
 {
 "given": " Gerben J.",
 "family": "Westerhof",
 "affiliation": [
 {
 "original_name": "Department of Psychology, Health, and Technology, University of Twente, The Netherlands",
 "normalized_name": "University of Twente",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/006hf6230",
 "GRID": "grid.6214.1"
 }
 }
 ]
 },
 {
 "given": " Sanne M. A.",
 "family": "Lamers",
 "affiliation": [
 {
 "original_name": "Department of Psychology, Health, and Technology, University of Twente, The Netherlands",
 "normalized_name": "University of Twente",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/006hf6230",
 "GRID": "grid.6214.1"
 }
 }
 ]
 },
 {
 "given": " Franciska",
 "family": "de Jong",
 "affiliation": [
 {
 "original_name": "Human Media Interaction, University of Twente, The Netherlands",
 "normalized_name": "University of Twente",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/006hf6230",
 "GRID": "grid.6214.1"
 }
 },
 {
 "original_name": "Erasmus Studio for e-research, Erasmus Universiteit Rotterdam, The Netherlands",
 "normalized_name": "Erasmus University Rotterdam",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/057w15z03",
 "GRID": "grid.6906.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-08-30",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu039",
 "identifier": {
 "string_id": "10.1093/llc/fqu039",
 "id_scheme": "DOI"
 },
 "abstract": "Linguistics is a challenging subject to teach online; however, some instructors are doing it with success. In order to investigate the factors involved in teaching successful online courses, the authors investigated literature related to student characteristics, instructor characteristics, and course design and implementation. The investigators then conducted a qualitative case study of actual online linguistics courses. Through observation of courses and rubrics and interviews with teachers and students, the authors analyze the factors involved with teaching a successful online linguistics course.",
 "article_title": "Teaching online courses in linguistics:",
 "authors": [
 {
 "given": " Rebecca Day",
 "family": "Babcock",
 "affiliation": [
 {
 "original_name": "The University of Texas of the Permian Basin, Odessa TX, USA",
 "normalized_name": "The University of Texas of the Permian Basin",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/051smbs96",
 "GRID": "grid.267328.a"
 }
 }
 ]
 },
 {
 "given": " Elizabeth Bilbrey",
 "family": "McMellon",
 "affiliation": [
 {
 "original_name": "The University of Texas of the Permian Basin, Odessa TX, USA Midland TX, USA",
 "normalized_name": "The University of Texas of the Permian Basin",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/051smbs96",
 "GRID": "grid.267328.a"
 }
 }
 ]
 },
 {
 "given": " Sailaja",
 "family": "Athyala",
 "affiliation": [
 {
 "original_name": "University of Texas San Antonio, San Antonio TX, USA",
 "normalized_name": "The University of Texas at San Antonio",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/01kd65564",
 "GRID": "grid.215352.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-08-21",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu040",
 "identifier": {
 "string_id": "10.1093/llc/fqu040",
 "id_scheme": "DOI"
 },
 "abstract": "Stories of several characters, where different characters may engage in separate activities at different locations over the same period, are produced by humans as linear discourses with no difficulty. The present article addresses this issue by engineering a computational model of the relevant task understood as that of composing a narrative discourse for the events in a chess game. The task of narrative composition is modelled as a set of operations that need to be carried out to obtain a span of narrative discourse from a set of events that inspire the narration. The model explores a set of intermediate representations required to capture the structure that is progressively imposed on the material, and connects this content planning task with a classic pipeline for natural language generation. Several strategies are explored for the linearization procedure and for the evaluation of its results. Additionally, the article considers this productive task immersed in a self-evaluation cycle where the produced discourse is validated via the construction of a possible interpretation (based exclusively on the information available in the discourse itself) and a comparison between this interpretation and the original source material.",
 "article_title": "Composing narrative discourse for stories of many characters: A case study over a chess game",
 "authors": [
 {
 "given": " Pablo",
 "family": "Gervás",
 "affiliation": [
 {
 "original_name": "Universidad Complutense de Madrid",
 "normalized_name": "Complutense University of Madrid",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/02p0gd045",
 "GRID": "grid.4795.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-08-22",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu042",
 "identifier": {
 "string_id": "10.1093/llc/fqu042",
 "id_scheme": "DOI"
 },
 "abstract": "Unexpectedness is a major factor controlling interest in narratives. Emotions, for instance, are felt intensely if they are associated with unexpected events. The problem with generating unexpected situations is that either characters, or the whole story, are at risk of being no longer believable. This issue is one of the main problems that make story design a hard task. Writers face it on a case by case basis. The automatic generation of interesting stories requires formal criteria to decide to what extent a given situation is unexpected and to what extent actions are kept believable. This paper proposes such formal criteria and makes suggestions concerning their use in story generation systems.",
 "article_title": "Can believable characters act unexpectedly?",
 "authors": [
 {
 "given": " Antoine",
 "family": "Saillenfest",
 "affiliation": [
 {
 "original_name": "Telecom ParisTech, France",
 "normalized_name": "Télécom ParisTech",
 "country": "France",
 "identifiers": {
 "ror": "https://ror.org/01naq7912",
 "GRID": "grid.463717.0"
 }
 }
 ]
 },
 {
 "given": " Jean-Louis",
 "family": "Dessalles",
 "affiliation": [
 {
 "original_name": "Telecom ParisTech, France",
 "normalized_name": "Télécom ParisTech",
 "country": "France",
 "identifiers": {
 "ror": "https://ror.org/01naq7912",
 "GRID": "grid.463717.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-08-13",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu037",
 "identifier": {
 "string_id": "10.1093/llc/fqu037",
 "id_scheme": "DOI"
 },
 "abstract": "When Robert Coover anointed Michael Joyce the ‘granddaddy’ of hypertext literature in a 1992 New York Times article, it could scarcely have been imagined that this pronouncement would come to define the origin of electronic literature. This short article examines the human and machinic operations obscuring Judy Malloy's Uncle Roger, a hypertext that predates afternoon. Malloy's reputation was stunted because Uncle Roger was algorithmically invisible, a factor that became increasingly important as the Web's commercial capacities matured. afternoon's endurance can be traced to its ISBN, which made afternoon easy for readers to find and united disparate stewards in preserving access to this work. Malloy's programming expertise and the goodwill among hypertext authors were insufficient to protect her against sexist exclusions that, in aggregate, fostered enduring disequilibria. While some male pioneers of hypertext are now full professors, Malloy and other early female hypertext pioneers are adjuncts or are otherwise at a remove from the academic power base. Ironically, Judy Malloy's papers—13,200 items, 15.6 linear feet—are collected at Duke University's Rubenstein Library, but Judy herself still seeks sustained academic employment. This gesture is read in the context of pursuing the digital humanities ‘for love’ in a higher education environment that's increasingly neoliberal in its financial allegiances.",
 "article_title": "Judy Malloy's seat at the (database) table: A feminist reception history of early hypertext literature",
 "authors": [
 {
 "given": " Kathi Inman",
 "family": "Berens",
 "affiliation": [
 {
 "original_name": "Annenberg School of Communication, University of Southern California, Los Angeles, CA, USA",
 "normalized_name": "University of Southern California",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/03taz7m60",
 "GRID": "grid.42505.36"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-07-31",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu034",
 "identifier": {
 "string_id": "10.1093/llc/fqu034",
 "id_scheme": "DOI"
 },
 "abstract": "I highlight and illustrate a recent practical strategy for critical argument analysis that I have devised. I refer to it as ‘digital argument deconstruction’. This strategy helps to establish critical purchase on arguments intended for consumption in the public sphere, particularly when readers might not be so knowledgeable about the standpoint being criticized in the argument. Digital argument deconstruction utilizes a recent technological facility—the appending of discussion forums to online arguments, e.g. in online newspapers. This facility allows readers to post responses to an argument and to debate issues raised in it. Taken as a whole, the online comments in the discussion forums can be regarded as supplements to these arguments. I highlight the convenient utility value of this digital supplementation for critical reading of arguments. Integral to this approach to critical reading is corpus linguistic method—the software-based analysis of collections of electronic texts. I show how corpus linguistic analysis of a discussion forum appended to an argument can help illuminate whether or not the argument distorts the standpoint it criticizes. I also show how there can be a penalty for such distortion—the cohesive structure of the argument can be shown to be unstable. Because an argument’s credibility and capacity to persuade are, amongst a number of things, dependent on effective cohesion, showing where an argument’s cohesion falls apart or ‘deconstructs’ diminishes its credibility. A theoretical stimulus for this approach comes from the work of the philosopher, Jacques Derrida.",
 "article_title": "Deconstructing arguments via digital mining of online comments",
 "authors": [
 {
 "given": " Kieran",
 "family": "O'Halloran",
 "affiliation": [
 {
 "original_name": "King’s College, University of London, UK",
 "normalized_name": "University of London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04cw6st05",
 "GRID": "grid.4464.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-07-26",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu035",
 "identifier": {
 "string_id": "10.1093/llc/fqu035",
 "id_scheme": "DOI"
 },
 "abstract": "The work of theoretical linguistics rarely focuses on poetry. This is far from surprising, as poetic language, especially in modern and contemporary literature, seems to defy the general rules of syntax and semantics, as observed in ordinary language. This article assumes, however, that linguistic theories should ideally be able to account for creative uses of language, down to their most difficult incarnations. It proposes that at the semantic level, what distinguishes poetry from other uses of language may be its ability to trace conceptual patterns which do not belong to everyday discourse but are latent in our shared language structure. Distributional semantics provides a theoretical and experimental basis for this exploration. First, the notion of a specific ‘semantics of poetry’ is discussed, with some help from literary criticism and philosophy. Then, distributionalism is introduced as a theory supporting the notion that the meaning of poetry comes from the meaning of ordinary language. In the second part of the article, experimental results are provided showing that (i) distributional representations can model the link between ordinary and poetic language, (ii) a distributional model can experimentally distinguish between poetic and randomized textual output, regardless of the complexity of the poetry involved, and (iii) there is a stable, but not immediately transparent, layer of meaning in poetry, which can be captured distributionally, across different levels of poetic complexity.",
 "article_title": "The semantics of poetry: A distributional reading",
 "authors": [
 {
 "given": " Aurélie",
 "family": "Herbelot",
 "affiliation": [
 {
 "original_name": "University of Cambridge, UK",
 "normalized_name": "University of Cambridge",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/013meh722",
 "GRID": "grid.5335.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-07-19",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu031",
 "identifier": {
 "string_id": "10.1093/llc/fqu031",
 "id_scheme": "DOI"
 },
 "abstract": "This article provides a brief description of Mapping the Catalogue of Ships, which maps the towns and contingents of Homer’s Catalogue of Ships, analyzing the poet’s knowledge and use of ancient Greek geography. We offer a brief account of the questions that drive our research, detail our novel method to analyze Homer’s poetry in terms of geospatial organization, and summarize the geospatial organizational principles that we have discovered. We discuss the necessity of a digital format to our research and the presentation of our argument, which requires simultaneous attention to literary, geographical, archival, and bibliographical material. The article also details the Neatline (neatline.org) platform that allows us to achieve these goals. We end with outlining future directions for our research and user interface.",
 "article_title": "Mapping Homer's Catalogue of Ships",
 "authors": [
 {
 "given": " Courtney",
 "family": "Evans",
 "affiliation": [
 {
 "original_name": "Department of Classics, University of Virginia, VA, USA",
 "normalized_name": "University of Virginia",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0153tk833",
 "GRID": "grid.27755.32"
 }
 }
 ]
 },
 {
 "given": " Ben",
 "family": "Jasnow",
 "affiliation": [
 {
 "original_name": "Department of Classics, University of Virginia, VA, USA",
 "normalized_name": "University of Virginia",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0153tk833",
 "GRID": "grid.27755.32"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-07-15",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu027",
 "identifier": {
 "string_id": "10.1093/llc/fqu027",
 "id_scheme": "DOI"
 },
 "abstract": "This article examines the impacts of capturing correspondence metadata through an exhaustive discussion of how details such as the sender and recipient of a letter, their respective addresses, and the date of writing can be entered in an intuitive and accurate fashion. The focus is on the development of fundamental input mechanisms, which can be reused for specific metadata items. Our discussion results in the implementation of a proof-of-concept application, which shows that only a single text box is needed for each metadata item, without violating any of the self-imposed goals and requirements.",
 "article_title": "An optimized platform for capturing metadata of historical correspondence",
 "authors": [
 {
 "given": " Martin",
 "family": "Andert",
 "affiliation": [
 {
 "original_name": "Institute of Computer Science, Martin-Luther-University Halle-Wittenberg, D-06099 Halle (Saale), Germany",
 "normalized_name": "Martin Luther University Halle-Wittenberg",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/05gqaka33",
 "GRID": "grid.9018.0"
 }
 }
 ]
 },
 {
 "given": " Frank",
 "family": "Berger",
 "affiliation": [
 {
 "original_name": "Institute of Computer Science, Martin-Luther-University Halle-Wittenberg, D-06099 Halle (Saale), Germany",
 "normalized_name": "Martin Luther University Halle-Wittenberg",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/05gqaka33",
 "GRID": "grid.9018.0"
 }
 }
 ]
 },
 {
 "given": " Paul",
 "family": "Molitor",
 "affiliation": [
 {
 "original_name": "Institute of Computer Science, Martin-Luther-University Halle-Wittenberg, D-06099 Halle (Saale), Germany",
 "normalized_name": "Martin Luther University Halle-Wittenberg",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/05gqaka33",
 "GRID": "grid.9018.0"
 }
 }
 ]
 },
 {
 "given": " Jörg",
 "family": "Ritter",
 "affiliation": [
 {
 "original_name": "Institute of Computer Science, Martin-Luther-University Halle-Wittenberg, D-06099 Halle (Saale), Germany",
 "normalized_name": "Martin Luther University Halle-Wittenberg",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/05gqaka33",
 "GRID": "grid.9018.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-06-27",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu020",
 "identifier": {
 "string_id": "10.1093/llc/fqu020",
 "id_scheme": "DOI"
 },
 "abstract": "For more than 40 years now, modern theories of literature insist on the role of paraphrases, rewritings, citations, reciprocal borrowings, and mutual contributions of many kinds. The notions of ‘intertextuality’, ‘transtextuality’, and ‘hypertextuality/hypotextuality’ were introduced in the seventies and eighties to approach these phenomena. Through the Phœbus project, computer scientists from the computer science laboratory of the University Pierre and Marie Curie collaborate with the literary teams of Paris-Sorbonne University to develop efficient tools for literary studies that take advantage of modern computer science techniques to detect borrowings of huge masses of texts and to help put them in context. In this context, we have developed a piece of software that automatically detects and explores networks of textual reuses in classical literature. This article describes the principles on which our program is based, the significant results that have already been obtained and the prospective for the near future. It is divided into four parts. The first part recalls the distinction between various types of borrowings like plagiarism, pastiches, citations, etc. The second enumerates the criteria that are retained to characterize reuses and citations on which we are focusing here. The third part describes the implementation and shows its efficiency by comparison with manual detection. Finally, we show some of the results that have already been obtained with the Phœbus program.",
 "article_title": "Automatic detection of reuses and citations in literary texts",
 "authors": [
 {
 "given": " Jean-Gabriel",
 "family": "Ganascia",
 "affiliation": [
 {
 "original_name": "ACASA team, LIP6 - University Pierre and Marie Curie, Paris, France",
 "normalized_name": "Marie Curie",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02aqv1x10",
 "GRID": "grid.419428.2"
 }
 },
 {
 "original_name": "Labex OBVIL, PRES Sorbonne University, Paris, France",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Peirre",
 "family": "Glaudes",
 "affiliation": [
 {
 "original_name": "Littérature française, XIXe-XXIe siècles, Paris-Sorbonne University, Paris, France",
 "normalized_name": "Sorbonne University",
 "country": "France",
 "identifiers": {
 "ror": "https://ror.org/02en5vm52",
 "GRID": "grid.462844.8"
 }
 },
 {
 "original_name": "Labex OBVIL, PRES Sorbonne University, Paris, France",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Andrea",
 "family": "Del Lungo",
 "affiliation": [
 {
 "original_name": "ALITHILA, Université Charles de Gaulle, Lille 3, Lille, France",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-06-26",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu026",
 "identifier": {
 "string_id": "10.1093/llc/fqu026",
 "id_scheme": "DOI"
 },
 "abstract": "This paper charts the origins, trajectory, development, challenges, and conclusion of Project Bamboo, a humanities cyberinfrastructure initiative funded by the Andrew W. Mellon Foundation between 2008 and 2012. Bamboo aimed to enhance arts and humanities research through the development of infrastructure and support for shared technology services. Its planning phase brought together scholars, librarians, and IT staff from a wide range of institutions, in order to gain insight into the scholarly practices Bamboo would support, and to build a community of future developers and users for Bamboo’s technical deliverables. From its inception, Bamboo struggled to define itself clearly and in a way that resonated with scholars, librarians, and IT staff alike. The early emphasis on a service-oriented architecture approach to supporting humanities research failed to connect with scholars, and the scope of Bamboo’s ambitions expanded to include scholarly networking, sharing ideas and solutions, and demonstrating how digital tools and methodologies can be applied to research questions. Funding constraints for Bamboo’s implementation phase led to the near-elimination of these community-oriented aspects of the project, but the lack of a shared vision that could supersede the individual interests of partner institutions resulted in a scope around which it was difficult to articulate a clear narrative. When Project Bamboo ended in 2012, it had failed to realize its most ambitious goals; this article explores the reasons for this, including technical approaches, communication difficulties, and challenges common to projects that bring together teams from different professional communities.",
 "article_title": "What Ever Happened to Project Bamboo?",
 "authors": [
 {
 "given": " Quinn",
 "family": "Dombrowski",
 "affiliation": [
 {
 "original_name": "Research IT, UC Berkeley, Berkeley, CA 94720, USA",
 "normalized_name": "University of California, Berkeley",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/01an7q238",
 "GRID": "grid.47840.3f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-06-17",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu023",
 "identifier": {
 "string_id": "10.1093/llc/fqu023",
 "id_scheme": "DOI"
 },
 "abstract": "The article focuses on two related issues: authorship distinction and the analysis of characters’ voices in fiction. It deals with the case of Elisabeth Wolff and Agatha Deken, two women writers from the Netherlands who collaboratively published several epistolary novels at the end of the 18th century. First, the task division between the two authors will be analysed based on their usage of words and their frequencies. Next, any stylistic differences between the characters (letter writers) will be dealt with. The focus lies on Wolff’s and Deken’s first joint novel, Sara Burgerhart (1782). As to the authorship, nothing clearly showed a clear task division, which implies that Deken’s and Wolff’s writing styles are very much alike. This confirms findings of other scholars, who found that collaborating authors jointly produce a style that is distinguishable from both authors’ personal styles. As to stylistic differences in the voices of the characters in Sara Burgerhart, it was found that only a couple of the letter writers are clearly distinguishable compared with the main characters in the novel. I experimented with two possible tools to zoom in on the exact differences between those characters, but the methods are still too subjective to my taste. In the follow-up research, I will look further than words and their frequencies as building stones of literary style.",
 "article_title": "Epistolary voices. The case of Elisabeth Wolff and Agatha Deken",
 "authors": [
 {
 "given": " Karina",
 "family": "van Dalen-Oskam",
 "affiliation": [
 {
 "original_name": "Huygens Institute for the History of the Netherlands (KNAW), NL-2509 LT The Hague, The Netherlands",
 "normalized_name": "Huygens Institute for the History of the Netherlands",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/04x6kq749",
 "GRID": "grid.450092.a"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-05-22",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu022",
 "identifier": {
 "string_id": "10.1093/llc/fqu022",
 "id_scheme": "DOI"
 },
 "abstract": "In this slightly modified version of my 2013 Roberto Busa Prize lecture, I look from the first four decades of digital humanities through its present toward a possible future. I find a means to construct this future by paying close attention to the enemy we need in order to grow: the fear that closed down the horizons of imaginative exploration during the years of the Cold War and that re-presents itself now clothed in numerous techno-scientific challenges to the human.",
 "article_title": "Getting there from here. Remembering the future of digital humanities: Roberto Busa Award lecture 2013",
 "authors": [
 {
 "given": " Willard",
 "family": "McCarty",
 "affiliation": [
 {
 "original_name": "King’s College London, UK and University of Western Sydney, Australia",
 "normalized_name": "Western Sydney University",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/03t52dk35",
 "GRID": "grid.1029.a"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-05-21",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu014",
 "identifier": {
 "string_id": "10.1093/llc/fqu014",
 "id_scheme": "DOI"
 },
 "abstract": "The study of intertextuality, or how authors make artistic use of other texts in their works, has a long tradition, and has in recent years benefited from a variety of applications of digital methods. This article describes an approach for detecting the sorts of intertexts that literary scholars have found most meaningful, as embodied in the free Tesserae website http://tesserae.caset.buffalo.edu/. Tests of Tesserae Versions 1 and 2 showed that word-level n-gram matching could recall a majority of parallels identified by scholarly commentators in a benchmark set. But these versions lacked precision, so that the meaningful parallels could be found only among long lists of those that were not meaningful. The Version 3 search described here adds a second stage scoring system that sorts the found parallels by a formula accounting for word frequency and phrase density. Testing against a benchmark set of intertexts in Latin epic poetry shows that the scoring system overall succeeds in ranking parallels of greater significance more highly, allowing site users to find meaningful parallels more quickly. Users can also choose to adjust both recall and precision by focusing only on results above given score levels. As a theoretical matter, these tests establish that lemma identity, word frequency, and phrase density are important constituents of what make a phrase parallel a meaningful intertext.",
 "article_title": "Modeling the scholars: Detecting intertextuality through enhanced word-level n-gram matching",
 "authors": [
 {
 "given": " Christopher",
 "family": "Forstall",
 "affiliation": [
 {
 "original_name": "Department of Classics, University at Buffalo, SUNY, Buffalo, NY, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Neil",
 "family": "Coffee",
 "affiliation": [
 {
 "original_name": "Department of Classics, University at Buffalo, SUNY, Buffalo, NY, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Thomas",
 "family": "Buck",
 "affiliation": [
 {
 "original_name": "Department of Classics, University at Buffalo, SUNY, Buffalo, NY, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Katherine",
 "family": "Roache",
 "affiliation": [
 {
 "original_name": "Department of Classics, University at Buffalo, SUNY, Buffalo, NY, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Sarah",
 "family": "Jacobson",
 "affiliation": [
 {
 "original_name": "Department of Classics, University at Buffalo, SUNY, Buffalo, NY, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-05-16",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu019",
 "identifier": {
 "string_id": "10.1093/llc/fqu019",
 "id_scheme": "DOI"
 },
 "abstract": "This paper examines prospects and limitations of citation studies in the humanities. We begin by presenting an overview of bibliometric analysis, noting several barriers to applying this method in the humanities. Following that, we present an experimental tool for extracting and classifying citation contexts in humanities journal articles. This tool reports the bibliographic information about each reference, as well as three features about its context(s): frequency, location-in-document, and polarity. We found that extraction was highly successful (above 85%) for three of the four journals, and statistics for the three citation figures were broadly consistent with previous research. We conclude by noting several limitations of the sentiment classifier and suggesting future areas for refinement.",
 "article_title": "Citations, contexts, and humanistic discourse: Toward automatic extraction and classification",
 "authors": [
 {
 "given": " Chris Alen",
 "family": "Sula",
 "affiliation": [
 {
 "original_name": "School of Information & Library Science, Pratt Institute, New York, NY, USA",
 "normalized_name": "Pratt Institute",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/007m3p006",
 "GRID": "grid.262107.0"
 }
 }
 ]
 },
 {
 "given": " Matthew",
 "family": "Miller",
 "affiliation": [
 {
 "original_name": "NYPL Labs, New York Public Library, New York, NY, USA",
 "normalized_name": "New York Public Library",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/02eysy271",
 "GRID": "grid.429888.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-05-15",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu017",
 "identifier": {
 "string_id": "10.1093/llc/fqu017",
 "id_scheme": "DOI"
 },
 "abstract": "This article addresses the ‘meaning problem’ of unsupervised topic modeling algorithms using a tool called the Networked Corpus, which offers a way to visualize topic models alongside the texts themselves. We argue that the relationship between quantitative methods and qualitative interpretation can be reframed by investigating the long history of machine learning procedures and their historical antecedents. The new method of visualization presented by the Networked Corpus enables users to compare the results of topic models with earlier methods of topical representation such as the 18th-century subject index. Although the article provides a brief description of the tool, the primary focus is to describe an argument for this kind of comparative analysis between topic models and older genres that perform similar tasks. Such comparative analysis provides a new method for developing conceptual histories of the categories of meaning on which the topic model and the index depend. These devices are linked by a shared attempt to represent what a text is ‘about’, but the concept of ‘aboutness’ has evolved over time. The Networked Corpus enables researchers to discover congruities and contradictions in how topic models and indexes represent texts in order to examine what kinds of information each historically situated device prioritizes.",
 "article_title": "Visibility and meaning in topic models and 18th-century subject indexes",
 "authors": [
 {
 "given": " Jeffrey M.",
 "family": "Binder",
 "affiliation": [
 {
 "original_name": "Department of English, The Graduate Center, City University of New York, New York, NY, USA",
 "normalized_name": "City University of New York",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00453a208",
 "GRID": "grid.212340.6"
 }
 }
 ]
 },
 {
 "given": " Collin",
 "family": "Jennings",
 "affiliation": [
 {
 "original_name": "Department of English, New York University, New York, NY, USA",
 "normalized_name": "New York University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0190ak572",
 "GRID": "grid.137628.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-05-09",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu015",
 "identifier": {
 "string_id": "10.1093/llc/fqu015",
 "id_scheme": "DOI"
 },
 "abstract": "Computer simulation is the only practical way to model diffusion of cultural features, including speech. We describe the use of a cellular automaton to model feature diffusion as the adaptive aspect of the complex system of speech. Throughout hundreds of iterations that correspond to the daily interaction of speakers across time, we can watch regional distributional patterns emerge as a consequence of simple update rules. A key feature of our simulations is validation with respect to distributions known to occur in survey data. We focus on the importance of appropriate visualizations to observe what is happening during the process of diffusion, with comparison between visualizations of actual survey data and visualizations applied to our simulation. In this way, we believe that we are breaking new ground in simulation of cultural interactions as complex systems. The study of speech as a complex system addresses language as an aspect of culture that emerges from human interaction. We believe that successful simulation of speech in cultural interaction as a complex system can suggest how other aspects of humanities, such as sites, artifacts, or styles in archaeology, can diffuse and change across space and time. Our successful simulation confirms our complex systems approach, and indicates how appropriate use of visualizations makes this possible.",
 "article_title": "Simulation of the Complex System of Speech Interaction: Digital Visualizations",
 "authors": [
 {
 "given": " William A.",
 "family": "Kretzschmar",
 "affiliation": [
 {
 "original_name": "Department of English, University of Georgia, Athens, GA, USA",
 "normalized_name": "University of Georgia",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00te3t702",
 "GRID": "grid.213876.9"
 }
 }
 ]
 },
 {
 "given": " Ilkka",
 "family": "Juuso",
 "affiliation": [
 {
 "original_name": "Department of Information Engineering, University of Oulu, Oulu, Finland",
 "normalized_name": "University of Oulu",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/03yj89h83",
 "GRID": "grid.10858.34"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-05-04",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu016",
 "identifier": {
 "string_id": "10.1093/llc/fqu016",
 "id_scheme": "DOI"
 },
 "abstract": "Based on Burrows's measure of stylometric difference that uses frequencies of most frequent words, Rolling Delta is a method for revealing stylometric signals of two (or more) authors in a collaborative text. It is applied here to study the texts written jointly by Joseph Conrad and Ford Madox Ford, producing results that generally confirm the usual critical consensus on the visibility of the two author's hand. It also confirms that Ford's claims to a sizeable fragment in Nostromo are unfounded.",
 "article_title": "Collaborative authorship: Conrad, Ford and Rolling Delta",
 "authors": [
 {
 "given": " Jan",
 "family": "Rybicki",
 "affiliation": [
 {
 "original_name": "Institute of English Studies, Jagiellonian University, Kraków, Poland",
 "normalized_name": "Jagiellonian University",
 "country": "Poland",
 "identifiers": {
 "ror": "https://ror.org/03bqmcz70",
 "GRID": "grid.5522.0"
 }
 }
 ]
 },
 {
 "given": " David",
 "family": "Hoover",
 "affiliation": [
 {
 "original_name": "Department of English, New York University, New York, NY, USA",
 "normalized_name": "New York University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0190ak572",
 "GRID": "grid.137628.9"
 }
 }
 ]
 },
 {
 "given": " Mike",
 "family": "Kestemont",
 "affiliation": [
 {
 "original_name": "ISLN/CLiPS, University of Antwerp, Belgium",
 "normalized_name": "University of Antwerp",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/008x57b05",
 "GRID": "grid.5284.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-04-29",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu012",
 "identifier": {
 "string_id": "10.1093/llc/fqu012",
 "id_scheme": "DOI"
 },
 "abstract": "This study examines the relationship between the frequencies of clause combination and the distribution of discourse-pragmatic markers of cohesion in a subsample of the Susanne corpus. It addresses the theory that clause grammar constitutes a form of grammar-cued discourse coherence which functions as an integrated system with other methods of managing coherence in language. Evidence is sought for whether increased clause density in a corpus correlates with a reduction in explicit cohesive devices. To address this, a computational approach is outlined for the coding of cohesion in a corpus, using a semi-automated data mining procedure. To validate this approach, it is compared with cohesion measures on the same data using the NLP tool Coh-Metrix 3.0. The two approaches are shown to positively correlate on a series of measures, suggesting they significantly overlap in quantifying the cohesion construct. The final analysis of the tagged corpus indicates that as frequencies of clause combination increase in a text, the use of explicit lexical cohesive devices decrease. Also, higher frequencies of clause combination positively correlate with an increased use of grammatical cohesive devices. Findings are interpreted as generally aligning with the expectations of the theoretical framework known as the Adaptive Approach to Grammar.",
 "article_title": "An analysis of the relationship between cohesion and clause combination in English discourse employing NLP and data mining approaches",
 "authors": [
 {
 "given": " Clarence",
 "family": "Green",
 "affiliation": [
 {
 "original_name": "School of Languages and Linguistics, University of Melbourne, Melbourne, Australia",
 "normalized_name": "University of Melbourne",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/01ej9dk98",
 "GRID": "grid.1008.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-04-11",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu011",
 "identifier": {
 "string_id": "10.1093/llc/fqu011",
 "id_scheme": "DOI"
 },
 "abstract": "In this article, I present two case studies that show how biographical and intellectual history can benefit from corpus-based linguistics and how databases from different disciplines can cross-pollinate. (i) Combining information from the PASE.ac.uk prosopography and syntactically annotated corpora, I show that the choice of auxiliary with ofslægen ‘killed’ in the Anglo-Saxon Chronicle is related to how the killing occurred, with wearð ofslægen consistently signalling death in battle. This finding sheds new light on the deaths of people like king Osred (716) and the earls Burghelm and Muca (822). (ii) The syntactic choice between it happened that X Y-ed or X happened to Y in late Middle English texts appears to determine whether the scribe/author believes X to be in control of what happens, providing novel evidence on medieval views of accountability levels with regard to adultery, sinning, and casualties. Particular attention is paid to the language use of the scribe of the late medieval Alphabet of Tales and how it reveals his pragmatic attitude towards sex outside marriage.",
 "article_title": "What grammar reveals about sex and death: interdisciplinary applications of corpus-based linguistics",
 "authors": [
 {
 "given": " Peter",
 "family": "Petré",
 "affiliation": [
 {
 "original_name": "KU Leuven, Research Unit Linguistics & Research Foundation Flanders, Belgium",
 "normalized_name": "KU Leuven",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/05f950310",
 "GRID": "grid.5596.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-04-02",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu005",
 "identifier": {
 "string_id": "10.1093/llc/fqu005",
 "id_scheme": "DOI"
 },
 "abstract": "Digital Humanities (DH) has come a long way towards establishing itself as a dynamic and innovative field of study. However, it has been pointed out that the DH community predominantly comprises scholars from a handful of mainly English-speaking countries, and a current challenge is achieving a broader internationalization of the DH community. This article provides an overview of the landscape in terms of geo-linguistic diversity, as well as reviewing current DH initiatives to broaden regional and linguistic diversity and identifies some of the main challenges ahead. The aim of this article is to serve as a benchmark of the current situation and suggest areas where further research is required.",
 "article_title": "Geographical and linguistic diversity in the Digital Humanities",
 "authors": [
 {
 "given": " Isabel",
 "family": "Galina Russell",
 "affiliation": [
 {
 "original_name": "Instituto de Investigaciones Bibliográficas, Universidad Nacional Autónoma de México (UNAM), Mexico",
 "normalized_name": "National Autonomous University of Mexico",
 "country": "Mexico",
 "identifiers": {
 "ror": "https://ror.org/01tmp8f25",
 "GRID": "grid.9486.3"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-03-29",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu007",
 "identifier": {
 "string_id": "10.1093/llc/fqu007",
 "id_scheme": "DOI"
 },
 "abstract": "Interoperability is the key term within the framework of the European-funded research project Interedition,1 whose aim is ‘to encourage the creators of tools for textual scholarship to make their functionality available to others, and to promote communication between scholars so that we can raise awareness of innovative working methods’. The tools developed by Interedition’s ‘Prototyping’ working group were tested by other research teams, which formulate strategic recommendations. To this purpose, the Centre for Manuscript Genetics (University of Antwerp), the Huygens Institute for the History of the Netherlands (The Hague), and the University of Würzburg have been working together within the framework of Interedition. One of the concrete results of collaboration is the development and fine-tuning of the text collation tool CollateX.2 In this article, we would like to investigate how the architecture of a digital archive containing modern manuscripts can be designed in such a way that users can autonomously collate textual units of their choice with the help of the collation tool CollateX and thus decide for themselves how efficiently this digital architecture functions—as an archive, as a genetic dossier, or as an edition. The first part introduces CollateX and its internal concepts and heuristics as a tool for digitally supported collation. How this tool can be integrated in the infrastructure of an electronic edition is discussed in part two. The third and final part examines the possibility of deploying CollateX for the collation of modern manuscripts by means of a test case: the Beckett Digital Manuscript Project (www.beckettarchive.org).",
 "article_title": "Computer-supported collation of modern manuscripts: CollateX and the Beckett Digital Manuscript Project",
 "authors": [
 {
 "given": " Ronald",
 "family": "Haentjens Dekker",
 "affiliation": [
 {
 "original_name": "Department of IT R&D, Huygens Institute for the History of the Netherlands, Royal Netherlands Academy of Arts and Sciences, The Netherlands",
 "normalized_name": "Royal Netherlands Academy of Arts and Sciences",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/043c0p156",
 "GRID": "grid.418101.d"
 }
 }
 ]
 },
 {
 "given": " Dirk",
 "family": "van Hulle",
 "affiliation": [
 {
 "original_name": "Department of Literary Studies, University of Antwerp, Antwerp, Belgium",
 "normalized_name": "University of Antwerp",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/008x57b05",
 "GRID": "grid.5284.b"
 }
 }
 ]
 },
 {
 "given": " Gregor",
 "family": "Middell",
 "affiliation": [
 {
 "original_name": "Institut für Deutsche Philologie, Universität Würzburg, Würzburg, Germany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Vincent",
 "family": "Neyt",
 "affiliation": [
 {
 "original_name": "Department of Literary Studies, University of Antwerp, Antwerp, Belgium",
 "normalized_name": "University of Antwerp",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/008x57b05",
 "GRID": "grid.5284.b"
 }
 }
 ]
 },
 {
 "given": " Joris",
 "family": "van Zundert",
 "affiliation": [
 {
 "original_name": "Methodology Research Program, Huygens Institute for the History of the Netherlands, Royal Netherlands Academy of Arts and Sciences, The Netherlands",
 "normalized_name": "Royal Netherlands Academy of Arts and Sciences",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/043c0p156",
 "GRID": "grid.418101.d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-03-20",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu008",
 "identifier": {
 "string_id": "10.1093/llc/fqu008",
 "id_scheme": "DOI"
 },
 "abstract": "Quantitative stylometry of ten translations of the same Bible passage into English, followed by Ward clustering, produces a dendrogram that reflects the well-known history and intent of the translations. We conclude that quantitative stylometry combined with clustering is a useful tool for reconstructing literary history.",
 "article_title": "Stylometric classification of different translations of the same text into the same language",
 "authors": [
 {
 "given": " Michael A.",
 "family": "Covington",
 "affiliation": [
 {
 "original_name": "Institute for Artificial Intelligence, The University of Georgia, GA, USA",
 "normalized_name": "University of Georgia",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00te3t702",
 "GRID": "grid.213876.9"
 }
 }
 ]
 },
 {
 "given": " Iris",
 "family": "Potter",
 "affiliation": [
 {
 "original_name": "Linguistics Program, The University of Georgia, GA, USA",
 "normalized_name": "University of Georgia",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00te3t702",
 "GRID": "grid.213876.9"
 }
 }
 ]
 },
 {
 "given": " Tony",
 "family": "Snodgrass",
 "affiliation": [
 {
 "original_name": "Institute for Artificial Intelligence, The University of Georgia, GA, USA",
 "normalized_name": "University of Georgia",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00te3t702",
 "GRID": "grid.213876.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-03-18",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu004",
 "identifier": {
 "string_id": "10.1093/llc/fqu004",
 "id_scheme": "DOI"
 },
 "abstract": "The three main objectives of the research project ‘No Problem Has Solution: A Digital Archive of the Book of Disquiet’1 are: (1) to represent the dynamics of the acts of writing and editing in the production of the LdoD2; (2) to explore the potential of the digital medium to simulate the history of this dynamics; and (3) to create a space for virtualizing the LdoD capable of fostering new dynamics of reading, editing, and researching in the encounter between readers and its material corpus of written fragments. This article describes the project’s rationale and proposes a conceptual model of the functions that the software application to be developed should be able to perform. In this model, the electronic encoding of the fragments should support radial configurations that respond to multiple interactions. This model of the dynamic and reconfigurative iterability of the archive will enable users to virtualize the book according to four functions: reader-function, editor-function, book-function, and author-function.",
 "article_title": "A model for a virtualLdoD",
 "authors": [
 {
 "given": " Manuel",
 "family": "Portela",
 "affiliation": [
 {
 "original_name": "CLP-Centre for Portuguese Literature, University of Coimbra, Portugal",
 "normalized_name": "University of Coimbra",
 "country": "Portugal",
 "identifiers": {
 "ror": "https://ror.org/04z8k9a98",
 "GRID": "grid.8051.c"
 }
 }
 ]
 },
 {
 "given": " António",
 "family": "Rito Silva",
 "affiliation": [
 {
 "original_name": "INESC-ID, Instituto Superior Técnico, University of Lisbon, Portugal",
 "normalized_name": "University of Lisbon",
 "country": "Portugal",
 "identifiers": {
 "ror": "https://ror.org/01c27hj86",
 "GRID": "grid.9983.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-03-06",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu002",
 "identifier": {
 "string_id": "10.1093/llc/fqu002",
 "id_scheme": "DOI"
 },
 "abstract": "The most common method of publishing new discoveries about art conservation techniques and research has been through traditional full-text publications. Such corpora typically only support searching via metadata (e.g. title, authors, or keywords) and full-text. In particular, it is difficult to discover valuable information about the chemical processes, experimental results, or preservation treatments associated with the conservation of paintings from a specific genre. This article addresses this problem by focusing on the extraction of structured data (that complies with a pre-defined ontology) from a distributed corpus of publications about painting conservation. Our specific extraction method involves a unique combination of named entity recognition (using gazetteer-based and machine learning-based methods) followed by relationship extraction (using rule-based and machine learning-based methods). The resulting structured data are stored in a resource description framework triple store, and a Web-based graphical user interface enables the SPARQL querying, retrieval, and display of the search results. The results from applying our techniques to a corpus of publications on art conservation indicate that our approach achieves higher quality precision and recall in extracting named entities and relations from publications, relative to alternative existing approaches.",
 "article_title": "Extracting structured data from publications in the Art Conservation Domain",
 "authors": [
 {
 "given": " Suleiman",
 "family": "Odat",
 "affiliation": [
 {
 "original_name": "School of ITEE, University of Queensland, Australia",
 "normalized_name": "University of Queensland",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00rqy9422",
 "GRID": "grid.1003.2"
 }
 }
 ]
 },
 {
 "given": " Tudor",
 "family": "Groza",
 "affiliation": [
 {
 "original_name": "School of ITEE, University of Queensland, Australia",
 "normalized_name": "University of Queensland",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00rqy9422",
 "GRID": "grid.1003.2"
 }
 }
 ]
 },
 {
 "given": " Jane",
 "family": "Hunter",
 "affiliation": [
 {
 "original_name": "School of ITEE, University of Queensland, Australia",
 "normalized_name": "University of Queensland",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00rqy9422",
 "GRID": "grid.1003.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-02-13",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqu001",
 "identifier": {
 "string_id": "10.1093/llc/fqu001",
 "id_scheme": "DOI"
 },
 "abstract": "We describe, evaluate, and improve the automatic annotation of diachronic corpora at the levels of word-class, lemma, chunks, and dependency syntax. As corpora we use the ARCHER corpus (texts from 1600 to 2000) and the ZEN corpus (texts from 1660 to 1800). Performance on Modern English is considerably lower than on Present Day English (PDE). We present several methods that improve performance. First we use the spelling normalization tool VARD to map spelling variants to their PDE equivalent, which improves tagging. We investigate the tagging changes that are due to the normalization and observe improvements, deterioration, and missing mappings. We then implement an optimized version, using VARD rules and preprocessing steps to improve normalization. We evaluate the improvement on parsing performance, comparing original text, standard VARD, and our optimized version. Over 90% of the normalization changes lead to improved parsing, and 17.3% of all 422 manually annotated sentences get a net improved parse. As a next step, we adapt the parser’s grammar, add a semantic expectation model and a model for prepositional phrases (PP)-attachment interaction to the parser. These extensions improve parser performance, marginally on PDE, more considerably on earlier texts—2—5% on PP-attachment relations (e.g. from 63.6 to 68.4% and from 70 to 72.9% on 17th century texts). Finally, we briefly outline linguistic applications and give two examples: gerundials and auxiliary verbs in the ZEN corpus, showing that despite high noise levels linguistic signals clearly emerge, opening new possibilities for large-scale research of gradient phenomena in language change.",
 "article_title": "Parsing early and late modern English corpora",
 "authors": [
 {
 "given": " Gerold",
 "family": "Schneider",
 "affiliation": [
 {
 "original_name": "English Department, University of Zurich, Switzerland",
 "normalized_name": "University of Zurich",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/02crff812",
 "GRID": "grid.7400.3"
 }
 }
 ]
 },
 {
 "given": " Hans Martin",
 "family": "Lehmann",
 "affiliation": [
 {
 "original_name": "English Department, University of Zurich, Switzerland",
 "normalized_name": "University of Zurich",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/02crff812",
 "GRID": "grid.7400.3"
 }
 }
 ]
 },
 {
 "given": " Peter",
 "family": "Schneider",
 "affiliation": [
 {
 "original_name": "English Department, University of Zurich, Switzerland",
 "normalized_name": "University of Zurich",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/02crff812",
 "GRID": "grid.7400.3"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2014-02-07",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt065",
 "identifier": {
 "string_id": "10.1093/llc/fqt065",
 "id_scheme": "DOI"
 },
 "abstract": "When evaluating machine translation outputs, linguistics is usually taken into account implicitly. Annotators have to decide whether a sentence is better than another or not, using, for example, adequacy and fluency criteria or, as recently proposed, editing the translation output so that it has the same meaning as a reference translation, and it is understandable. Therefore, the important fields of linguistics of meaning (semantics) and grammar (syntax) are indirectly considered. In this study, we propose to go one step further towards a linguistic human evaluation. The idea is to introduce linguistics implicitly by formulating precise guidelines. These guidelines strictly mark the difference between the sub-fields of linguistics such as: morphology, syntax, semantics, and orthography. We show our guidelines have a high inter-annotation agreement and wide-error coverage. Additionally, we examine how the linguistic human evaluation data correlate with: among different types of machine translation systems (rule and statistical-based); and with adequacy and fluency.",
 "article_title": "Towards human linguistic machine translation evaluation",
 "authors": [
 {
 "given": " Marta R.",
 "family": "Costa-jussà",
 "affiliation": [
 {
 "original_name": "Institute for Infocomm Research. 1 Fusionopolis Way, 21-01 Connexis (South Tower) Singapore 138632",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Mireia",
 "family": "Farrús",
 "affiliation": [
 {
 "original_name": "Pompeu Fabra University. C/ Tanger/Roc Boronat, 08018 Barcelona",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-12-07",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt068",
 "identifier": {
 "string_id": "10.1093/llc/fqt068",
 "id_scheme": "DOI"
 },
 "abstract": "This article explores a concept of method in computer-assisted literary criticism, using a current digital humanities project as a case study. The project is investigating aspects of intertextuality between English poetry and the Oxford English Dictionary, second edition (OED2). In the course of adopting, applying, and adapting methods to guide computer-assisted comparisons between OED2 and poetry corpora, questions have arisen about the desired relations among research question, method, result, and outcome. Arguing that additional deliberation on what method means to us is now both appropriate and essential to the maturing discipline of digital humanities, in this article I discuss what digital methods have shown us about OED2 and Geoffrey Hill’s notoriously intertextual long poem The Triumph of Love (1998), both as an example and an illustration of one way of reflecting on these questions: a concept of digital method as tautology.",
 "article_title": "Method as tautology in the digital humanities",
 "authors": [
 {
 "given": " David-Antoine",
 "family": "Williams",
 "affiliation": [
 {
 "original_name": "English Department, St Jerome’s University in the University of Waterloo, Canada",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-11-30",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt066",
 "identifier": {
 "string_id": "10.1093/llc/fqt066",
 "id_scheme": "DOI"
 },
 "abstract": "The aim of this study is to find such a minimal size of text samples for authorship attribution that would provide stable results independent of random noise. A few controlled tests for different sample lengths, languages, and genres are discussed and compared. Depending on the corpus used, the minimal sample length varied from 2,500 words (Latin prose) to 5,000 or so words (in most cases, including English, German, Polish, and Hungarian novels). Another observation is connected with the method of sampling: contrary to common sense, randomly excerpted ‘bags of words’ turned out to be much more effective than the classical solution, i.e. using original sequences of words (‘passages’) of desired size. Although the tests have been performed using the Delta method (Burrows, J.F. (2002). ‘Delta’: a measure of stylistic difference and a guide to likely authorship. Literary and Linguistic Computing, 17(3): 267–87) applied to the most frequent words, some additional experiments have been conducted for support vector machines and k-NN applied to most frequent words, character 3-grams, character 4-grams, and parts-of-speech-tag 3-grams. Despite significant differences in overall attributive success rate between particular methods and/or style markers, the minimal amount of textual data needed for reliable authorship attribution turned out to be method-independent.",
 "article_title": "Does size matter? Authorship attribution, small samples, big problem",
 "authors": [
 {
 "given": " Maciej",
 "family": "Eder",
 "affiliation": [
 {
 "original_name": "Pedagogical University of Kraków, Poland and Polish Academy of Sciences, Institute of Polish Language, Kraków, Poland",
 "normalized_name": "Pedagogical University of Kraków",
 "country": "Poland",
 "identifiers": {
 "ror": "https://ror.org/030mz2444",
 "GRID": "grid.412464.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-11-15",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt063",
 "identifier": {
 "string_id": "10.1093/llc/fqt063",
 "id_scheme": "DOI"
 },
 "abstract": "Hildegard of Bingen (1098–1179) is one of the most influential female authors of the Middle Ages. From the point of view of computational stylistics, the oeuvre attributed to Hildegard is fascinating. Hildegard dictated her texts to secretaries in Latin, a language of which she did not master all grammatical subtleties. She therefore allowed her scribes to correct her spelling and grammar. Especially Hildegard’s last collaborator, Guibert of Gembloux, seems to have considerably reworked her works during his secretaryship. Whereas her other scribes were only allowed to make superficial linguistic changes, Hildegard would have permitted Guibert to render her language stylistically more elegant. In this article, we focus on two shorter texts: the Visio ad Guibertum missa and Visio de Sancto Martino, both of which Hildegard allegedly authored during Guibert’s secretaryship. We analyze a corpus containing the letter collections of Hildegard, Guibert, and Bernard of Clairvaux using a number of common stylometric techniques. We discuss our results in the light of the Synergy Hypothesis, suggesting that texts resulting from collaboration can display a style markedly different from that of the collaborating authors. Finally, we demonstrate that Guibert must have reworked the disputed visionary texts allegedly authored by Hildegard to such an extent that style-oriented computational procedures attribute the texts to Guibert.",
 "article_title": "Collaborative authorship in the twelfth century: A stylometric study of Hildegard of Bingen and Guibert of Gembloux",
 "authors": [
 {
 "given": " Mike",
 "family": "Kestemont",
 "affiliation": [
 {
 "original_name": "Institute for the Study of Literature in the Low Countries & CLiPS Computational Linguistics Group, University of Antwerp, Belgium",
 "normalized_name": "University of Antwerp",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/008x57b05",
 "GRID": "grid.5284.b"
 }
 }
 ]
 },
 {
 "given": " Sara",
 "family": "Moens",
 "affiliation": [
 {
 "original_name": "History Department, Ghent University, Belgium",
 "normalized_name": "Ghent University",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/00cv9y106",
 "GRID": "grid.5342.0"
 }
 }
 ]
 },
 {
 "given": " Jeroen",
 "family": "Deploige",
 "affiliation": [
 {
 "original_name": "History Department, Ghent University, Belgium",
 "normalized_name": "Ghent University",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/00cv9y106",
 "GRID": "grid.5342.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-10-27",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt059",
 "identifier": {
 "string_id": "10.1093/llc/fqt059",
 "id_scheme": "DOI"
 },
 "abstract": "There is a need in the humanities for a 3D WebGIS with analytical tools that allow researchers to analyze 3D models linked to spatially referenced data. Geographic Information Systems (GIS) allow for complex spatial analysis of 2.5D data. For example, they offer bird’s eye views of landscapes with extruded building footprints, but one cannot ‘get on the ground’ and interact with true 3D models from a pedestrian perspective. Meanwhile, 3D models and virtual environments visualize data in 3D space, but analytical tools are simple rotation or lighting effects. The MayaArch3D Project is developing a 3D WebGIS—called QueryArch3D—to allow these two distinct approaches to ‘talk to each other’ for studies of architecture and landscapes—in this case, the eighth-century Maya kingdom of Copan, Honduras. With this tool, researchers can search and query, in real time via a virtual reality (VR) environment, segmented 3D models of multiple resolutions (as well as computer-assisted design and reality-based) that are linked to attribute data stored in a spatial database. Beta tests indicate that this tool can assist researchers in expanding questions and developing new analytical methods in humanities research. This article summarizes the results of a pilot project that started in 2009, with an art historian and an archaeologist’s collaborative research on the ancient Maya kingdom and UNESCO World Heritage site of Copan in Honduras—called MayaArch3D. The project researches innovative approaches to integrate GIS, 3D digital models, and VR environments online for teaching and research on ancient architecture and landscapes. It has grown into an international, interdisciplinary project that brings together art historians, archaeologists, and cultural resource managers with experts in remote sensing, photogrammetry, 3D modeling, and VR. The Start Up Phase was funded by two National Endowment for the Humanities, Digital Humanities Start-Up grants to the University of New Mexico (PI: Jennifer von Schwerin) and developed and beta tested a pipeline and prototype 3D WebGIS—called QueryArch3D. The prototype version is available at http://mayaarch3d.org/project-history/). Project results indicate that it is possible to bridge the gap between 3D and GIS to create a resource for researchers of Maya architecture to compare and analyze 3D models and archaeological data in the context of a geographically referenced, VR landscape.",
 "article_title": "The MayaArch3D project: A 3D WebGIS for analyzing ancient architecture and landscapes",
 "authors": [
 {
 "given": "Jennifer",
 "family": "von Schwerin",
 "affiliation": [
 {
 "original_name": "Commission for the Archaeology of Non-European Cultures, German Archaeological Institute, 53173 Bonn, Germany",
 "normalized_name": "Deutsches Archäologisches Institut",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/041qv0h25",
 "GRID": "grid.424195.f"
 }
 }
 ]
 },
 {
 "given": "Heather",
 "family": "Richards-Rissetto",
 "affiliation": [
 {
 "original_name": "3D Optical Metrology Unit, Bruno Kessler Foundation, Trento, Italy",
 "normalized_name": "Fondazione Bruno Kessler",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/01j33xk10",
 "GRID": "grid.11469.3b"
 }
 },
 {
 "original_name": "Department of Anthropology, University of New Mexico, Albuquerque, New Mexico, USA",
 "normalized_name": "University of New Mexico",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05fs6jp91",
 "GRID": "grid.266832.b"
 }
 }
 ]
 },
 {
 "given": "Fabio",
 "family": "Remondino",
 "affiliation": [
 {
 "original_name": "3D Optical Metrology Unit, Bruno Kessler Foundation, Trento, Italy",
 "normalized_name": "Fondazione Bruno Kessler",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/01j33xk10",
 "GRID": "grid.11469.3b"
 }
 }
 ]
 },
 {
 "given": "Giorgio",
 "family": "Agugiaro",
 "affiliation": [
 {
 "original_name": "3D Optical Metrology Unit, Bruno Kessler Foundation, Trento, Italy",
 "normalized_name": "Fondazione Bruno Kessler",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/01j33xk10",
 "GRID": "grid.11469.3b"
 }
 }
 ]
 },
 {
 "given": "Gabrio",
 "family": "Girardi",
 "affiliation": [
 {
 "original_name": "Graphitech Center for Advanced Computer Graphics Technologies, Trento, Italy",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-09-27",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt053",
 "identifier": {
 "string_id": "10.1093/llc/fqt053",
 "id_scheme": "DOI"
 },
 "abstract": "In this article, we provide a discussion of the concept of visual interactive workflows, how they relate to our previous work on structured surfaces, and how they have been adapted to experiments in managing articles for journal publication and managing biographical histories being written and tagged in XML. We conclude with a user experience study of the prototypes, which suggests that they are relatively acceptable at the level of reflective response, but might benefit from more iteration in their use of process and element metaphors.",
 "article_title": "Visual workflow interfaces for editorial processes",
 "authors": [
 {
 "given": " Luciano",
 "family": "Frizzera",
 "affiliation": [
 {
 "original_name": "University of Alberta, Canada",
 "normalized_name": "University of Alberta",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/0160cpw27",
 "GRID": "grid.17089.37"
 }
 }
 ]
 },
 {
 "given": " Milena",
 "family": "Radzikowska",
 "affiliation": [
 {
 "original_name": "Mount Royal University, Canada",
 "normalized_name": "Mount Royal University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04evsam41",
 "GRID": "grid.411852.b"
 }
 }
 ]
 },
 {
 "given": " Geoff",
 "family": "Roeder",
 "affiliation": [
 {
 "original_name": "University of British Columbia, Canada",
 "normalized_name": "University of British Columbia",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03rmrcq20",
 "GRID": "grid.17091.3e"
 }
 }
 ]
 },
 {
 "given": " Ernesto",
 "family": "Peña",
 "affiliation": [
 {
 "original_name": "University of British Columbia, Canada",
 "normalized_name": "University of British Columbia",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03rmrcq20",
 "GRID": "grid.17091.3e"
 }
 }
 ]
 },
 {
 "given": " Teresa",
 "family": "Dobson",
 "affiliation": [
 {
 "original_name": "University of British Columbia, Canada",
 "normalized_name": "University of British Columbia",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03rmrcq20",
 "GRID": "grid.17091.3e"
 }
 }
 ]
 },
 {
 "given": " Stan",
 "family": "Ruecker",
 "affiliation": [
 {
 "original_name": "IIT Institute of Design, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Geoffrey",
 "family": "Rockwell",
 "affiliation": [
 {
 "original_name": "University of Alberta, Canada",
 "normalized_name": "University of Alberta",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/0160cpw27",
 "GRID": "grid.17089.37"
 }
 }
 ]
 },
 {
 "given": " Susan",
 "family": "Brown",
 "affiliation": [
 {
 "original_name": "Guelph University, Canada",
 "normalized_name": "University of Guelph",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/01r7awg59",
 "GRID": "grid.34429.38"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-09-19",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt060",
 "identifier": {
 "string_id": "10.1093/llc/fqt060",
 "id_scheme": "DOI"
 },
 "abstract": "Scholars are using the Web every day to search, read, collaborate, and ultimately do their research. While some of the basic activities that the scholars do, such as reading and writing papers, are already well supported in the digital world, some essential scholarly primitives, such as annotation, augmentation, contextualization, and externalization, do not yet have clear support in terms of software tools. What scholars ultimately do during their research activity is to iteratively and collaboratively create new knowledge. With the advent of the Digital Humanities, we now have the opportunity—and technology—to capture at least a part of this knowledge and make it available as machine-processable data so to be better explorable and discoverable. In this paper, we present and discuss Pundit: a novel semantic annotation tool that enables scholars to collect, annotate, and contextualize Web resources. Deep-linking is used in conjunction with an RDF-based data model to allow granular selection of content (e.g. text excerpts, image fragments). Pundit aims at enabling scholars to produce meaningful machine-readable data that captures the semantics of their annotations. By providing a customizable annotation environment, where domain specific vocabularies can be loaded, and easy ways of integrating with existing Web archives or libraries, Pundit enables users to publish their annotations and collaboratively build a semantic graph. Such a graph can be consumed via HTTP APIs and standard SPARQL, thus allowing existing Linked Data applications to easily work with the data and Web clients in general to build specific visualizations.",
 "article_title": "Pundit: augmenting web contents with semantics",
 "authors": [
 {
 "given": " Marco",
 "family": "Grassi",
 "affiliation": [
 {
 "original_name": "Semedia, Università Politecnica delle Marche, Italy",
 "normalized_name": "Marche Polytechnic University",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/00x69rs40",
 "GRID": "grid.7010.6"
 }
 }
 ]
 },
 {
 "given": " Christian",
 "family": "Morbidoni",
 "affiliation": [
 {
 "original_name": "Semedia, Università Politecnica delle Marche, Italy",
 "normalized_name": "Marche Polytechnic University",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/00x69rs40",
 "GRID": "grid.7010.6"
 }
 }
 ]
 },
 {
 "given": " Michele",
 "family": "Nucci",
 "affiliation": [
 {
 "original_name": "Semedia, Università Politecnica delle Marche, Italy",
 "normalized_name": "Marche Polytechnic University",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/00x69rs40",
 "GRID": "grid.7010.6"
 }
 }
 ]
 },
 {
 "given": " Simone",
 "family": "Fonda",
 "affiliation": [
 {
 "original_name": "Net7 SRL, Italy",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Francesco",
 "family": "Piazza",
 "affiliation": [
 {
 "original_name": "Semedia, Università Politecnica delle Marche, Italy",
 "normalized_name": "Marche Polytechnic University",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/00x69rs40",
 "GRID": "grid.7010.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-09-19",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt061",
 "identifier": {
 "string_id": "10.1093/llc/fqt061",
 "id_scheme": "DOI"
 },
 "abstract": "In this article we apply up-to-date methods of quantitative language comparison, inspired by algorithms successfully applied in bioinformatics to decode DNA and determine the genetic relatedness of humans, to language data in an attempt to shed light on the current situation of a family of languages called Dogon, which are spoken in Mali, West Africa. Our aim is to determine the linguistic subgroupings of these languages, which we believe will shed light on their prehistory, highlight the linguistic diversity of these groups and which may ultimately inform studies on the cultural boundaries of these languages.",
 "article_title": "Investigating the relatedness of the endangered Dogon languages",
 "authors": [
 {
 "given": " Steven",
 "family": "Moran",
 "affiliation": [
 {
 "original_name": "University of Marburg",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "University of Zurich",
 "normalized_name": "University of Zurich",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/02crff812",
 "GRID": "grid.7400.3"
 }
 }
 ]
 },
 {
 "given": " Jelena",
 "family": "Prokić",
 "affiliation": [
 {
 "original_name": "University of Marburg",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-09-18",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt058",
 "identifier": {
 "string_id": "10.1093/llc/fqt058",
 "id_scheme": "DOI"
 },
 "abstract": "This research article provides a summary of our approach in providing integrated multilingual access to diverse digital archives of Japanese Ukiyo-e prints. We propose a novel method, which generates links across databases using Linked Data. A retrieval system has been developed for realizing the proposed method, which dynamically creates links to miscellaneous Linked Data resources from authority data. By using the proposed method, users would allowed to access to additional data about a certain record in multiple databases not depending on languages and formats of each database. Experimental evaluations have conducted to measure reliability of the generated links. The experimental results show high accuracy rate and prove the effectiveness of the proposed method. Links to major Linked Data resources were created successfully.",
 "article_title": "Linked data driven multilingual access to diverse Japanese Ukiyo-e databases by generating links dynamically",
 "authors": [
 {
 "given": " Biligsaikhan",
 "family": "Batjargal",
 "affiliation": [
 {
 "original_name": "Kinugasa Research Organization, Ritsumeikan University, Japan",
 "normalized_name": "Ritsumeikan University",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/0197nmd03",
 "GRID": "grid.262576.2"
 }
 }
 ]
 },
 {
 "given": " Takeo",
 "family": "Kuyama",
 "affiliation": [
 {
 "original_name": "Graduate School of Information Science and Engineering, Ritsumeikan University, Japan",
 "normalized_name": "Ritsumeikan University",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/0197nmd03",
 "GRID": "grid.262576.2"
 }
 }
 ]
 },
 {
 "given": " Fuminori",
 "family": "Kimura",
 "affiliation": [
 {
 "original_name": "Kinugasa Research Organization, Ritsumeikan University, Japan",
 "normalized_name": "Ritsumeikan University",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/0197nmd03",
 "GRID": "grid.262576.2"
 }
 }
 ]
 },
 {
 "given": " Akira",
 "family": "Maeda",
 "affiliation": [
 {
 "original_name": "College of Information Science and Engineering, Ritsumeikan University, Japan",
 "normalized_name": "Ritsumeikan University",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/0197nmd03",
 "GRID": "grid.262576.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-09-15",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt057",
 "identifier": {
 "string_id": "10.1093/llc/fqt057",
 "id_scheme": "DOI"
 },
 "abstract": "According to Saussure (Saussure and Harris, 2001), there are two systems of writing. Phonetic systems try to respond to the succession of sounds that make up a word, based on the irreducible elements used in speaking. In an ideographic system, each word is represented by a single sign that is unrelated to the sounds of the word itself, but expresses the idea which the word represents. The classic example of an ideographic writing system is Chinese. There is a common misunderstanding that treats each Chinese character as a separate sign. Hanzi (the system of Chinese Characters) serves as a kind of common information carrier created and shared by the whole Chinese society, and as such it is obviously neither disorderly nor unsystematic. On the contrary, there must be some intrinsic laws that make Hanzi the most mature ideographic system in the world. As Complex Network analysis has become an effective tool to analyze complex systems, this article aims to use some of these methods to identify such intrinsic laws of the Hanzi system.",
 "article_title": "Complex network perspective on graphic form system of Hanzi",
 "authors": [
 {
 "given": " Jiajia",
 "family": "Hu",
 "affiliation": [
 {
 "original_name": "School of Chinese Language and Literature, Beijing Normal University, Beijing 100875, China",
 "normalized_name": "Beijing Normal University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/022k4wk35",
 "GRID": "grid.20513.35"
 }
 },
 {
 "original_name": "Research Center for Folklore, Classics and Chinese Characters, Beijing Normal University, Beijing 100875, China",
 "normalized_name": "Beijing Normal University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/022k4wk35",
 "GRID": "grid.20513.35"
 }
 }
 ]
 },
 {
 "given": " Ning",
 "family": "Wang",
 "affiliation": [
 {
 "original_name": "School of Chinese Language and Literature, Beijing Normal University, Beijing 100875, China",
 "normalized_name": "Beijing Normal University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/022k4wk35",
 "GRID": "grid.20513.35"
 }
 },
 {
 "original_name": "Research Center for Folklore, Classics and Chinese Characters, Beijing Normal University, Beijing 100875, China",
 "normalized_name": "Beijing Normal University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/022k4wk35",
 "GRID": "grid.20513.35"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-09-14",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt054",
 "identifier": {
 "string_id": "10.1093/llc/fqt054",
 "id_scheme": "DOI"
 },
 "abstract": "Although a substantial corpus of digital materials is now available to scholarship across the disciplines, objective evidence of their use, impact, and value, based on a robust assessment, is sparse. Traditional methods of assessment of impact in the humanities, notably citation in scholarly publications, are not an effective way of assessing impact of digital content. These issues are problematic in the field of Digital Humanities where there is a need to effectively assess impact to justify its continued funding and existence. A number of qualitative and quantitative methods exist that can be used to monitor the use of digital resources in various contexts although they have yet to be applied widely. These have been made available to the creators, managers, and funders of digital content in an accessible form through the TIDSR (Toolkit for the Impact of Digital Scholarly Resources) developed by the Oxford Internet Institute. In 2011, the authors of this article developed the SPHERE project (Stormont Parliamentary Hansards: Embedded in Research and Education) specifically to use TIDSR to evaluate the use and impact of The Stormont Papers, a digital collection of the Hansards of the Stormont Northern Irish Parliament from 1921 to 1972. This article presents the methodology, findings, and analysis of the project. The authors argue that TIDSR is a useful and, critically, transferrable method to understand and increase the impact of digital resources. The findings of the project are modified into a series of wider recommendations on protecting the investment in digital resources by increasing their use, value, and impact. It is reasonable to suggest that effectively showing the impact of Digital Humanities is critical to its survival.",
 "article_title": "Assessing and measuring impact of a digital collection in the humanities: An analysis of the SPHERE (Stormont Parliamentary Hansards: Embedded in Research and Education) Project",
 "authors": [
 {
 "given": " Lorna M.",
 "family": "Hughes",
 "affiliation": [
 {
 "original_name": "National Library of Wales",
 "normalized_name": "National Library of Wales",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/03rjyp183",
 "GRID": "grid.421620.3"
 }
 }
 ]
 },
 {
 "given": " Paul S.",
 "family": "Ell",
 "affiliation": [
 {
 "original_name": "Queen’s University Belfast",
 "normalized_name": "Queen's University Belfast",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/00hswnk62",
 "GRID": "grid.4777.3"
 }
 }
 ]
 },
 {
 "given": " Gareth A. G.",
 "family": "Knight",
 "affiliation": [
 {
 "original_name": "London School of Hygiene & Tropical Medicine",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Milena",
 "family": "Dobreva",
 "affiliation": [
 {
 "original_name": "University of Malta",
 "normalized_name": "University of Malta",
 "country": "Malta",
 "identifiers": {
 "ror": "https://ror.org/03a62bv60",
 "GRID": "grid.4462.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-09-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt050",
 "identifier": {
 "string_id": "10.1093/llc/fqt050",
 "id_scheme": "DOI"
 },
 "abstract": "In this article we propose an approach to the study of art history based on geography of Hispanic Baroque art by digital means that showcase the multiplicity of possible places of art. Our study advances four elements of a digital geography of art (communities, semantic maps, areas, and flows)—a methodology that can be expanded in future Digital Humanities research.",
 "article_title": "Towards a digital geography of Hispanic Baroque art",
 "authors": [
 {
 "given": "Juan Luis",
 "family": "Suárez",
 "affiliation": [
 {
 "original_name": "The CulturePlex Lab, University of Western Ontario",
 "normalized_name": "Western University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/02grkyz14",
 "GRID": "grid.39381.30"
 }
 }
 ]
 },
 {
 "given": "Fernando",
 "family": "Sancho-Caparrini",
 "affiliation": [
 {
 "original_name": "Department of Computer Science and Artificial Intelligence, University of Seville",
 "normalized_name": "University of Seville",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/03yxnpp24",
 "GRID": "grid.9224.d"
 }
 }
 ]
 },
 {
 "given": "Elika",
 "family": "Ortega",
 "affiliation": [
 {
 "original_name": "The CulturePlex Lab, University of Western Ontario",
 "normalized_name": "Western University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/02grkyz14",
 "GRID": "grid.39381.30"
 }
 }
 ]
 },
 {
 "given": "Javier",
 "family": "de la Rosa",
 "affiliation": [
 {
 "original_name": "The CulturePlex Lab, University of Western Ontario",
 "normalized_name": "Western University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/02grkyz14",
 "GRID": "grid.39381.30"
 }
 }
 ]
 },
 {
 "given": "Natalia",
 "family": "Caldas",
 "affiliation": [
 {
 "original_name": "The CulturePlex Lab, University of Western Ontario",
 "normalized_name": "Western University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/02grkyz14",
 "GRID": "grid.39381.30"
 }
 }
 ]
 },
 {
 "given": "David",
 "family": "Brown",
 "affiliation": [
 {
 "original_name": "The CulturePlex Lab, University of Western Ontario",
 "normalized_name": "Western University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/02grkyz14",
 "GRID": "grid.39381.30"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-08-15",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt045",
 "identifier": {
 "string_id": "10.1093/llc/fqt045",
 "id_scheme": "DOI"
 },
 "abstract": "Skaldic poetry is a highly complex textual phenomenon both in terms of the intricacy of the poetry and its contextual environment. Extensible Markup Language (XML) applications such as that of the Text Encoding Initiative provide a means of semantic representation of some of these complexities. XML, however, has limitations in representing semantic relationships that do not conform to the tree model. This article presents the relational data model as a way of representing the structure of skaldic texts and their contextual environment. The relational data model raises both problems and possibilities for this type of project. The main problem addressed here is the representation of the syntagmatic structures of texts in a data model that is not intrinsically ordered. The advantages are also explored, including networked data editing and management, quantitative linguistic analysis, dynamic representation of the data, and the ability to extend the structure and reuse data for related projects without creating redundancy.",
 "article_title": "Relational data modelling of textual corpora: The Skaldic Project and its extensions",
 "authors": [
 {
 "given": " Tarrin",
 "family": "Wills",
 "affiliation": [
 {
 "original_name": "University of Aberdeen",
 "normalized_name": "University of Aberdeen",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/016476m91",
 "GRID": "grid.7107.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-08-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt049",
 "identifier": {
 "string_id": "10.1093/llc/fqt049",
 "id_scheme": "DOI"
 },
 "abstract": "This contribution discusses some of the challenges involved in building an ontology for research about the philosopher Ludwig Wittgenstein. It pays special attention to different ontological conceptions (event based versus object based). It also discusses how best to model, within the ontology, conflicting views emerging in both Wittgenstein’s work and Wittgenstein scholarship. The contribution presents relevant work in progress at the Wittgenstein Archives at the University of Bergen, which has a special focus on Wittgenstein’s Nachlass, his philosophical estate.",
 "article_title": "Sharing and debating Wittgenstein by using an ontology",
 "authors": [
 {
 "given": " Alois",
 "family": "Pichler",
 "affiliation": [
 {
 "original_name": "The Wittgenstein Archives at the University of Bergen, Bergen, Norway",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Amélie",
 "family": "Zöllner-Weber",
 "affiliation": [
 {
 "original_name": "The Wittgenstein Archives at the University of Bergen, Bergen, Norway",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-08-12",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt047",
 "identifier": {
 "string_id": "10.1093/llc/fqt047",
 "id_scheme": "DOI"
 },
 "abstract": "Different computational models have been proposed to automatically determine the most probable author of a disputed text (authorship attribution). These models can be viewed as special approaches in the text categorization domain. In this perspective, in a first step we need to determine the most effective features (words, punctuation symbols, part-of-speech, bigram of words, etc.) to discriminate between different authors. To achieve this, we can consider different independent feature-scoring selection functions (information gain, gain ratio, pointwise mutual information, odds ratio, chi-square, bi-normal separation, GSS, Darmstadt Indexing Approach (DIA), and correlation coefficient). Other term selection strategies have also been suggested in specific authorship attribution studies. To compare these two families of selection procedures, we have extracted articles from two newspapers and belonging to two categories (sports and politics). To enlarge the basis of our evaluations, we have chosen one newspaper written in the English language (‘Glasgow Herald’) and a second one in Italian (‘La Stampa’). The resulting collections contain from 987 to 2,036 articles written by four to ten columnists. Using the Kullback–Leibler divergence, the chi-square measure and the Delta rule as attribution schemes, this study found that some simple selection strategies (based on occurrence frequency or document frequency) may produce similar, and sometimes better, results compared with more complex ones.",
 "article_title": "Comparative evaluation of term selection functions for authorship attribution",
 "authors": [
 {
 "given": " Jacques",
 "family": "Savoy",
 "affiliation": [
 {
 "original_name": "Computer Science Department, University of Neuchatel, Neuchâtel, Switzerland",
 "normalized_name": "University of Neuchâtel",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/00vasag41",
 "GRID": "grid.10711.36"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-08-07",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt044",
 "identifier": {
 "string_id": "10.1093/llc/fqt044",
 "id_scheme": "DOI"
 },
 "abstract": "This article demonstrates that the history of computing in the humanities is an almost uncharted research topic. It argues that this oversight must be remedied as a matter of urgency so that the evolutionary model of progress that currently dominates the field can be countered. We describe the ‘Hidden Histories’ pilot project and explore the origins and practice of oral history; in the corresponding issue of Digital Humanities Quarterly, five oral history interviews that we carried out during the project are presented. We conclude that the selection of interviews presented here demonstrate that oral history is an important and productive methodology in such research. The five oral history interviews form primary sources, which can be used in the writing of a history of computing in the humanities; furthermore, they contain new information and interpretations, which cannot be gleaned from published scholarly articles, for example, information about the varied entry routes into the field that have existed and the interrelationship between myth and history in the narratives we create about the emergence of digital humanities.",
 "article_title": "Oral History and the Hidden Histories project: towards histories of computing in the humanities",
 "authors": [
 {
 "given": " Julianne",
 "family": "Nyhan",
 "affiliation": [
 {
 "original_name": "Department of Information Studies, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Andrew",
 "family": "Flinn",
 "affiliation": [
 {
 "original_name": "Department of Information Studies, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Anne",
 "family": "Welsh",
 "affiliation": [
 {
 "original_name": "Department of Information Studies, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-07-31",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt046",
 "identifier": {
 "string_id": "10.1093/llc/fqt046",
 "id_scheme": "DOI"
 },
 "abstract": "The Department of Classics at Tufts University and the Perseus Project have jointly designed and tested an integrated platform (the Perseids Platform) on which students and scholars can collaboratively transcribe, edit, and translate Latin and Greek texts, creating vetted open source digital editions. This project, while giving students the opportunity to work with original untranslated documents, also contributes to the efforts of the scholarly community worldwide to meet the challenge of publishing large numbers of primary source documents online while preserving high editorial standards. The platform integrates the Son of SUDA Online software, originally developed to edit papyrological texts, and the Collections, Indexes, and Texts, with Extensions architecture, originally developed by the Center for Hellenic Studies of Harvard University to support the Homer Multitext Project. The present article discusses our scholarly and pedagogical objectives in developing the platform, the technical challenges we faced in the course of our work, and the results we obtained.",
 "article_title": "Developing a New Integrated Editing Platform for Source Documents in Classics",
 "authors": [
 {
 "given": " Bridget",
 "family": "Almas",
 "affiliation": [
 {
 "original_name": "The Perseus Project, Tufts University, Medford, MA, USA",
 "normalized_name": "Tufts University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05wvpxv85",
 "GRID": "grid.429997.8"
 }
 }
 ]
 },
 {
 "given": " Marie-Claire",
 "family": "Beaulieu",
 "affiliation": [
 {
 "original_name": "Department of Classics, Tufts University, Medford, MA, USA",
 "normalized_name": "Tufts University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05wvpxv85",
 "GRID": "grid.429997.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-07-26",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt039",
 "identifier": {
 "string_id": "10.1093/llc/fqt039",
 "id_scheme": "DOI"
 },
 "abstract": "In computational stylistics, any influence of unwanted noise—e.g. caused by an untidily prepared corpus—might lead to biased or false results. Relying on contaminated data is similar to using dirty test tubes in a laboratory: it inescapably means falling into systematic error. An important question is what degree of nonchalance is acceptable to obtain sufficiently reliable results. The present study attempts to verify the impact of unwanted noise in a series of experiments conducted on several corpora of English, German, Polish, Ancient Greek, and Latin prose texts. In 100 iterations, a given corpus was gradually damaged, and controlled tests for authorship were applied. The first experiment was designed to show the correlation between a dirty corpus and attribution accuracy. The second was aimed to test how disorder in word frequencies—produced by scribal and/or editorial modifications—affects the attribution abilities of particular corpora. The goal of the third experiment was to test how much ‘authorial’ data a given text needs to have to trace authorial fingerprint through a mass of external quotations.",
 "article_title": "Mind your corpus: systematic errors in authorship attribution",
 "authors": [
 {
 "given": "M.",
 "family": "Eder",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-07-24",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt040",
 "identifier": {
 "string_id": "10.1093/llc/fqt040",
 "id_scheme": "DOI"
 },
 "abstract": "Used here to describe the investigation of significant sound or prosodic patterns within the context of a system that can translate these patterns into comparative visualizations across texts, the term ‘distant listening’ is used provocatively to suggest that readers might interpret prosodic patterns as ‘noise’ (or seemingly unintelligible information) with close reading practices. In this study, we show that these same patterns appear coherent and discoverable within ProseVis, a visualization tool that supports these hermeneutics within a discovery-based paradigm that allows for new ways of making meaning. Charles Bernstein discusses ‘close listening’ as possibly contradictory to ‘ “readings” of poems that are based exclusively on the printed text and that ignore the poet’s own performances, the “total” sound of the work, and the relation of sound to semantics’ (Bernstein, 1998, p. 4). Likewise, this study considers the efficacy of using prosodic textual elements as features for similarity metrics instead of or alongside words and n-gram frequencies. In particular, this discussion describes the continued development of this work as a contribution to and within the context of authorship attribution and stylometric studies that consider the interpretability of prosodic features. To that end, in the first part of this discussion, we place the study within the theoretical and practical context of author attribution studies. In the second part of this discussion, we consider how changing similarity metric calculations through the inclusion and exclusion of certain prosodic features (such as tone and stress) and algorithmic parameters (such as the window size of sounds and weighting power) can facilitate the discovery of previously unidentifiable author-similarity patterns. Finally, in the third part of this study, we explore questions of identity construction within this framework of author attribution analysis by comparing ‘Melanctha’, the longest story in Gertrude Stein’s Three Lives (1909), with 150 different narrative voices from the First Person Narratives of the Documenting the American South collection.",
 "article_title": "Distant Listening to Gertrude Stein's 'Melanctha': Using Similarity Analysis in a Discovery Paradigm to Analyze Prosody and Author Influence",
 "authors": [
 {
 "given": " Tanya",
 "family": "Clement",
 "affiliation": [
 {
 "original_name": "School of Information, University of Texas at Austin, Austin",
 "normalized_name": "The University of Texas at Austin",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00hj54h04",
 "GRID": "grid.89336.37"
 }
 }
 ]
 },
 {
 "given": " David",
 "family": "Tcheng",
 "affiliation": [
 {
 "original_name": "Illinois Informatics Institute, University of Illinois at Urbana-Champaign, Urbana",
 "normalized_name": "University of Illinois at Urbana-Champaign",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047426m28",
 "GRID": "grid.35403.31"
 }
 }
 ]
 },
 {
 "given": " Loretta",
 "family": "Auvil",
 "affiliation": [
 {
 "original_name": "Illinois Informatics Institute, University of Illinois at Urbana-Champaign, Urbana",
 "normalized_name": "University of Illinois at Urbana-Champaign",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047426m28",
 "GRID": "grid.35403.31"
 }
 }
 ]
 },
 {
 "given": " Boris",
 "family": "Capitanu",
 "affiliation": [
 {
 "original_name": "Illinois Informatics Institute, University of Illinois at Urbana-Champaign, Urbana",
 "normalized_name": "University of Illinois at Urbana-Champaign",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047426m28",
 "GRID": "grid.35403.31"
 }
 }
 ]
 },
 {
 "given": " Joao",
 "family": "Barbosa",
 "affiliation": [
 {
 "original_name": "Texas Advanced Computing Center, University of Texas at Austin, Austin",
 "normalized_name": "The University of Texas at Austin",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00hj54h04",
 "GRID": "grid.89336.37"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-07-24",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt031",
 "identifier": {
 "string_id": "10.1093/llc/fqt031",
 "id_scheme": "DOI"
 },
 "abstract": "Much research in translation studies indicates that translated texts are ontologically different from original non-translated ones. Translated texts, in any language, can be considered a dialect of that language, known as ‘translationese’. Several characteristics of translationese have been proposed as universal in a series of hypotheses. In this work, we test these hypotheses using a computational methodology that is based on supervised machine learning. We define several classifiers that implement various linguistically informed features, and assess the degree to which different sets of features can distinguish between translated and original texts. We demonstrate that some feature sets are indeed good indicators of translationese, thereby corroborating some hypotheses, whereas others perform much worse (sometimes at chance level), indicating that some ‘universal’ assumptions have to be reconsidered.In memoriam: Miriam Shlesinger, 1947–2012",
 "article_title": "On the features of translationese",
 "authors": [
 {
 "given": " Vered",
 "family": "Volansky",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, University of Haifa, Haifa, Israel",
 "normalized_name": "University of Haifa",
 "country": "Israel",
 "identifiers": {
 "ror": "https://ror.org/02f009v59",
 "GRID": "grid.18098.38"
 }
 }
 ]
 },
 {
 "given": " Noam",
 "family": "Ordan",
 "affiliation": [
 {
 "original_name": "Institut für Angewandte Sprachwissenschaft sowie Übersetzen und Dolmetschen, Universität des Saarlandes, Saarbrücken, Germany",
 "normalized_name": "Saarland University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/01jdpyv68",
 "GRID": "grid.11749.3a"
 }
 }
 ]
 },
 {
 "given": " Shuly",
 "family": "Wintner",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, University of Haifa, Haifa, Israel",
 "normalized_name": "University of Haifa",
 "country": "Israel",
 "identifiers": {
 "ror": "https://ror.org/02f009v59",
 "GRID": "grid.18098.38"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-07-04",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt038",
 "identifier": {
 "string_id": "10.1093/llc/fqt038",
 "id_scheme": "DOI"
 },
 "abstract": "The article describes an ongoing project that aims at building a reference corpus of German computer-mediated communication (CMC) as a new component of an already existing reference corpus of written contemporary German. The ‘Deutsches Referenzkorpus zur internetbasierten Kommunikation’ (DeRiK) shall include data from the most prominent CMC genres amongst German Internet users and, thus, close a gap in the coverage of the corpus resources in the project ‘Digitales Wörterbuch der deutschen Sprache’ (DWDS), which are maintained and provided by the Berlin-Brandenburg Academy of Sciences and Humanities. The focus of the article is on the role of the DeRiK component within the DWDS framework, on sampling issues, and on CMC-specific issues of corpus annotation.",
 "article_title": "DeRiK: A German reference corpus of computer-mediated communication",
 "authors": [
 {
 "given": " Michael",
 "family": "Beißwenger",
 "affiliation": [
 {
 "original_name": "TU Dortmund University, Institut für deutsche Sprache und Literatur, Germany",
 "normalized_name": "TU Dortmund University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/01k97gp34",
 "GRID": "grid.5675.1"
 }
 }
 ]
 },
 {
 "given": " Maria",
 "family": "Ermakova",
 "affiliation": [
 {
 "original_name": "Berlin-Brandenburg Academy of Sciences and Humanities, Digitales Wörterbuch der deutschen Sprache, Germany",
 "normalized_name": "Berlin-Brandenburg Academy of Sciences and Humanities",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/05jgq9443",
 "GRID": "grid.420264.6"
 }
 }
 ]
 },
 {
 "given": " Alexander",
 "family": "Geyken",
 "affiliation": [
 {
 "original_name": "Berlin-Brandenburg Academy of Sciences and Humanities, Digitales Wörterbuch der deutschen Sprache, Germany",
 "normalized_name": "Berlin-Brandenburg Academy of Sciences and Humanities",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/05jgq9443",
 "GRID": "grid.420264.6"
 }
 }
 ]
 },
 {
 "given": " Lothar",
 "family": "Lemnitzer",
 "affiliation": [
 {
 "original_name": "Berlin-Brandenburg Academy of Sciences and Humanities, Digitales Wörterbuch der deutschen Sprache, Germany",
 "normalized_name": "Berlin-Brandenburg Academy of Sciences and Humanities",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/05jgq9443",
 "GRID": "grid.420264.6"
 }
 }
 ]
 },
 {
 "given": " Angelika",
 "family": "Storrer",
 "affiliation": [
 {
 "original_name": "TU Dortmund University, Institut für deutsche Sprache und Literatur, Germany",
 "normalized_name": "TU Dortmund University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/01k97gp34",
 "GRID": "grid.5675.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-07-04",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt035",
 "identifier": {
 "string_id": "10.1093/llc/fqt035",
 "id_scheme": "DOI"
 },
 "abstract": "Ambiguity is one of the most significant problems in Natural Language Processing. This difficulty may not be apparent to native speakers because of their natural ability at resolving it using contextual information and common sense knowledge. In contrast, current computer applications are still lacking the ability to disambiguate complex texts efficiently. The most common type of ambiguity is lexical ambiguity, and this is noticed even in highly inflectional languages such as Greek. In the present article, all the patterns of predictable lexical ambiguity in Modern Greek Language are registered, verified and quantified as occurred in the Neurolingo computational lexicon, after a study of morpho-syntactic characteristics that differentiate the ambiguous words.",
 "article_title": "Analysis of lexical ambiguity in Modern Greek using a computational lexicon",
 "authors": [
 {
 "given": "Panagiotis",
 "family": "Gakis",
 "affiliation": [
 {
 "original_name": "Department of Primary Education, University of Patras, Greece",
 "normalized_name": "University of Patras",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/017wvtq80",
 "GRID": "grid.11047.33"
 }
 }
 ]
 },
 {
 "given": "Christos",
 "family": "Panagiotakopoulos",
 "affiliation": [
 {
 "original_name": "Department of Primary Education, University of Patras, Greece",
 "normalized_name": "University of Patras",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/017wvtq80",
 "GRID": "grid.11047.33"
 }
 }
 ]
 },
 {
 "given": "Kyriakos",
 "family": "Sgarbas",
 "affiliation": [
 {
 "original_name": "Department of Electrical and Computer Engineering, University of Patras, Greece",
 "normalized_name": "University of Patras",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/017wvtq80",
 "GRID": "grid.11047.33"
 }
 }
 ]
 },
 {
 "given": "Christos",
 "family": "Tsalidis",
 "affiliation": [
 {
 "original_name": "“Neurolingo” Company",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-07-03",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt037",
 "identifier": {
 "string_id": "10.1093/llc/fqt037",
 "id_scheme": "DOI"
 },
 "abstract": "Structured Prosopography provides a formal model for representing prosopography: a branch of historical research that traditionally has focused on the identification of people that appear in historical sources. Since the 1990s, KCL’s Department of Digital Humanities has been involved in the development of structured prosopographical databases using a general ‘factoid-oriented’ model of structure that links people to the information about them via spots in primary sources that assert that information. Recent developments, particularly the World Wide Web, and its related technologies around the Semantic Web, have promoted the possibility to both interconnecting dispersed data, and allowing it to be queried semantically. To the purpose of making available our prosopographical databases on the Semantic Web, in this article we review the principles behind our established factoid-based model and reformulate it using a more interoperable approach, based on knowledge representation principles and formal ontologies. In particular, we are going to focus primarily on a high-level semantic analysis of the factoid notion, on its relation to other cultural heritage standards such as CIDOC-CRM, and on the modularity and extensibility of the proposed solutions.",
 "article_title": "Factoid-based prosopography and computer ontologies: towards an integrated approach",
 "authors": [
 {
 "given": " Michele",
 "family": "Pasin",
 "affiliation": [
 {
 "original_name": "Department of Digital Humanities, Kings College, London, UK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " John",
 "family": "Bradley",
 "affiliation": [
 {
 "original_name": "Department of Digital Humanities, Kings College, London, UK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-06-30",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt041",
 "identifier": {
 "string_id": "10.1093/llc/fqt041",
 "id_scheme": "DOI"
 },
 "abstract": "Redfern [(2012), The lognormal distribution is not an appropriate parametric model for shot length distributions of Hollywood films. Literary and Linguistic Computing, doi:10.1093/llc/fqs066] disputes the idea that the lognormal distribution is a suitable parametric model for the shot length distribution of films. The force of his arguments against the idea is diminished by problems in his exposition, the most serious is the manner in which hypothesis testing is deployed. The application fails to deal adequately with the effect sample size has on P-values, and this compromises much of the analysis. There is, nevertheless, strong evidence of a fairly systematic departure from lognormality, manifest in the fact that distributions mostly remain positively skewed after log-transformation. This is not recognized in the article and thus not exploited. The present article shows that after a second transformation, normality can be achieved for well over half the films, which are thus distributionally regular in this sense. Some suggestions as to why lognormality, or any other form of distributional regularity, might be of interest are offered at the start of the article, which concludes with an illustration of how the establishment of a distributional ‘norm’ might then be exploited.",
 "article_title": "On the distributional regularity of shot lengths in film",
 "authors": [
 {
 "given": " Mike",
 "family": "Baxter",
 "affiliation": [
 {
 "original_name": "Nottingham Trent University, UK",
 "normalized_name": "Nottingham Trent University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04xyxjd90",
 "GRID": "grid.12361.37"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-06-30",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt036",
 "identifier": {
 "string_id": "10.1093/llc/fqt036",
 "id_scheme": "DOI"
 },
 "abstract": "The purpose of this article is to examine the linguistic differences between poems written by ‘amateurs’ and those written by ‘professionals’ and then to use these characteristics to rank a number of contemporary American poems. The corpus of poems used consist of 100 poems randomly selected from a recent anthology of professional poets and a control group of 100 poems written by amateurs. The poems were reduced to ninety-eight linguistic and psycholinguistic variables, and these were used in a machine learning algorithm to build an ensemble classifier. The accuracy of the classifier was 84.5%. The probability scores of the individual poems was then used to rank the professional poems on a continuum representing amateur at one extreme and professional at the other, thereby providing an objective means of ranking contemporary poems.",
 "article_title": "Ranking contemporary American poems",
 "authors": [
 {
 "given": "Michael",
 "family": "Dalvean",
 "affiliation": [
 {
 "original_name": "Australian National University",
 "normalized_name": "Australian National University",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/019wvm592",
 "GRID": "grid.1001.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-06-29",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt032",
 "identifier": {
 "string_id": "10.1093/llc/fqt032",
 "id_scheme": "DOI"
 },
 "abstract": "Stemmatology, or the reconstruction of the transmission history of texts, is a field that stands particularly to gain from digital methods. Many scholars already take stemmatic approaches that rely heavily on computational analysis of the collated text (e.g. Robinson and O’Hara 1996; Salemans 2000; Heikkilä 2005; Windram et al. 2008 among many others). Although there is great value in computationally assisted stemmatology, providing as it does a reproducible result and allowing access to the relevant methodological process in related fields such as evolutionary biology, computational stemmatics is not without its critics. The current state-of-the-art effectively forces scholars to choose between a preconceived judgment of the significance of textual differences (the Lachmannian or neo-Lachmannian approach, and the weighted phylogenetic approach) or to make no judgment at all (the unweighted phylogenetic approach). Some basis for judgment of the significance of variation is sorely needed for medieval text criticism in particular. By this, we mean that there is a need for a statistical empirical profile of the text-genealogical significance of the different sorts of variation in different sorts of medieval texts. The rules that apply to copies of Greek and Latin classics may not apply to copies of medieval Dutch story collections; the practices of copying authoritative texts such as the Bible will most likely have been different from the practices of copying the Lives of local saints and other commonly adapted texts. It is nevertheless imperative that we have a consistent, flexible, and analytically tractable model for capturing these phenomena of transmission. In this article, we present a computational model that captures most of the phenomena of text variation, and a method for analysis of one or more stemma hypotheses against the variation model. We apply this method to three ‘artificial traditions’ (i.e. texts copied under laboratory conditions by scholars to study the properties of text variation) and four genuine medieval traditions whose transmission history is known or deduced in varying degrees. Although our findings are necessarily limited by the small number of texts at our disposal, we demonstrate here some of the wide variety of calculations that can be made using our model. Certain of our results call sharply into question the utility of excluding ‘trivial’ variation such as orthographic and spelling changes from stemmatic analysis.",
 "article_title": "Beyond the tree of texts: Building an empirical model of scribal variation through graph analysis of texts and stemmata",
 "authors": [
 {
 "given": " Tara L.",
 "family": "Andrews",
 "affiliation": [
 {
 "original_name": "KU Leuven, Belgium",
 "normalized_name": "KU Leuven",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/05f950310",
 "GRID": "grid.5596.f"
 }
 }
 ]
 },
 {
 "given": " Caroline",
 "family": "Macé",
 "affiliation": [
 {
 "original_name": "KU Leuven, Belgium",
 "normalized_name": "KU Leuven",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/05f950310",
 "GRID": "grid.5596.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-06-27",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt030",
 "identifier": {
 "string_id": "10.1093/llc/fqt030",
 "id_scheme": "DOI"
 },
 "abstract": "In an article published in Literary and Linguistic Computing, Redfern argues against the use of a lognormal distribution and summarizes previous work as ‘lacking in methodological detail and statistical rigour’. This response will summarize the article’s methodology and conclusion, arguing that while Redfern finds that films are not ‘perfectly’ lognormal, this is hardly evidence worthy of the ultimate conclusion that a lognormal fit is ‘inappropriate’. Perfection is fleeting, and cannot be expected when modeling real data. Reanalysis of Redfern’s methodology and findings shows that the lognormal distribution offers a pretty good fit.",
 "article_title": "Horseshoes, handgrenades, and model fitting: the lognormal distribution is a pretty good model for shot-length distribution of Hollywood films",
 "authors": [
 {
 "given": " Jordan",
 "family": "DeLong",
 "affiliation": [
 {
 "original_name": "Cornell University, USA",
 "normalized_name": "Cornell University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05bnh6r87",
 "GRID": "grid.5386.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-06-19",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt025",
 "identifier": {
 "string_id": "10.1093/llc/fqt025",
 "id_scheme": "DOI"
 },
 "abstract": "The political negotiation, erection, and fall of national and cultural borders represent an issue that frequently occupies the media. Given the historical importance of boundaries as a marker of cultural identity, as well as their function to separate and unite people, the Body Type Dictionary (BTD; Wilson, 2006) represents a suitable computerized content analysis measure to analyse vocabulary qualified to measure body boundaries and their penetrability. Out of this context, this study aimed to assess the inter-method reliability of the BTD (Wilson, 2006) in relation to Fisher and Cleveland’s (1956, 1958) manual scoring system for high and low barrier personalities. The results indicated that Fisher and Cleveland’s manually coded barrier and penetration imagery scores showed an acceptable positive correlation with the computerized frequency counts of the BTD’s coded barrier and penetration imagery scores, thereby indicating an inter-method reliability. In addition, barrier and penetration imagery correlated positively with primordial thought language in the picture response test, and narratives of everyday and dream memories, thereby indicating correlational validity.",
 "article_title": "Assessing the inter-method reliability and correlational validity of the Body Type Dictionary",
 "authors": [
 {
 "given": " Laura A.",
 "family": "Cariola",
 "affiliation": [
 {
 "original_name": "Lancaster University, Department of Linguistics and English Language",
 "normalized_name": "Lancaster University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04f2nsd36",
 "GRID": "grid.9835.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-05-22",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt027",
 "identifier": {
 "string_id": "10.1093/llc/fqt027",
 "id_scheme": "DOI"
 },
 "abstract": "The study investigates to what extent traditional stylistics and non-traditional stylometry can co-operate in the study of translations in terms of translatorial style. Stylistic authorship attribution methods based on a multivariate analysis of most-frequent-word frequencies are used in attempts at identifying translators. While these methods usually identify the author of the original rather than the translator, a case study is presented of the Polish translation of a single novel by Virginia Woolf, Night and Day, in which one translator took over from the other; the point of this takeover has been successfully identified with the above-mentioned methods.",
 "article_title": "The stylistics and stylometry of collaborative translation: Woolf's Night and Day in Polish",
 "authors": [
 {
 "given": " Jan",
 "family": "Rybicki",
 "affiliation": [
 {
 "original_name": "Jagiellonian University, Kraków, Poland",
 "normalized_name": "Jagiellonian University",
 "country": "Poland",
 "identifiers": {
 "ror": "https://ror.org/03bqmcz70",
 "GRID": "grid.5522.0"
 }
 }
 ]
 },
 {
 "given": " Magda",
 "family": "Heydel",
 "affiliation": [
 {
 "original_name": "Jagiellonian University, Kraków, Poland",
 "normalized_name": "Jagiellonian University",
 "country": "Poland",
 "identifiers": {
 "ror": "https://ror.org/03bqmcz70",
 "GRID": "grid.5522.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-05-28",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt028",
 "identifier": {
 "string_id": "10.1093/llc/fqt028",
 "id_scheme": "DOI"
 },
 "abstract": "The frequencies of individual words have been the mainstay of computer-assisted authorial attribution over the past three decades. The usefulness of this sort of data is attested in many benchmark trials and in numerous studies of particular authorship problems. It is sometimes argued, however, that since language as spoken or written falls into word sequences, on the ‘idiom principle’, and since language is characteristically produced in the brain in chunks, not in individual words, n-grams with n higher than 1 are superior to individual words as a source of authorship markers. In this article, we test the usefulness of word n-grams for authorship attribution by asking how many good-quality authorship markers are yielded by n-grams of various types, namely 1-grams, 2-grams, 3-grams, 4-grams, and 5-grams. We use two ways of formulating the n-grams, two corpora of texts, and two methods for finding and assessing markers. We find that when using methods based on regularly occurring markers, and drawing on all the available vocabulary, 1-grams perform best. With methods based on rare markers, and all the available vocabulary, strict 3-gram sequences perform best. If we restrict ourselves to a defined word-list of function-words to form n-grams, 2-grams offer a striking improvement on 1-grams.",
 "article_title": "Language chunking, data sparseness, and the value of a long marker list: explorations with word n-grams and authorial attribution",
 "authors": [
 {
 "given": " Alexis",
 "family": "Antonia",
 "affiliation": [
 {
 "original_name": "Centre for Literary and Linguistic Computing, University of Newcastle, Australia",
 "normalized_name": "University of Newcastle Australia",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00eae9z71",
 "GRID": "grid.266842.c"
 }
 }
 ]
 },
 {
 "given": " Hugh",
 "family": "Craig",
 "affiliation": [
 {
 "original_name": "Centre for Literary and Linguistic Computing, University of Newcastle, Australia",
 "normalized_name": "University of Newcastle Australia",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00eae9z71",
 "GRID": "grid.266842.c"
 }
 }
 ]
 },
 {
 "given": " Jack",
 "family": "Elliott",
 "affiliation": [
 {
 "original_name": "Centre for Literary and Linguistic Computing, University of Newcastle, Australia",
 "normalized_name": "University of Newcastle Australia",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00eae9z71",
 "GRID": "grid.266842.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-05-24",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt026",
 "identifier": {
 "string_id": "10.1093/llc/fqt026",
 "id_scheme": "DOI"
 },
 "abstract": "In this article, the application of Ant-Colony Optimization (ACO) to a morphological segmentation task is described, where the aim is to analyse a set of words into their constituent stem and ending. A number of criteria for determining the optimal segmentation are evaluated comparatively while at the same time investigating more comprehensively the effectiveness of the ACO system in defining appropriate values for system parameters. Owing to the characteristics of the task at hand, particular emphasis is placed on studying the ACO process for learning sessions of a limited duration. Morphological segmentation becomes hardest in highly inflectional languages, where each stem is associated with a large number of distinct endings. Consequently, the present article investigates morphological segmentation of words from a highly inflectional language, specifically Ancient Greek, by combining pattern-recognition principles with limited linguistic knowledge. To weigh these sources of knowledge, a set of weights is used as a set of system parameters, to be optimized via ACO. ACO-based experimental results are shown to be of a higher quality than those achieved by manual optimisation or ‘randomised generate and test’ methods. This illustrates the applicability of the ACO-based approach to the morphological segmentation task.",
 "article_title": "Optimizing word segmentation tasks using ant colony metaheuristics",
 "authors": [
 {
 "given": " George",
 "family": "Tambouratzis",
 "affiliation": [
 {
 "original_name": "Institute for Language and Speech Processing, Athens, Greece",
 "normalized_name": "Institute for Language and Speech Processing",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/00z24kr14",
 "GRID": "grid.424851.e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-05-24",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt023",
 "identifier": {
 "string_id": "10.1093/llc/fqt023",
 "id_scheme": "DOI"
 },
 "abstract": "This study is designed to analyze the use of nominalization in English translations of Chinese literary prose based on eight English translations of Chinese novels. It follows ‘Lees, R. (1963). The Grammar of English Nominalizations. The Hague: Mouton’ in defining English nominalization as a nominalized transform of a finite verbal form and ‘Mathesius, V. (1975). Selected Writings in English and General Linguistics. The Hague: Mouton’ theory of ‘complex condensation of the sentence’. It describes English nominalization from the formal-syntactic level as adverbial, in the positions of subject and object, condensing a finite clausal structure. In the qualitative analysis, various effects of the use of nominalization are described based on three English versions of the Chinese classic novel Hong Lou Meng. In the quantitative analysis, three general patterns of the use of nominalization are found in the eight English translations of Chinese novels: it is predominantly used as adverbial (as opposed to in the positions of object and subject), in the form of gerundive nominalization (as opposed to derived and zero-derived nominalizations), and in the narrative (as opposed to dialogues). In comparison with nominalization used in some English novels, it is found that nominalization is significantly more used in the English translations of Chinese novels at large.",
 "article_title": "A corpus-based study of nominalization in English translations of Chinese literary prose",
 "authors": [
 {
 "given": " Yu",
 "family": "Hou",
 "affiliation": [
 {
 "original_name": "Yanshan University, Qinhuangdao, China",
 "normalized_name": "Yanshan University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/02txfnf15",
 "GRID": "grid.413012.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-05-14",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt018",
 "identifier": {
 "string_id": "10.1093/llc/fqt018",
 "id_scheme": "DOI"
 },
 "abstract": "Most authorship attribution studies have focused on works that are available in the language used by the original author (Holmes, 1994; Juola, 2006) because this provides a direct way of examining an author's linguistic habits. Sometimes, however, questions of authorship arise regarding a work only surviving in translation. One example is ‘Constance’, the putative ‘last play’ of Oscar Wilde, only existing in a supposed French translation of a lost English original.The present study aims to take a step towards dealing with cases of this kind by addressing two related questions: (1) to what extent are authorial differences preserved in translation; (2) to what extent does this carry-over depend on the particular translator?With these aims, we analysed 262 letters written by Vincent van Gogh and by his brother Theo, dated between 1888 and 1890, each available in the original French and in an English translation. We also performed a more intensive investigation of a subset of this corpus, comprising forty-eight letters, for which two different English translations were obtainable. Using three different indices of discriminability (classification accuracy, Hedge's g, and area under the receiver operating characteristic curve), we found that much of the stylistic discriminability between the two brothers was preserved in the English translations. Subsidiary analyses were used to identify which lexical features were contributing most to inter-author discriminability.Discrimination between translation sources was possible, although less effective than between authors. We conclude that ‘handprints’ of both author and translator can be found in translated texts, using appropriate techniques.",
 "article_title": "Found in translation: To what extent is authorial discriminability preserved by translators?",
 "authors": [
 {
 "given": " Richard S.",
 "family": "Forsyth",
 "affiliation": [
 {
 "original_name": "16 Halliday Avenue, Leeds LS12 3PQ, UK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Phoenix W. Y.",
 "family": "Lam",
 "affiliation": [
 {
 "original_name": "Hong Kong Baptist University, Hong Kong",
 "normalized_name": "Hong Kong Baptist University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/0145fw131",
 "GRID": "grid.221309.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-05-07",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt019",
 "identifier": {
 "string_id": "10.1093/llc/fqt019",
 "id_scheme": "DOI"
 },
 "abstract": "In this article I develop a set of simple algorithms for deriving syllable count information for words from fixed-meter poetry. The focus is on the determination of what features of language or meter might be most useful. I therefore first review what factors might be useful for this, selecting those that require as little information as possible about the language in question and making as few computational demands as possible. We end up with algorithms based on: (i) the number of syllables in each line, (ii) the number of words in each line, (iii) the number of letters in those words, and (iv) the frequency of those words.I test these algorithms on corpora from English and Welsh, getting parallel results in both cases. The results establish that the variables I identify do have significant success in deriving syllable count, but that work remains to be done.",
 "article_title": "Calculating syllable count automatically from fixed-meter poetry in English and Welsh",
 "authors": [
 {
 "given": " Michael",
 "family": "Hammond",
 "affiliation": [
 {
 "original_name": "University of Arizona",
 "normalized_name": "University of Arizona",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/03m2x1q45",
 "GRID": "grid.134563.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-05-04",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt020",
 "identifier": {
 "string_id": "10.1093/llc/fqt020",
 "id_scheme": "DOI"
 },
 "abstract": "Pearson’s chi-squared test is probably the most popular statistical test used in corpus linguistics, particularly for studying linguistic variations between corpora. Oakes and Farrow (2007) proposed various adaptations of this test to allow for the simultaneous comparison of more than two corpora while also yielding an almost correct Type I error rate (i.e. claiming that a word is most frequently found in a variety of English, when in actuality this is not the case). By means of resampling procedures, the present study shows that when used in this context, the chi-squared test produces far too many significant results, even in its modified version. Several potential approaches to circumventing this problem are discussed in the conclusion.",
 "article_title": "Inadequacy of the chi-squared test to examine vocabulary differences between corpora",
 "authors": [
 {
 "given": " Yves",
 "family": "Bestgen",
 "affiliation": [
 {
 "original_name": "Université catholique de Louvain, Belgium",
 "normalized_name": "Université Catholique de Louvain",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/02495e989",
 "GRID": "grid.7942.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-04-16",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt021",
 "identifier": {
 "string_id": "10.1093/llc/fqt021",
 "id_scheme": "DOI"
 },
 "abstract": "We define a model of discourse coherence based on Barzilay and Lapata’s entity grids as a stylometric feature for authorship attribution. Unlike standard lexical and character-level features, it operates at a discourse (cross-sentence) level. We test it against and in combination with standard features on nineteen book-length texts by nine nineteenth-century authors. We find that coherence alone performs often as well as and sometimes better than standard features, though a combination of the two has the highest performance overall. We observe that despite the difference in levels, there is a correlation in performance of the two kinds of features.",
 "article_title": "Patterns of local discourse coherence as a feature for authorship attribution",
 "authors": [
 {
 "given": " Vanessa Wei",
 "family": "Feng",
 "affiliation": [
 {
 "original_name": "University of Toronto, Canada",
 "normalized_name": "University of Toronto",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03dbr7087",
 "GRID": "grid.17063.33"
 }
 }
 ]
 },
 {
 "given": " Graeme",
 "family": "Hirst",
 "affiliation": [
 {
 "original_name": "University of Toronto, Canada",
 "normalized_name": "University of Toronto",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03dbr7087",
 "GRID": "grid.17063.33"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-04-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt014",
 "identifier": {
 "string_id": "10.1093/llc/fqt014",
 "id_scheme": "DOI"
 },
 "abstract": "MONK is a web-based text mining software application hosted by the University of Illinois Library that enables researchers to analyze encoded digital texts from select databases and digital archives. This study examines sets of quantitative and qualitative data to explore the usage of MONK as a research tool: the author analyzes eighteen months of web analytics data from the MONK website and responses from five interviews with MONK users to examine the ways in which MONK has been most commonly used by researchers. In the paper's analysis, the author considers the implications of MONK's use in digital humanities research and teaching, and how a digital humanities tool such as MONK can be maintained for public use. This study ultimately explores how user studies of digital humanities tools can reveal insights into humanities scholars' needs for using digital tools to pursue new research methodologies, and argues that studying the usability and preservation of digital humanities tools will enable information professionals to address humanities scholars' needs for their digital scholarship.",
 "article_title": "Under the Workbench: An analysis of the use and preservation of MONK text mining research software",
 "authors": [
 {
 "given": " Harriett E.",
 "family": "Green",
 "affiliation": [
 {
 "original_name": "University of Illinois at Urbana-Champaign, USA",
 "normalized_name": "University of Illinois at Urbana-Champaign",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047426m28",
 "GRID": "grid.35403.31"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-04-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt016",
 "identifier": {
 "string_id": "10.1093/llc/fqt016",
 "id_scheme": "DOI"
 },
 "abstract": "This article describes PlotVisML, a simple, flexible XML schema for encoding literary narratives that was developed by an interdisciplinary team of researchers in literary studies, interface design, computing studies, and education as part of a research project on reading, writing, and teaching complex literary narrative. PlotVisML is a simple, adaptable schema consisting of five key elements: <action>, <dialogue>, and <narration> (tags for marking up narrative events), and <character> and <object> (tags for encoding narrative objects). Fictional narratives that have been marked up using PlotVisML can be visualized in PlotVis, a digital scholarly tool that allows users to model and interact with literary narratives in three dimensions. Both PlotVis, an interactive visualization tool, and PlotVisML, our custom XML schema for encoding literary narratives, were designed to permit challenging new views on familiar plotlines and, more importantly, to depart from conventional ways of modeling narrative in literary instruction. In discussing the process of developing PlotVisML, we contribute to the ongoing discussion of text encoding as a form of close reading (e.g., Liepert, 2009).",
 "article_title": "Challenging new views on familiar plotlines: A discussion of the use of XML in the development of a scholarly tool for literary pedagogy",
 "authors": [
 {
 "given": " Monica",
 "family": "Brown",
 "affiliation": [
 {
 "original_name": "Department of English, The University of British Columbia, Vancouver, British Columbia, Canada",
 "normalized_name": "University of British Columbia",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03rmrcq20",
 "GRID": "grid.17091.3e"
 }
 }
 ]
 },
 {
 "given": " Teresa",
 "family": "Dobson",
 "affiliation": [
 {
 "original_name": "Department of Language and Literacy Education, The University of British Columbia, Vancouver, British Columbia, Canada",
 "normalized_name": "University of British Columbia",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03rmrcq20",
 "GRID": "grid.17091.3e"
 }
 }
 ]
 },
 {
 "given": " Dustin",
 "family": "Grue",
 "affiliation": [
 {
 "original_name": "Department of English, The University of British Columbia, Vancouver, British Columbia, Canada",
 "normalized_name": "University of British Columbia",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03rmrcq20",
 "GRID": "grid.17091.3e"
 }
 }
 ]
 },
 {
 "given": " Stan",
 "family": "Ruecker",
 "affiliation": [
 {
 "original_name": "Institute of Design, Illinois Institute of Technology, Chicago, IL, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-03-28",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt015",
 "identifier": {
 "string_id": "10.1093/llc/fqt015",
 "id_scheme": "DOI"
 },
 "abstract": "We compute the rate of textual signals of risk of war recognizable in series of consecutive political speeches about a disputed issue serious enough to entail an international conflict. The speeches concern Iran’s nuclear program. We trace textual signals forewarning of risks of war that reactions to this affair lead to. The thrust of the textual analysis rests on the interplay of affiliation and power words in continuous texts, following D. C. McClelland’s model for anticipating wars. The speeches are those of Iranian President Mahmoud Ahmadinejad, US Secretary of State Hillary R. Clinton, Iranian Grand Ayatollah Ali Khamenei, and Israeli Prime Minister Benjamin Netanyahu. Prefiguring a military confrontation before it occurs involves structuring information from unstructured data. Despite such imperfect knowledge, by the end of January 2012, our results show a receding risk of war on the Iranian side, but an increasing risk on the American one, while remaining ambiguous on the Israeli one.",
 "article_title": "Textual fingerprints of risk of war",
 "authors": [
 {
 "given": " Robert L.",
 "family": "Hogenraad",
 "affiliation": [
 {
 "original_name": "Université catholique de Louvain, Louvain-la-Neuve, Belgium",
 "normalized_name": "Université Catholique de Louvain",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/02495e989",
 "GRID": "grid.7942.8"
 }
 }
 ]
 },
 {
 "given": " Rauf R.",
 "family": "Garagozov",
 "affiliation": [
 {
 "original_name": "Center for Strategic Studies, Baku, Azerbaijan",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-03-22",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt009",
 "identifier": {
 "string_id": "10.1093/llc/fqt009",
 "id_scheme": "DOI"
 },
 "abstract": "This study investigates data from the BBC Voices project, which contains a large amount of vernacular data collected by the BBC between 2004 and 2005. The project was designed primarily to collect information on vernacular speech around the UK for broadcasting purposes. As part of the project, a web-based questionnaire was created, to which tens of thousands of people supplied their way of denoting thirty-eight variables that were known to exhibit marked lexical variation. Along with their variants, those responding to the online prompts provided information on their age, gender, and—significantly for this study—their location, this being recorded by means of their postcode. In this study, we focus on the relative frequency of the top ten variants for all variables in every postcode area. By using hierarchical spectral partitioning of bipartite graphs, we are able to identify four contemporary geographical dialect areas together with their characteristic lexical variants. Even though these variants can be said to characterize their respective geographical area, they also occur in other areas, and not all people in a certain region use the characteristic variant. This supports the view that dialect regions are not clearly defined by strict borders, but are fuzzy at best.",
 "article_title": "Analyzing the BBC Voices data: Contemporary English dialect areas and their characteristic lexical variants",
 "authors": [
 {
 "given": " Martijn",
 "family": "Wieling",
 "affiliation": [
 {
 "original_name": "Department of Quantitative Linguistics, University of Tübingen, Tübingen, Germany",
 "normalized_name": "University of Tübingen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/03a1kwz48",
 "GRID": "grid.10392.39"
 }
 }
 ]
 },
 {
 "given": " Clive",
 "family": "Upton",
 "affiliation": [
 {
 "original_name": "School of English, University of Leeds, Leeds, UK",
 "normalized_name": "University of Leeds",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/024mrxd33",
 "GRID": "grid.9909.9"
 }
 }
 ]
 },
 {
 "given": " Ann",
 "family": "Thompson",
 "affiliation": [
 {
 "original_name": "School of English, University of Leeds, Leeds, UK",
 "normalized_name": "University of Leeds",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/024mrxd33",
 "GRID": "grid.9909.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-03-05",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt011",
 "identifier": {
 "string_id": "10.1093/llc/fqt011",
 "id_scheme": "DOI"
 },
 "abstract": "Although the aggregation of many linguistic variables has provided new insights into the structure of language varieties, aggregation studies have been criticized for obscuring the behavior of individual input variables. Previous solutions to this criticism consisted of extensive post-hoc calculations, simple correlation measures, or highly complex algorithms. We think that these solutions can be improved. Therefore, the current article proposes a creative use of Individual Differences Scaling (INDSCAL) as an alternative, more straightforward solution. INDSCAL is a branch of Multidimensional Scaling, which is currently the preferred dimension reduction technique for most aggregation studies. The link to the existing methodology and the simplicity of its rationale are the main advantages of INDSCAL. The article introduces INDSCAL by means of a non-linguistic example, a discussion of the mathematical properties, and a case study on the lexical convergence between Belgian and Netherlandic Dutch in a corpus of language from 1950 and 1990. The case study shows how INDSCAL reproduces the results of a typical aggregation study, but elegantly keeps open the possibility of investigating the behavior of individual variables.",
 "article_title": "Transparent aggregation of variables with Individual Differences Scaling",
 "authors": [
 {
 "given": " Tom",
 "family": "Ruette",
 "affiliation": [
 {
 "original_name": "Institut für deutsche Sprache und Linguistik, Humboldt Universität zu Berlin, Berlin, Germany",
 "normalized_name": "Humboldt University of Berlin",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/01hcx6992",
 "GRID": "grid.7468.d"
 }
 }
 ]
 },
 {
 "given": " Dirk",
 "family": "Speelman",
 "affiliation": [
 {
 "original_name": "Quantitative Lexicology and Variational Linguistics, K.U.Leuven, Leuven, Belgium",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-02-24",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt008",
 "identifier": {
 "string_id": "10.1093/llc/fqt008",
 "id_scheme": "DOI"
 },
 "abstract": "In recent years, great availability of various language resources in different forms as well as rapid development of computer technology and programming skills have made researchers in the fields of linguistics and computer science cooperate in solving different problems of computational linguistics and natural language processing. Building large monolingual as well as bilingual corpora in digital forms and storing them in computer memories has enabled linguists and language engineers to automatically explore techniques for processing information with the help of various computer programs without any need to manually collect and analyze data.One of the main applications of monolingual corpora can be seen in developing automatic spell-checking systems. In such systems, a large monolingual corpus can function as a database instead of a monolingual dictionary. In the present study, it has been tried to demonstrate the effectiveness of a large monolingual corpus of Persian in improving the output quality of a spell-checker developed for this language.In the present spelling correction system, the three phases of error detection, making suggestions, and ranking suggestions are performed in three separate stages. An experiment was carried out to evaluate the performance of the spell-checking system.",
 "article_title": "FarsiSpell: A spell-checking system for Persian using a large monolingual corpus",
 "authors": [
 {
 "given": " Tayebeh",
 "family": "Mosavi Miangah",
 "affiliation": [
 {
 "original_name": "Payame Noor University, Islamic Republic of Iran",
 "normalized_name": "Payame Noor University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/031699d98",
 "GRID": "grid.412462.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-02-23",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs045",
 "identifier": {
 "string_id": "10.1093/llc/fqs045",
 "id_scheme": "DOI"
 },
 "abstract": "Digitization of Japanese historical documents has gained much attraction in the field of humanities in Japan recently, and numbers of documents are already available in digitized text format. However, text analysis of these documents has rarely been done mainly due to the lack of natural language processing tools that can handle pre-modern Japanese. In this article, we propose a method to extract and visualize the relationships among persons from Japanese historical documents with an aid of supplementary information such as personal name and place name indices. The goal of the method is to extract dynamics of relationships among historical persons. The method utilizes locational information to obtain latent relationships among persons based on their spatial activities. The proposed method is applied to a Japanese historical chronicle written in the 12th century. Experimental results showed a strong correspondence to the known historical facts, and the results of a user survey completed by researchers of Japanese history demonstrated some potential for the method to serve as a new approach in the fields of humanities.",
 "article_title": "Visualization of relationships among historical persons from Japanese historical documents",
 "authors": [
 {
 "given": " Fuminori",
 "family": "Kimura",
 "affiliation": [
 {
 "original_name": "College of Information Science and Engineering, Ritsumeikan University, Japan",
 "normalized_name": "Ritsumeikan University",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/0197nmd03",
 "GRID": "grid.262576.2"
 }
 }
 ]
 },
 {
 "given": " Takahiko",
 "family": "Osaki",
 "affiliation": [
 {
 "original_name": "Independent Researcher",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Taro",
 "family": "Tezuka",
 "affiliation": [
 {
 "original_name": "Graduate School of Library, Information and Media Studies, University of Tsukuba, Japan",
 "normalized_name": "University of Tsukuba",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/02956yf07",
 "GRID": "grid.20515.33"
 }
 }
 ]
 },
 {
 "given": " Akira",
 "family": "Maeda",
 "affiliation": [
 {
 "original_name": "College of Information Science and Engineering, Ritsumeikan University, Japan",
 "normalized_name": "Ritsumeikan University",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/0197nmd03",
 "GRID": "grid.262576.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-02-21",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt001",
 "identifier": {
 "string_id": "10.1093/llc/fqt001",
 "id_scheme": "DOI"
 },
 "abstract": "In digital humanities, within a core semantic scope, the term ‘text’ occurs ubiquitously, with both mass and count noun senses. This article sets out to define the relationship between the two senses—between some text and a text—and in particular to say what makes a text discrete. Three characteristics of a scholarly edition (considered the normative instance of a countable text) are isolated and discussed in relation to several marginal cases. I conclude that two of them—the representation of language and intent to communicate—give us text in the mass sense. Examining the third characteristic—that the communication be complete within its bounds—it becomes clear that it is impossible to say that an entity is intrinsically a text because the count noun sense of text is—as Renear and Dubin assert about three of the four Functional Requirements for Bibliographic Records Group 1 entity types—a role, not a type.",
 "article_title": "On the term 'text' in digital humanities",
 "authors": [
 {
 "given": " Paul",
 "family": "Caton",
 "affiliation": [
 {
 "original_name": "King's College London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-02-09",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqt002",
 "identifier": {
 "string_id": "10.1093/llc/fqt002",
 "id_scheme": "DOI"
 },
 "abstract": "Quantifying the similarity or dissimilarity between documents is an important task in authorship attribution, information retrieval, plagiarism detection, text mining, and many other areas of linguistic computing. Numerous similarity indices have been devised and used, but relatively little attention has been paid to calibrating such indices against externally imposed standards, mainly because of the difficulty of establishing agreed reference levels of inter-text similarity. The present article introduces a multi-register corpus gathered for this purpose, in which each text has been located in a similarity space based on ratings by human readers. This provides a resource for testing similarity measures derived from computational text-processing against reference levels derived from human judgement, i.e. external to the texts themselves. We describe the results of a benchmarking study in five different languages in which some widely used measures perform comparatively poorly. In particular, several alternative correlational measures (Pearson r, Spearman rho, tetrachoric correlation) consistently outperform cosine similarity on our data. A method of using what we call ‘anchor texts’ to extend this method from monolingual inter-text similarity-scoring to inter-text similarity-scoring across languages is also proposed and tested.",
 "article_title": "Document dissimilarity within and across languages: A benchmarking study",
 "authors": [
 {
 "given": " Richard S.",
 "family": "Forsyth",
 "affiliation": [
 {
 "original_name": "University of Leeds, UK",
 "normalized_name": "University of Leeds",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/024mrxd33",
 "GRID": "grid.9909.9"
 }
 }
 ]
 },
 {
 "given": " Serge",
 "family": "Sharoff",
 "affiliation": [
 {
 "original_name": "University of Leeds, UK",
 "normalized_name": "University of Leeds",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/024mrxd33",
 "GRID": "grid.9909.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-02-07",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs077",
 "identifier": {
 "string_id": "10.1093/llc/fqs077",
 "id_scheme": "DOI"
 },
 "abstract": "This article describes the work performed in the Pattern Redundancy Analysis for Document Image Indexing and Transcription research project. The project focused on layout analysis, text/graphics separation, optical character recognition (OCR), and text transcription processes dedicated to old and precious books. The originality of this work relies on the analysis and exploitation of pattern redundancy in documents to enable the efficient indexing and quick transcription of books and the identification of typographic materials. For these purposes, we have developed two software packages. The first, AGORA, performs page layout analysis, text/graphics separation, and pattern (letterform) extraction simultaneously. These patterns are then processed to group similar patterns together in single clusters so that different letterforms of a book can be extracted and analysed to compute redundancy rates. This process allows a significant reduction of the number of letterforms to be recognized. Once the clustering of letterforms is done, a user may assign a label to each cluster using the second software, RETRO. Labels are then automatically assigned to each corresponding character to perform the text transcription of the whole book. Thus, if 90% of the letterforms are detected as redundant, only one character out of ten must be labelled by the user to transcribe the book. Moreover, this transcription method allows us to deal easily with the special characters that appear frequently in old books. It is also possible to use our clustering approach to extract and create new font packages from specific printing material (e.g. from rare books printed with particular types or woodblocks). These new font packages could be incorporated into the training step of optical fonts recognition methods to improve the recognition results of OCRs on rare or specific books. The identification of typographic materials could also be useful for the study of both the aesthetic (such as how the thickness and shape of printing types evolved from the 15th to the mid-16th century) and economic aspects of printing historically. Until the second half of the 16th century, for instance, printing types circulated among workshops, and printers frequently sold or lent types to their fellows.",
 "article_title": "Interactive layout analysis, content extraction, and transcription of historical printed books using Pattern Redundancy Analysis",
 "authors": [
 {
 "given": " Jean-Yves",
 "family": "Ramel",
 "affiliation": [
 {
 "original_name": "Laboratoire d'Informatique de Tours (EA 6300) Ecole d'ingénieurs Polytechnique de l'Université de Tours, France",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Nicolas",
 "family": "Sidère",
 "affiliation": [
 {
 "original_name": "Laboratoire d'Informatique de Tours (EA 6300) Ecole d'ingénieurs Polytechnique de l'Université de Tours, France",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Frédéric",
 "family": "Rayar",
 "affiliation": [
 {
 "original_name": "Laboratoire d'Informatique de Tours (EA 6300) Ecole d'ingénieurs Polytechnique de l'Université de Tours, France",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-01-29",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs058",
 "identifier": {
 "string_id": "10.1093/llc/fqs058",
 "id_scheme": "DOI"
 },
 "abstract": "One of the principle signs that speech is a complex system is the nonlinear arrangement of frequencies of variants in linguistic survey data. When the counts are charted by frequency, they form an asymptotic hyperbolic curve (A-curve) at every scale of analysis. The shape of the curve is sensitive to sample size: a small sample is unlikely to show an A-curve. So, too, categorization: too large a number of categories makes the data appear linear because of the small number of tokens in each category, while allowing too few categories, such as the two data points from binary categories, also gives us a line, not a curve. The A-curve can only be observed when the number of categories into which the data are sorted lies between these two extremes. Common practice in dialectology and sociolinguistics has been to establish a small number of possible categories such as phonemes for pronunciation, or to notice only the few most frequently occurring variants and to ignore the rest. Such methods cannot address the underlying complexity of the data. In this essay, we discuss the Gini coefficient, used in economics, as a means to measure optimal nonlinearity. In an experiment where pronunciation data from survey research on the American English vowel system are analyzed in various subsamples, we demonstrate that A-curves do exist in the data in all cases, and we establish parameters for the interaction of sample size and number of categories in the design of valid and reliable experiments.",
 "article_title": "Scaled measurement of geographic and social speech data",
 "authors": [
 {
 "given": " William A.",
 "family": "Kretzschmar",
 "affiliation": [
 {
 "original_name": "University of Georgia, USA",
 "normalized_name": "University of Georgia",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00te3t702",
 "GRID": "grid.213876.9"
 }
 }
 ]
 },
 {
 "given": " Brendan A.",
 "family": "Kretzschmar",
 "affiliation": [
 {
 "original_name": "University of Georgia, USA",
 "normalized_name": "University of Georgia",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00te3t702",
 "GRID": "grid.213876.9"
 }
 }
 ]
 },
 {
 "given": " Irene M.",
 "family": "Brockman",
 "affiliation": [
 {
 "original_name": "Massachusetts Institute of Technology, USA",
 "normalized_name": "Massachusetts Institute of Technology",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/042nb2s44",
 "GRID": "grid.116068.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-01-29",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs069",
 "identifier": {
 "string_id": "10.1093/llc/fqs069",
 "id_scheme": "DOI"
 },
 "abstract": "This article reports on a study of XML-markup experiences as reading practices of secondary students studying English literature in a public high school in Vancouver, British Columbia, Canada. Since training in the digital humanities (DH) has historically been restricted to those in undergraduate and graduate programs, an important consideration in DH education is how we might implement DH methods in secondary school curricula with a view to introducing prospective scholars to the field prior to their admission to post-secondary education. A concomitant goal would be to investigate a new locus for DH education, at a different level of education and in a different institutional environment, to observe how or if DH might migrate from the locale to which it has acclimatized. Our work maps a method for developing this pedagogy and presents findings on students’ semantic tagging of two short stories: Ernest Hemingway’s (1927) ‘Hills Like White Elephants’ and Sean O’Faolain’s (1948) ‘The Trout’. Analysis of this tagging reveals markup as reading practice and describes how students negotiate between the experiences of reading, how these experiences may be realized by text, and the ways in which XML markup—as process—mediates between.",
 "article_title": "Reading practices and digital experiences: An investigation into secondary students' reading practices and XML-markup experiences of fiction",
 "authors": [
 {
 "given": " Dustin",
 "family": "Grue",
 "affiliation": [
 {
 "original_name": "University of British Columbia, Canada",
 "normalized_name": "University of British Columbia",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03rmrcq20",
 "GRID": "grid.17091.3e"
 }
 }
 ]
 },
 {
 "given": " Teresa M.",
 "family": "Dobson",
 "affiliation": [
 {
 "original_name": "University of British Columbia, Canada",
 "normalized_name": "University of British Columbia",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03rmrcq20",
 "GRID": "grid.17091.3e"
 }
 }
 ]
 },
 {
 "given": " Monica",
 "family": "Brown",
 "affiliation": [
 {
 "original_name": "University of British Columbia, Canada",
 "normalized_name": "University of British Columbia",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03rmrcq20",
 "GRID": "grid.17091.3e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-01-20",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs067",
 "identifier": {
 "string_id": "10.1093/llc/fqs067",
 "id_scheme": "DOI"
 },
 "abstract": "TextGrid’s Text-Image-Link-Editor is used to link segments of text with sections on the corresponding image. A typical application is the linking of scans of facsimiles with their transcriptions, though these texts can also be created during the linking process, which allows also for image annotations. The information on the linking between manuscript fragments and the corresponding transcription is itself stored in TEI P5. TextGrid is a virtual research environment for the humanities disciplines dealing with texts in a wide sense (philologies, epigraphy, linguistics, musicology, art history, etc.). The joint research project TextGrid is part of the D-Grid initiative and is funded by the German Federal Ministry of Education and Research (BMBF) for the period starting from 1 June 2009 to 31 May 2012 (reference number: 01UG0901A). TextGrid consists of two principal building blocks, the grid-based back-end TextGridRep that hosts both infrastructure services and the repository layer for access to research data and long-term archiving, and the user-facing TextGrid Laboratory (TextGridLab). The TextGridLab, a single point of entry to the virtual research environment, provides integrated access to both new and existing tools and services via user-friendly software based on the eclipse framework [TG]. TBLE is a key component of the TextGridLab that has been under continuous development since 2008 and is by now in practical use.",
 "article_title": "The text-image-link-editor: A tool for linking facsimiles and transcriptions, and image annotations",
 "authors": [
 {
 "given": " Yahya Ahmed Ali",
 "family": "Al-Hajj",
 "affiliation": [
 {
 "original_name": "Worms University of Applied Sciences, Germany",
 "normalized_name": "University of Applied Sciences Worms",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/031ph8d53",
 "GRID": "grid.440515.1"
 }
 }
 ]
 },
 {
 "given": " Marc Wilhelm",
 "family": "Küster",
 "affiliation": [
 {
 "original_name": "Worms University of Applied Sciences, Germany",
 "normalized_name": "University of Applied Sciences Worms",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/031ph8d53",
 "GRID": "grid.440515.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-01-18",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs074",
 "identifier": {
 "string_id": "10.1093/llc/fqs074",
 "id_scheme": "DOI"
 },
 "abstract": "One of the major challenges in the process of machine translation is word sense disambiguation (WSD), which is defined as choosing the correct meaning of a multi-meaning word in a text. Supervised learning methods are usually used to solve this problem. The disambiguation task is performed using the statistics of the translated documents (as training data) or dual corpora of source and target languages. In this article, we present a supervised learning method for WSD, which is based on K-nearest neighbor algorithm. As the first step, we extract two sets of features: the set of words that have occurred frequently in the text and the set of words surrounding the ambiguous word. In order to improve the classification accuracy, we perform a feature selection process and then propose a feature weighting strategy to tune the classifier. In order to show that the proposed schemes are not language dependent, we apply the suggested schemes to two sets of data, i.e. English and Persian corpora. The evaluation results show that the feature selection and feature weighting strategies have a significant effect on the accuracy of the classification system. The results are also encouraging compared with the state of the art.",
 "article_title": "An accurate word sense disambiguation system based on weighted lexical features",
 "authors": [
 {
 "given": "Abdoreza",
 "family": "Rezapour",
 "affiliation": [
 {
 "original_name": "Shiraz University, Iran",
 "normalized_name": "Shiraz University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/028qtbk54",
 "GRID": "grid.412573.6"
 }
 }
 ]
 },
 {
 "given": "Seyed Mostafa",
 "family": "Fakhrahmad",
 "affiliation": [
 {
 "original_name": "Shiraz University, Iran",
 "normalized_name": "Shiraz University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/028qtbk54",
 "GRID": "grid.412573.6"
 }
 }
 ]
 },
 {
 "given": "Mohammad Hadi",
 "family": "Sadreddini",
 "affiliation": [
 {
 "original_name": "Shiraz University, Iran",
 "normalized_name": "Shiraz University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/028qtbk54",
 "GRID": "grid.412573.6"
 }
 }
 ]
 },
 {
 "given": "Mansoor",
 "family": "Zolghadri Jahromi",
 "affiliation": [
 {
 "original_name": "Shiraz University, Iran",
 "normalized_name": "Shiraz University",
 "country": "Iran",
 "identifiers": {
 "ror": "https://ror.org/028qtbk54",
 "GRID": "grid.412573.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-01-17",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs057",
 "identifier": {
 "string_id": "10.1093/llc/fqs057",
 "id_scheme": "DOI"
 },
 "abstract": "A careful investigation of synchronic patterns of linguistic variation with underlying linguistic features can lead to important insights into the comprehension of diachronic phonetic processes. In this article, we showed that the method of spectral partitioning of bipartite graphs applied to synchronic dialectal data can effectively and reliably be used to investigate diachronic processes, thus contributing to a deeper understanding of the relationship between synchronic variation and diachronic change. This was illustrated through a case study carried out on Tuscan dialects, focusing on so-called Tuscan ‘gorgia’, a lenition process consisting of the spirantization of stop consonants. In particular, from a quantitative analysis of the sound correspondences involving voiceless and voiced stops, we tracked the evolution of the spirantization phenomenon in several respects. First, we tracked spirantization geographically, across Tuscany from the influential center of Florence to the peripheral areas. Second, we tracked it phonologically, from voiceless to voiced stops, and within each voicing class from velars to dentals and then to bilabials. Finally, we tracked it demographically, with young speakers using the most innovative sound correspondences more than old speakers. The fact that these results are in line with the literature on the topic of Tuscan ‘gorgia’ demonstrates the potential of the method of spectral partitioning of bipartite graphs with respect to the reconstruction of diachronic processes starting from diatopically distributed synchronic dialectal data.",
 "article_title": "Synchronic patterns of Tuscan phonetic variation and diachronic change: Evidence from a dialectometric study",
 "authors": [
 {
 "given": " Simonetta",
 "family": "Montemagni",
 "affiliation": [
 {
 "original_name": "Istituto di Linguistica Computazionale ‘Antonio Zampolli’ – CNR, Italy",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Martijn",
 "family": "Wieling",
 "affiliation": [
 {
 "original_name": "Center for Language and Cognition Groningen, University of Groningen, The Netherlands",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 }
 ]
 },
 {
 "given": " Bob",
 "family": "de Jonge",
 "affiliation": [
 {
 "original_name": "Center for Language and Cognition Groningen, University of Groningen, The Netherlands",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 }
 ]
 },
 {
 "given": " John",
 "family": "Nerbonne",
 "affiliation": [
 {
 "original_name": "Center for Language and Cognition Groningen, University of Groningen, The Netherlands",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 },
 {
 "original_name": "Freiburg Institute of Advanced Studies, Germany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-01-17",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs073",
 "identifier": {
 "string_id": "10.1093/llc/fqs073",
 "id_scheme": "DOI"
 },
 "abstract": "This study draws from a large corpus of Congressional speeches from the 101st to the 110th Congress (1989–2008), to examine gender differences in language use in a setting of political debates. Female legislators’ speeches demonstrated characteristics of both a feminine language style (e.g. more use of emotion words, fewer articles) and a masculine one (e.g. more nouns and long words, fewer personal pronouns). A trend analysis found that these gender differences have consistently existed in the Congressional speeches over the past 20 years, regardless of the topic of debate. The findings lend support to the argument that gender differences in language use persist in professional settings like the floor of Congress.",
 "article_title": "Language and gender in Congressional speech",
 "authors": [
 {
 "given": " Bei",
 "family": "Yu",
 "affiliation": [
 {
 "original_name": "Syracuse University, USA",
 "normalized_name": "Syracuse University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/025r5qe02",
 "GRID": "grid.264484.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-01-12",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "29",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs076",
 "identifier": {
 "string_id": "10.1093/llc/fqs076",
 "id_scheme": "DOI"
 },
 "abstract": "This article will explain the structure and function of a digital research environment for Buddhist studies entitled Research Base for Indian and Buddhist Studies (RBIB). In the field of Buddhist studies (and especially in the area of Indian Buddhism), scholars face various obstacles in their efforts to share materials—in both paper and digital media. In establishing the RBIB, we have considered it to be of paramount importance to preserve the continuity of the prior tradition of studies within the paper medium, while at the same time developing a methodology that takes best advantage of the digital medium. After identifying six basic conditions that will satisfy the demands of both approaches, we have implemented a Web collaboration system that fulfills these conditions. Our system also makes functional parts of the RBIB that enable the presentation of the relationships between arbitrary fragments of related texts in various canonical languages through a user-friendly interface, which in turn allows users to learn how to edit and browse relationship data. Our system has thus far been highly evaluated by testers, and it has been further facilitated by recent developments in Information Communications Technology. Humanities digitization has a deep mutual relationship with this new technology.",
 "article_title": "Towards a digital research environment for Buddhist studies",
 "authors": [
 {
 "given": " Kiyonori",
 "family": "Nagasaki",
 "affiliation": [
 {
 "original_name": "International Institute for Digital Humanities",
 "normalized_name": "International Institute for Digital Humanities",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/0454arg59",
 "GRID": "grid.474291.d"
 }
 }
 ]
 },
 {
 "given": " Toru",
 "family": "Tomabechi",
 "affiliation": [
 {
 "original_name": "International Institute for Digital Humanities",
 "normalized_name": "International Institute for Digital Humanities",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/0454arg59",
 "GRID": "grid.474291.d"
 }
 }
 ]
 },
 {
 "given": " Masahiro",
 "family": "Shimoda",
 "affiliation": [
 {
 "original_name": "University of Tokyo",
 "normalized_name": "University of Tokyo",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/057zh3y96",
 "GRID": "grid.26999.3d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-01-17",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs052",
 "identifier": {
 "string_id": "10.1093/llc/fqs052",
 "id_scheme": "DOI"
 },
 "abstract": "This article investigates several linguistic changes which are ongoing in north-western Catalan using a contemporary corpus. We take advantage of a range of dialectometric methods that allow us to calculate and analyse the linguistic distance between varieties in apparent time from an aggregate perspective. Specifically, we pay attention to the process of structural dialect loss due to linguistic advergence to standard and eastern Catalan in many north-western Catalan dialects located in Catalonia (Spain) and Andorra. We also provide evidence that the dialect leveling taking place in these two areas strongly contrasts with the relative stability of the Catalan dialects on the other side of the Catalan–Aragonese border in Spain, where Catalan is not an official language. These opposite sociolinguistic situations (Catalonia and Andorra have strong language policies to support Catalan, whereas Aragon does not) have triggered a twofold process of vertical advergence between the Catalan spoken in Catalonia and Andorra towards the prestigious varieties, on the one hand; and of horizontal divergence between these dialects and those located in Aragon, on the other hand. This situation has notably strengthened the border differences between Aragon and Catalonia during the last 80 years. This article is one of the first attempts to study the border effects not only between regions belonging to different countries but also between different administrative regions ‘within’ the same country. In addition, we investigate the different roles of urban versus rural areas, providing support for the view that the spatial and hierarchical diffusion patterns are complementary.",
 "article_title": "Linguistic advergence and divergence in north-western Catalan: A dialectometric investigation of dialect leveling and border effects",
 "authors": [
 {
 "given": " Esteve",
 "family": "Valls",
 "affiliation": [
 {
 "original_name": "University of Barcelona, Spain",
 "normalized_name": "University of Barcelona",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/021018s57",
 "GRID": "grid.5841.8"
 }
 }
 ]
 },
 {
 "given": " Martijn",
 "family": "Wieling",
 "affiliation": [
 {
 "original_name": "University of Groningen, The Netherlands",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 }
 ]
 },
 {
 "given": " John",
 "family": "Nerbonne",
 "affiliation": [
 {
 "original_name": "University of Groningen, The Netherlands",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-01-16",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs053",
 "identifier": {
 "string_id": "10.1093/llc/fqs053",
 "id_scheme": "DOI"
 },
 "abstract": "Traditional Estonian dialect classifications are based on the phonology, morphology, and lexis, and there are very few studies about syntax available. The present article is the first quantitative syntactic study of Estonian dialects. We concentrate on constructions consisting of finite and non-finite verbs, and we apply contemporary statistical methods to explore the syntactic variation. Our results show that even bare token frequencies can identify syntactic patterns quite well, and that analyses exploiting collostructional methods makes the variational patterns even clearer. We use correspondence analysis and clustering to detect geographic influence on variation. The results suggest a syntax-based classification of dialects differs from the traditional classifications based mainly on phonology and lexis. Our data reveal systematic differences between eastern and western dialects at the syntactic level, whereas analyses based on phonology and lexis distinguish mainly between northern and southern dialects. The western dialects make more use of analytic constructions consisting of a finite and a non-finite verb form.",
 "article_title": "Variation of verbal constructions in Estonian dialects",
 "authors": [
 {
 "given": " Kristel",
 "family": "Uiboaed",
 "affiliation": [
 {
 "original_name": "University of Tartu, Estonia",
 "normalized_name": "University of Tartu",
 "country": "Estonia",
 "identifiers": {
 "ror": "https://ror.org/03z77qz90",
 "GRID": "grid.10939.32"
 }
 }
 ]
 },
 {
 "given": " Cornelius",
 "family": "Hasselblatt",
 "affiliation": [
 {
 "original_name": "University of Groningen, The Netherlands",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 }
 ]
 },
 {
 "given": " Liina",
 "family": "Lindström",
 "affiliation": [
 {
 "original_name": "University of Tartu, Estonia",
 "normalized_name": "University of Tartu",
 "country": "Estonia",
 "identifiers": {
 "ror": "https://ror.org/03z77qz90",
 "GRID": "grid.10939.32"
 }
 }
 ]
 },
 {
 "given": " Kadri",
 "family": "Muischnek",
 "affiliation": [
 {
 "original_name": "University of Tartu, Estonia",
 "normalized_name": "University of Tartu",
 "country": "Estonia",
 "identifiers": {
 "ror": "https://ror.org/03z77qz90",
 "GRID": "grid.10939.32"
 }
 }
 ]
 },
 {
 "given": " John",
 "family": "Nerbonne",
 "affiliation": [
 {
 "original_name": "University of Groningen, The Netherlands",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-01-12",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs068",
 "identifier": {
 "string_id": "10.1093/llc/fqs068",
 "id_scheme": "DOI"
 },
 "abstract": "An often-overlooked challenge to the field of digital humanities is the lack of interest in the discipline by young scholars. Despite being the so-called digital natives, many of my museum studies students have no desire to engage with new technology. This short paper is a snapshot of my attempt to teach digital curation and online exhibit development within the framework of my material culture seminar. It analyses 3 years of student exhibits developed using Omeka and points to new directions the project will go over the next several years. I began the research project by asking the following questions of my students: What does material culture look like on the web? How do you curate it? How does the public interact with virtual objects? What is the relationship between virtual and physical museum artifacts? However, after seeing the students struggle with basic web development, I expanded my own research questions to include: What skills do emerging professionals need and how can we integrate technical training into an academic program?",
 "article_title": "Omeka in the classroom: The challenges of teaching material culture in a digital world",
 "authors": [
 {
 "given": " Allison C.",
 "family": "Marsh",
 "affiliation": [
 {
 "original_name": "University of South Carolina",
 "normalized_name": "University of South Carolina",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/02b6qw903",
 "GRID": "grid.254567.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-01-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs070",
 "identifier": {
 "string_id": "10.1093/llc/fqs070",
 "id_scheme": "DOI"
 },
 "abstract": "In this article, we examine the application of computational stylometry to psychological profiling. We adapt several techniques, which have proven useful for author identification to the problem of identifying an individual author’s Myers-Briggs personality type indicator from the statistical features of the text. The Myers-Briggs type indicator assigns four binary classifications to define personality type: Extrovert–Introvert, Intuitive–Sensing, Thinking–Feeling, and Judging–Perceiving. For this study, we use the Personae corpus, which consists of 145 Dutch-language texts all pertaining to a specific topic, each labeled with the Myers-Briggs personality profile of the author (Luyckx K and Daelemans W, Personae: A Corpus for Author and Personality Prediction from Text, In Proceedings of the 6th Language Resources and Evaluation Conference. Marrakech, Morocco: International Conference on Language Resources and Evaluation. 2008). Our system builds upon earlier work by Luyckx and Daelemans (Using Syntactic Features to Predict Author Personality from Text. In Proceedings of Digital Humanities 2008, Oulu, Finland: Digital Humanities, pp. 146–9.) to provide a set of best practices for personality profiling. We propose a more sophisticated modeling technique, combined with more advanced feature selection and state-of-the-art analysis methods from author identification to achieve a significant improvement over previous systems.",
 "article_title": "Psychological profiling through textual analysis",
 "authors": [
 {
 "given": " John",
 "family": "Noecker",
 "affiliation": [
 {
 "original_name": "Duquesne University",
 "normalized_name": "Duquesne University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/02336z538",
 "GRID": "grid.255272.5"
 }
 }
 ]
 },
 {
 "given": " Michael",
 "family": "Ryan",
 "affiliation": [
 {
 "original_name": "Duquesne University",
 "normalized_name": "Duquesne University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/02336z538",
 "GRID": "grid.255272.5"
 }
 }
 ]
 },
 {
 "given": " Patrick",
 "family": "Juola",
 "affiliation": [
 {
 "original_name": "Duquesne University",
 "normalized_name": "Duquesne University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/02336z538",
 "GRID": "grid.255272.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-01-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs050",
 "identifier": {
 "string_id": "10.1093/llc/fqs050",
 "id_scheme": "DOI"
 },
 "abstract": "The relation between the semantic meaning of a lexical variable and the spatial distribution of its variants has been a common field of interest in traditional German dialectology throughout the past century. In the literature in question, several claims regarding the nature of this relation can be found that identify certain semantic properties with spatial distribution patterns. These assumptions are the result of observations the authors made through the qualitative study of their data. Whether these findings can be substantiated in a quantitative analysis, however, has not yet been tested. Neither has a systematic explanatory framework that accounts for these postulated relations been devised. This article investigates these issues by using methods from geostatistical dialectometry that allow certain distributional characteristics of linguistic variables to be quantified. The indices obtained in this way are then tested against the relevance of subject areas. Building on the results, an explanatory framework for their interpretation with respect to basic mechanisms of language variation and change in space is introduced.",
 "article_title": "Lexical meaning and spatial distribution. Evidence from geostatistical dialectometry",
 "authors": [
 {
 "given": " Simon",
 "family": "Pickl",
 "affiliation": [
 {
 "original_name": "University of Salzburg, Austria",
 "normalized_name": "University of Salzburg",
 "country": "Austria",
 "identifiers": {
 "ror": "https://ror.org/05gs8cd61",
 "GRID": "grid.7039.d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-01-06",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs048",
 "identifier": {
 "string_id": "10.1093/llc/fqs048",
 "id_scheme": "DOI"
 },
 "abstract": "In our earlier work, an approach to defining dialect areas using multidimensional scaling (MDS) of the total collection of available raw data (from a region of Romania) has produced results that showed ‘some’ but ‘not all’ of the dialect distinctions that were anticipated. To investigate this situation, we have extended our approach in two ways, one methodological and one technical. Methodologically, we have switched from looking at raw data to examining interpretive maps based on recognized dialect distinctions. Further, we have categorized these interpretations as phonetic (regular and irregular), morphophonemic, morphological, and lexical, examining each category separately. The result is a much clearer set of dialect distinctions, as seen in the MDS pictures. However, the dialect distinctions vary by category, leading us to make suggestions about the role of each category in defining the notion of dialect. Our technical extension is the creation and use of a 3D viewer for looking at the MDS pictures. We project the linguistic-distance space into three, instead of two, dimensions, and manipulate the resulting structure interactively, thus uncovering and eliminating any accidental ‘closeness’, as sometimes happens in the 2D case. Strikingly, the resulting 3D objects seem to be very flat, which strongly suggests that there are only two relevant dimensions for distinguishing these dialects, although the two dimensions do not correspond exclusively to geographic dimensions. The result of these extensions is that the multidimensional approach becomes even more viable as a way of selecting dialect and dialect-transition areas, and perhaps more accessible for use with languages and dialects beyond our own study area.",
 "article_title": "Defining dialect regions with interpretations: Advancing the multidimensional scaling approach",
 "authors": [
 {
 "given": " Sheila",
 "family": "Embleton",
 "affiliation": [
 {
 "original_name": "York University, Toronto, Canada",
 "normalized_name": "York University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/05fq50484",
 "GRID": "grid.21100.32"
 }
 }
 ]
 },
 {
 "given": " Dorin",
 "family": "Uritescu",
 "affiliation": [
 {
 "original_name": "York University, Toronto, Canada",
 "normalized_name": "York University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/05fq50484",
 "GRID": "grid.21100.32"
 }
 }
 ]
 },
 {
 "given": " Eric S.",
 "family": "Wheeler",
 "affiliation": [
 {
 "original_name": "York University, Toronto, Canada",
 "normalized_name": "York University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/05fq50484",
 "GRID": "grid.21100.32"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-01-06",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs047",
 "identifier": {
 "string_id": "10.1093/llc/fqs047",
 "id_scheme": "DOI"
 },
 "abstract": "This study explores the linguistic application of bipartite spectral graph partitioning, a graph-theoretic technique that simultaneously identifies clusters of similar localities as well as clusters of features characteristic of those localities. We compare the results using this approach with previously published results on the same dataset using cluster and principal component analysis (Shackleton 2007). Although the results of the spectral partitioning method and Shackleton’s approach overlap to a broad extent, the analyses offer complementary insights into the data. The traditional cluster analysis detects some clusters that are not identified by the spectral partitioning analysis, whereas the reverse also occurs. Similarly, the principal component analysis and the spectral partitioning analysis detect many overlapping but also some different linguistic variants. The main benefit of the bipartite spectral graph partitioning method over the alternative approaches remains its ability to simultaneously identify sensible geographical clusters of localities with their corresponding linguistic features.",
 "article_title": "Analyzing phonetic variation in the traditional English dialects: Simultaneously clustering dialects and phonetic features",
 "authors": [
 {
 "given": " Martijn",
 "family": "Wieling",
 "affiliation": [
 {
 "original_name": "University of Groningen, The Netherlands",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 }
 ]
 },
 {
 "given": " Robert G.",
 "family": "Shackleton",
 "affiliation": [
 {
 "original_name": "Congressional Budget Office, USA",
 "normalized_name": "Congressional Budget Office",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/03trkbn45",
 "GRID": "grid.431721.2"
 }
 }
 ]
 },
 {
 "given": " John",
 "family": "Nerbonne",
 "affiliation": [
 {
 "original_name": "University of Groningen, The Netherlands",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-01-06",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs055",
 "identifier": {
 "string_id": "10.1093/llc/fqs055",
 "id_scheme": "DOI"
 },
 "abstract": "In 1457, the Florentine merchant, Giovanni Rucellai, started to compose a family records and commonplace book, the Zibaldone Quaresimale. His goal was to transmit knowledge to his sons. This article is a report on the computer-assisted analysis of the Zibaldone and the knowledge Giovanni intended to transmit. The 2nd and 3rd sections treat the theoretical framework applied for knowledge structure analysis and the technical requirements this imposed. In the 4th section, I explain how I transformed the manuscript into a semantically and linguistically annotated corpus with the help of semi-automatic procedures. I also discuss the integrated research environment that I developed to store and link information from secondary and primary sources. In the 6th section, through a concrete research problem, the analysis of social perception, I demonstrate the practical application and the power of the digital environment. This section also presents how the knowledge system described in the codex is reconstructed with the help of a Web Ontology Language ontology. Finally, I argue that a project in Digital Humanities can bring new insights only if a comprehensive theoretical model directs the design and the use of the digital environment; one that functions as a framework to interpret the data that the digital environment produces.",
 "article_title": "The computer-assisted analysis of a medieval commonplace book and diary (MS Zibaldone Quaresimale by Giovanni Rucellai)",
 "authors": [
 {
 "given": " Gábor Mihály",
 "family": "Tóth",
 "affiliation": [
 {
 "original_name": "University of Oxford, UK",
 "normalized_name": "University of Oxford",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/052gg0110",
 "GRID": "grid.4991.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-01-05",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs049",
 "identifier": {
 "string_id": "10.1093/llc/fqs049",
 "id_scheme": "DOI"
 },
 "abstract": "The aim of this article was to present a new tool for doing dialectometry. The program, called ‘DiaTech’, incorporates features of previous programs, especially features of the VDM program created under the direction of H. Goebl. Its main goal is to motivate dialectology studies and dialectologists by providing a new comfortable and efficient tool. With regard to the linguistic features of the program, the most novel feature of ‘DiaTech’ is its ability to manage ‘multiple responses’, that is, for each question, the dialectologist has the option to record more than one item. As far as its basic technological features are concerned, the ‘DiaTech’ program can be used with different platforms; it has an interface in different languages. Regarding statistical procedures, the DiaTech program gives access to a wide variety of distances, including those that are most typically used in dialectometry for bidimensional and multivariate analyses (cluster, correlation, etc.). In addition, the program makes use of different algorithms for visualization and classification. Finally, it provides the necessary tools to create different types of maps with a polygonized background: question by question maps (as in a linguistic atlas), identity maps, honeycomb maps, synopsis of skewness, standard deviation, dendrogramic maps, correlation maps, etc.",
 "article_title": "'DiaTech': A new tool for dialectology",
 "authors": [
 {
 "given": " Gotzon",
 "family": "Aurrekoetxea",
 "affiliation": [
 {
 "original_name": "Department of Linguistics and Basque Studies, University of the Basque Country (UPV/EHU), Spain",
 "normalized_name": "University of the Basque Country",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/000xsnr85",
 "GRID": "grid.11480.3c"
 }
 }
 ]
 },
 {
 "given": " Karmele",
 "family": "Fernandez-Aguirre",
 "affiliation": [
 {
 "original_name": "Department of Applied Economy III (Statistics and Econometrics), University of the Basque Country (UPV/EHU), Spain",
 "normalized_name": "University of the Basque Country",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/000xsnr85",
 "GRID": "grid.11480.3c"
 }
 }
 ]
 },
 {
 "given": " Jesús",
 "family": "Rubio",
 "affiliation": [
 {
 "original_name": "Department of Applied Economy III (Statistics and Econometrics), University of the Basque Country (UPV/EHU), Spain",
 "normalized_name": "University of the Basque Country",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/000xsnr85",
 "GRID": "grid.11480.3c"
 }
 }
 ]
 },
 {
 "given": " Borja",
 "family": "Ruiz",
 "affiliation": [
 {
 "original_name": "UEU (Basque Summer University), Spain",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Jon",
 "family": "Sánchez",
 "affiliation": [
 {
 "original_name": "Department of Electronics and Telecommunications, University of the Basque Country (UPV/EHU), Spain",
 "normalized_name": "University of the Basque Country",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/000xsnr85",
 "GRID": "grid.11480.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2013-01-05",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs044",
 "identifier": {
 "string_id": "10.1093/llc/fqs044",
 "id_scheme": "DOI"
 },
 "abstract": "We present WordSeer, an exploratory analysis environment for literary text. Literature study is a cycle of reading, interpretation, exploration, and understanding. While there is now abundant technological support for reading and interpreting literary text in new ways through text-processing algorithms, the other parts of the cycle—exploration and understanding—have been relatively neglected. We are motivated by the literature on sensemaking, an area of computer science devoted to supporting open-ended analysis on large collections of data. Our software system integrates tools for algorithmic processing of text with interaction techniques that support the interpretive, exploratory, and note-taking aspects of scholarship. At present, the system supports grammatical search and contextual similarity determination, visualization of patterns of word context, and examination and organization of the source material for comparison and hypothesis building. This article illustrates its capabilities by analyzing language-use differences between male and female characters in Shakespeare’s plays. We find that when love is a major plot point, the language Shakespeare uses to refer to women becomes more physical, and the language referring to men becomes more sentimental. Future work will incorporate additional sensemaking tools to aid comparison, exploration, grouping, and pattern recognition.",
 "article_title": "Supporting exploratory text analysis in literature study",
 "authors": [
 {
 "given": " Aditi",
 "family": "Muralidharan",
 "affiliation": [
 {
 "original_name": "University of California at Berkeley, USA",
 "normalized_name": "University of California, Berkeley",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/01an7q238",
 "GRID": "grid.47840.3f"
 }
 }
 ]
 },
 {
 "given": " Marti A.",
 "family": "Hearst",
 "affiliation": [
 {
 "original_name": "University of California at Berkeley, USA",
 "normalized_name": "University of California, Berkeley",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/01an7q238",
 "GRID": "grid.47840.3f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-12-24",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs054",
 "identifier": {
 "string_id": "10.1093/llc/fqs054",
 "id_scheme": "DOI"
 },
 "abstract": "There has been widespread excitement in recent years about the emergence of large-scale digital initiatives (LSDIs) such as Google Book Search. Although many have become excited at the prospect of a digital recreation of the Library of Alexandria, there has also been great controversy surrounding these projects. This article looks at one of these controversies: the suggestion that mass digitization is creating a virtual rubbish dump of our cultural heritage. It discusses some of the quantitative methods being used to analyse the big data that have been created, and two major concerns that have arisen as a result. First, there is the concern that quantitative analysis has inadvertently fed a culture that favours information ahead of traditional research methods. Second, little information exists about how LSDIs are used for any research other than quantitative methods. These problems have helped to fuel the idea that digitization is destroying the print medium, when in many respects it still closely remediates the bibliographic codes of the Gutenberg era. The article concludes that more work must be done to understand what impact mass digitization has had on all researchers in the humanities, rather than just the early adopters, and briefly mentions the work that the author is undertaking in this area.",
 "article_title": "Mass digitization and the garbage dump: The conflicting needs of quantitative and qualitative methods",
 "authors": [
 {
 "given": " Paul",
 "family": "Gooding",
 "affiliation": [
 {
 "original_name": "University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-12-25",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs051",
 "identifier": {
 "string_id": "10.1093/llc/fqs051",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents a statistical comparison of common patterns of regional phonetic and lexical variation in American English based on the results of two previous dialect studies. Because these two studies are based on datasets that represent different cities, this article also introduces a general method for comparing dialect maps that are based on different sets of locations. This method of comparison consists of two steps. First, the dialects maps are defined across a shared set of reference locations through ordinary kriging. Second, these normalized maps are correlated to each other in order to estimate the similarity between the original dialect maps. The results of this comparison show that regional phonetic and lexical variation follow similar patterns in Modern American English.",
 "article_title": "A statistical comparison of regional phonetic and lexical variation in American English",
 "authors": [
 {
 "given": " Jack",
 "family": "Grieve",
 "affiliation": [
 {
 "original_name": "Aston University, UK",
 "normalized_name": "Aston University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05j0ve876",
 "GRID": "grid.7273.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-12-25",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs056",
 "identifier": {
 "string_id": "10.1093/llc/fqs056",
 "id_scheme": "DOI"
 },
 "abstract": "The importance of abductive reasoning is increasingly emphasized within diverse research domains in which interpretation plays a central role. This reasoning type appears to provide an answer to various significant issues in diverse domains, especially in combination with deductive and inductive reasoning, as C. S. Peirce eventually presented it in his process of (scientific) inquiry. Central to our interpretation of Peirce’s process of inquiry, thus stands a cycle of abductive, deductive, and inductive reasoning, which is iterated continuously with the surrounding world as its subject. This world here is understood as the environment that surrounds us and that we experience through our senses. The continuous iteration of Peirce’s process of inquiry allows constructing experience-based knowledge dynamically. This kind of knowledge comes closer to the dynamic memory and reasoning that is required for active interpretation. Issues that might be better understood and addressed accordingly involve not only interpretation but also idea generation, creativity, surprise, and so forth. This article documents a part of our efforts in simulating such a reasoning cycle using currently available technologies. Diverse hypotheses and conclusions have been made in these simulation efforts. For instance, we hypothesize that Peirce’s reasoning cycle might be configured in reasoning levels, with each level handling information or patterns in different levels of invariance and meaning. These efforts have resulted in an environment in which a reasoning agent processes basic colour information and gradually builds up interpretations of such colours based on incoming information.",
 "article_title": "Including the power of interpretation through a simulation of Peirce's process of inquiry",
 "authors": [
 {
 "given": "P.",
 "family": "Pauwels",
 "affiliation": [
 {
 "original_name": "Institute for Logic, Language and Computation, University of Amsterdam, Amsterdam, The Netherlands",
 "normalized_name": "University of Amsterdam",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/04dkp9463",
 "GRID": "grid.7177.6"
 }
 }
 ]
 },
 {
 "given": "R.",
 "family": "Bod",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-12-23",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs063",
 "identifier": {
 "string_id": "10.1093/llc/fqs063",
 "id_scheme": "DOI"
 },
 "abstract": "Land deeds were the only proof of ownership in pre-1900 Taiwan. They are indispensable for the studies of Taiwan’s social, anthropological, and economic evolution. We have built a full-text digital library that contains almost 40,000 land deeds. The deeds in our collection range over 250 years and are collected from over 100 sources. The unprecedented volume and diversity of the sources provide an exciting source of primary documents for historians. But they also pose an interesting challenge: how to tell if two land deeds are related. In this article, we describe an approach to discover two important relations: successive transactions and allotment agreements involving the same property. Our method enabled us to construct 6,035 such transaction pairs. We also introduce a notion of ‘land transitivity graph’ to capture the transitivity embedded in these transactions. We discovered 2,436 such graphs, the largest of which includes 104 deeds. Some of these graphs involve land behavior that had never been studied before.",
 "article_title": "Discovering land transaction relations from land deeds of Taiwan",
 "authors": [
 {
 "given": " Shih-Pei",
 "family": "Chen",
 "affiliation": [
 {
 "original_name": "National Taiwan University, Taiwan",
 "normalized_name": "National Taiwan University",
 "country": "Taiwan",
 "identifiers": {
 "ror": "https://ror.org/05bqach95",
 "GRID": "grid.19188.39"
 }
 }
 ]
 },
 {
 "given": " Yu-Ming",
 "family": "Huang",
 "affiliation": [
 {
 "original_name": "National Taiwan University, Taiwan",
 "normalized_name": "National Taiwan University",
 "country": "Taiwan",
 "identifiers": {
 "ror": "https://ror.org/05bqach95",
 "GRID": "grid.19188.39"
 }
 }
 ]
 },
 {
 "given": " Jieh",
 "family": "Hsiang",
 "affiliation": [
 {
 "original_name": "National Taiwan University, Taiwan",
 "normalized_name": "National Taiwan University",
 "country": "Taiwan",
 "identifiers": {
 "ror": "https://ror.org/05bqach95",
 "GRID": "grid.19188.39"
 }
 }
 ]
 },
 {
 "given": " Hsieh-Chang",
 "family": "Tu",
 "affiliation": [
 {
 "original_name": "National Taiwan University, Taiwan",
 "normalized_name": "National Taiwan University",
 "country": "Taiwan",
 "identifiers": {
 "ror": "https://ror.org/05bqach95",
 "GRID": "grid.19188.39"
 }
 }
 ]
 },
 {
 "given": " Hou-Ieong",
 "family": "Ho",
 "affiliation": [
 {
 "original_name": "National Taiwan University, Taiwan",
 "normalized_name": "National Taiwan University",
 "country": "Taiwan",
 "identifiers": {
 "ror": "https://ror.org/05bqach95",
 "GRID": "grid.19188.39"
 }
 }
 ]
 },
 {
 "given": " Ping-Yen",
 "family": "Chen",
 "affiliation": [
 {
 "original_name": "National Taiwan University, Taiwan",
 "normalized_name": "National Taiwan University",
 "country": "Taiwan",
 "identifiers": {
 "ror": "https://ror.org/05bqach95",
 "GRID": "grid.19188.39"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-12-22",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs065",
 "identifier": {
 "string_id": "10.1093/llc/fqs065",
 "id_scheme": "DOI"
 },
 "abstract": "In this study, we propose an integrated method to automatically evaluate very brief summaries (around 50 words) using the computational tool latent semantic analysis (LSA). The method proposed is based on a regression equation calculated with a corpus of a 100 summaries (the training sample) and is validated on a different sample of summaries (validation sample). The equation incorporates two parameters extracted from LSA: (1) the semantic similarity of the summary, measured using the summary–expert summaries method and (2) the vector length. The study is based on a sample of 786 summaries by students at four academic levels. All of these students summarized either an expository or a narrative text; their summaries were then evaluated by four graders on a scale of 0–10. The results support three ideas. First, that incorporating both parameters into the method is more successful than the traditional cosine measure. The reliability of LSA for evaluating summaries rises >0.80 level for the expository text. Second, that LSA shows practically the same level of sensitivity as the human graders to the quality of the summaries at different academic levels. Third, that the method overcomes a serious limitation of LSA: its difficulties evaluating very brief texts.",
 "article_title": "Using latent semantic analysis to grade brief summaries: A study exploring texts at different academic levels",
 "authors": [
 {
 "given": " Ricardo",
 "family": "Olmos",
 "affiliation": [
 {
 "original_name": "Universidad Autónoma de Madrid, Spain",
 "normalized_name": "Autonomous University of Madrid",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01cby8j38",
 "GRID": "grid.5515.4"
 }
 }
 ]
 },
 {
 "given": " José A.",
 "family": "León",
 "affiliation": [
 {
 "original_name": "Universidad Autónoma de Madrid, Spain",
 "normalized_name": "Autonomous University of Madrid",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01cby8j38",
 "GRID": "grid.5515.4"
 }
 }
 ]
 },
 {
 "given": " Guillermo",
 "family": "Jorge-Botana",
 "affiliation": [
 {
 "original_name": "Universidad Nacional de Educación a Distancia, Spain",
 "normalized_name": "National University of Distance Education",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/02msb5n36",
 "GRID": "grid.10702.34"
 }
 }
 ]
 },
 {
 "given": " Inmaculada",
 "family": "Escudero",
 "affiliation": [
 {
 "original_name": "Universidad Nacional de Educación a Distancia, Spain",
 "normalized_name": "National University of Distance Education",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/02msb5n36",
 "GRID": "grid.10702.34"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-12-22",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs060",
 "identifier": {
 "string_id": "10.1093/llc/fqs060",
 "id_scheme": "DOI"
 },
 "abstract": "‘Dialectal stratigraphy’ aims to focus on the cartography of ancient lexicon. It seeks to represent cartographically how the diatopic variation of a sample of sixty words has evolved. The project begins with the earliest period of written Catalan and indicates the words’ geographical location and their graphic form and semantic progression over time. Unlike conventional atlases which use only a single axis, two axes of linguistic representation are used in dialectal stratigraphy, those of space and time. The distribution of words in the map is represented in layers depicting linguistic change over time. From a methodological point of view, a number of dynamic maps have been created. The maps have a chronological axis that: (1) allows the words to be traced to their initial geographical place; (2) shows their evolution over the passage of the centuries; and (3) makes it possible to observe its geographical movement. In addition, this comprehensive overview allows us to track the course of Eastern and Western Catalan dialects which have been subject of so much controversy of late and also provides information about transitional areas. The aim of this article is to show the potential of this technique for exploring the reasons for changes in lexicon.",
 "article_title": "Dynamic cartography with diachronic data: Dialectal stratigraphy",
 "authors": [
 {
 "given": " Maria-Pilar",
 "family": "Perea",
 "affiliation": [
 {
 "original_name": "Universitat de Barcelona, Spain",
 "normalized_name": "University of Barcelona",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/021018s57",
 "GRID": "grid.5841.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-12-18",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs064",
 "identifier": {
 "string_id": "10.1093/llc/fqs064",
 "id_scheme": "DOI"
 },
 "abstract": "This research-in-progress report describes ongoing work on a doctoral dissertation, which attempts to model the prototypical structure of the tourist brochure as a multimodal artefact. By using a multimodal corpus based on the Genre and Multimodality model, the dissertation investigates how the brochures use both language and image to fulfil their communicative function. This article focuses on a specific aspect of the prototypical structure, that is, how the brochures organize the content in the layout and signal its interrelations. The article suggests that the layout and the rhetorical relations between the content are intertwined in what may be called the ‘rhetoric-layout interface’. By drawing on a sample of three brochures published in 1984, 1988, and 2006, the article explores how this interface shapes the multimodal structure of the tourist brochures. The relationship between the rhetorical and the layout structure is suggested to be reciprocal: adopting a particular configuration in the rhetorical structure also affects the range of choices available in the layout structure and vice versa.The article concludes that the interface between the rhetorical and the layout structure warrants attention in modeling the prototypical structure, and suggests that certain structural signals related to the use of two-dimensional space require specific attention in corpus analysis. Moreover, extensive cross-layer analyses with larger corpora will be required to tease out the range of different configurations in the tourist brochures, and to create a prototypical model of the multimodal artefact.",
 "article_title": "The interface between rhetoric and layout in multimodal artefacts",
 "authors": [
 {
 "given": " Tuomo",
 "family": "Hiippala",
 "affiliation": [
 {
 "original_name": "University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-12-15",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs066",
 "identifier": {
 "string_id": "10.1093/llc/fqs066",
 "id_scheme": "DOI"
 },
 "abstract": "We examine the assertion that the two-parameter log-normal distribution is an appropriate parametric model for the shot length distributions of Hollywood films. A review of the claims made in favour of assuming log-normality for shot length distributions finds them to be lacking in methodological detail and statistical rigour. We find there is no supporting evidence to justify the assumption of log-normality in general for shot length distributions. In order to test this assumption, we examined a total of 134 Hollywood films from 1935 to 2005, inclusive, to determine goodness-of-fit of a normal distribution to log-transformed shot lengths of these films using four separate measures: the ratio of the geometric mean to the median; the ratio of the shape factor σ to the estimator σ* = √(2 × ln (\u2060/M)); the Shapiro–Francia test; and the Jarque–Bera test. Normal probability plots were also used for visual inspection of the data. The results show that, while a small number of films are well modelled by a log-normal distribution, this is not the case for the overwhelming majority of films tested (125 out of 134). Therefore, we conclude there is no justification for claiming the log-normal distribution is an adequate parametric model of shot length data for Hollywood films and recommend the use of robust statistics that do not require underlying parametric models for the analysis of film style.",
 "article_title": "The log-normal distribution is not an appropriate parametric model for shot length distributions of Hollywood films",
 "authors": [
 {
 "given": " Nick",
 "family": "Redfern",
 "affiliation": [
 {
 "original_name": "Independent Researcher",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-12-15",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "30",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs040",
 "identifier": {
 "string_id": "10.1093/llc/fqs040",
 "id_scheme": "DOI"
 },
 "abstract": "Estrategias Contemporáneas de Lectura is a project focused on research and teaching that emphasizes the importance of interpretation in the study of Classical Antiquity. The aim of the project is to support research with digital tools that document the process by which a perspective point or horizon of interpretation is constructed, by following the development of individual and group work processes. The progress of the project has posed theoretical and technical challenges related to a diversity of methodologies and expectations of the project. However, the development of these discussions has showed the relevance of interpretation and its complexity, making it a fruitful experience.",
 "article_title": "Documenting horizons of interpretation in philosophy",
 "authors": [
 {
 "given": " Ernesto Priani",
 "family": "Saisó",
 "affiliation": [
 {
 "original_name": "History of Philosophy and Humanities Computing, Facultad de Filosofía y Letras, Universidad Nacional Autónoma de México",
 "normalized_name": "National Autonomous University of Mexico",
 "country": "Mexico",
 "identifiers": {
 "ror": "https://ror.org/01tmp8f25",
 "GRID": "grid.9486.3"
 }
 }
 ]
 },
 {
 "given": " Leticia Flores",
 "family": "Farfán",
 "affiliation": [
 {
 "original_name": "History of Philosophy, Facultad de Filosofía y Letras, Universidad Nacional Autónoma de México",
 "normalized_name": "National Autonomous University of Mexico",
 "country": "Mexico",
 "identifiers": {
 "ror": "https://ror.org/01tmp8f25",
 "GRID": "grid.9486.3"
 }
 }
 ]
 },
 {
 "given": " Isabel",
 "family": "Galina",
 "affiliation": [
 {
 "original_name": "Instituto de Investigaciones Bibliográficas, Universidad Nacional Autónoma de México",
 "normalized_name": "National Autonomous University of Mexico",
 "country": "Mexico",
 "identifiers": {
 "ror": "https://ror.org/01tmp8f25",
 "GRID": "grid.9486.3"
 }
 }
 ]
 },
 {
 "given": " Rafael Gómez",
 "family": "Choreño",
 "affiliation": [
 {
 "original_name": "History of Philosophy, Facultad de Filosofía y Letras, Universidad Nacional Autónoma de México",
 "normalized_name": "National Autonomous University of Mexico",
 "country": "Mexico",
 "identifiers": {
 "ror": "https://ror.org/01tmp8f25",
 "GRID": "grid.9486.3"
 }
 }
 ]
 },
 {
 "given": " Marat Ocampo Gutiérrez",
 "family": "de Velasco",
 "affiliation": [
 {
 "original_name": "Facultad de Filosofía y Letras, Universidad Nacional Autónoma de México",
 "normalized_name": "National Autonomous University of Mexico",
 "country": "Mexico",
 "identifiers": {
 "ror": "https://ror.org/01tmp8f25",
 "GRID": "grid.9486.3"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-10-15",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs046",
 "identifier": {
 "string_id": "10.1093/llc/fqs046",
 "id_scheme": "DOI"
 },
 "abstract": "The aim of this article was to distinguish different authorial layers within a 15th-century chronicle, a rare medieval autograph or author’s copy (Croniken van der Duytscher Oirden or Jüngere Hochmeisterchronik), and to test specifically the validity of claims concerning the original composition of the text. A better apprehension of the creative process involved in composing the Croniken is essential for the interpretation and understanding of the purpose and intended audience of the text. Furthermore, it gives an insight into the historiographical activities in the ‘peripheral’ bailiwicks of the Teutonic Order. Computational techniques, in this case John Burrows’ tried-and-tested Delta method, play an invaluable role in both the solution of these issues as well as in pointing in the direction of new enquiries. Here, the Delta method was used to create a walking window, only 2,000 words in length, across the entire chronicle. Despite the small sample size, chosen because in the present case, a finer granularity and precision in detecting the shifts in authorial styles was as important as reliability, Delta was able to pick out distinct parts of the chronicle, some as short as just >500 words.",
 "article_title": "Layer on layer. 'Computational archaeology' in 15th-century Middle Dutch historiography",
 "authors": [
 {
 "given": " Rombert J.",
 "family": "Stapel",
 "affiliation": [
 {
 "original_name": "Fryske Akademy",
 "normalized_name": "Fryske Akademy",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/05fcmfe52",
 "GRID": "grid.450022.1"
 }
 },
 {
 "original_name": "Royal Netherlands Academy of Arts and Sciences",
 "normalized_name": "Royal Netherlands Academy of Arts and Sciences",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/043c0p156",
 "GRID": "grid.418101.d"
 }
 },
 {
 "original_name": "Leiden University, Netherlands",
 "normalized_name": "Leiden University",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/027bh9e22",
 "GRID": "grid.5132.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-12-05",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs013",
 "identifier": {
 "string_id": "10.1093/llc/fqs013",
 "id_scheme": "DOI"
 },
 "abstract": "This article explores building blocks in extant and emerging social media toward the possibilities they offer to the scholarly edition in electronic form, positing that we are witnessing the nascent stages of a new ‘social’ edition existing at the intersection of social media and digital editing. Beginning with a typological formulation of electronic scholarly editions, activities common to humanities scholars who engage with texts as expert readers are considered, noting that many methods of engagement both reflect the interrelated nature of long-standing professional reading strategies and are social in nature; extending this frame work, the next steps in the scholarly edition’s development in its incorporation of social media functionality reflect the importance of traditional humanistic activities and workflows, and include collaboration, incorporating contributions by its readers and re-visioning the role of the editor away from that of ultimate authority and more toward that of facilitator of reader involvement. Intended to provide a ‘toolkit’ for academic consideration, this discussion of the emerging social edition points to new methods of textual engagement in digital literary studies and is accompanied by two integral, detailed appendices, published in Digital Humanities Quarterly under the title ‘Pertinent discussions toward modeling the social edition: Annotated bibliographies’ (http://www.digitalhumanities.org/dhq/vol/6/1/000111/000111.html): one addressing issues pertinent to online reading and interaction, and another on social networking tools.",
 "article_title": "Toward modeling the social edition: An approach to understanding the electronic scholarly edition in the context of new and emerging social media",
 "authors": [
 {
 "given": " Ray",
 "family": "Siemens",
 "affiliation": [
 {
 "original_name": "Electronic Textual Cultures Lab, University of Victoria",
 "normalized_name": "University of Victoria",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04s5mat29",
 "GRID": "grid.143640.4"
 }
 }
 ]
 },
 {
 "given": " Meagan",
 "family": "Timney",
 "affiliation": [
 {
 "original_name": "Blurb, Inc.",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Cara",
 "family": "Leitch",
 "affiliation": [
 {
 "original_name": "Department of English, University of Victoria",
 "normalized_name": "University of Victoria",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04s5mat29",
 "GRID": "grid.143640.4"
 }
 }
 ]
 },
 {
 "given": " Corina",
 "family": "Koolen",
 "affiliation": [
 {
 "original_name": "Centre for the Arts in Society, Leiden University",
 "normalized_name": "Leiden University",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/027bh9e22",
 "GRID": "grid.5132.5"
 }
 }
 ]
 },
 {
 "given": " Alex",
 "family": "Garnett",
 "affiliation": [
 {
 "original_name": "School of Library, Archival & Information Studies, University of British Columbia",
 "normalized_name": "University of British Columbia",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03rmrcq20",
 "GRID": "grid.17091.3e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-10-25",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs032",
 "identifier": {
 "string_id": "10.1093/llc/fqs032",
 "id_scheme": "DOI"
 },
 "abstract": "This esssay intends to understand the relationships between arts (especially literature) and technologies, in our current environment characterized by intense technological saturation. Anyway, so far, there is nothing substantially new in this contrast we want to establish between arts and technology: the first ones are always based on some techniques (which are mostly internal to arts) and have constantly tensioned relationships with technologies (which are mostly external to arts). And when I say tensioned relationships, it means that I am trying to understand the distances and rapprochements between arts and technology, without having to choose definitely a possibility or another, as it has often been done by artists, aesthetes, critics, and theorists.",
 "article_title": "Retard of progress",
 "authors": [
 {
 "given": " Alckmar",
 "family": "Luiz dos Santos",
 "affiliation": [
 {
 "original_name": "Universidade Federal de Santa Catarina, Brazil CNPq, Brazil",
 "normalized_name": "Universidade Federal de Santa Catarina",
 "country": "Brazil",
 "identifiers": {
 "ror": "https://ror.org/041akq887",
 "GRID": "grid.411237.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-09-24",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs037",
 "identifier": {
 "string_id": "10.1093/llc/fqs037",
 "id_scheme": "DOI"
 },
 "abstract": "This article discusses the reception of electronic literature, focusing on the development of new literary reading rituals in electronic environments in the Hispanic world. It consists of three parts: a revision of the situation of Hispanic reader communities in the electronic environment; the description of the results of a series of literary on-screen reading experiences with university students, and a final exposition of some reading strategies required to bridge the gap between print and online literature.",
 "article_title": "Literary reading rituals and practices on new interfaces",
 "authors": [
 {
 "given": " Amelia",
 "family": "Sanz",
 "affiliation": [
 {
 "original_name": "University Complutense of Madrid, Spain",
 "normalized_name": "Complutense University of Madrid",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/02p0gd045",
 "GRID": "grid.4795.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-09-24",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs035",
 "identifier": {
 "string_id": "10.1093/llc/fqs035",
 "id_scheme": "DOI"
 },
 "abstract": "Ever since scholars in the humanities have studied computer games, the relationship between play and narrative has been a much contested issue. Much dissent stems from incompatible basic assumptions about play and narrative, which, this article argues, can be reconciled by a formalist approach to games and narrative on a structural level. First, event structures and story structures are shown to be central to various theories of narrative. Correlating these findings with Espen Aarseth’s reflections upon nonlinearity, an understanding of narrative revolving around event logic is developed. Building on the theory of games developed by Roger Caillois, the article then develops a model of games in which three layers of structures are governed by three types of rules. The most abstract of these layers arranges game elements in a meta-structure which is based on both ludic and narrative logic. In a final step, nonlinear game structures are explained within this model and categorized in a typology that orders them by the type of agency players can execute.",
 "article_title": "Narrative rules? Story logic and the structures of games",
 "authors": [
 {
 "given": " Hans-Joachim",
 "family": "Backe",
 "affiliation": [
 {
 "original_name": "Ruhr-University Bochum, Bochum, Germany",
 "normalized_name": "Ruhr University Bochum",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/04tsk2644",
 "GRID": "grid.5570.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-08-12",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs036",
 "identifier": {
 "string_id": "10.1093/llc/fqs036",
 "id_scheme": "DOI"
 },
 "abstract": "This study investigates the problem of appropriate choice of texts for the training set in machine-learning classification techniques. Although intuition suggests picking the most typical texts (whatever ‘typical’ means) by the authors studied, any arbitrary choice might substantially affect the final results. Thus, to eschew cherry picking, we introduce a method of verification of the choice of ‘typical’ samples, inspired by k-fold cross-validation procedures. Namely, we use a bootstrap-like approach to choose randomly, in 500 iterations, the samples for the training and the test sets. Next, we examine the obtained 500 attribution accuracy scores: if the density function shows widespread results, the corpus is assumed to be very sensitive to the permutations of the training set. To test this methodology empirically, we have selected roughly similar corpora in five languages: English, French, German, Italian, and Polish. The results show considerable resistance of the English corpus to permutations, while the other corpora turned out to be more dependent on the choice of the samples; the Polish corpus produces both accuracy and consistency below any acceptable standards.",
 "article_title": "Do birds of a feather really flock together, or how to choose training samples for authorship attribution",
 "authors": [
 {
 "given": " Maciej",
 "family": "Eder",
 "affiliation": [
 {
 "original_name": "Pedagogical University of Kraków, Poland",
 "normalized_name": "Pedagogical University of Kraków",
 "country": "Poland",
 "identifiers": {
 "ror": "https://ror.org/030mz2444",
 "GRID": "grid.412464.1"
 }
 }
 ]
 },
 {
 "given": " Jan",
 "family": "Rybicki",
 "affiliation": [
 {
 "original_name": "Jagiellonian University, Kraków, Poland",
 "normalized_name": "Jagiellonian University",
 "country": "Poland",
 "identifiers": {
 "ror": "https://ror.org/03bqmcz70",
 "GRID": "grid.5522.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-08-12",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs034",
 "identifier": {
 "string_id": "10.1093/llc/fqs034",
 "id_scheme": "DOI"
 },
 "abstract": "The article explores whether stylometric methods used in non-traditional authorship attribution can help to gain more insight in how medieval scribes dealt with the text they were copying. The research corpus consists of transcriptions from all more or less complete manuscripts of Jacob van Maerlant’s Scolastica, a Middle Dutch translation/adaptation of Peter Comestor’s Medieval Latin Historia scholastica. Five episodes were selected totalling seventy samples of around 1,200 tokens each. Cluster analysis and principal component analysis are used to compare the copies per episode. The results based on the Middle Dutch texts were highly influenced by irrelevant spelling variation. Since the aim was to explore differences on the content level of the copies, the analyses were extended to lemmatised versions of the texts. The results based on the lemmatised texts are a good starting point for the exploration of the ways in which Scolastica scribes dealt with the work they were copying. The main results of the exploration are that most copies of an episode cluster closely together, with only occasional outliers. The outliers are not the same for each episode, which suggests that a separate analysis and explanation per episode is needed—scribes may have had reasons to elaborate on one topic and to leave another untouched, for instance under the instruction of a patron. The article closes with some pointers for the next steps in the research, which are expected to need other kinds of methods for analysis.",
 "article_title": "The secret life of scribes. Exploring fifteen manuscripts of Jacob van Maerlant's Scolastica (1271)",
 "authors": [
 {
 "given": " Karina",
 "family": "van Dalen-Oskam",
 "affiliation": [
 {
 "original_name": "Huygens Institute for the History of the Netherlands (Royal Netherlands Academy of Arts and Sciences), The Netherlands",
 "normalized_name": "Royal Netherlands Academy of Arts and Sciences",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/043c0p156",
 "GRID": "grid.418101.d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-08-09",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs031",
 "identifier": {
 "string_id": "10.1093/llc/fqs031",
 "id_scheme": "DOI"
 },
 "abstract": "It has been an accepted notion that ‘inter-textuality’ is the basis of all communication. Games, inasmuch as they use semiotic systems, are no exception. At the same time the special rhetorical use of specific references and allusions to other texts, particularly in literature, is also an established fact. It is however, quite surprising to find rhetorical inter-textuality in computer games, even in single player action of the shooting type, because of the demands such games make on the player’s time and attention. Following a theoretical grounding in theories of allusion (Ben-Porat, 1976, 1978) and game theory (Aarseth, 1997, 1999, 2005a,b, 2006, 2012), the article presents six distinct types of rhetorical allusions, discussing them in relation to the narrativity level of the game to which they belong, to the source text position vis-à-vis the game, and to published evidence concerning the identification of such literary canonic traces and reflections on their contribution to the game. The results are hardly surprising, but still interesting. Game-produced narratives are not literary, certainly not literary inter-textual texts. Consequently, although there are numerous inter-textual relations between computer games and canonic, as well as popular literary texts, very few of them can be actualized as rhetorical allusions, and even less will. They are not treated as such by those who use them, though their authors may think and act otherwise. Neither triggers nor a high concentration of narrative elements effects actualizations. Significantly, gamers’ behavior is not different from that of average readers and the nature of the triggers is typical of contemporary culture: they consist of minimal cultural units, former attributes of canonic works that have become detached from and independent of their sources.",
 "article_title": "Allusive inter-textuality in computer games",
 "authors": [
 {
 "given": " Ziva",
 "family": "Ben-Porat",
 "affiliation": [
 {
 "original_name": "The Porter Institute for Poetics and Semiotics, Tel Aviv University, Israel",
 "normalized_name": "Tel Aviv University",
 "country": "Israel",
 "identifiers": {
 "ror": "https://ror.org/04mhzgx49",
 "GRID": "grid.12136.37"
 }
 },
 {
 "original_name": "Department of Culture, Creation and Production, Sapir Academic College, Israel",
 "normalized_name": "Sapir College",
 "country": "Israel",
 "identifiers": {
 "ror": "https://ror.org/04hwjfc40",
 "GRID": "grid.430165.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-08-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs020",
 "identifier": {
 "string_id": "10.1093/llc/fqs020",
 "id_scheme": "DOI"
 },
 "abstract": "In an earlier study that identified previously unrecognized writings of the young Thomas Hobbes, questions were raised about the authorship of some of Francis Bacon’s published works. This article reports a follow-up study in which two independent statistical analyses of Bacon’s English works both conclude that, whereas Bacon’s autographic writings show clearly that they are authored by the same person; almost none of his published works can be matched statistically with the autographs. The most likely explanation for this dramatic finding is that Bacon’s well-known reliance on secretaries may have been sufficiently extensive that his writing patterns are obscured or replaced by theirs. This finding suggests a far simpler explanation for a wide array of anomalies in Bacon’s works than others have offered. The study further identifies some of Bacon’s works written during a period when Thomas Hobbes was his secretary, which match Hobbes’s writing pattern.",
 "article_title": "Who wrote Bacon? Assessing the respective roles of Francis Bacon and his secretaries in the production of his English works",
 "authors": [
 {
 "given": " Noel B.",
 "family": "Reynolds",
 "affiliation": [
 {
 "original_name": "Brigham Young University, Political Science",
 "normalized_name": "Brigham Young University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047rhhm47",
 "GRID": "grid.253294.b"
 }
 }
 ]
 },
 {
 "given": " G. Bruce",
 "family": "Schaalje",
 "affiliation": [
 {
 "original_name": "Brigham Young University, Statistics",
 "normalized_name": "Brigham Young University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047rhhm47",
 "GRID": "grid.253294.b"
 }
 }
 ]
 },
 {
 "given": " John L.",
 "family": "Hilton",
 "affiliation": [
 {
 "original_name": "Brigham Young University, Statistics",
 "normalized_name": "Brigham Young University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047rhhm47",
 "GRID": "grid.253294.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-08-01",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs027",
 "identifier": {
 "string_id": "10.1093/llc/fqs027",
 "id_scheme": "DOI"
 },
 "abstract": "Like most authors of digital works of the narrative genre, Gregory Chatonsky is opposed to the idea that plots should be written according to the novelistic traditions. His hyperfiction entitled The Subnetwork is no exception. For the clash of heterogeneous media in this work to produce a ‘community of metaphors’, as opposed to a dialectical reasoning or a conventional narrative, every single media must be indifferently compatible with each other. Occasional relationships are thus established between different worlds, different parts of individual and collective history, which highlights a more fundamental relation of co-membership, where heterogeneous elements are always likely to assemble according to the ‘brotherhood of a new metaphor’ (Rancière, 2003, Le destin des images. Paris: La Fabrique, p. 67). The range of metaphorical brotherhood yet widens in The Subnetwork, through the introduction of animated texts and the possibility that readers are given to ‘manipulate’ (interact with) the work. Using a semio-pragmatic methodology developed at University Paris 8, I will first examine in detail the construction of meaning in these combinations between texts and movement or manipulation and their relationship with the contexts in a reading process. Digital literature often experiments with unexpected combinations based on a (de-)coherence between text, movement, and manipulation gestures, called animation figures and manipulation figures: I would situate a part of the poetic potential of digital literature in these ‘spaces of indeterminacy’.",
 "article_title": "Animation and manipulation figures in digital literature and the poetics of (de-)coherence: As exemplified by Gregory Chatonsky's The Subnetwork",
 "authors": [
 {
 "given": " Alexandra",
 "family": "Saemmer",
 "affiliation": [
 {
 "original_name": "University Paris 8, France",
 "normalized_name": "Paris 8 University",
 "country": "France",
 "identifiers": {
 "ror": "https://ror.org/04wez5e68",
 "GRID": "grid.15878.33"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-07-24",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs030",
 "identifier": {
 "string_id": "10.1093/llc/fqs030",
 "id_scheme": "DOI"
 },
 "abstract": "This contribution comments on certain works of digital literature in order to demonstrate their use of formal and thematic literary techniques and show that ‘wreaders’ have their own creative pattern. Playing with hyperlinks involves disorganized thinking, associative laxity and conceptual, and linguistic alterations that infringe the linear construction of the literary paradigm. The mechanism that appears during this creative ‘wreadering–wandering’ process operates in such a way that time and space converge to produce what we will call ‘digital entropy’, a creative force in which it is nowadays possible to identify cultural keywords. The expansive nature of this ‘entropy’ means that digital work arising from the local becomes universal. A discussion is included on the new ‘complex digital ego’, which operates under multiple cultural and transliterary parameters to denounce the crisis in the analogue aesthetic. Some of the characteristics attributable to digital literature—collective experimentation and the rupture of narrative linearity—are exemplified in literary stories from collective and experimental Hispanic digital literature. We also avail ourselves of some examples of pioneer digital literary works written in Spanish, in which a number of specific qualities can be found in the very virtual nature of the text. This study presents an original approach to these works in relation to three pathways to reading: Hypertextual Reading, Ekphrastic Reading, and Serendipity Reading.",
 "article_title": "Poetics of crisis or crisis of poetics in digital reading/writing?: The case of Spanish digital literature*",
 "authors": [
 {
 "given": " Dolores",
 "family": "Romero López",
 "affiliation": [
 {
 "original_name": "Complutense University of Madrid, Spain",
 "normalized_name": "Complutense University of Madrid",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/02p0gd045",
 "GRID": "grid.4795.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-07-21",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs033",
 "identifier": {
 "string_id": "10.1093/llc/fqs033",
 "id_scheme": "DOI"
 },
 "abstract": "Tesserae is a web-based tool for automatically detecting allusions in Latin poetry. Although still in the start-up phase, it already is capable of identifying significant numbers of known allusions, as well as similar numbers of allusions previously unnoticed by scholars. In this article, we use the tool to examine allusions to Vergil’s Aeneid in the first book of Lucan’s Civil War. Approximately 3,000 linguistic parallels returned by the program were compared with a list of known allusions drawn from commentaries. Each was examined individually and graded for its literary significance, in order to benchmark the program’s performance. All allusions from the program and commentaries were then pooled in order to examine broad patterns in Lucan’s allusive techniques which were largely unapproachable without digital methods. Although Lucan draws relatively constantly from Vergil’s generic language in order to maintain the epic idiom, this baseline is punctuated by clusters of pointed allusions, in which Lucan frequently subverts Vergil’s original meaning. These clusters not only attend the most significant characters and events but also play a role in structuring scene transitions. Work is under way to incorporate the ability to match on word meaning, phrase context, as well as metrical and phonological features into future versions of the program.",
 "article_title": "The Tesserae Project: intertextual analysis of Latin poetry",
 "authors": [
 {
 "given": " Neil",
 "family": "Coffee",
 "affiliation": [
 {
 "original_name": "The University at Buffalo, The State University of New York, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Jean-Pierre",
 "family": "Koenig",
 "affiliation": [
 {
 "original_name": "The University at Buffalo, The State University of New York, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Shakthi",
 "family": "Poornima",
 "affiliation": [
 {
 "original_name": "The University at Buffalo, The State University of New York, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Christopher W.",
 "family": "Forstall",
 "affiliation": [
 {
 "original_name": "The University at Buffalo, The State University of New York, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Roelant",
 "family": "Ossewaarde",
 "affiliation": [
 {
 "original_name": "The University at Buffalo, The State University of New York, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Sarah L.",
 "family": "Jacobson",
 "affiliation": [
 {
 "original_name": "The University at Buffalo, The State University of New York, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-07-21",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs026",
 "identifier": {
 "string_id": "10.1093/llc/fqs026",
 "id_scheme": "DOI"
 },
 "abstract": "This essay proposes a methodology for the analysis of poetic digital works, based on the procedural model. This methodology is here applied to Jean-Marie Dutey’s le mange-texte. The article will provide a reminder of the definition of some concepts and highlight the various effects on the work of the changes in technical contexts of execution. The program is also being studied in a rhetorical dimension. This paper demonstrates that a reading of the screen is not enough to reach all the aesthetic representations of the work and aims to complete it with an operation of meta-reading. We will then analyze the rhetorical level induced by the execution and show why the obsolescence of the work does not mean the death of the work.",
 "article_title": "Signs and apparatus in digital poetry: The example of Jean-Marie Dutey's le mange-texte",
 "authors": [
 {
 "given": " Philippe",
 "family": "Bootz",
 "affiliation": [
 {
 "original_name": "Université Paris 8, France",
 "normalized_name": "Paris 8 University",
 "country": "France",
 "identifiers": {
 "ror": "https://ror.org/04wez5e68",
 "GRID": "grid.15878.33"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-07-19",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs028",
 "identifier": {
 "string_id": "10.1093/llc/fqs028",
 "id_scheme": "DOI"
 },
 "abstract": "Museum collections represent a highly challenging search space. This article proposes a novel approach for co-referent record identification which is suitable for use across multiple separate collections. The proposed approach is intended to be suitable for use despite highly imprecise/uncertain attribute values in the records. It is hoped that this can be achieved through a combination of aspects from the fields of probabillistic record linkage, document classification, and fuzzy clustering.",
 "article_title": "Improving record matching in imprecise and uncertain datasets",
 "authors": [
 {
 "given": " David",
 "family": "Croft",
 "affiliation": [
 {
 "original_name": "De Montfort University, UK",
 "normalized_name": "De Montfort University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0312pnr83",
 "GRID": "grid.48815.30"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-07-16",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs021",
 "identifier": {
 "string_id": "10.1093/llc/fqs021",
 "id_scheme": "DOI"
 },
 "abstract": "Test scores for linguistic features, word-patterns and word-lengths, in conjunction with parallels of word and thought, can provide corroborative internal evidence both for and against the attribution to Goldsmith of items in the Critical Review. While this evidence strengthens the case for most of the attributions in Friedman's edition of the Collected Works, and endorses his decision to reject some claimants, it also suggests a few modifications to the canon.",
 "article_title": "Goldsmith's contributions to the 'Critical Review': a supplement",
 "authors": [
 {
 "given": " Peter",
 "family": "Dixon",
 "affiliation": [
 {
 "original_name": "University of London, UK (formerly Queen Mary)",
 "normalized_name": "University of London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04cw6st05",
 "GRID": "grid.4464.2"
 }
 }
 ]
 },
 {
 "given": " David",
 "family": "Mannion",
 "affiliation": [
 {
 "original_name": "University of London, UK (formerly Royal Holloway)",
 "normalized_name": "University of London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04cw6st05",
 "GRID": "grid.4464.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-07-13",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs018",
 "identifier": {
 "string_id": "10.1093/llc/fqs018",
 "id_scheme": "DOI"
 },
 "abstract": "Those working within the academy are drawing collaborations, both within and across their home institutions, to undertake increasingly complex and sophisticated research questions, a trend supported by the granting agencies. Advances in computers and telecommunications have facilitated these collaborations by allowing teams to recruit the right person and expertise, regardless of location. To ensure that they are able to achieve their research objectives, these teams must find methods and means to maximize the benefits associated generally with collaboration while minimizing challenges and to also address those challenges more specifically associated with the geographical, linguistic and cultural diversity. This article contributes to this understanding by reporting on interviews conducted with individuals with experience in teams that cross geographical, linguistic and cultural boundaries and focus on understanding the benefits and challenges associated with collaboration with membership and the strategies used to strengthen them. Whereas these teams benefit from these collaborations, they experience many challenges, including language and cultural differences, differing access to and comfort levels with technology, and often conflicting requirements from funding agencies and stakeholders. These teams have devised strategies at project and individual levels, with clearly articulated project plans, project liaisons, flexibility and other soft and language skills, multiple communication channels, and others, to mitigate these challenges. The article concludes with recommendations for funders, projects and individuals.",
 "article_title": "A trip around the world: Accommodating geographical, linguistic and cultural diversity in academic research teams",
 "authors": [
 {
 "given": " Lynne",
 "family": "Siemens",
 "affiliation": [
 {
 "original_name": "School of Public Administration, University of Victoria, Canada",
 "normalized_name": "University of Victoria",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04s5mat29",
 "GRID": "grid.143640.4"
 }
 }
 ]
 },
 {
 "given": " Elisabeth",
 "family": "Burr",
 "affiliation": [
 {
 "original_name": "Universität Leipzig, Institut für Romanistik, Germany",
 "normalized_name": "Leipzig University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/03s7gtk40",
 "GRID": "grid.9647.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-06-27",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs017",
 "identifier": {
 "string_id": "10.1093/llc/fqs017",
 "id_scheme": "DOI"
 },
 "abstract": "Previous research in conceptual history, the study of change over time of key terms and value systems, has been carried out manually using a restricted number of pre-identified texts. We propose that a method combining techniques from corpus and computational linguistics can be exploited to support conceptual history with semantic searches on a vast sample of texts. To exemplify this method, we focus on a fundamental concept in modern science, the experimental method, in order to trace when the pre-existing and primarily religious concept of experiment (or experience) took on its modern, scientific meaning. We contrast a manual approach using the existing Early English Books Online search interface with an automatic method using corpus linguistics software and methods to turn the transcribed portion of the same dataset into a corpus. Both approaches allow us to separate the religious and scientific senses and plot their change over time. We observe a rapid change in the meaning of experimental from overwhelmingly religious to largely scientific within the 1660s. However, the automatic corpus method is much more efficient and will support future scholars in carrying out iterative studies in a matter of minutes rather than through weeks of painstaking work. Such methodological innovation has the potential to support the formation of new research questions, which could not have been considered previously.",
 "article_title": "Experiments in 17th century English: manual versus automatic conceptual history",
 "authors": [
 {
 "given": " Stephen",
 "family": "Pumfrey",
 "affiliation": [
 {
 "original_name": "Lancaster University",
 "normalized_name": "Lancaster University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04f2nsd36",
 "GRID": "grid.9835.7"
 }
 }
 ]
 },
 {
 "given": " Paul",
 "family": "Rayson",
 "affiliation": [
 {
 "original_name": "Lancaster University",
 "normalized_name": "Lancaster University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04f2nsd36",
 "GRID": "grid.9835.7"
 }
 }
 ]
 },
 {
 "given": " John",
 "family": "Mariani",
 "affiliation": [
 {
 "original_name": "Lancaster University",
 "normalized_name": "Lancaster University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04f2nsd36",
 "GRID": "grid.9835.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-06-04",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs014",
 "identifier": {
 "string_id": "10.1093/llc/fqs014",
 "id_scheme": "DOI"
 },
 "abstract": "Author discrimination consists of checking whether two texts are written by the same author or not. In this investigation, we try to make an author discrimination between the Quran (The holy words and statements of God in the Islamic religion) and the Hadith (statements said by the prophet Muhammad). The Quran is taken in its entirety, whereas for the Prophet’s statements, we chose only the certified texts of the Bukhari book. Thus, three series of experiments are done and commented on. The first series of experiments analyses the two books in a global form (the text of every book is analyzed as a unique big text). It concerns nine different experiments. The second series of experiments analyses the two books in a segmental form (four different segments of text are extracted from every book). It concerns five different experiments. The third series of experiments makes an automatic authorship attribution of the two books in a segmental form by employing several classifiers and several types of features. The sizes of the segments are more or less in the same range (four different text segments, with approximately the same size, are extracted from every book). It concerns two different experiments. This investigation sheds light on an old enigma, which has not been solved for 14 centuries: in fact, all the results of this investigation have shown that the two books should have two different authors.",
 "article_title": "Author discrimination between the Holy Quran and Prophet's statements",
 "authors": [
 {
 "given": " Halim",
 "family": "Sayoud",
 "affiliation": [
 {
 "original_name": "Department of Electronics and Informatics, USTHB University, Algiers, Algeria",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-05-12",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs010",
 "identifier": {
 "string_id": "10.1093/llc/fqs010",
 "id_scheme": "DOI"
 },
 "abstract": "The present study explores automatic classification of Swedish politicians and their speeches into classes based on personal traits—gender, age, and political affiliation—as a means for measuring and analyzing how these traits influence language use. Support Vector Machines classified 200-word passages, represented by binary bag-of-word-forms vectors. Different feature selections were tried. The performance of the classifiers was assessed using test data from authors unseen in the training data. Author-level predictions derived from twenty-one text-level predictions reached an accuracy rate of 81.2% for gender, 89.4% for political affiliation, and 78.9% for age. Classification concerning each basic distinction was applied to general populations of politicians and to cohorts defined by the other classes. The outcomes suggest that the extent to which these personal traits are expressed in language use varies considerably among the different cohorts and that different traits affect different layers of the vocabulary. The accuracy rates for gender classification were higher for the right wing and older cohorts than for the opposite ones. Age prediction gave higher accuracy for the right wing cohort. Political classification gave the highest accuracy rates when all forms were included in the feature sets, whereas feature sets restricted to verbs or function words gave the highest scores for gender prediction, and the lowest ones for political classification.",
 "article_title": "Automatic prediction of gender, political affiliation, and age in Swedish politicians from the wording of their speeches--A comparative study of classifiability",
 "authors": [
 {
 "given": " Mats",
 "family": "Dahllöf",
 "affiliation": [
 {
 "original_name": "Department of Linguistics and Philology, Uppsala University, Sweden",
 "normalized_name": "Uppsala University",
 "country": "Sweden",
 "identifiers": {
 "ror": "https://ror.org/048a87296",
 "GRID": "grid.8993.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-04-08",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs004",
 "identifier": {
 "string_id": "10.1093/llc/fqs004",
 "id_scheme": "DOI"
 },
 "abstract": "This article discusses the crowdsourced manuscript transcription project Transcribe Bentham, and how it will impact upon long-established editorial practices at the Bentham Project, University College London, which is producing the new and authoritative edition of The Collected Works of Jeremy Bentham. We site Transcribe Bentham in the burgeoning field of scholarly crowdsourcing projects, and, by detailing our experiences of running and administering the project, attempt to assess the potential benefits of engaging the public in humanities research. The article examines the conceptualization and development of Transcribe Bentham, and how editorial practices at the Bentham Project may change as a result. We account for the design of the bespoke transcription tool which is at the project's heart, and which allows volunteers to transcribe the material and encode it in TEI-compliant XML. We attempt to answer five key questions: is crowdsourcing the transcription of complex manuscripts cost-effective? Is crowdsourcing exploitative? Are volunteer-produced transcripts of sufficient quality for editorial use and uploading to a digital repository, and what quality controls are required? Does crowdsourcing ensure sustainability and widen access to this priceless material? And finally, should the success of a project like Transcribe Bentham be measured solely according to cost-effectiveness or the volume of work produced, or do considerations of public engagement and access outweigh such concerns?",
 "article_title": "Transcription maximized; expense minimized? Crowdsourcing and editing The Collected Works of Jeremy Bentham*",
 "authors": [
 {
 "given": " Tim",
 "family": "Causer",
 "affiliation": [
 {
 "original_name": "Bentham Project, University College London",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Justin",
 "family": "Tonra",
 "affiliation": [
 {
 "original_name": "Department of English, University of Virginia",
 "normalized_name": "University of Virginia",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0153tk833",
 "GRID": "grid.27755.32"
 }
 }
 ]
 },
 {
 "given": " Valerie",
 "family": "Wallace",
 "affiliation": [
 {
 "original_name": "Bentham Project, University College London",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 },
 {
 "original_name": "Center for History and Economics, Harvard University",
 "normalized_name": "Harvard University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/03vek6s52",
 "GRID": "grid.38142.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-03-29",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs009",
 "identifier": {
 "string_id": "10.1093/llc/fqs009",
 "id_scheme": "DOI"
 },
 "abstract": "The remarkable advances in the field of ICT have led to the appearance of interesting innovations in literature classrooms, one of which is multimedia. Multimedia has been proven to be a powerful learning tool as it is able to provide extensive learning opportunities, thus breaking away from the traditional and restrictive ‘chalk and talk’ type of teaching. This study examined the incorporation of an after-reading assignment called ‘The Multimedia Project’ in a literature classroom. It involved ninety-six students taking English literature courses at the Faculty of Modern Languages and Communication, Universiti Putra Malaysia. Multimedia can be defined in a variety of ways, but for this project multimedia refers to a literary text presentation, primarily made using sound and images. Through this project, the students had opportunities to explore and develop their knowledge and critically analyze the literary texts covered in class. This study relied on two types of analysis: an evaluation of the students’ multimedia presentations and a survey of the students’ opinions regarding the project. The findings indicate that the multimedia project proved to be effective in advancing students’ literary experience and critical appreciation. The students’ opinions also confirmed the viability of multimedia as a practical application tool in teaching literature as well as in promoting visual literacy.",
 "article_title": "Advancing aesthetic literary experience through a multimedia project",
 "authors": [
 {
 "given": " Zainor Izat",
 "family": "Zainal",
 "affiliation": [
 {
 "original_name": "Universiti Putra Malaysia, Malaysia",
 "normalized_name": "Universiti Putra Malaysia",
 "country": "Malaysia",
 "identifiers": {
 "ror": "https://ror.org/02e91jd64",
 "GRID": "grid.11142.37"
 }
 }
 ]
 },
 {
 "given": " Ann Rosnida",
 "family": "Mohd Deni",
 "affiliation": [
 {
 "original_name": "Sunway University, Malaysia",
 "normalized_name": "Sunway University",
 "country": "Malaysia",
 "identifiers": {
 "ror": "https://ror.org/04mjt7f73",
 "GRID": "grid.430718.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-03-23",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs003",
 "identifier": {
 "string_id": "10.1093/llc/fqs003",
 "id_scheme": "DOI"
 },
 "abstract": "We describe a new supervised machine learning approach for detecting authorship deception, a specific type of authorship attribution task particularly relevant for cybercrime forensic investigations, and demonstrate its validity on two case studies drawn from realistic online data sets. The core of our approach involves identifying uncharacteristic behavior for an author, based on a writeprint extracted from unstructured text samples of the author's writing. The writeprints used here involve stylometric features and content features derived from topic models, an unsupervised approach for identifying relevant keywords that relate to the content areas of a document. One innovation of our approach is to transform the writeprint feature values into a representation that individually balances characteristic and uncharacteristic traits of an author, and we subsequently apply a Sparse Multinomial Logistic Regression classifier to this novel representation. Our method yields high accuracy for authorship deception detection on the two case studies, confirming its utility.",
 "article_title": "Detecting authorship deception: a supervised machine learning approach using author writeprints",
 "authors": [
 {
 "given": " Lisa",
 "family": "Pearl",
 "affiliation": [
 {
 "original_name": "University of California, Irvine",
 "normalized_name": "California Coast University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05t99sp05",
 "GRID": "grid.468726.9"
 }
 }
 ]
 },
 {
 "given": " Mark",
 "family": "Steyvers",
 "affiliation": [
 {
 "original_name": "University of California, Irvine",
 "normalized_name": "California Coast University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05t99sp05",
 "GRID": "grid.468726.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-03-09",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs001",
 "identifier": {
 "string_id": "10.1093/llc/fqs001",
 "id_scheme": "DOI"
 },
 "abstract": "Old Chinese phonology is considered one of the most difficult branches of learning in Chinese philology. The traditional methodology has been empirical and its conclusions are very hard to understand and remember for modern people who do not use Old Chinese any more. This article, based on the theories and findings in Old Chinese phonology studies, uses the graph model in mathematics as the method to describe the initial-rhyme relationships of Old Chinese, and the Euclidean distance on two-dimensional plane to represent the similarity of the sounds in Chinese words (or characters) in the phonological harmony. It provides a more intuitive method of quantitative analysis, which makes the qualitative phonological relationships of Old Chinese easier to be measured and compared. Although the model is still in its infancy and there is room for refinement, it may bring insights to Chinese study, such as the research of Xiesheng series in Chinese characters, or Chinese etymology.",
 "article_title": "Graph model of Old Chinese phonological system and computing",
 "authors": [
 {
 "given": " Jiajia",
 "family": "Hu",
 "affiliation": [
 {
 "original_name": "School of Computer Science and Engineering, Beihang University, China",
 "normalized_name": "Beihang University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/00wk2mp56",
 "GRID": "grid.64939.31"
 }
 }
 ]
 },
 {
 "given": " Ning",
 "family": "Wang",
 "affiliation": [
 {
 "original_name": "School of Chinese Language and Literature, Beijing Normal University, China",
 "normalized_name": "Beijing Normal University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/022k4wk35",
 "GRID": "grid.20513.35"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-02-29",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs002",
 "identifier": {
 "string_id": "10.1093/llc/fqs002",
 "id_scheme": "DOI"
 },
 "abstract": "Natural language text analysis presupposes the encoding of morphological phenomena. In this article, we present some particularities of Modern Greek and the way these are encoded in the presented electronic lexicon. The project plan of its development combined both simple planning algorithms and more elaborate ones for the generation and recognition processes. The resulted lexicon exhibits fast access to its contents and easy content management. It is re-usable and modular enough to support existing NLP applications.",
 "article_title": "Design and implementation of an electronic lexicon for Modern Greek",
 "authors": [
 {
 "given": " Panagiotis",
 "family": "Gakis",
 "affiliation": [
 {
 "original_name": "University of Patras",
 "normalized_name": "University of Patras",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/017wvtq80",
 "GRID": "grid.11047.33"
 }
 }
 ]
 },
 {
 "given": " Christos",
 "family": "Panagiotakopoulos",
 "affiliation": [
 {
 "original_name": "University of Patras",
 "normalized_name": "University of Patras",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/017wvtq80",
 "GRID": "grid.11047.33"
 }
 }
 ]
 },
 {
 "given": " Kyriakos",
 "family": "Sgarbas",
 "affiliation": [
 {
 "original_name": "University of Patras",
 "normalized_name": "University of Patras",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/017wvtq80",
 "GRID": "grid.11047.33"
 }
 }
 ]
 },
 {
 "given": " Christos",
 "family": "Tsalidis",
 "affiliation": [
 {
 "original_name": "“Neurolingo” Company",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-02-21",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqs007",
 "identifier": {
 "string_id": "10.1093/llc/fqs007",
 "id_scheme": "DOI"
 },
 "abstract": "Proper names in literary texts have different functions. The most important one in real life, identification, is only one of these. Some others are to make the fiction more ‘real’ or to present ideas about a character by using a name with certain meanings or associations to manipulate the reader’s expectations. A description of the functions of a certain name in a certain text becomes relevant when the researcher can point out how it compares to the functions of other names and names in other texts. The article describes how research into names in literary texts needs a quantitative approach to reach a higher level of relevancy. To get a first impression of what may be normal in literary texts, a corpus of twenty-two Dutch and twenty-two English novels and ten translations into the other language in both sets were gathered. The occurrences of all names in these novels have been tagged for those data categories that seemed useful for the literary stylistic research planned. Some first results of the statistics are presented and the use of the approach is illustrated by means of an analysis of the use of geographical names in the Dutch novel Boven is het stil by Gerbrand Bakker and its English translation by David Colmer, The Twin. In the evaluation of the results, special attention is paid to the status of currently available digital tools for named entity recognition and classification, followed by a wish-list for the tools that this kind of research really needs.",
 "article_title": "Names in novels: An experiment in computational stylistics",
 "authors": [
 {
 "given": " Karina",
 "family": "van Dalen-Oskam",
 "affiliation": [
 {
 "original_name": "Huygens Institute for the History of the Netherlands (Royal Netherlands Academy of Arts and Sciences), The Netherlands",
 "normalized_name": "Royal Netherlands Academy of Arts and Sciences",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/043c0p156",
 "GRID": "grid.418101.d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2012-03-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "28",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr043",
 "identifier": {
 "string_id": "10.1093/llc/fqr043",
 "id_scheme": "DOI"
 },
 "abstract": "We show how in colonial Potosí (present-day Bolivia) social and political stability was achieved through the self-organization of society through the repetition of religious rituals. Our analysis shows that the population of Potosí develops over the time a series of cycles of rituals and miracles as a response to social upheaval and natural disasters and that these cycles of religious performance become crucial mechanisms of cooperation among different ethnic and religious groups. Our methodology starts with a close reading and annotation of the Historia de Potosí by Bartolomé Arzans. Then, we model the religious cycles of miracles and rituals and store all social and cultural information about the cycles in a multirelational graph database. Finally, we perform graph analysis through traversals queries in order to establish facts concerning social networks, historical evolution of behaviors, types of participation of miraculous characters according to dates, parts of the city, ethnic groups, etc. It is also important to note that the religious activity at the group level gave native communities a way to participate in the social life. It also guaranteed that the city performed its role as producer of silver in the global economic structure of the Spanish empire. This case proves the importance of religion as a mechanism of stability and self-organization in periods of social or political turbulence. The multidisciplinary methodology combining traditional humanistic techniques with graph analysis shows a great potential for other sociological, historical, and literary problems.",
 "article_title": "The Potosi principle: religious prosociality fosters self-organization of larger communities under extreme natural and economic conditions",
 "authors": [
 {
 "given": " Juan Luis",
 "family": "Suárez",
 "affiliation": [
 {
 "original_name": "The CulturePlex Lab, Faculty of Arts and Humanities, University of Western Ontario, 1151 Richmond Street, London, ON, Canada N6A 3K7",
 "normalized_name": "Western University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/02grkyz14",
 "GRID": "grid.39381.30"
 }
 }
 ]
 },
 {
 "given": " Shiddarta",
 "family": "Vásquez",
 "affiliation": [
 {
 "original_name": "The CulturePlex Lab, Faculty of Arts and Humanities, University of Western Ontario, 1151 Richmond Street, London, ON, Canada N6A 3K7",
 "normalized_name": "Western University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/02grkyz14",
 "GRID": "grid.39381.30"
 }
 }
 ]
 },
 {
 "given": " Fernando",
 "family": "Sancho-Caparrini",
 "affiliation": [
 {
 "original_name": "Department of Computer Science and Artificial Intelligence, E.T.S. Ingeniería Informática, Universidad de Sevilla, Av. Reina Mercedes, s/n, 41012, Sevilla, Spain",
 "normalized_name": "University of Seville",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/03yxnpp24",
 "GRID": "grid.9224.d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-12-09",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr050",
 "identifier": {
 "string_id": "10.1093/llc/fqr050",
 "id_scheme": "DOI"
 },
 "abstract": "This article provides an account of the steps involved in adapting IBM's Languageware natural language processing software to a large corpus of highly non-standard 17th century documents. It examines the challenges encountered as part of this process, and outlines the approach adopted to provide a robust and reusable tool for the linguistic analysis of early modern source texts.",
 "article_title": "Natural language processing and early-modern dirty data: applying IBM Languageware to the 1641 depositions",
 "authors": [
 {
 "given": " Mark S.",
 "family": "Sweetnam",
 "affiliation": [
 {
 "original_name": "Department of History, School of Histories and Humanities, Trinity College Dublin",
 "normalized_name": "Trinity College Dublin",
 "country": "Ireland",
 "identifiers": {
 "ror": "https://ror.org/02tyrky19",
 "GRID": "grid.8217.c"
 }
 }
 ]
 },
 {
 "given": " Barbara A.",
 "family": "Fennell",
 "affiliation": [
 {
 "original_name": "School of Languages and Literature, University of Aberdeen",
 "normalized_name": "University of Aberdeen",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/016476m91",
 "GRID": "grid.7107.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-12-17",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr049",
 "identifier": {
 "string_id": "10.1093/llc/fqr049",
 "id_scheme": "DOI"
 },
 "abstract": "Variation and change in relativization strategies has been well documented (e.g. Ball 1996: 46, Biber and Clark 2002, Biber, Johansson, Leech, Conrad and Finegan 1999, Johansson 2006, Lehmann 2002). Certain types of relative clause, namely that-relatives and zero relatives, were difficult to retrieve from plain-text corpora. Studies therefore either relied on manual extraction of data or a subset of possible relativization strategies. In some text types, however, the zero relative is an important member of the class of possible relativizers. Recent advances in syntactic annotation should have made that-relatives and zero relatives more accessible to automatic retrieval. In this article, we test precision and recall of searches on a modest-sized corpus, i.e. scientific texts from ARCHER (A Representative Corpus of Historical English Registers), as a preliminary to future work on the large corpora which are increasingly becoming available. The parser retrieved some false positives and at the same time missed some relevant data. We discuss structural reasons for both kinds of shortcoming as well as the possibilities and limitations of parser adaptation.",
 "article_title": "Retrieving relatives from historical data",
 "authors": [
 {
 "given": " Marianne",
 "family": "Hundt",
 "affiliation": [
 {
 "original_name": "University of Zurich, Switzerland",
 "normalized_name": "University of Zurich",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/02crff812",
 "GRID": "grid.7400.3"
 }
 }
 ]
 },
 {
 "given": " David",
 "family": "Denison",
 "affiliation": [
 {
 "original_name": "The University of Manchester, UK",
 "normalized_name": "University of Manchester",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/027m9bs27",
 "GRID": "grid.5379.8"
 }
 }
 ]
 },
 {
 "given": " Gerold",
 "family": "Schneider",
 "affiliation": [
 {
 "original_name": "University of Zurich, Switzerland",
 "normalized_name": "University of Zurich",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/02crff812",
 "GRID": "grid.7400.3"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-12-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr038",
 "identifier": {
 "string_id": "10.1093/llc/fqr038",
 "id_scheme": "DOI"
 },
 "abstract": "The Chymistry of Isaac Newton project, an online scholarly edition of Newton's alchemical manuscripts, has engaged in a process to include a number of core alchemical symbols into the Unicode standard, a standard for digital representation of characters and symbols from the world's languages, scripts, and writing systems. Our article explores the relationship between information technology standardization and humanities research. We discuss Newton's engagement with alchemy and explore the graphic dimensions of alchemical discourse. We illustrate this discussion with examples of Newton's use of alchemical symbols. We examine Unicode itself, particularly a core Unicode principle distinguishing between the abstract character and the image or glyph of the character, and we discuss the tensions between this core principle and the representation of graphic, symbolic, and pictorial discourse. We describe our experience with the Unicode proposal process and illustrate again—this time with an organizational scheme for the symbols—how the technical standardization process forced a reexamination of our historical materials. Our conclusions reemphasize the potential for mutually beneficial relationships between certain types of information technology standardization and humanities research and suggest that study of the graphic qualities of alchemical discourse, especially in light of competing theories of text represented by standards like Unicode, may contribute to our understanding of the increasingly graphic, iconic, and pictorial nature of information and communication.",
 "article_title": "The liberty of invention: alchemical discourse and information technology standardization",
 "authors": [
 {
 "given": " John A.",
 "family": "Walsh",
 "affiliation": [
 {
 "original_name": "School of Library and Information Science, Indiana University, Bloomington, Indiana, USA",
 "normalized_name": "Indiana University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/01kg8sb98",
 "GRID": "grid.257410.5"
 }
 }
 ]
 },
 {
 "given": " Wallace Edd",
 "family": "Hooper",
 "affiliation": [
 {
 "original_name": "History and Philosophy of Science, Indiana University, Bloomington, Indiana, USA",
 "normalized_name": "Indiana University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/01kg8sb98",
 "GRID": "grid.257410.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-12-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr045",
 "identifier": {
 "string_id": "10.1093/llc/fqr045",
 "id_scheme": "DOI"
 },
 "abstract": "In order to investigate in explicit detail the way that y- and th- pronouns alternate in the Shakespearean corpus, I have undertaken a collocational analysis of the full corpus of Shakespeare's 37 plays and found that (1) second-person pronouns can be disambiguated based on context alone, (2) y- pronouns seem to be used in more formal situations or when an inferior is addressing a social better, and (3) the th- pronoun is reserved for addressing peers, servants, or other familiar personages. Through the Python Natural Language Toolkit (Bird et al., 2009, Natural Language Processing with Python. Sebastopol, CA: O'Reilly Media), I implemented a Naïve Bayes classifier that in effect treats each occurrence of a second-person pronoun as a black box that must be resolved into either a y- pronoun or a th- pronoun based only on the surrounding words. Using tenfold cross-validation, the classifier achieves an accuracy of 78.3% when fellow th- and y- pronouns are excluded from the context and 88.0% when we allow fellow th- and y- pronouns to assist in classification. Most interesting, however, are the context words that prove most informative in categorizing the pronouns. Significantly, the words most useful in classifying a pronoun as a y- pronoun include high-register words such as lordship, madam, lords, and sir. After a group of conjugated second-person verbs like art and wert, the words most associated with th- pronouns are words such as torment, nuncle, lesser, and villain. The ability to discriminate between forms based only on context confirms the hypothesis that the two classes of second-person pronoun are indeed used distinctly in the Shakespearean corpus. The list of words most helpful in making that distinction strongly suggests a difference in formality. We can also gain additional insight into the plays by examining some of the unexpected words that collocate with either one form or the other.",
 "article_title": "A Naive Bayes classifier for Shakespeare's second-person pronoun",
 "authors": [
 {
 "given": " Kyle",
 "family": "Mahowald",
 "affiliation": [
 {
 "original_name": "Department of Brain and Cognitive Sciences, Cambridge MA 02139, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr039",
 "identifier": {
 "string_id": "10.1093/llc/fqr039",
 "id_scheme": "DOI"
 },
 "abstract": "This study is to investigate the translator's fingerprints as manifested in his/her style in translation. It reports a case study of two Chinese translations of Ulysses, adopting a corpus-based approach. The parallel subcorpora of the self-built Bilingual Corpus of Ulysses (BCU) consist of Joyce's Ulysses and its two Chinese versions produced by Xiao (1994 Tran. Ulysses, Nanjing: Yilin Press) and Jin (1997 Tran. Ulysses, Beijing: People's Literature Publishing House), respectively, and the comparable subcorpora include Xiao's original writings in Chinese. The comparison of the keyword lists shows that Xiao, the literary writer and translator, leaves some traces of lexical idiosyncrasy in his composition and translation. On the syntactic level the comparison reveals that due to the interference of the English language Xiao post-positions more adverbial clauses in translation than in composition, a feature that distinguishes the translated text from non-translated original writing. This indicates that the fingerprints of the translator are left on the translated text both as a result of his/her linguistic idiosyncrasy and of the interference and constraints of the languages s/he is dealing with in translation.",
 "article_title": "Looking for translator's fingerprints: a corpus-based study on Chinese translations of Ulysses",
 "authors": [
 {
 "given": " Qing",
 "family": "Wang",
 "affiliation": [
 {
 "original_name": "Shandong Jiaotong University, Jinan, China",
 "normalized_name": "Shandong Jiaotong University",
 "country": "China",
 "identifiers": {
 "ror": "https://ror.org/01848hk04",
 "GRID": "grid.460017.4"
 }
 }
 ]
 },
 {
 "given": " Defeng",
 "family": "Li",
 "affiliation": [
 {
 "original_name": "SOAS, UK & SJTU, China",
 "normalized_name": "School of Oriental and African Studies",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04vrxay34",
 "GRID": "grid.22631.34"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-11-04",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "27",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr034",
 "identifier": {
 "string_id": "10.1093/llc/fqr034",
 "id_scheme": "DOI"
 },
 "abstract": "This article describes research aimed at improving the accuracy of an information extraction (IE) system by treating coordinate structures systematically. Commas, coordinating conjunctions, and adjacent comma–conjunction pairs are considered to be potential indicators of coordination in natural language. A recursive algorithm is implemented which converts sentences containing classified potential coordinators into sequences of simple sentences. Several approaches to the classification of potential coordinators are presented, one exploiting memory-based learning, another exploiting the publicly available Stanford parser, and a hybrid approach that classifies commas and conjunctions using the former system and comma–conjunction pairs using the latter. The article describes the initial set of features developed for exploitation by the memory-based classifier and presents optimization of that classifier. A baseline system is also described. The sentence simplification module was exploited by an IE system. With regard to the automatic classifiers that form the basis for simplification, comparative evaluation demonstrated that IE can be performed with greatest accuracy when exploiting the hybrid classifier. It also demonstrated that a simple baseline classifier induces improved accuracy when compared to systems that ignore the presence of coordinate structures in input sentences. The article presents an analysis of the errors made by the different sentence simplification modules and the IE system that exploits them. Directions for future research are suggested.",
 "article_title": "Comparing methods for the syntactic simplification of sentences in information extraction",
 "authors": [
 {
 "given": " Richard J.",
 "family": "Evans",
 "affiliation": [
 {
 "original_name": "University of Wolverhampton, UK",
 "normalized_name": "University of Wolverhampton",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01k2y1055",
 "GRID": "grid.6374.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-09-01",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr031",
 "identifier": {
 "string_id": "10.1093/llc/fqr031",
 "id_scheme": "DOI"
 },
 "abstract": "This article examines the success of authorship attribution of Burrows’s Delta in several corpora representing a variety of languages and genres. Contrary to the approaches of our predecessors, who only investigated the attributive effectiveness of the very top of the list of the most frequent words, hundreds of possible combinations of word vectors were tested in this study, not solely starting with the most frequent word in each corpus. The results show that Delta works best for prose in English and German and less well for agglutinative languages such as Polish or Latin.",
 "article_title": "Deeper Delta across genres and languages: do we really need the most frequent words?",
 "authors": [
 {
 "given": " Jan",
 "family": "Rybicki",
 "affiliation": [
 {
 "original_name": "Pedagogical University, Kraków, Poland",
 "normalized_name": "Pedagogical University",
 "country": "Mozambique",
 "identifiers": {
 "ror": "https://ror.org/0331kj160",
 "GRID": "grid.442441.3"
 }
 }
 ]
 },
 {
 "given": " Maciej",
 "family": "Eder",
 "affiliation": [
 {
 "original_name": "Pedagogical University, Kraków, Poland",
 "normalized_name": "Pedagogical University",
 "country": "Mozambique",
 "identifiers": {
 "ror": "https://ror.org/0331kj160",
 "GRID": "grid.442441.3"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-07-16",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr026",
 "identifier": {
 "string_id": "10.1093/llc/fqr026",
 "id_scheme": "DOI"
 },
 "abstract": "Paraphrasing is very useful for many applications that normally involve deep linguistic alterations of a sentence, like summarization, textual entailment and question answering, and usually require sophisticated external resources, pre-processing, and semantic thesauri. This article presents a methodology for generating shallow linguistic alterations of Modern Greek sentences making use of only a low-resource chunker and taking advantage of the freedom in phrase ordering of the language. A statistical significance testing process is applied for extracting ‘swappable’ phrase bigrams. A supervised filtering phase follows, which helps to remove erroneous paraphrasing schemata, taking into account the context in which the alteration is to take place. Unlike most previous approaches to paraphrasing, the proposed process is knowledge-poor (and thus quite easily portable to other languages with a syntactic structure similar to Modern Greek), robust (applicable to any type of text), domain independent, and leads to the generation of a significant number of paraphrases, by allowing the application of more than one syntactic alterations per sentence. The significance of the automatically generated paraphrases is shown by their application in hiding secret information underneath a cover text in a steganographic communication channel. For this purpose, they need not be sophisticated linguistic alterations, but grammatically correct and significant in number, to ensure security. A steganographic security and capacity analysis of the presented implementation, as well as an explanatory description of the trade-off between them, is included to show the usefulness and the practical value of the methodology.",
 "article_title": "Linguistic steganography with knowledge-poor paraphrase generation",
 "authors": [
 {
 "given": " Katia Lida",
 "family": "Kermanidis",
 "affiliation": [
 {
 "original_name": "Department of Informatics, Ionian University, Greece",
 "normalized_name": "Ionian University",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/01xm4n520",
 "GRID": "grid.449127.d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-05-30",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr028",
 "identifier": {
 "string_id": "10.1093/llc/fqr028",
 "id_scheme": "DOI"
 },
 "abstract": "In addition to drawing upon content experts, librarians, archivists, developers, programmers, managers, and others, many emerging digital projects also pull in disciplinary expertise from areas that do not typically work in team environments. To be effective, these teams must find processes—some of which are counter to natural individually oriented work habits—which support the larger goals and group-oriented work of these digital projects. This article will explore the similarities and differences in approaches within and between members of the Digital Libraries (DL) and Digital Humanities (DH) communities by formally documenting the nature of collaboration in these teams. While there are many similarities in approaches between DL and DH project teams, some interesting differences exist and may influence the effectiveness of a digital project team with membership that draws from these two communities. Conclusions are focused on supporting strong team processes with recommendations for documentation, communication, training, and the development of team skills and perspectives.",
 "article_title": "A tale of two cities: implications of the similarities and differences in collaborative approaches within the digital libraries and digital humanities communities",
 "authors": [
 {
 "given": " Lynne",
 "family": "Siemens",
 "affiliation": [
 {
 "original_name": "School of Public Administration, University of Victoria",
 "normalized_name": "University of Victoria",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04s5mat29",
 "GRID": "grid.143640.4"
 }
 }
 ]
 },
 {
 "given": " Richard",
 "family": "Cunningham",
 "affiliation": [
 {
 "original_name": "Acadia Digital Culture Observatory, Acadia University",
 "normalized_name": "Acadia University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/00839we02",
 "GRID": "grid.411959.1"
 }
 }
 ]
 },
 {
 "given": " Wendy",
 "family": "Duff",
 "affiliation": [
 {
 "original_name": "Faculty of Information, University of Toronto",
 "normalized_name": "University of Toronto",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03dbr7087",
 "GRID": "grid.17063.33"
 }
 }
 ]
 },
 {
 "given": " Claire",
 "family": "Warwick",
 "affiliation": [
 {
 "original_name": "Department of Information Studies, University College London",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-05-31",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr018",
 "identifier": {
 "string_id": "10.1093/llc/fqr018",
 "id_scheme": "DOI"
 },
 "abstract": "Spoken discourse is a uniquely valuable source of data in cognitive research. A natural way of representing spoken discourse is in the form of a transcript in standard orthography. However, since transcribing is, for neuroscientists at any rate, no more than a means to an end, many researchers give only cursory descriptions of the transcription process, including the assessment of agreement between transcribers. This article introduces a novel approach to the systematic assessment of agreement between transcripts. The method first involves the automated alignment of two texts, followed by the automatic identification and quantification of discrepancies. A similarity score is then computed, providing researchers with a tool to evaluate the accuracy of the pair of transcripts in question. Most importantly, the automated production of a set of comparison tables reveals and summarizes the actual mismatches found, making it possible to identify common causes of discrepancy. Through applying this approach to medical data collected for an investigation of dementia, the present study demonstrates its value in the amendment of transcripts and the improvement of transcription practices, which pave the way towards more reliable transcriptions for research purposes.",
 "article_title": "Techniques for transcribers: assessing and improving consistency in transcripts of spoken language",
 "authors": [
 {
 "given": " Peter",
 "family": "Garrard",
 "affiliation": [
 {
 "original_name": "Stroke and Dementia Research Centre, St George's, University of London, London, UK",
 "normalized_name": "University of London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04cw6st05",
 "GRID": "grid.4464.2"
 }
 }
 ]
 },
 {
 "given": " Anne-Marie",
 "family": "Haigh",
 "affiliation": [
 {
 "original_name": "Nuffield Department of Medicine, University of Oxford, Oxford, UK",
 "normalized_name": "University of Oxford",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/052gg0110",
 "GRID": "grid.4991.5"
 }
 }
 ]
 },
 {
 "given": " Celeste",
 "family": "de Jager",
 "affiliation": [
 {
 "original_name": "Nuffield Department of Medicine, University of Oxford, Oxford, UK",
 "normalized_name": "University of Oxford",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/052gg0110",
 "GRID": "grid.4991.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-05-26",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr013",
 "identifier": {
 "string_id": "10.1093/llc/fqr013",
 "id_scheme": "DOI"
 },
 "abstract": "We present a large-scale longitudinal study of lexical and syntactic changes in language in Alzheimer's disease using complete, fully parsed texts and a large number of measures, using as our subjects the British novelists Iris Murdoch (who died with Alzheimer's), Agatha Christie (who was suspected of it), and P.D. James (who has aged healthily). We avoid the limitations and deficiencies of Garrard et al.'s [(2005), The effects of very early Alzheimer's disease on the characteristics of writing by a renowned author. Brain, 128 (2): 250–60] earlier study of Iris Murdoch. Our results support the hypothesis that signs of dementia can be found in diachronic analyses of patients’ writings, and in addition lead to new understanding of the work of the individual authors whom we studied. In particular, we show that it is probable that Agatha Christie indeed suffered from the onset of Alzheimer's while writing her last novels, and that Iris Murdoch exhibited a ‘trough’ of relatively impoverished vocabulary and syntax in her writing in her late 40s and 50s that presaged her later dementia.",
 "article_title": "Longitudinal detection of dementia through lexical and syntactic changes in writing: a case study of three British novelists",
 "authors": [
 {
 "given": "Xuan",
 "family": "Le",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, University of Toronto, Toronto, Ontario, Canada M5S 3G4",
 "normalized_name": "University of Toronto",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03dbr7087",
 "GRID": "grid.17063.33"
 }
 }
 ]
 },
 {
 "given": "Ian",
 "family": "Lancashire",
 "affiliation": [
 {
 "original_name": "Department of English, University of Toronto, Toronto, Ontario, Canada M5R 2M8",
 "normalized_name": "University of Toronto",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03dbr7087",
 "GRID": "grid.17063.33"
 }
 }
 ]
 },
 {
 "given": "Graeme",
 "family": "Hirst",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, University of Toronto, Toronto, Ontario, Canada M5S 3G4",
 "normalized_name": "University of Toronto",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03dbr7087",
 "GRID": "grid.17063.33"
 }
 }
 ]
 },
 {
 "given": "Regina",
 "family": "Jokel",
 "affiliation": [
 {
 "original_name": "Department of Speech–Language Pathology, University of Toronto, Toronto, Ontario, Canada M5G 1V7",
 "normalized_name": "University of Toronto",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03dbr7087",
 "GRID": "grid.17063.33"
 }
 },
 {
 "original_name": "Kunin-Lunenfeld Applied Research Unit, Baycrest Hospital, 3560 Bathurst Street, North York, Ontario, Canada M6A 2E1",
 "normalized_name": "Baycrest Hospital",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03gp5b411",
 "GRID": "grid.423198.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-05-26",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr022",
 "identifier": {
 "string_id": "10.1093/llc/fqr022",
 "id_scheme": "DOI"
 },
 "abstract": "Corpus linguistics and Geographical Information Systems (GIS) are approaches exploiting computer-based methodologies in the study of, respectively, language and language usage, and spatial patterns in geographical databases. We present an approach that uses corpus methods to bridge the gap between the textual content of a corpus (and, thus, the typically textual concerns of many branches of the humanities) and the geo-referenced database at the heart of a GIS. Using part-of-speech tagging to extract instances of proper nouns from a corpus, and a gazetteer to limit these instances to those representing place–names, a database of the places mentioned in a corpus can be created, visualized, and analysed using GIS technology. It is also possible to visualize the meanings associated with particular place–names, by building GIS databases on the collocation of place–names with particular semantic categories in their immediate context. In this way, we can create maps that visualize the geographical distribution of mentions of concepts such as war, government, or money in a particular data set. The approach cannot be entirely automated and some manual intervention is required. Nevertheless, the method is clearly valuable for the interpretation of spatial phenomena in text corpora.",
 "article_title": "Visual GISting: bringing together corpus linguistics and Geographical Information Systems",
 "authors": [
 {
 "given": " Ian N.",
 "family": "Gregory",
 "affiliation": [
 {
 "original_name": "Department of History, Lancaster University, Lancaster, LA1 4YG, UK",
 "normalized_name": "Lancaster University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04f2nsd36",
 "GRID": "grid.9835.7"
 }
 }
 ]
 },
 {
 "given": " Andrew",
 "family": "Hardie",
 "affiliation": [
 {
 "original_name": "Department of Linguistics and English Language, Lancaster University, Lancaster, LA1 4YL, UK",
 "normalized_name": "Lancaster University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04f2nsd36",
 "GRID": "grid.9835.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-05-21",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr020",
 "identifier": {
 "string_id": "10.1093/llc/fqr020",
 "id_scheme": "DOI"
 },
 "abstract": "The focus of this article is a system for visualizing social network data derived from a TEI-encoded corpus of texts. It describes the collection of biographies of historical Chinese Buddhist monks, which constitutes this corpus and the TEI markup, in particular the innovative concept of a ‘nexus-point’ that was originally applied to them with the goal of producing GIS-like visualizations [see Bingenheimer, M., Hung, J.-J., and Wiles, S. (2009). Markup meets GIS - Visualizing the ‘Biographies of Eminent Buddhist Monks’. In Banissi, E. et al. (eds), Proceedings of Information Visualization IV 2009. IEEE Computer Society: 550–4.]. Over the course of this work, it became clear that a data set of nexus-points could be derived from this markup which would support a representation of the social network which can be inferred from the corpus. The nature of this social network is explored and some interesting preliminary applications are suggested. The software architecture which supports the visualization, based on the Prefuse toolkit, is introduced. Finally, the scope for the future development of the corpus and the system are discussed, and some avenues for potentially fruitful analysis are suggested. Throughout the article, it is argued that the methods and techniques employed here are applicable well beyond the present context. In describing this project of social network visualization, it is demonstrated that a well-marked-up TEI corpus can, with very little additional technical overhead and using the same markup, serve as the basis for multiple representations of the same data.",
 "article_title": "Social network visualization from TEI data",
 "authors": [
 {
 "given": " Marcus",
 "family": "Bingenheimer",
 "affiliation": [
 {
 "original_name": "Library and Information Center, Dharma Drum Buddhist College, Taiwan, R.O.C.",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Jen-Jou",
 "family": "Hung",
 "affiliation": [
 {
 "original_name": "Library and Information Center, Dharma Drum Buddhist College, Taiwan, R.O.C.",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Simon",
 "family": "Wiles",
 "affiliation": [
 {
 "original_name": "Library and Information Center, Dharma Drum Buddhist College, Taiwan, R.O.C.",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-05-23",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr024",
 "identifier": {
 "string_id": "10.1093/llc/fqr024",
 "id_scheme": "DOI"
 },
 "abstract": "Computing is not the only way to model and simulate humanities problems. In the specific field of conflict simulation, there is a long and continuing tradition of using manual modelling techniques such as maps and counters to create playable games which mirror some of the dynamics of real armed conflicts. Computer games are not automatically superior to such manual models, since mass market commercial software focuses far more on entertainment than on realistic simulation, and since the enormous capabilities of computers tend to encourage detailed incorporation of quantifiable technicalities at the expense of the vital but much less tractable human element. The biggest limitation of computer models is their limited transparency and design accessibility for non-programmers such as humanities students and scholars. Manual modelling offers a valuable ‘bridge’ between computing and traditional humanities scholarship, allowing easier generation and use of specifically tailored models, and building synergistic relationships which foster more widespread and effective adoption of digital techniques.",
 "article_title": "The benefits and limits of computerization in conflict simulation",
 "authors": [
 {
 "given": " Philip",
 "family": "Sabin",
 "affiliation": [
 {
 "original_name": "King's College London, London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-05-17",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr021",
 "identifier": {
 "string_id": "10.1093/llc/fqr021",
 "id_scheme": "DOI"
 },
 "abstract": "The challenge in literary computing is (1) to model texts, to produce digital editions and (2) to model the meaning of literary phenomena which readers have in their mind when reading a text. Recently, an approach was proposed to describe and present structure and attributes of literary characters (i.e. the mental representation in a reader’s mind), to explore, and to compare different representations using an ontology. In order to expand the ontology for literary characters, users must manually extract information about characters from literary texts and, again manually, add them to the ontology. In this contribution, I present an application that supports users when working with ontologies in literary studies. Therefore, semi-automatic suggestions for including information in an ontology are generated. The challenge of my approach is to encode aspects of literary characters in a text and to fit it automatically to the ontology of literary characters. The application has been tested by using an extract of the novel ‘Melmoth the Wanderer’ (1820), written by Charles Robert Maturin. For the main character, Melmoth, 72 instances were generated and assigned successfully to the ontology. In conclusion, I think that this approach is not limited to the theme of character descriptions; it can also be adapted to other topics in literary computing and Digital Humanities.",
 "article_title": "Text encoding and ontology--enlarging an ontology by semi-automatic generated instances",
 "authors": [
 {
 "given": " Amélie",
 "family": "Zöllner-Weber",
 "affiliation": [
 {
 "original_name": "The Wittgenstein Archives (WAB), University of Bergen, Norway",
 "normalized_name": "University of Bergen",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/03zga2b32",
 "GRID": "grid.7914.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-05-16",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr019",
 "identifier": {
 "string_id": "10.1093/llc/fqr019",
 "id_scheme": "DOI"
 },
 "abstract": "At the time Darwin first published the Origin of Species, the word ‘evolution’ was used by most biologists of the time to refer not only to specific development, as is the case today, but also to embryological development. Darwin's own stance in that matter is however open to debate, his rare use of the word making it hard to determine whether it is strictly specific or dual, and thus whether the author's conception of evolution is representative or ahead of its time. While this situation certainly stimulates philological, historical, and philosophical debates, it however complicates any attempt to settle the matter on a strict lexical basis, thus making standard text-mining techniques ineffective. To address this specific issue, a computer-assisted method for ‘reading Darwin between the lines’ is here attempted and described: by using an iterative concordance clustering algorithm, this approach aims at ‘digging’ into Darwin's concept of evolution as found in the sixth edition of the Origin of Species, regardless of any proper designation. In light of the results thus obtained, the concept of evolution in the sixth edition of the Origin of Species appears closer to its modern and strictly specific interpretation, inferences made to words related to embryological development being rather rare.",
 "article_title": "The concept of evolution in the Origin of Species: a computer-assisted analysis",
 "authors": [
 {
 "given": " Maxime B.",
 "family": "Sainte-Marie",
 "affiliation": [
 {
 "original_name": "Université du Québec à Montréal (UQAM), Laboratoire d'analyse cognitive de l'information (LANCI), Montreal, Quebec, Canada",
 "normalized_name": "University of Quebec at Montreal",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/002rjbv21",
 "GRID": "grid.38678.32"
 }
 }
 ]
 },
 {
 "given": " Jean-Guy",
 "family": "Meunier",
 "affiliation": [
 {
 "original_name": "Université du Québec à Montréal (UQAM), Laboratoire d'analyse cognitive de l'information (LANCI), Montreal, Quebec, Canada",
 "normalized_name": "University of Quebec at Montreal",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/002rjbv21",
 "GRID": "grid.38678.32"
 }
 }
 ]
 },
 {
 "given": " Nicolas",
 "family": "Payette",
 "affiliation": [
 {
 "original_name": "Université du Québec à Montréal (UQAM), Laboratoire d'analyse cognitive de l'information (LANCI), Montreal, Quebec, Canada",
 "normalized_name": "University of Quebec at Montreal",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/002rjbv21",
 "GRID": "grid.38678.32"
 }
 }
 ]
 },
 {
 "given": " Jean-François",
 "family": "Chartier",
 "affiliation": [
 {
 "original_name": "Université du Québec à Montréal (UQAM), Laboratoire d'analyse cognitive de l'information (LANCI), Montreal, Quebec, Canada",
 "normalized_name": "University of Quebec at Montreal",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/002rjbv21",
 "GRID": "grid.38678.32"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-05-17",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr015",
 "identifier": {
 "string_id": "10.1093/llc/fqr015",
 "id_scheme": "DOI"
 },
 "abstract": "Digital papyrology encompasses artefact digitization and digital support for its interpretation. Digitization is never neutral, and this article presents how, within the e-Science and Ancient Documents project (eSAD), we are developing a software tool that strives to support the act of interpretation while both avoiding spurious exactitude and allowing genuine uncertainty. We first assert that digitization is both sampling and interpreting. Our model of papyrological interpretation thus takes on board the types of expertise that papyrologists draw onto while interpreting ancient and scarcely legible documents. Mimesis serving as a guiding principle, we present how we digitize our text-bearing artefacts (in particular incised documents), taking into account the real-world strategies of the experts. We then argue that, throughout the interpretation process, uncertainty plays a key role, which we illustrate with the example of a Roman stylus tablet that was interpreted twice 92 years apart. To allow the expression of uncertainty, we show how mimesis is again our design strategy: our tool aims to enable the experts to trace the text—a strategy we observed them deploying; further it will support reasoning about hypotheses of interpretation by setting an epistemological framework in which pieces of evidence towards hypotheses of interpretation can be evaluated as in crossword puzzle solving—another expert strategy.",
 "article_title": "Digitizing the act of papyrological interpretation: negotiating spurious exactitude and genuine uncertainty",
 "authors": [
 {
 "given": " Ségolène M.",
 "family": "Tarte",
 "affiliation": [
 {
 "original_name": "Oxford e-Research Centre, University of Oxford, UK",
 "normalized_name": "University of Oxford",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/052gg0110",
 "GRID": "grid.4991.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-05-14",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr023",
 "identifier": {
 "string_id": "10.1093/llc/fqr023",
 "id_scheme": "DOI"
 },
 "abstract": "It is universally recognized that humans process speech and language in chunks, each meaningful in itself. Any two renditions or assimilations of a given sentence will exhibit similarities and discrepancies in the distribution of phrase breaks. Automated phrase break prediction assigns pauses to plain text as input, evaluated against human performance encapsulated in ‘gold standard’ boundary annotations in a speech corpus. This article advocates an enhanced feature set for phrase break prediction, incorporating non-traditional prosodic features. The authors have developed ProPOSEL, a prosody and part-of-speech English lexicon, as text annotation and text analytics tool. Application of ProPOSEL has so far uncovered a statistically significant correlation in English between certain sound patterns (i.e. the diphthongs and triphthongs of Received Pronunciation) and phrase breaks in very different genres. Thus, presence or absence of a complex vowel could easily be incorporated as an extra non-traditional classificatory feature in phrase break models. Our approach also suggests new possibilities for statistical analysis of texts, particularly authorship and genre, via favoured sound and rhythmic patterns in addition to lexis. Moreover, we suggest that our approach of text data-mining descriptive annotations of projected prosody for Text-to-Speech Synthesis and stylistic analysis is applicable to other languages.",
 "article_title": "Non-traditional prosodic features for automated phrase break prediction",
 "authors": [
 {
 "given": " Claire",
 "family": "Brierley",
 "affiliation": [
 {
 "original_name": "University of Leeds, UK",
 "normalized_name": "University of Leeds",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/024mrxd33",
 "GRID": "grid.9909.9"
 }
 }
 ]
 },
 {
 "given": " Eric",
 "family": "Atwell",
 "affiliation": [
 {
 "original_name": "University of Leeds, UK",
 "normalized_name": "University of Leeds",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/024mrxd33",
 "GRID": "grid.9909.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-05-14",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr017",
 "identifier": {
 "string_id": "10.1093/llc/fqr017",
 "id_scheme": "DOI"
 },
 "abstract": "Referring to the concept of archival bond, we define stories as formed by documents that relate to a target activity and developed a method called paragraph alignment to find these documents. The method computes archival bond by measuring the cosine similarity between document paragraphs. We tested the method in a chaotic case study collection created in a shared server by different authors. Results demonstrate that this method is more efficient to find stories than calculating the cosine similarity between entire documents. This research helps archivists make sense of collections that are considered inaccessible and whose stories may otherwise be lost.",
 "article_title": "Finding stories in the archive through paragraph alignment",
 "authors": [
 {
 "given": " Weijia",
 "family": "Xu",
 "affiliation": [
 {
 "original_name": "Texas Advanced Computing Center, University of Texas at Austin, Austin, TX, USA",
 "normalized_name": "The University of Texas at Austin",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00hj54h04",
 "GRID": "grid.89336.37"
 }
 }
 ]
 },
 {
 "given": " Maria",
 "family": "Esteva",
 "affiliation": [
 {
 "original_name": "Texas Advanced Computing Center, University of Texas at Austin, Austin, TX, USA",
 "normalized_name": "The University of Texas at Austin",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00hj54h04",
 "GRID": "grid.89336.37"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-05-13",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr016",
 "identifier": {
 "string_id": "10.1093/llc/fqr016",
 "id_scheme": "DOI"
 },
 "abstract": "Digital Humanities faces many issues in the current financial and educational climate. In this closing plenary from the Digital Humanities conference 2010 at King’s College London, major concerns about the current role and function of Digital Humanities are raised, demonstrating the practical and theoretical aspects of Digital Humanities research in regard to an individual project at University College London: Transcribe Bentham. It is suggested that those in the Digital Humanities have to be more aware of our history, impact, and identity, if the discipline is to continue to flourish in tighter economic climes, and that unless we maintain and establish a more professional attitude towards our scholarly outputs, we will remain ‘present, not voting’ within the academy. The plenary ends with suggestions as to how the individual, institution, and funding body can foster and aid the Digital Humanities, ensuring the field’s relevance and impact in today’s academic culture. This article is a transcript of what was planned to be said at DH2010, although the spoken plenary digresses from the following in places. The video of the speech can be viewed at http://www.arts-humanities.net/video/dh2010_keynote_melissa_terras_present_not_voting_digital_humanities_panopticon.",
 "article_title": "Present, not voting: Digital Humanities in the Panopticon: closing plenary speech, Digital Humanities 2010",
 "authors": [
 {
 "given": " Melissa",
 "family": "Terras",
 "affiliation": [
 {
 "original_name": "Reader in Electronic Communication, Department of Information Studies, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-05-07",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr004",
 "identifier": {
 "string_id": "10.1093/llc/fqr004",
 "id_scheme": "DOI"
 },
 "abstract": "Many corpus linguists make the tacit assumption that part-of-speech frequencies remain constant during the period of observation. In this article, we will consider two related issues: (1) the reliability of part-of-speech tagging in a diachronic corpus and (2) shifts in tag ratios over time. The purpose is both to serve the users of the corpus by making them aware of potential problems, and to obtain linguistically interesting results. We use noun and pronoun ratios as diagnostics indicative of opposing stylistic tendencies, but we are also interested in testing whether any observed variation in the ratios could be accounted for in sociolinguistic terms. The material for our study is provided by the Parsed Corpus of Early English Correspondence (PCEEC), which consists of 2.2 million running words covering the period 1415–1681. The part-of-speech tagging of the PCEEC has its problems, which we test by reannotating the corpus according to our own principles and comparing the two annotations. While there are quite a few changes, the mean percentage of change is very small for both nouns and pronouns. As for variation over time, the mean frequency of nouns declines somewhat, while the mean frequency of pronouns fluctuates with no clear diachronic trend. However, women consistently use more pronouns than men, while men use more nouns than women. More fine-grained distinctions are needed to uncover further regularities and possible reasons for this variation.",
 "article_title": "Variation in noun and pronoun frequencies in a sociohistorical corpus of English",
 "authors": [
 {
 "given": " Tanja",
 "family": "Säily",
 "affiliation": [
 {
 "original_name": "Department of Modern Languages, University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 }
 ]
 },
 {
 "given": " Terttu",
 "family": "Nevalainen",
 "affiliation": [
 {
 "original_name": "Department of Modern Languages, University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 }
 ]
 },
 {
 "given": " Harri",
 "family": "Siirtola",
 "affiliation": [
 {
 "original_name": "Department of Computer Sciences, University of Tampere, Finland",
 "normalized_name": "Tampere University",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/033003e23",
 "GRID": "grid.502801.e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-05-07",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqr001",
 "identifier": {
 "string_id": "10.1093/llc/fqr001",
 "id_scheme": "DOI"
 },
 "abstract": "Hongloumeng by Xueqin Cao (Hsueh-ch‘in Ts'ao) is generally considered one of the greatest classical Chinese novel. Of all nine published English translations known today, the one translated by Hawkes and Minford (the Story of the Stone, Penguin, 1973–86) and the other by Yang and Yang (A Dream of Red Mansions1, Foreign Languages Press in Beijing, 1978–80) are the best known among translators and literary scholars. Over the years, both have been carefully scrutinized and much critiqued. Translators and translation scholars have been engaged in heated debates over salient features of the translations, strategies employed by the translators, the possible effects of the two translations and so on [cf. Liu and Gu (1997) On translation of cultural contents in Hong Lou Meng [in Chinese]. Chinese Translators Journal, 1: 16–19; Wang (2001) A Comparative Study of the English Translations of Poetry in Hong Lou Meng. Xi’an: Shanxi Normal University Press; Feng (2006) On the Translation of Hong Lou Meng [in Chinese]. Shanghai: Shanghai Foreign Language Education Press; Liu (2008), Translating tenor: With reference to the English versions of Hong Lou Meng. Meta, 53(3): 528–48], with the eventual aim to determine which translation better captures the style of the original text or author. Like many debates of similar nature, no definitive conclusions have been reached despite such an intense interest. We believe a corpus-assisted examination [Baker, M. (2000). Towards a methodology for investigating the style of a literary translator. Target, 12(2): 241–66; Baker, M. (1993). Corpus linguistics and translation studies: Implications and applications. In Gill, F., Baker, M., and Tognini-Bonelli, E. (eds), Text and Technology: In Honour of John Sinclair. Amsterdam: Benjamins, pp. 233–50] of the two translations will provide more convincing analysis and can better describe the differences in the translation style of the two famous translations. A particular effort is further made to interpret the reasons for the different strategies adopted by the two different pairs of translators in the social, political, and ideological context of the translations.",
 "article_title": "Translation Style and Ideology: a Corpus-assisted Analysis of two English Translations of Hongloumeng",
 "authors": [
 {
 "given": " Defeng",
 "family": "Li",
 "affiliation": [
 {
 "original_name": "Centre for Translation Studies, SOAS, University of London",
 "normalized_name": "University of London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04cw6st05",
 "GRID": "grid.4464.2"
 }
 }
 ]
 },
 {
 "given": " Chunling",
 "family": "Zhang",
 "affiliation": [
 {
 "original_name": "Department of Linguistics, University of Alberta",
 "normalized_name": "University of Alberta",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/0160cpw27",
 "GRID": "grid.17089.37"
 }
 }
 ]
 },
 {
 "given": " Kanglong",
 "family": "Liu",
 "affiliation": [
 {
 "original_name": "Shue Yan University",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-03-04",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq029",
 "identifier": {
 "string_id": "10.1093/llc/fqq029",
 "id_scheme": "DOI"
 },
 "abstract": "The nearest shrunken centroid (NSC) methodology, originally developed for high-dimensional genomics problems, was recently applied in a stylometric study. Although NSC has many advantages, stylometric problems usually differ from genomics problems in several important ways: texts are of a wide range of sizes, a large series of texts are often the subjects for classification, and most importantly the set of candidate authors cannot usually be assumed to be closed. Consequently, naïve application of NSC methodology can produce misleading results. We extend the NSC methodology for more general application to stylometry. Reanalysis of the Book of Mormon using the open-set NSC method produced dramatically different results from a closed-set NSC analysis.",
 "article_title": "Extended nearest shrunken centroid classification: A new method for open-set authorship attribution of texts of varying sizes",
 "authors": [
 {
 "given": " G. Bruce",
 "family": "Schaalje",
 "affiliation": [
 {
 "original_name": "Department of Statistics, Brigham Young University, Provo, UT, USA",
 "normalized_name": "Brigham Young University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047rhhm47",
 "GRID": "grid.253294.b"
 }
 }
 ]
 },
 {
 "given": " Paul J.",
 "family": "Fields",
 "affiliation": [
 {
 "original_name": "Department of Statistics, Brigham Young University, Provo, UT, USA",
 "normalized_name": "Brigham Young University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047rhhm47",
 "GRID": "grid.253294.b"
 }
 }
 ]
 },
 {
 "given": " Matthew",
 "family": "Roper",
 "affiliation": [
 {
 "original_name": "Neal A. Maxwell Institute for Religious Scholarship, Brigham Young University, Provo, UT, USA",
 "normalized_name": "Brigham Young University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047rhhm47",
 "GRID": "grid.253294.b"
 }
 }
 ]
 },
 {
 "given": " Gregory L.",
 "family": "Snow",
 "affiliation": [
 {
 "original_name": "Statistical Data Center, LDS Hospital Intermountain Health Care, Salt Lake City, UT, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2011-01-20",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq027",
 "identifier": {
 "string_id": "10.1093/llc/fqq027",
 "id_scheme": "DOI"
 },
 "abstract": "Moving from a traditional dialect geography research methodology to one in which data are processed electronically, and where visualization is used as a research tool, can be of great benefit to dialect geography. A working environment offering full support for using visualization as a research tool could take dialect geography into the era of e-Science. Despite the advent of electronic data processing, electronic publishing and Geographic Information Systems (GIS), an analysis of the most important computerized tools for dialect geography research suggests that there is little support for the use of modern data mining and analysis techniques connected to visualization for the analysis and interpretation of dialect data. In this article, we use the electronic publication of two major dialect dictionaries to illustrate the value of visualization as a research tool by showing how visual data mining and combining dialect data with independent data sets applies to dialect geography research. We argue that there is no need for large-scale software development because visualization, as a research tool, is supported to a large extent by geo-browsers such as ‘Google Earth’, which make it possible to flexibly combine and visualize different types of geo-referenced data.",
 "article_title": "Visualization as a research tool for dialect geography using a geo-browser",
 "authors": [
 {
 "given": " Folkert",
 "family": "de Vriend",
 "affiliation": [
 {
 "original_name": "Radboud University, Centre for Language and Speech Technology, Nijmegen, The Netherlands",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Lou",
 "family": "Boves",
 "affiliation": [
 {
 "original_name": "Radboud University, Centre for Language and Speech Technology, Nijmegen, The Netherlands",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Roeland",
 "family": "van Hout",
 "affiliation": [
 {
 "original_name": "Radboud University, Centre for Language Studies, Nijmegen, The Netherlands",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Jos",
 "family": "Swanenberg",
 "affiliation": [
 {
 "original_name": "Tilburg University, Department of Culture Studies, Tilburg, The Netherlands",
 "normalized_name": "Tilburg University",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/04b8v1s79",
 "GRID": "grid.12295.3d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-12-25",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq028",
 "identifier": {
 "string_id": "10.1093/llc/fqq028",
 "id_scheme": "DOI"
 },
 "abstract": "Since the 1970s, the Regressive Imagery Dictionary (RID) has been widely used as a content analysis tool for both psychological and literary research on texts. Today, besides the original English version, it exists in translations for seven other languages. However, the wide-ranging validation studies conducted on the English version have mostly not been replicated for the various translations, hence the validity of these translations must rest for the time being on their concurrent validity with the English original. This article examines the concurrent validity of the German, Latin, and Portuguese translations of the RID. Taking the English RID as a de facto standard, it uses translations of the psalms (N = 150) to check how far the three translations of the RID correspond to the English original in identifying whether there is a significant dominance of primary or secondary process lexis in a text. Overall, compared against the English version, the Latin translation has 77.33% accuracy, the German translation 68%, and the Portuguese translation 56.67%. In terms of the sensitivity and specificity of classification, the Latin translation performs quite well on both measures; in contrast, the German translation is conservative, whilst the Portuguese translation is liberal.",
 "article_title": "The Regressive Imagery Dictionary: A test of its concurrent validity in English, German, Latin, and Portuguese",
 "authors": [
 {
 "given": " Andrew",
 "family": "Wilson",
 "affiliation": [
 {
 "original_name": "Department of Linguistics and English Language, County South, Lancaster University, Lancaster LA1 4YL, UK",
 "normalized_name": "Lancaster University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04f2nsd36",
 "GRID": "grid.9835.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-12-21",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq024",
 "identifier": {
 "string_id": "10.1093/llc/fqq024",
 "id_scheme": "DOI"
 },
 "abstract": "As scholarly publishing transitions from a static medium (paper) to a digital one, a necessary tension has emerged between a static, or archival, approach to content, and the dynamic, ever-evolving requirements of online resources. Two years after the release of the NINES website (the Networked Infrastructure for nineteenth-century Electronic Scholarship), the first online peer-reviewing organization and hub for the aggregation of scholarly resources in nineteenth-century studies, the development team decided to evaluate the site’s efficacy and update it accordingly. But because of NINES’s unique position as a federation of scholar-driven (mostly primary-source oriented) sites as well as a forward-thinking software developer, it was essential that any changes to the site remain true to the institution’s dual roles. This article explores the NINES redesign as an experiment in implementing usability studies and user-centered design to enhance its appeal within our community. This narrative is meant as a case study, one to be considered within the larger context of the questions and challenges faced by those creating, managing, and using digital projects.",
 "article_title": "Testing NINES",
 "authors": [
 {
 "given": " Dana",
 "family": "Wheeles",
 "affiliation": [
 {
 "original_name": "University of Virginia",
 "normalized_name": "University of Virginia",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0153tk833",
 "GRID": "grid.27755.32"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-12-16",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq026",
 "identifier": {
 "string_id": "10.1093/llc/fqq026",
 "id_scheme": "DOI"
 },
 "abstract": "This article details a modeling methodology that is appropriate for historical, functional documents that are to be digitally represented and hosted within a software environment for humanities research. The functionality is derived from Use Case modeling that can be undertaken in consultation with the User Group. The Use Cases are an expression of the whole-system model as they embody the interaction of User, with the document, in the software environment. The encoding mechanism largely practiced within the humanities computing community is represented by the TEI, which seeks to provide a set of guidelines for encoding humanities documents. However, TEI offers no guidance in relation to creating an encoding of a document that is supportive of the software environment that will host it, the interaction mechanisms required, or the User. We argue that modeling with recourse to the Logical, the Physical and the Interaction classes enables not just the generation of an appropriate encoding scheme, but also the software to manipulate it. We situate Use Case methodology within Activity Theory and relate this to the humanities computing community. The argument is framed in relation to the creation of a digital edition of an 18th century Spanish Account Book manuscript.",
 "article_title": "Appropriate Use Case modeling for humanities documents",
 "authors": [
 {
 "given": " Aja",
 "family": "Teehan",
 "affiliation": [
 {
 "original_name": "National University of Ireland, Ireland",
 "normalized_name": "National University of Ireland",
 "country": "Ireland",
 "identifiers": {
 "ror": "https://ror.org/00shsf120",
 "GRID": "grid.9344.a"
 }
 }
 ]
 },
 {
 "given": " John G.",
 "family": "Keating",
 "affiliation": [
 {
 "original_name": "National University of Ireland, Ireland",
 "normalized_name": "National University of Ireland",
 "country": "Ireland",
 "identifiers": {
 "ror": "https://ror.org/00shsf120",
 "GRID": "grid.9344.a"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-12-16",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq018",
 "identifier": {
 "string_id": "10.1093/llc/fqq018",
 "id_scheme": "DOI"
 },
 "abstract": "The Corpus of Contemporary American English is the first large, genre-balanced corpus of any language, which has been designed and constructed from the ground up as a ‘monitor corpus’, and which can be used to accurately track and study recent changes in the language. The 400 million words corpus is evenly divided between spoken, fiction, popular magazines, newspapers, and academic journals. Most importantly, the genre balance stays almost exactly the same from year to year, which allows it to accurately model changes in the ‘real world’. After discussing the corpus design, we provide a number of concrete examples of how the corpus can be used to look at recent changes in English, including morphology (new suffixes –friendly and –gate), syntax (including prescriptive rules, quotative like, so not ADJ, the get passive, resultatives, and verb complementation), semantics (such as changes in meaning with web, green, or gay), and lexis––including word and phrase frequency by year, and using the corpus architecture to produce lists of all words that have had large shifts in frequency between specific historical periods.",
 "article_title": "The Corpus of Contemporary American English as the first reliable monitor corpus of English",
 "authors": [
 {
 "given": " Mark",
 "family": "Davies",
 "affiliation": [
 {
 "original_name": "Brigham Young University, Provo, UT, USA",
 "normalized_name": "Brigham Young University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047rhhm47",
 "GRID": "grid.253294.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-10-29",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq021",
 "identifier": {
 "string_id": "10.1093/llc/fqq021",
 "id_scheme": "DOI"
 },
 "abstract": "In this article, we argue that, just as an edition of a book can be a means of reifying a theory about how books should be edited, so can the creation of an experimental digital prototype be understood as conveying an argument about designing interfaces. Building on this premise, we explore theoretical affinities shared by recent design and book history scholarship, and connect those theories to the emerging practice of peer-reviewing digital objects in scholarly contexts. We suggest a checklist for subjecting prototypes directly to peer review: Is the argument reified by the prototype contestable, defensible, and substantive?Does the prototype have a recognizable position in the context of similar work, either in terms of concept or affordances?Is the prototype part of a series of prototypes with an identifiable trajectory?Does the prototype address possible objections?Is the prototype itself an original contribution to knowledge?We also outline some implications for funding agencies interested in supporting researchers who are designing experimental computer prototypes. For instance, if a series of prototypes functions as a set of smaller arguments within a larger debate, it might be more appropriate to fund the sequence rather than treating each project as an individual proposal.",
 "article_title": "How a prototype argues",
 "authors": [
 {
 "given": " Alan",
 "family": "Galey",
 "affiliation": [
 {
 "original_name": "Faculty of Information/Book History and Print Culture Program, University of Toronto, Canada",
 "normalized_name": "University of Toronto",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03dbr7087",
 "GRID": "grid.17063.33"
 }
 }
 ]
 },
 {
 "given": " Stan",
 "family": "Ruecker",
 "affiliation": [
 {
 "original_name": "University of Alberta, Canada With the INKE Team1",
 "normalized_name": "University of Alberta",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/0160cpw27",
 "GRID": "grid.17089.37"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-10-28",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq020",
 "identifier": {
 "string_id": "10.1093/llc/fqq020",
 "id_scheme": "DOI"
 },
 "abstract": "Constructing readings of damaged and abraded ancient documents is a difficult, complex, and a time-consuming task. It frequently involves reference to a variety of linguistic and archaeological datasets and the integration of previous knowledge of similar documentary material. Due to the involved and lengthy reading process, it is often difficult to record and recall how the final interpretation of the document was reached and which competing hypotheses were presented, adopted, or discarded in the process of reading. This article discusses the development of the application called DUGA, which uses Decision Support System (DSS) technology to aid the day-to-day reading of damaged documents. Such an application will facilitate the process of transcribing texts by providing a framework in which scholars can record, track, and trace their progress. DUGA will include a word search facility of external resources such as the Vindolanda ink tablets through the knowledge base Web Service called APPELLO. This functionality will support the scholars through their reading process by suggesting words, which may confirm current interpretations or inspire new ones. Furthermore, DUGA will allow continuity between working sessions, and the complete documentation of the reading process, that has hitherto been implicit in published editions.",
 "article_title": "Towards a decision support system for reading ancient documents",
 "authors": [
 {
 "given": " Henriette",
 "family": "Roued-Cunliffe",
 "affiliation": [
 {
 "original_name": "Centre for the Study of Ancient Documents, University of Oxford, UK",
 "normalized_name": "University of Oxford",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/052gg0110",
 "GRID": "grid.4991.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-10-22",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq022",
 "identifier": {
 "string_id": "10.1093/llc/fqq022",
 "id_scheme": "DOI"
 },
 "abstract": "The sustainability of digital humanities research projects is a pressing issue for humanities computing. Currently, even well-established large digital projects like the Linguistic Atlas Project (LAP) are at future risk because funding and other resources are contingent on grant funding or faculty status of the director, neither of which will necessarily be available to maintain the project over time. The mission of the university library, however, includes archiving and dissemination, now increasingly of digital materials as well as traditional paper. Collaboration with the university library is the only realistic option for long-term sustainability of digital humanities projects in the current environment. Unlike paper collections, which only require secure storage, digital projects also require the means of adaptation to new electronic media and operating environments. Even data storage requires that materials from digital projects be included in library media refresh cycles, which will include transfer of old data to new media as technology develops. Projects like LAP should provide resources to assist the library in starting the project archive, including staff time, and funding for equipment. Project metadata must be provided and, to the extent possible, integrated with library systems and finding aids. Project staff will also need to maintain a Web presence and tools developed for the project. Such cooperation leads toward the development of a digital institutional repository, in which research results and tools may be maintained in the library, not just for the humanities but across many disciplines.",
 "article_title": "Library collaboration with large digital humanities projects",
 "authors": [
 {
 "given": " William A.",
 "family": "Kretzschmar",
 "affiliation": [
 {
 "original_name": "University of Georgia, USA",
 "normalized_name": "University of Georgia",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00te3t702",
 "GRID": "grid.213876.9"
 }
 }
 ]
 },
 {
 "given": " William",
 "family": "Gray Potter",
 "affiliation": [
 {
 "original_name": "University of Georgia, USA",
 "normalized_name": "University of Georgia",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00te3t702",
 "GRID": "grid.213876.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-10-20",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq019",
 "identifier": {
 "string_id": "10.1093/llc/fqq019",
 "id_scheme": "DOI"
 },
 "abstract": "Most memory institutions are now engaging with digitizing holdings to provide online access. Although, recent developments in technology have allowed users to create high quality digital resources out with institutional boundaries, little consideration has been given to the potential contribution that the general public can make to digitizing our cultural heritage. This article seeks to scope the growing trend of the creation of amateur online museums, archives, and collections, and demonstrates that the best examples of this endeavor can teach best practice to traditional memory institutions in how to make their collections useful, interesting, and used by online communities.",
 "article_title": "Digital curiosities: resource creation via amateur digitization",
 "authors": [
 {
 "given": " Melissa",
 "family": "Terras",
 "affiliation": [
 {
 "original_name": "University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-10-18",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq017",
 "identifier": {
 "string_id": "10.1093/llc/fqq017",
 "id_scheme": "DOI"
 },
 "abstract": "We develop an aggregate measure of syntactic difference for automatically finding common syntactic differences between collections of text. With the use of this measure, it is possible to mine for differences between, for example, the English of learners and natives, or between related dialects. If formulated in advance, hypotheses can also be tested for statistical significance. It enables us to find not only absence or presence, but also under- and overuse of specific constructs. We have applied our measure to the English of Finnish immigrants in Australia to look for traces of Finnish grammar in their English. The outcomes of this detection process were analysed and found to be insightful. A report is included in this article. Besides explaining our method, we also go into the theory behind it, including permutation statistics, and the custom normalizations required for applying these tests to syntactical data. We also explain how to use the software we developed to apply this method to new corpora, and give some suggestions for further research.",
 "article_title": "Automatically Extracting Typical Syntactic Differences from Corpora",
 "authors": [
 {
 "given": " Wybo",
 "family": "Wiersma",
 "affiliation": [
 {
 "original_name": "King's College London",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 },
 {
 "given": " John",
 "family": "Nerbonne",
 "affiliation": [
 {
 "original_name": "University of Groningen",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 }
 ]
 },
 {
 "given": " Timo",
 "family": "Lauttamus",
 "affiliation": [
 {
 "original_name": "University of Oulu",
 "normalized_name": "University of Oulu",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/03yj89h83",
 "GRID": "grid.10858.34"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-10-19",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq016",
 "identifier": {
 "string_id": "10.1093/llc/fqq016",
 "id_scheme": "DOI"
 },
 "abstract": "Vladimir Levenshtein’s edit distance algorithm is used to reveal disparities between delimiter stripped texts of the Senate amended Treaty of Fort Laramie with Sioux, etc., 1851 as corrected in a previous study, and of other federal copies of this transaction. All of the latter deviated markedly from that newly created version, reflecting errors of exclusion, of the absence in some transcripts of the Senate modification, of editorial decisions made by Charles J. Kappler during the preparation of his treaty compilations at the beginning of the twentieth century, and of spelling. These results confirmed that the instrument was until now never published in its complete formal state. This study may serve as a model for future text analyses that might benefit from the employment of Levenshtein’s metric.",
 "article_title": "Comparing nearly identical treaty texts: a note on the Treaty of Fort Laramie with Sioux, etc., 1851 and Levenshtein's edit distance metric",
 "authors": [
 {
 "given": " Charles D.",
 "family": "Bernholz",
 "affiliation": [
 {
 "original_name": "Love Memorial Library, University of Nebraska, Lincoln, NE 68588, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Brian L.",
 "family": "Pytlik Zillig",
 "affiliation": [
 {
 "original_name": "Love Memorial Library, University of Nebraska, Lincoln, NE 68588, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-09-21",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq015",
 "identifier": {
 "string_id": "10.1093/llc/fqq015",
 "id_scheme": "DOI"
 },
 "abstract": "A metrical system is the particular rhythm upon which a verse is structured. Classical Ancient Greek poetry demonstrates a wide variety of metrical systems, the most ancient one being the hexameter. Two of the longest and most famous poems of Ancient Greek poetry, namely Iliad and Odyssey, were composed in the hexameter by Homer. This system is named ‘hexameter’, because the verse is divided into six sections, and so is the rhythm of reciting it. Each section has a fixed scheme, thus it can have only two or three syllables in a predefined combination. The aim of this project was the development of a program that will automatically scan such a verse, by using the least possible computing and linguistic resources. The term ‘scansion’ denotes the discovery of the particular pattern of the metrical system of the verse. That is in which positions of the verse long syllables are located, in which positions are short, and how these syllables form the fixed scheme of every section of the verse. Words inside verses were carefully selected to conform to the above standards.",
 "article_title": "Computerized Scansion of Ancient Greek Hexameter",
 "authors": [
 {
 "given": " Evangelos C.",
 "family": "Papakitsos",
 "affiliation": [
 {
 "original_name": "General Department of Mathematics, Technological Educational Institute of Piraeus, Aigaleo, Greece",
 "normalized_name": "Technological Educational Institute of Piraeus",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/00ks0ea23",
 "GRID": "grid.426224.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-09-18",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq014",
 "identifier": {
 "string_id": "10.1093/llc/fqq014",
 "id_scheme": "DOI"
 },
 "abstract": "This article examines the use of lexical bundles—repeated word groups of differing lengths—in two German Bible translations and analyzes their use in relation to the comparative readability of the two texts. The texts included in this study are the four Gospels and the book of Acts in Martin Luther’s classic translation of the Bible and the modern translation Hoffnung für alle (Hfa). The study is both quantitative and qualitative in nature, looking at lexical bundle statistics in aggregate and at specific uses of lexical bundles in context. The results indicate that the older translation used many more lexical bundles, but types that were used by the newer version were used more effectively. Overall, however, the older version has the advantage in readability due to its greater use of lexical bundles.",
 "article_title": "Lexical bundles and German bibles",
 "authors": [
 {
 "given": "N.",
 "family": "Shrefler",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-09-17",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq013",
 "identifier": {
 "string_id": "10.1093/llc/fqq013",
 "id_scheme": "DOI"
 },
 "abstract": "Applications of authorship attribution `in the wild’ [Koppel, M., Schler, J., and Argamon, S. (2010). Authorship attribution in the wild. Language Resources and Evaluation. Advanced Access published January 12, 2010:10.1007/s10579-009-9111-2], for instance in social networks, will likely involve large sets of candidate authors and only limited data per author. In this article, we present the results of a systematic study of two important parameters in supervised machine learning that significantly affect performance in computational authorship attribution: (1) the number of candidate authors (i.e. the number of classes to be learned), and (2) the amount of training data available per candidate author (i.e. the size of the training data). We also investigate the robustness of different types of lexical and linguistic features to the effects of author set size and data size. The approach we take is an operationalization of the standard text categorization model, using memory-based learning for discriminating between the candidate authors. We performed authorship attribution experiments on a set of three benchmark corpora in which the influence of topic could be controlled. The short text fragments of e-mail length present the approach with a true challenge. Results show that, as expected, authorship attribution accuracy deteriorates as the number of candidate authors increases and size of training data decreases, although the machine learning approach continues performing significantly above chance. Some feature types (most notably character n-grams) are robust to changes in author set size and data size, but no robust individual features emerge.",
 "article_title": "The effect of author set size and data size in authorship attribution",
 "authors": [
 {
 "given": " Kim",
 "family": "Luyckx",
 "affiliation": [
 {
 "original_name": "CLiPS Computational Linguistics Group, University of Antwerp, Belgium",
 "normalized_name": "University of Antwerp",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/008x57b05",
 "GRID": "grid.5284.b"
 }
 }
 ]
 },
 {
 "given": " Walter",
 "family": "Daelemans",
 "affiliation": [
 {
 "original_name": "CLiPS Computational Linguistics Group, University of Antwerp, Belgium",
 "normalized_name": "University of Antwerp",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/008x57b05",
 "GRID": "grid.5284.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-08-17",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "26",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq011",
 "identifier": {
 "string_id": "10.1093/llc/fqq011",
 "id_scheme": "DOI"
 },
 "abstract": "This article deals with the lemmatization of Middle Dutch literature. This text collection—like any other medieval corpus—is characterized by an enormous spelling variation, which makes it difficult to perform a computational analysis of this kind of data. Lemmatization is therefore an essential preprocessing step in many applications, since it allows the abstraction from superficial textual variation, for instance in spelling. The data we will work with is the Corpus-Gysseling, containing all surviving Middle Dutch literary manuscripts dated before 1300 AD. In this article we shall present a language-independent system that can ‘learn’ intra-lemma spelling variation. We describe a series of experiments with this system, using Memory-Based Machine Learning and propose two solutions for the lemmatization of our data: the first procedure attempts to generate new spelling variants, the second one seeks to implement a novel string distance metric to better detect spelling variants. The latter system attempts to rerank candidates suggested by a classic Levenshtein distance, leading to a substantial gain in lemmatization accuracy. This research result is encouraging and means a substantial step forward in the computational study of Middle Dutch literature. Our techniques might be of interest to other research domains as well because of their language-independent nature.",
 "article_title": "Weigh your words--memory-based lemmatization for Middle Dutch",
 "authors": [
 {
 "given": " Mike",
 "family": "Kestemont",
 "affiliation": [
 {
 "original_name": "Institute for the Study of Literature in the Netherlands (ISLN)",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "University of Antwerp, Belgium",
 "normalized_name": "University of Antwerp",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/008x57b05",
 "GRID": "grid.5284.b"
 }
 }
 ]
 },
 {
 "given": " Walter",
 "family": "Daelemans",
 "affiliation": [
 {
 "original_name": "CLiPS Computational Linguistics Group, University of Antwerp, Belgium",
 "normalized_name": "University of Antwerp",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/008x57b05",
 "GRID": "grid.5284.b"
 }
 }
 ]
 },
 {
 "given": " Guy",
 "family": "De Pauw",
 "affiliation": [
 {
 "original_name": "CLiPS Computational Linguistics Group, University of Antwerp, Belgium",
 "normalized_name": "University of Antwerp",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/008x57b05",
 "GRID": "grid.5284.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-08-05",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq003",
 "identifier": {
 "string_id": "10.1093/llc/fqq003",
 "id_scheme": "DOI"
 },
 "abstract": "Categorization and taxonomy are topical issues in intertextuality studies. Instead of increasing the number of overlapping or contradictory definitions (often established with reference to limited databases) which exist even for key concepts such as “allusion ” or “quotation”, we propose an electronically implemented data-driven approach based on the isolation, analysis and description of a number of relevant parameters such as general text relation, marking for quotation, modification etc. If a systematic parameter analysis precedes discussions of possible correlations and the naming of features bundles as composite categories, a dynamic approach to categorization emerges which does justice to the varied and complex phenomena in this field. The database is the HyperHamlet corpus, a chronologically and generically wide-ranging collection of Hamlet references that confront linguistic and literary researchers with a comprehensive range of formal and stylistic issues. Its multi-dimensional encodings and search facilities provide the indispensable ‘freedom from the analytic limits of hardcopy', as Jerome McGann put it. The methodological and heuristic gains include a more complete description of possible parameter settings, a clearer recognition of multiple parameter settings (as implicit in existing genre definitions), a better understanding of how parameters interact, descriptions of disregarded literary phenomena that feature unusual parameter combinations and, finally, descriptive labels for the most polysemous areas that may clarify matters without increasing taxonomical excess.",
 "article_title": "A 'key to all quotations'? A corpus-based parameter model of intertextuality",
 "authors": [
 {
 "given": "Regula",
 "family": "Hohl Trillini",
 "affiliation": [
 {
 "original_name": "Department of English, University of Basel, Basel, Switzerland",
 "normalized_name": "University of Basel",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/02s6k3f65",
 "GRID": "grid.6612.3"
 }
 }
 ]
 },
 {
 "given": "Sixta",
 "family": "Quassdorf",
 "affiliation": [
 {
 "original_name": "Department of English, University of Basel, Basel, Switzerland",
 "normalized_name": "University of Basel",
 "country": "Switzerland",
 "identifiers": {
 "ror": "https://ror.org/02s6k3f65",
 "GRID": "grid.6612.3"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-05-19",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq006",
 "identifier": {
 "string_id": "10.1093/llc/fqq006",
 "id_scheme": "DOI"
 },
 "abstract": "In this article, we review the process of building ODIN, the Online Database of Interlinear Text (http://odin.linguistlist.org) a multilingual repository of linguistically analyzed language data. ODIN is built from interlinear text that has been harvested from scholarly linguistic documents posted on the web. At the time of this writing, ODIN holds nearly 190,000 instances of interlinear text representing annotated language data for more than 1,000 languages (representing data from >10% of the world's languages). ODIN's charter has been to make these data available to linguists and other language researchers via search, providing the facility to find instances of language data and related resources (i.e. the documents from which data were extracted) by language name, language family, and even annotations used to markup the data (e.g. NOM, ACC, ERG, PST, 3SG). Further, we have sought to enrich the data we have collected and extract ‘knowledge’ from the enriched content. To enrich the data, we use a variety of statistical tagging and parsing methods applied in the English translations. An enhanced search facility allows users to find data across languages for a variety of syntactic constructions and constituent orders, facilitating unprecedented automated and online discovery of language data.",
 "article_title": "Developing ODIN: A Multilingual Repository of Annotated Language Data for Hundreds of the World's Languages",
 "authors": [
 {
 "given": " William D.",
 "family": "Lewis",
 "affiliation": [
 {
 "original_name": "Microsoft Research, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Fei",
 "family": "Xia",
 "affiliation": [
 {
 "original_name": "Department of Linguistics, University of Washington, USA",
 "normalized_name": "University of Washington",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00cvxb145",
 "GRID": "grid.34477.33"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-05-08",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq007",
 "identifier": {
 "string_id": "10.1093/llc/fqq007",
 "id_scheme": "DOI"
 },
 "abstract": "Embedded generalized markup, as applied by digital humanists to the recording and studying of our textual cultural heritage, suffers from a number of serious technical drawbacks. As a result of its evolution from early printer control languages, generalized markup can only express a document’s ‘logical’ structure via a repertoire of permissible printed format structures. In addition to the well-researched overlap problem, the embedding of markup codes into texts that never had them when written leads to a number of further difficulties: the inclusion of potentially obsolescent technical and subjective information into texts that are supposed to be archivable for the long term, the manual encoding of information that could be better computed automatically, and the obscuring of the text by highly complex technical data. Many of these problems can be alleviated by asserting a separation between the versions of which many cultural heritage texts are composed, and their content. In this way the complex interconnections between versions can be handled automatically, leaving only simple markup for individual versions to be handled by the user.",
 "article_title": "The inadequacy of embedded markup for cultural heritage texts",
 "authors": [
 {
 "given": " Desmond",
 "family": "Schmidt",
 "affiliation": [
 {
 "original_name": "Information Security Institute, Queensland University of Technology, Queensland, Australia",
 "normalized_name": "Queensland University of Technology",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/03pnv4752",
 "GRID": "grid.1024.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-04-17",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq005",
 "identifier": {
 "string_id": "10.1093/llc/fqq005",
 "id_scheme": "DOI"
 },
 "abstract": "Of all American literary mysteries The Diary of a Public Man has been perhaps the most perplexing. Set principally in Washington DC, it covers a short but critical period in the nation’s history, the secession winter of 1860–61. The Diary entries are dated during the last months of James Buchanan’s ill-fated administration and the first 2 weeks after Abraham Lincoln’s inauguration. The publisher refused to name the author yet, despite the Diary’s anonymity, it has been used and quoted by historians for more than a century. It is clearly the work of an exceptionally gifted writer. The Diarist pictures himself as a strong Union man, much worried whether the crisis can be resolved without resort to war. Naturally there has been much speculation as to the Diary’s authorship. This article describes how traditional and non-traditional methods of authorship attribution may be employed on the Diary, which we believe to have been written by William Henry Hurlbert. We argue that the joint interdisciplinary approach employed in this article should be the way in which attributional research is conducted. Information on the traditional attribution section of this article is adapted from the forthcoming book by Daniel W. Crofts, A Secession Crisis Enigma: William Henry Hurlbert and ‘The Diary of a Public Man’ (Louisiana University Press, 2010)",
 "article_title": "The diary of a public man: a case study in traditional and non-traditional authorship attribution",
 "authors": [
 {
 "given": " David I.",
 "family": "Holmes",
 "affiliation": [
 {
 "original_name": "The College of New Jersey, Ewing, USA",
 "normalized_name": "Princeton University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00hx57361",
 "GRID": "grid.16750.35"
 }
 }
 ]
 },
 {
 "given": " Daniel W.",
 "family": "Crofts",
 "affiliation": [
 {
 "original_name": "The College of New Jersey, Ewing, USA",
 "normalized_name": "Princeton University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00hx57361",
 "GRID": "grid.16750.35"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-04-15",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq008",
 "identifier": {
 "string_id": "10.1093/llc/fqq008",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents the design of an interoperable database for digital documentation of oral discourse genres in multiple languages. Focussing on stylistic form and cultural specificity of artistic expression, the categories of study that serve as data fields build on contextual and functional approaches to verbal art performance. The database is part of a larger project known as VOVA (VOcal and Verbal Arts archives) that seeks to create digital tools for editing and annotating stylized oral discourse for purposes of comparative study of oral traditions and the preservation of endangered languages. Detailed descriptions of fields and numerous examples of the type of data solicited by VOVA, taken from leading scholarship in the field, help to clarify the scientific aims of the project. Search modes for consulting the database are also provided. Relations between the symbol-making and symbol-using activities of language use, text editing, and the digital humanities are discussed in light of the anthropological and linguistic research that will serve as a basis for a systematic study of stylistics in speech.",
 "article_title": "Digital documentation of oral discourse genres",
 "authors": [
 {
 "given": " Catharine",
 "family": "Mason",
 "affiliation": [
 {
 "original_name": "Université de Caen-Basse Normandie, France",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-04-15",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq004",
 "identifier": {
 "string_id": "10.1093/llc/fqq004",
 "id_scheme": "DOI"
 },
 "abstract": "We report on a significant correlation between lexical items containing complex vowels in their present day canonical forms, and prosodic-syntactic boundaries in Milton’s Paradise Lost, where all line terminals, whether end-stopped or run-on, plus line-medials with associated punctuation, constitute boundary tokens and equate to gold-standard phrase break annotations. Real-world knowledge of present day English pronunciation is projected onto each word token in two different versions, constituting two phrasing variants, of Book 1 of the poem via ProPOSEL, a prosody and part-of-speech English lexicon developed by the authors; and pertinent differences in place of articulation of English vowels in Milton’s day and ours are also discussed. The chi-squared test for independence returns a two-tailed P-value of less than 0.0001 for the association of this vowel subset and phrase breaks in both samples. This leads us to speculate that the poet’s unpremeditated use of complex vowels—which slow down verse movement in Paradise Lost and thus generate rhythmic junctures—may represent a phrasing device habitual not just to poets but to native English speakers in general. Concurrent work on a corpus of present-day British English speech corroborates our findings. Hence, complex vowels may constitute new predictive features in phrasing models for English.",
 "article_title": "Holy smoke: vocalic precursors of phrase breaks in Milton's Paradise Lost",
 "authors": [
 {
 "given": " Claire",
 "family": "Brierley",
 "affiliation": [
 {
 "original_name": "University of Bolton, UK",
 "normalized_name": "University of Bolton",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01t884y44",
 "GRID": "grid.36076.34"
 }
 },
 {
 "original_name": "University of Leeds, UK",
 "normalized_name": "University of Leeds",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/024mrxd33",
 "GRID": "grid.9909.9"
 }
 }
 ]
 },
 {
 "given": " Eric",
 "family": "Atwell",
 "affiliation": [
 {
 "original_name": "University of Leeds, UK",
 "normalized_name": "University of Leeds",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/024mrxd33",
 "GRID": "grid.9909.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-04-15",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq001",
 "identifier": {
 "string_id": "10.1093/llc/fqq001",
 "id_scheme": "DOI"
 },
 "abstract": "We compare and benchmark the performance of five classification methods, four of which are taken from the machine learning literature, in a classic authorship attribution problem involving the Federalist Papers. Cross-validation results are reported for each method, and each method is further employed in classifying the disputed papers and the few papers that are generally understood to be coauthored. These tests are performed using two separate feature sets: a “raw” feature set containing all words and word bigrams that are common to all of the authors, and a second “pre-processed” feature set derived by reducing the raw feature set to include only words meeting a minimum relative frequency threshold. Each of the methods tested performed well, but nearest shrunken centroids and regularized discriminant analysis had the best overall performances with 0/70 cross-validation errors.",
 "article_title": "A comparative study of machine learning methods for authorship attribution",
 "authors": [
 {
 "given": " Matthew L.",
 "family": "Jockers",
 "affiliation": [
 {
 "original_name": "Department of English, Stanford University, Stanford, CA 94305, USA",
 "normalized_name": "Stanford University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00f54p054",
 "GRID": "grid.168010.e"
 }
 }
 ]
 },
 {
 "given": " Daniela M.",
 "family": "Witten",
 "affiliation": [
 {
 "original_name": "Department of Statistics, Stanford University, Stanford, CA 94305, USA",
 "normalized_name": "Stanford University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00f54p054",
 "GRID": "grid.168010.e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-04-13",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqq002",
 "identifier": {
 "string_id": "10.1093/llc/fqq002",
 "id_scheme": "DOI"
 },
 "abstract": "The use of corpus material and methods represents a major methodological innovation in Chinese historical linguistics. The very exciting findings uncovered in this article may be seen as the first systematic large-scale investigation of the various morpho-syntactic patterns underpinning the evolution of Chinese lexis. In this article, we have made a ground-breaking investigation into the diverse lexical modes and patterns which have emerged and developed in each major period in Chinese history, in which the generation of corpus linguistic data and the subsequent computational statistical modelling have been essential.",
 "article_title": "A corpus-based study of lexical periodization in historical Chinese",
 "authors": [
 {
 "given": " Meng ",
 "family": "Ji",
 "affiliation": [
 {
 "original_name": "School of Law, Tohoku University, Japan",
 "normalized_name": "Tohoku University",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/01dq60k83",
 "GRID": "grid.69566.3a"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-04-14",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp037",
 "identifier": {
 "string_id": "10.1093/llc/fqp037",
 "id_scheme": "DOI"
 },
 "abstract": "New technologies have always influenced communication, by adding new ways of communication to the existing ones and/or changing the ways in which existing forms of communication are utilized. This is particularly obvious in the way in which computer-mediated communication (CMC) has had an impact on communication. In this exploratory article, we are concerned with some characteristics of a newly evolving form of Spanish Internet orthography that differ from standard Spanish spelling. Three types of deviations from ‘the norm’ are considered: a reduction (post-vocalic d/[ð] deletion in -ado), a transformation (namely the spelling change from ch to x), and reduplication (of characters). Based on a corpus of approximately 2.7 million words of regionally balanced informal internet Spanish compiled in 2008, we describe the spelling changes and discuss a variety of sometimes interacting factors governing the rates of spelling variants such as overall frequency effects, functional (pragmatic, sociolinguistic, and iconicity-related) characteristics, and phonological constraints. We also compare our findings to data from Mark Davies's (2002) Corpus del Español (100 million words, 1200s–1900s, http://www.corpusdelespanol.org) as well as other sources and relate them to the discussion of the register/genre of Internet language.",
 "article_title": "k dixez? A corpus study of Spanish Internet orthography",
 "authors": [
 {
 "given": " Mark",
 "family": "Myslín",
 "affiliation": [
 {
 "original_name": "University of California, Santa Barbara, CA, USA",
 "normalized_name": "California Coast University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05t99sp05",
 "GRID": "grid.468726.9"
 }
 }
 ]
 },
 {
 "given": " Stefan Th.",
 "family": "Gries",
 "affiliation": [
 {
 "original_name": "University of California, Santa Barbara, CA, USA",
 "normalized_name": "California Coast University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05t99sp05",
 "GRID": "grid.468726.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2010-01-08",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp039",
 "identifier": {
 "string_id": "10.1093/llc/fqp039",
 "id_scheme": "DOI"
 },
 "abstract": "Although vast amounts of authentic materials are now available online to help language learners build up vocabulary and language skills in many languages, the consumer is almost ‘spoiled for choice’, and often at a loss where to begin. This article aims to provide an overall menu of language- learning and teaching websites, to help both students and teachers select more useful Computer-Assisted Language Learning (CALL) sites and programs, showing how to combine them into an effective online reading and vocabulary learning program for either classroom- or self-access. It will help both kinds of users to be able to better filter through the rivers of online data, to find and focus on what we will refer to as the ‘CALL or ESL/EFL gold’, meaning websites most content- and media-rich for English as a Second/Foreign Language teaching or learning. Though our discussion will be in English mostly about using these sites to improve English learning, many of the sites included in this framework can be used for learning as many as 140 major languages of the world. While most language learners are still using more traditional classrooms and textbooks, CALL-based instruction is growing rapidly. The practical problem for both teachers and students who have such resources, however, is to find some practical tool to plow through the plethora of online data, useful in helping schools to make a sensible CALL system to help students learn language and vocabulary most enjoyably and effectively. This article begins to suggest how to construct such an integrated CALL program, including many well-designed sites that combine the advantages of using authentic materials with online tools to help simplify them and provide various kinds of language learning support that can aid both students and teachers. Ten established research-based goals for L2 reading are integrated into a proposed framework for using online reading programs in a way that follows a clear ‘Taxonomy of Vocabulary Development (Deeper Lexical Processing)’.",
 "article_title": "Constructing a roadmap to more systematic and successful online reading and vocabulary acquisition",
 "authors": [
 {
 "given": " John Paul",
 "family": "Loucky",
 "affiliation": [
 {
 "original_name": "Seinan JoGakuin University, Fukuokaken, Japan",
 "normalized_name": "Seinan Gakuin University",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/03jqhsn85",
 "GRID": "grid.443473.3"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-12-13",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp040",
 "identifier": {
 "string_id": "10.1093/llc/fqp040",
 "id_scheme": "DOI"
 },
 "abstract": "Twenty-eight items in the British Magazine have been attributed to Goldsmith, the majority in Essays and Criticisms by Dr. Goldsmith (1798). The strength of the external evidence depends on the authority of that collection; it is shakier than its editor claimed. Internal evidence comes from a Goldsmith ‘profile’ of stylistic features, established by reference to contemporary essayists, from measures of sentence-length, distinctive features of the attributed essays, and parallels of word and thought. We conclude that most of the attributed essays, including those proposed since 1798, are unlikely to be Goldsmith's.",
 "article_title": "Goldsmith and the 'British Magazine': A reconsideration",
 "authors": [
 {
 "given": " Peter",
 "family": "Dixon",
 "affiliation": [
 {
 "original_name": "Queen Mary and Westfield College, University of London, UK",
 "normalized_name": "University of London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04cw6st05",
 "GRID": "grid.4464.2"
 }
 }
 ]
 },
 {
 "given": " David",
 "family": "Mannion",
 "affiliation": [
 {
 "original_name": "Royal Holloway, University of London, UK",
 "normalized_name": "University of London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04cw6st05",
 "GRID": "grid.4464.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-11-30",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp038",
 "identifier": {
 "string_id": "10.1093/llc/fqp038",
 "id_scheme": "DOI"
 },
 "abstract": "The Coruña Corpus (CC): a Collection of Samples for the Historical Study of English Scientific Writing is a project on which the MUSTE group has been working since 2003 in the University of A Coruña (Spain). It has been designed as a tool for the study of language change in English scientific writing in general as well as within the different scientific disciplines (excluding medicine) between 1650 and 1900. Its purpose is to facilitate investigation at all linguistic levels, although, in principle, phonology is not included among our intended research topics. At the same time, we believe that the CC is an excellent tool for the study of scientific register/style at particular moments in history: it also offers the researcher the chance to analyse how this ‘specific English’ behaves from a synchronic point of view. To allow for socio-linguistic research using these scientific texts, we have included, when possible, some personal details about the author of each sample and, even, about the work from which the sample has been extracted in a separate file. From a technical point of view, all the texts have been keyed in following the Text Encoding Initiative conventions and saved in the XML format. The use of an extended mark-up language will make wide distribution and exploitation possible. Moreover, in order to retrieve information from the compiled data, we have decided to create a corpus management tool. Loosely speaking, the Coruña Corpus Tool is an Information Retrieval system, where the indexed textual repository is a set of compiled documents that constitutes the CC.",
 "article_title": "CETA in the Context of the Coruna Corpus",
 "authors": [
 {
 "given": " Begoña",
 "family": "Crespo García",
 "affiliation": [
 {
 "original_name": "Department de Filoloxía Inglesa, Universidade da Coruña, A Coruña, Spain",
 "normalized_name": "University of A Coruña",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01qckj285",
 "GRID": "grid.8073.c"
 }
 }
 ]
 },
 {
 "given": " Isabel",
 "family": "Moskowich-Spiegel Fandiño",
 "affiliation": [
 {
 "original_name": "Department de Filoloxía Inglesa, Universidade da Coruña, A Coruña, Spain",
 "normalized_name": "University of A Coruña",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01qckj285",
 "GRID": "grid.8073.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-11-20",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp036",
 "identifier": {
 "string_id": "10.1093/llc/fqp036",
 "id_scheme": "DOI"
 },
 "abstract": "This article provides quantitative evidence for a hypothesis concerning fourth-century translations of Indian Buddhist texts from Prakrit and Sanskrit into Chinese. Using a Variable Length n-Gram Feature Extraction Algorithm, principal component analysis and average linkage clustering we are able to show that 24 sutras, attributed by the tradition to different translators, were in fact translated by the same translator or group of translators. Since part of our method is based on assigning weight to n-grams, the analysis is capable of yielding distinctive features, i.e. strings of Chinese characters, that are characteristic of the translator(s). This is the first time that these techniques have successfully been applied to medieval Chinese texts. The results of this study open up a number of new directions for the lexicographic and syntactic study of early Chinese translations of Buddhist texts.",
 "article_title": "Quantitative evidence for a hypothesis regarding the attribution of early Buddhist translations",
 "authors": [
 {
 "given": " Jen-Jou",
 "family": "Hung",
 "affiliation": [
 {
 "original_name": "Library and Information Center, Dharma Drum Buddhist College, Taiwan, ROC",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Marcus",
 "family": "Bingenheimer",
 "affiliation": [
 {
 "original_name": "Library and Information Center, Dharma Drum Buddhist College, Taiwan, ROC",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Simon",
 "family": "Wiles",
 "affiliation": [
 {
 "original_name": "Library and Information Center, Dharma Drum Buddhist College, Taiwan, ROC",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-11-17",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp033",
 "identifier": {
 "string_id": "10.1093/llc/fqp033",
 "id_scheme": "DOI"
 },
 "abstract": "The authors have worked over several years on a software tool to make word counts from an archive of old-spelling early modern English plays and poems. In this article we present the outcome, a computational model for dealing automatically with variant spelling, implemented in an application which we call an ‘Intelligent Archive’. We also reflect on the perspective on Early Modern English, and on the probabilistic aspect of language in general, gained from working through the practical problems which arose in establishing the model.",
 "article_title": "Old spellings, new methods: automated procedures for indeterminate linguistic data",
 "authors": [
 {
 "given": " Hugh",
 "family": "Craig",
 "affiliation": [
 {
 "original_name": "Centre for Literary and Linguistic Computing, School of Humanities and Social Science, The University of Newcastle, Australia",
 "normalized_name": "University of Newcastle Australia",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00eae9z71",
 "GRID": "grid.266842.c"
 }
 }
 ]
 },
 {
 "given": " R.",
 "family": "Whipp",
 "affiliation": [
 {
 "original_name": "Centre for Literary and Linguistic Computing, School of Humanities and Social Science, The University of Newcastle, Australia",
 "normalized_name": "University of Newcastle Australia",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00eae9z71",
 "GRID": "grid.266842.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-10-13",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp034",
 "identifier": {
 "string_id": "10.1093/llc/fqp034",
 "id_scheme": "DOI"
 },
 "abstract": "The article examines how the etymological composition of the Sanskrit lexicon is influenced by time and whether this composition can be used to date Sanskrit texts automatically. For this purpose, statistical tests are applied to a corpus of lexically analyzed texts. Results reported in the article may contribute to the diachronic lexicography of Sanskrit and help to develop computational methods for analyzing anonymous and undated Sanskrit texts.",
 "article_title": "Etymological trends in the Sanskrit vocabulary",
 "authors": [
 {
 "given": " Oliver",
 "family": "Hellwig",
 "affiliation": [
 {
 "original_name": "Südasien-Institut, Universität Heidelberg, Germany",
 "normalized_name": "Heidelberg University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/038t36y30",
 "GRID": "grid.7700.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-10-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp035",
 "identifier": {
 "string_id": "10.1093/llc/fqp035",
 "id_scheme": "DOI"
 },
 "abstract": "Using statistically derived keywords to characterize texts has become an important research method for digital humanists and corpus linguists in areas such as literary analysis and the exploration of genre difference. Keywords—and the associated concepts of ‘keyness’ and ‘key-keyness’—have inspired conferences and workshops, many and varied research papers, and are central to several modern corpus processing tools. In this article, we present evidence that (at least for the task of biographical sentence classification) frequent words characterize texts better than keywords or key-keywords. Using the naïve Bayes learning algorithm in conjunction with frequency-, keyword-, and key-keyword-based text representation to classify a corpus of biographical sentences, we discovered that the use of frequent words alone provided a classification accuracy better than either the keyword or key-keyword representations at a statistically significant level. This result suggests that (for the biographical sentence classification task at least) frequent words characterize texts better than keywords derived using more computationally intensive methods.",
 "article_title": "Mining a corpus of biographical texts using keywords",
 "authors": [
 {
 "given": " Mike",
 "family": "Conway",
 "affiliation": [
 {
 "original_name": "National Institute of Informatics, Japan",
 "normalized_name": "National Institute of Informatics",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/04ksd4g47",
 "GRID": "grid.250343.3"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-10-07",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp032",
 "identifier": {
 "string_id": "10.1093/llc/fqp032",
 "id_scheme": "DOI"
 },
 "abstract": "There has been dramatic growth in information communication technologies (ICT) infrastructure for the arts and humanities research community in recent years in the UK and elsewhere. No domain-wide survey of how researchers are using ICT and what they perceive their future needs to be has been undertaken previously and consequently what is needed in terms of a generic ICT infrastructure to support arts and humanities research is not well understood. The RePAH (Research Portals for the Arts and Humanities) Project is an AHRC funded study into the user needs for information portals to support research in the Arts and Humanities. It uses a combination of questionnaires, focus groups and Delphi opinion gathering, combined with server log-analysis data, to identify users’ information discovery strategies, Internet usage patterns, awareness and attitudes towards current services and technologies and responses to what future portal developments can deliver. Responsibility for funding this kind of infrastructure is split between a number of different agencies. This makes sector-wide information gathering for strategic planning and development difficult. The results of this study may help providers to understand where the priorities lie for the arts and humanities research community and help users to appreciate some of the possibilities within their grasp.",
 "article_title": "Research portals in the arts and humanities",
 "authors": [
 {
 "given": " Stephen",
 "family": "Brown",
 "affiliation": [
 {
 "original_name": "Knowledge Media Design, De Montfort University, The Gateway, Leicester LE1 9BH, UK",
 "normalized_name": "De Montfort University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0312pnr83",
 "GRID": "grid.48815.30"
 }
 }
 ]
 },
 {
 "given": " Mark",
 "family": "Greengrass",
 "affiliation": [
 {
 "original_name": "Humanities Research Institute, Sheffield University, 34 Gell Street, Sheffield S3 7QY, UK",
 "normalized_name": "University of Sheffield",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05krs5044",
 "GRID": "grid.11835.3e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-10-06",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp031",
 "identifier": {
 "string_id": "10.1093/llc/fqp031",
 "id_scheme": "DOI"
 },
 "abstract": "Linguists studying grammar often describe their models using a syntax tree. Drawing a syntax tree involves the depiction of a rooted tree with additional syntactic features using specific domain conventions. TreeForm assists users in developing syntax trees, complete with movement lines, coreference, and feature association, in order to explore their syntactic theories and explain them to their colleagues. It is a drag-and-drop alternative to LaTeX and labelled bracket notation tools already available, which many linguists find difficult to use. We compare the output of TreeForm to those existing tools and show that it is able to better respect the conventions of the domain. We assess how easily linguists learn to use TreeForm through a series of cognitive walkthroughs. Our reviews find that TreeForm is a viable alternative to existing tools.",
 "article_title": "TreeForm: Explaining and exploring grammar through syntax trees",
 "authors": [
 {
 "given": " Donald",
 "family": "Derrick",
 "affiliation": [
 {
 "original_name": "University of British Columbia, Vancouver, Canada",
 "normalized_name": "University of British Columbia",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/03rmrcq20",
 "GRID": "grid.17091.3e"
 }
 }
 ]
 },
 {
 "given": " Daniel",
 "family": "Archambault",
 "affiliation": [
 {
 "original_name": "INRIA Bordeaux Sud-Ouest, France",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-10-02",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp030",
 "identifier": {
 "string_id": "10.1093/llc/fqp030",
 "id_scheme": "DOI"
 },
 "abstract": "Part I of this series, [doi:10.1093/llc/fqp029], applied our ‘new-optics’ methodology to the ‘Shakespeare’ scenes in STMO and concluded that it had too much Shakespeare discrepancy to fit comfortably into the Canon. We considered it an improbable, but not impossible Shakespeare ascription for the 1600s and placed it for now in the High Apocrypha. We thought it extremely improbable that the whole of STMO could be by Shakespeare, or that the ‘Shakespeare’ parts could have been written in the 1590s. Part II, published here, addresses the ‘Shakespeare’ scenes of Edward III. Taken separately, four of the five ‘Shakespeare’ blocks of Edw3 fall inside our Shakespeare ballpark. So does a sixth block, scenes 4.05–4.09. If we followed the consensus strictly, all five Shakespeare blocks, taken as a group, would not make a probable solo Shakespeare ascription. However, if we switched 4.04 to ‘non-Shakespeare,’ and 4.05–4.09 to ‘Shakespeare,’ the revised Shakespeare blocks would be a plausible Shakespeare ascription even as a group, justifying the inclusion of Edw3 in the Canon as partly Shakespeare's: 1.02; 2.01–2.02; and 4.05–4.09. The odds that the ‘non-Shakespeare’ scenes, collectively, or individually (except for 4.05–4.09) could be his are vanishingly low. The full article may be found online at http://www.claremontmckenna.edu/facultysites/govt/ FacMember/welliott/UTConference/2ToughNuts.pdf",
 "article_title": "Two tough nuts to crack: did Shakespeare write the 'Shakespeare' portions of Sir Thomas More and Edward III? Part II: Conclusion",
 "authors": [
 {
 "given": " Ward E. Y.",
 "family": "Elliott",
 "affiliation": [
 {
 "original_name": "Claremont McKenna College, Claremont, California, USA",
 "normalized_name": "Claremont McKenna College",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/04n1me355",
 "GRID": "grid.254272.4"
 }
 }
 ]
 },
 {
 "given": " Robert J.",
 "family": "Valenza",
 "affiliation": [
 {
 "original_name": "Claremont McKenna College, Claremont, California, USA",
 "normalized_name": "Claremont McKenna College",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/04n1me355",
 "GRID": "grid.254272.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-08-14",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "25",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp026",
 "identifier": {
 "string_id": "10.1093/llc/fqp026",
 "id_scheme": "DOI"
 },
 "abstract": "The work of the Shakespeare Clinic of Claremont McKenna College, led by Ward E.Y. Elliott and Robert J. Valenza, is recognized for its pioneering computer analysis of many early modern texts to determine whether William Shakespeare (1564–1616) wrote the works traditionally ascribed to him. The Clinic achieved its primary objective of eliminating all other known candidates and thus confirming that Shakespeare wrote them. Two general methods of analysis were applied to whole plays and variable-sized large texts: Discrete Composite Analysis and Continuous Composite Analysis.. The first uses univariate analysis to determine acceptance or rejection of forty-eight stylometric tests for each text. The second uses a multi-dimensional composite mean for Shakespeare derived from all forty-eight in order to determine acceptance or rejection for each text. This article notes the omission of Discrete Analysis to take into consideration statistical dependencies between the forty-eight tests, the partly arbitrary ‘handfitting’ of acceptance–rejection boundaries for each of the forty-eight tests, the failure to take into full account the factor of chronology, and the absence of discussion of the part played by prior probabilities as to existing beliefs concerning attribution. By this last point, I mean the role played by the existing traditional consensus as to Shakespeare attribution, prior to linguistic analysis. For Continuous Analysis, it is noted that the stated probabilities are not true probabilities as acknowledged, and that the resulting acceptance–rejection levels for them are calibrated in line with prior beliefs. Principal component analysis is shown to give improved results in dealing with co-authored Shakespeare plays, Henry VIII, Timon of Athens, and Pericles. This does not invalidate the overall aim of the Shakespeare Clinic.",
 "article_title": "Untangling the derivatives: points for clarification in the findings of the Shakespeare Clinic",
 "authors": [
 {
 "given": "T.",
 "family": "Merriam",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-07-20",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp025",
 "identifier": {
 "string_id": "10.1093/llc/fqp025",
 "id_scheme": "DOI"
 },
 "abstract": "Bilingual dictionaries are vital resources in many areas of natural language processing. Numerous methods of machine translation require bilingual dictionaries of large coverage, but less-frequent language pairs rarely have any digitalized resources of such kind. Since the need for these resources is increasing, but the human resources are scarce for less represented languages, efficient automatized methods are imperative. This article presents a fully automated, robust intermediate language-based bilingual dictionary generation method that uses the WordNet of the intermediate language to build a new bilingual dictionary. We propose the usage of WordNet in order to increase accuracy; we also introduce a bidirectional selection method with a flexible threshold to maximize recall. The evaluations showed 79% accuracy and 51% weighted recall, outperforming representative pivot language-based methods. A dictionary generated with this method will still need manual post-editing, but the improved recall and precision decrease the work of human correctors.",
 "article_title": "Dictionary generation for less-frequent language pairs using WordNet",
 "authors": [
 {
 "given": " István",
 "family": "Varga",
 "affiliation": [
 {
 "original_name": "Graduate School of Science and Engineering, Yamagata University, Yonezawa, Japan",
 "normalized_name": "Yamagata University",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/00xy44n04",
 "GRID": "grid.268394.2"
 }
 }
 ]
 },
 {
 "given": " Shoichi",
 "family": "Yokoyama",
 "affiliation": [
 {
 "original_name": "Graduate School of Science and Engineering, Yamagata University, Yonezawa, Japan",
 "normalized_name": "Yamagata University",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/00xy44n04",
 "GRID": "grid.268394.2"
 }
 }
 ]
 },
 {
 "given": " Chikara",
 "family": "Hashimoto",
 "affiliation": [
 {
 "original_name": "National Institute of Information and Communications Technology, Kyoto, Japan",
 "normalized_name": "National Institute of Information and Communications Technology",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/016bgq349",
 "GRID": "grid.28312.3a"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-07-16",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp027",
 "identifier": {
 "string_id": "10.1093/llc/fqp027",
 "id_scheme": "DOI"
 },
 "abstract": "The dangers of computational approaches to authorship attribution in the absence of an adequate set of training texts for the claimant authors are well known. This study aims to show, however, that significant progress can be made even where conditions are quite problematic. We investigate a difficult authorship question involving three texts, ostensibly by three authors, each of whom wrote nothing else. Only one of the texts can be unquestionably ascribed to a known author, and this author has been suggested as the true author of one of the two remaining texts. We investigate these three texts, along with similar texts by other authors, using cluster analysis, Delta analysis, t-testing, and PCA. We also create simulations of our authorship problem using sets of three texts of known authorship by one, two, and three authors. We test these sets using correct and incorrect assumptions of authorial difference, and then compare the results with analyses of our three texts based on the same range of assumptions. By combining information from all of these tests, we achieve what we believe is a persuasive, if not conclusive, solution to a significant and long-standing question concerning the authorship of Maria Warda's violently anti-Mormon Female Life Among the Mormons. At the same time, we demonstrate methods for making progress in cases where conditions are less than ideal.",
 "article_title": "An exercise in non-ideal authorship attribution: the mysterious Maria Ward",
 "authors": [
 {
 "given": " David L.",
 "family": "Hoover",
 "affiliation": [
 {
 "original_name": "Department of English, New York University, UK",
 "normalized_name": "New York University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0190ak572",
 "GRID": "grid.137628.9"
 }
 }
 ]
 },
 {
 "given": " Shervin",
 "family": "Hess",
 "affiliation": [
 {
 "original_name": "Department of English, New York University, UK",
 "normalized_name": "New York University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0190ak572",
 "GRID": "grid.137628.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-07-14",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp024",
 "identifier": {
 "string_id": "10.1093/llc/fqp024",
 "id_scheme": "DOI"
 },
 "abstract": "This article shows that the TEI tag set for feature structures can be adopted to represent a heterogeneous set of linguistic corpora. The majority of corpora is annotated using markup languages that are based on the Annotation Graph framework, the upcoming Linguistic Annotation Format ISO standard, or according to tag sets defined by or based upon the TEI guidelines. A unified representation comprises the separation of conceptually different annotation layers contained in the original corpus data (e.g. syntax, phonology, and semantics) into multiple XML files. These annotation layers are linked to each other implicitly by the identical textual content of all files. A suitable data structure for the representation of these annotations is a multi-rooted tree that again can be represented by the TEI and ISO tag set for feature structures. The mapping process and representational issues are discussed as well as the advantages and drawbacks associated with the use of the TEI tag set for feature structures as a storage and exchange format for linguistically annotated data.",
 "article_title": "SusTEInability of linguistic resources through feature structures",
 "authors": [
 {
 "given": " Andreas",
 "family": "Witt",
 "affiliation": [
 {
 "original_name": "Institut für Deutsche Sprache, Mannheim, Germany",
 "normalized_name": "Institute for the German Language",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/00hvwkt50",
 "GRID": "grid.443960.c"
 }
 }
 ]
 },
 {
 "given": "Georg",
 "family": "Rehm",
 "affiliation": [
 {
 "original_name": "vionto GmbH, Berlin, Germany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Erhard",
 "family": "Hinrichs",
 "affiliation": [
 {
 "original_name": "Tübingen University, General and Computational Linguistics, Germany",
 "normalized_name": "University of Tübingen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/03a1kwz48",
 "GRID": "grid.10392.39"
 }
 }
 ]
 },
 {
 "given": " Timm",
 "family": "Lehmberg",
 "affiliation": [
 {
 "original_name": "Hamburg University, SFB Multilingualism, Germany",
 "normalized_name": "Universität Hamburg",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/00g30e956",
 "GRID": "grid.9026.d"
 }
 }
 ]
 },
 {
 "given": " Jens",
 "family": "Stegmann",
 "affiliation": [
 {
 "original_name": "Bielefeld University, Faculty of Linguistics and Literary Studies, Germany",
 "normalized_name": "Bielefeld University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/02hpadn98",
 "GRID": "grid.7491.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-06-12",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp019",
 "identifier": {
 "string_id": "10.1093/llc/fqp019",
 "id_scheme": "DOI"
 },
 "abstract": "This article reports on the details behind a poster presented a the Text Encoding Initiative (TEI) Members' Meeting at the University of Maryland, College Park, in November 2007. It looks at the creation of of af scholarly electronic edition of a late-medieval play, The Conversion of Saint Paul from Bodleian MS Digby 133 using TEI P5 XML. In addition to exploring various new features available in the TEI P5 Guidelines, it also examines the methodology used to create the text, up-scaling from purely presentation markup to descriptive markup, and how this might simplify the creation of such editions. In an attempt to create an interoperable, flexible, and agile edition, it stores anything not directly related to the transcription of the text in separate files in a stand-off manner. In an attempt to experiment with creating a resource which leverages the advantages of networked editions, it documents the attempt to interoperate with the Middle English Dictionary. Although this first appears to be a failure, it highlights some of the inherent problems in attempting to build editions that are dependent on the resources of others. The article concludes with an urge to text encoders to make more of an effort to share examples of, both good and bad, community practice.",
 "article_title": "Converting Saint Paul: A new TEI P5 edition of The Conversion of Saint Paul using stand-off methodology",
 "authors": [
 {
 "given": " James",
 "family": "Cummings",
 "affiliation": [
 {
 "original_name": "Oxford University Computing Services, University of Oxford, UK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-06-06",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp020",
 "identifier": {
 "string_id": "10.1093/llc/fqp020",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents the results of the work on kundige bok, one of Göttingen's town records, containing late medieval town law. Due to the fact that this law was frequently subject to change, the text itself was revised over and over again, giving evidence for its frequent use and its dynamic nature. What has come to us, is, thus, a multi-layered text in which all layers represent a different (e.g. chronological) stage of the town law. Consequently they have to be regarded, processed and represented equally. A dynamic text like this requires a dynamic representation. The article shows how an electronic scholarly edition of a multi-layered text can be created and used, first, to reconstruct the genesis of the text; second, to make this evolution understandable, processable and visible; and third, with the text as a witness to display the development of urban law and urban life in the Late Middle Ages.This article: outlines the challenge of editing a multi-layered medieval manuscript;discusses why this leads to a new understanding of a critical edition of such a text; andintroduces the techniques used to create the electronic edition of kundige bok, in particular highlighting the linkage between the two dimensions of ‘text’and ‘time’ based on the TEI P5 scheme.",
 "article_title": "Reconstructing the textual evolution of a medieval manuscript",
 "authors": [
 {
 "given": " Malte",
 "family": "Rehbein",
 "affiliation": [
 {
 "original_name": "Moore Institute, National University of Ireland, Galway, Ireland",
 "normalized_name": "National University of Ireland",
 "country": "Ireland",
 "identifiers": {
 "ror": "https://ror.org/00shsf120",
 "GRID": "grid.9344.a"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-06-04",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp017",
 "identifier": {
 "string_id": "10.1093/llc/fqp017",
 "id_scheme": "DOI"
 },
 "abstract": "The TEI Consortium has taken on the task of maintaining the Guidelines for Electronic Text Encoding and Interchange. This article describes how the latest major revision to these Guidelines was developed over the course of >6 years by the members of the TEI Technical Council and workgroups charged and overseen by the Council and gives background information and reasoning for the decisions taken. Among the new additions for P5, two of the most outstanding, the chapters on Names, Dates, People, and Places and on digital facsimiles are treated in some more detail. The article concludes with a brief account of the decisions made with respect to customization and conformance.",
 "article_title": "The making of TEI P5",
 "authors": [
 {
 "given": " Christian",
 "family": "Wittern",
 "affiliation": [
 {
 "original_name": "Kyoto University, Kyoto, Japan",
 "normalized_name": "Kyoto University",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/02kpeqv85",
 "GRID": "grid.258799.8"
 }
 }
 ]
 },
 {
 "given": " Arianna",
 "family": "Ciula",
 "affiliation": [
 {
 "original_name": "King's College, London, UK",
 "normalized_name": "Bansomdejchaopraya Rajabhat University",
 "country": "Thailand",
 "identifiers": {
 "ror": "https://ror.org/03e0h3d81",
 "GRID": "grid.443695.9"
 }
 }
 ]
 },
 {
 "given": " Conal",
 "family": "Tuohy",
 "affiliation": [
 {
 "original_name": "New Zealand Electronic Text Centre, Wellington, New Zealand",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-05-30",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp007",
 "identifier": {
 "string_id": "10.1093/llc/fqp007",
 "id_scheme": "DOI"
 },
 "abstract": "The Henry III Fine Rolls project is a collaborative project between the National Archives in the UK, the departments of History and the Centre for Computing in the Humanities at King's College London, and the department of History and American Studies at Canterbury Christ Church University. Its aim is to produce a digital and print edition of the Fine Rolls from the reign of the 13th-century English King Henry III (1216–72). At the core of the resource are the translated summaries of the fine rolls which have been encoded in TEI XML, complemented by an overarching RDF/OWL conceptual model and digital facsimiles. In this article, we reflect on the ontological complexities of a dual publication, by bringing together various theoretical frameworks. Our aim is to take inspiration from these theories and connect them to the experience of producing two objects of different materiality but of very close scope. Ultimately, we will also explain how some of these reflections have been used to design a study for evaluating the utility of this edition.",
 "article_title": "Reflecting on a dual publication: Henry III Fine Rolls print and web",
 "authors": [
 {
 "given": " Arianna",
 "family": "Ciula",
 "affiliation": [
 {
 "original_name": "Centre for Computing in the Humanities, King's College London, London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 },
 {
 "given": " Tamara",
 "family": "Lopez",
 "affiliation": [
 {
 "original_name": "Centre for Computing in the Humanities, King's College London, London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-05-21",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp023",
 "identifier": {
 "string_id": "10.1093/llc/fqp023",
 "id_scheme": "DOI"
 },
 "abstract": "Translation, adaptation, and other forms of appropriation of literary works can result in bodies of parallel texts. For the purpose of studying appropriation strategies, it is important to be able to annotate digital representations of these parallel text structures. This article uses early modern emblem culture (books of engravings or woodcuts, accompanied by mottos and explanatory texts) to investigate the forms this text parallelism may take. It defines requirements for annotation definition and proposes a TEI (Text Encoding Initiative) extension to implement these requirements. In the proposed encoding scheme, TEI feature structures will be used for storing annotation information. This scheme should be useful for annotating parallel text structures as well as for other annotation tasks. The annotation scheme assumes the annotated texts are available in XML. If this is not the case (there is no electronic version of the text at all or perhaps only a facsimile) the article suggests the definition of a TEI proxy document. A TEI proxy document contains enough of the structural aspects of the texts to serve as a basis for attaching annotations to the text. Outside of the annotation context, proxy documents may serve as a basis for adding functionality to image-based editions.",
 "article_title": "Towards a TEI-based encoding scheme for the annotation of parallel texts",
 "authors": [
 {
 "given": " Peter",
 "family": "Boot",
 "affiliation": [
 {
 "original_name": "Huygens Institute, Royal Netherlands Academy of Arts and Sciences, The Hague, The Netherlands",
 "normalized_name": "Royal Netherlands Academy of Arts and Sciences",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/043c0p156",
 "GRID": "grid.418101.d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-05-19",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp022",
 "identifier": {
 "string_id": "10.1093/llc/fqp022",
 "id_scheme": "DOI"
 },
 "abstract": "This article addresses the need for TEI display tools. In order to illustrate the need for display tools, we begin with a brief review of the tools that are currently available, summarizing in particular those listed on the TEI Wiki Tools page. We then turn to a discussion of our work on the development of the TEIViewer (http://teiviewer.org), a simple, JavaScript-driven, portable display tool designed to facilitate the online representation of and interaction with elements and attributes described within select modules of the TEI P5 Guidelines and encoded as layers of data and metadata in TEI-XML documents. We explain how the TEIViewer works by describing the interactions between the XML source layer, the display layer generated via XSL, and the interactive layer powered by jQuery and CSS; and we explain why we chose the jQuery JavaScript library to manage the Viewer's functionality as well as the advantages of this decision. Finally we describe current implementations and plans for release.",
 "article_title": "The TEIViewer: Facilitating the transition from XML to web display",
 "authors": [
 {
 "given": " Stephanie A.",
 "family": "Schlitz",
 "affiliation": [
 {
 "original_name": "Web Projects and Applications, Penn State University, University Park, PA, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Garrick S.",
 "family": "Bodine",
 "affiliation": [
 {
 "original_name": "Department of English, Bloomsburg University of Pennsylvania, Bloomsburg, PA, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-05-15",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp016",
 "identifier": {
 "string_id": "10.1093/llc/fqp016",
 "id_scheme": "DOI"
 },
 "abstract": "This article describes the life cycle of a TEI Document within TextGrid, an eHumanities platform for scholarly text processing, in which structured search is based on the TEI framework and metadata with restricted values. A workbench is provided that offers tools for handling TEI documents, TextGridLab, making it easier to annotate, process, search, and persistently store new digitized texts. The digitization and annotation of the Campe dictionary1 serves as a first test bed. The overall framework of TextGrid is very generic and can handle different types of text (literary editions, linguistic corpora, lexica) as well as heterogeneous data formats (plain text, XML/TEI, images). In fact, the TextGrid repository, TextGridRep, is designed as a digital virtual library over federated archives, where humanities projects are invited to participate. Sharing of data is enabled by means of a grid-based architecture. Specifically the middleware includes most of the treatment of authorization, search, and file management. TextGrid is entirely based on open source software including Eclipse2 and Globus Toolkit.",
 "article_title": "TEI documents in the grid",
 "authors": [
 {
 "given": " Andrea",
 "family": "Zielinski",
 "affiliation": [
 {
 "original_name": "Institut für Deutsche Sprache Mannheim, Germany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Wolfgang",
 "family": "Pempe",
 "affiliation": [
 {
 "original_name": "Saphor GmbH, Germany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Peter",
 "family": "Gietz",
 "affiliation": [
 {
 "original_name": "DAASI International GmbH, Germany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Martin",
 "family": "Haase",
 "affiliation": [
 {
 "original_name": "Institut für Deutsche Sprache Mannheim, Germany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-05-15",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp021",
 "identifier": {
 "string_id": "10.1093/llc/fqp021",
 "id_scheme": "DOI"
 },
 "abstract": "This article investigates the issues to be faced while producing a digital edition of a representative medieval text: Statuta Comunis Vicentie (1264). Statuta comunis are collections of civic rules very common in Northern Italy since the twelfth century. We are dealing specifically with the ones of Vicenza, a town near Venice. Statuta were usually organized in a single or multiple codices, including the collection of the civic rules, matched and allotted in big chapters (libri) according to the subject. Another fundamental characteristic is the constant review of the original text in different periods, generally due to changes in the government or in the organization of the city. Therefore, the most relevant matters to deal with are: first, description of metadata; second, structural analysis of the text; third, the markup of the additions and amendments; and fourth; identification of specific semantic values, in particular personal names, organizational names and names of places. This article outlines the reasons for choosing XML/TEI for the project, how to address the four matters listed above and how the chosen standard can be customized to treat the peculiar aspects of this text according to the traditional editing practice.",
 "article_title": "The digital edition of the Statuta comunis Vicentie of 1264",
 "authors": [
 {
 "given": " Luigi",
 "family": "Siciliano",
 "affiliation": [
 {
 "original_name": "Dipartimento di Studi Storici e Geografici, Università degli Studi di Firenze, Florence, Italy",
 "normalized_name": "University of Florence",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/04jr1s763",
 "GRID": "grid.8404.8"
 }
 }
 ]
 },
 {
 "given": " Viviana",
 "family": "Salardi",
 "affiliation": [
 {
 "original_name": "Dipartimento di Discipline Storico Artistiche, Archeologiche e Geografiche, Università degli Studi di Verona, Verona, Italy",
 "normalized_name": "University of Verona",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/039bp8j42",
 "GRID": "grid.5611.3"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-05-15",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp015",
 "identifier": {
 "string_id": "10.1093/llc/fqp015",
 "id_scheme": "DOI"
 },
 "abstract": "Text Encoding Initiative (TEI) is an organization, a research community, and a markup language. Looking back into the history of these three TEIs, this article tries to describe what has been achieved and what its future challenges will be. The historical analysis is based on a closer look at the development of the TEI-L and topics covered by the Guidelines. A final section outlines possible roles of the TEI as an infrastructure for digital libraries and disciplinary virtual environments.",
 "article_title": "TEI in a crystal ball",
 "authors": [
 {
 "given": " Fotis",
 "family": "Jannidis",
 "affiliation": [
 {
 "original_name": "Institut für Deutsche Philologie, Universität Würzburg, Würzburg, Germany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-05-15",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp018",
 "identifier": {
 "string_id": "10.1093/llc/fqp018",
 "id_scheme": "DOI"
 },
 "abstract": "The Text Encoding Initiative (TEI)1 has provided a complex and comprehensive system of provisions for scholarly text encoding. Although a major focus of the ‘digital humanities’ domain, and despite much teaching effort by the TEI community, there is a lack of teaching materials available, which would encourage the adoption of the TEI's recommendations and the widespread use of its text encoding guidelines in the wider academic community. This article describes the background, plans, and aims of the TEI by Example project, and why we believe it is a necessary addition to the materials currently provided by the TEI itself. The teaching materials currently available are not suited to the needs of self directed learners, and the development of stand alone, online tutorials in the TEI are an essential addition to the extant resources, in order to encourage and facilitate the uptake of TEI by both individuals and institutions.",
 "article_title": "Teaching TEI: The Need for TEI by Example",
 "authors": [
 {
 "given": " Melissa",
 "family": "Terras",
 "affiliation": [
 {
 "original_name": "Department of Information Studies, University College London, London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Ron",
 "family": "Van den Branden",
 "affiliation": [
 {
 "original_name": "Centre for Scholarly Editing and Document Studies, Royal Academy of Dutch Language and Literature, Gent, Belgium",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Edward",
 "family": "Vanhoutte",
 "affiliation": [
 {
 "original_name": "Centre for Scholarly Editing and Document Studies, Royal Academy of Dutch Language and Literature, Gent, Belgium",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-05-13",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp006",
 "identifier": {
 "string_id": "10.1093/llc/fqp006",
 "id_scheme": "DOI"
 },
 "abstract": "This article describes work undertaken by the VERA project to investigate how archaeologists work with information technology (IT) on excavation sites. We used a diary study to research the usual patterns of behaviour of archaeologists digging the Silchester Roman town site during the summer of 2007. Although recording had previously been undertaken using pen and paper, during the 2007 season a part of the dig was dedicated to trials of IT and archaeologists used digital pens and paper and Nokia N800 handheld PDAs to record their work. The goal of the trial was to see whether it was possible to record data from the dig whilst still on site, rather than waiting until after the excavation to enter it into the Integrated Archaeological Database (IADB) and to determine whether the archaeologists found the new technology helpful. The digital pens were a success, however, the N800s were not successful given the extreme conditions on site. Our findings confirmed that it was important that technology should fit in well with the work being undertaken rather than being used for its own sake, and should respect established work flows. We also found that the quality of data being entered was a recurrent concern as was the reliability of the infrastructure and equipment.",
 "article_title": "iTrench: A study of user reactions to the use of information technology in field archaeology",
 "authors": [
 {
 "given": " Claire",
 "family": "Warwick",
 "affiliation": [
 {
 "original_name": "Department of Information Studies, University College London, London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Claire",
 "family": "Fisher",
 "affiliation": [
 {
 "original_name": "Department of Information Studies, University College London, London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Melissa",
 "family": "Terras",
 "affiliation": [
 {
 "original_name": "Department of Information Studies, University College London, London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Mark",
 "family": "Baker",
 "affiliation": [
 {
 "original_name": "Department of Archaeology and School of Systems Engineering, University of Reading, Reading, UK",
 "normalized_name": "University of Reading",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05v62cm79",
 "GRID": "grid.9435.b"
 }
 }
 ]
 },
 {
 "given": " Amanda",
 "family": "Clarke",
 "affiliation": [
 {
 "original_name": "Department of Archaeology and School of Systems Engineering, University of Reading, Reading, UK",
 "normalized_name": "University of Reading",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05v62cm79",
 "GRID": "grid.9435.b"
 }
 }
 ]
 },
 {
 "given": " Mike",
 "family": "Fulford",
 "affiliation": [
 {
 "original_name": "Department of Archaeology and School of Systems Engineering, University of Reading, Reading, UK",
 "normalized_name": "University of Reading",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05v62cm79",
 "GRID": "grid.9435.b"
 }
 }
 ]
 },
 {
 "given": " Matt",
 "family": "Grove",
 "affiliation": [
 {
 "original_name": "Department of Archaeology and School of Systems Engineering, University of Reading, Reading, UK",
 "normalized_name": "University of Reading",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05v62cm79",
 "GRID": "grid.9435.b"
 }
 }
 ]
 },
 {
 "given": " Emma",
 "family": "O'Riordan",
 "affiliation": [
 {
 "original_name": "Department of Archaeology and School of Systems Engineering, University of Reading, Reading, UK",
 "normalized_name": "University of Reading",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05v62cm79",
 "GRID": "grid.9435.b"
 }
 }
 ]
 },
 {
 "given": " Mike",
 "family": "Rains",
 "affiliation": [
 {
 "original_name": "York Archaeological Trust, York, UK",
 "normalized_name": "York Archaeological Trust",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01hg95g34",
 "GRID": "grid.439177.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-05-05",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp012",
 "identifier": {
 "string_id": "10.1093/llc/fqp012",
 "id_scheme": "DOI"
 },
 "abstract": "As libraries increasingly undertake digitization projects, it behooves us to consider the collection/capture, organization, preservation, and dissemination of all forms of documentation, including and beyond written text. While several libraries have funded projects which acknowledge the need to digitize other forms of text, few have extended the digital projects to include film, much less performed texts. Further, as more performing arts incorporate born-digital elements, use digital tools to create media-rich performance experiences, and look to the possibility for digital preservation of the performance text, the capture of the performance event and its born-digital artefacts must be considered. This article, then, presents a first look at the ARTeFACT project, undertaken at the University of Virginia Library in collaboration with an introductory course in Engineering and a student choreographer at Brenau University Women's College. Historical intersections of technology and dance are introduced, theoretical concerns of using technology in dance are considered, the processes involved in the creation, capture, and preservation of dance data are discussed along with the technologies used to produce an interactive dance performance.",
 "article_title": "Performance as digital text: Capturing signals and secret messages in a media-rich experience",
 "authors": [
 {
 "given": " Jama S.",
 "family": "Coartney",
 "affiliation": [
 {
 "original_name": "Digital Media Laboratory, University of Virginia, Charlottesville, VA, USA",
 "normalized_name": "University of Virginia",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0153tk833",
 "GRID": "grid.27755.32"
 }
 }
 ]
 },
 {
 "given": " Susan L.",
 "family": "Wiesner",
 "affiliation": [
 {
 "original_name": "University Libraries, University of North Carolina, Greensboro, NC, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-05-05",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp010",
 "identifier": {
 "string_id": "10.1093/llc/fqp010",
 "id_scheme": "DOI"
 },
 "abstract": "The content in information systems and virtual reconstructions in the cultural heritage sector is to a large degree directly based on information deduced from the study of texts. In many cases, even if the texts are available electronically, the links from the deduced facts to the original texts are not available and in many cases very costly to re-establish. Reproducibility of results is a core concept in text-based research as in all research. Thus, such links should be expressed explicitly in the systems and in accordance with the data standards developed in the fields of text encoding and conceptual modelling. To do this it is necessary to create a combined understanding of text encoding represented by the TEI guidelines and the understanding of conceptual models represented by initiatives like the CIDOC CRM and FRBRoo. In this article, we study a part of this complex by comparing the expressive power of the real world descriptions TEI P5 by mapping central parts of the CIDOC CRM onto TEI P5. It is clear that the TEI P5 has moved a great step in the direction towards an event-oriented model compared with TEI P4. Our use of CIDOC CRM as a yardstick shows that the expressiveness of TEI P5 can be greatly improved by extending the scope of very restricted elements like the relation element and adding a few new elements to the TEI.",
 "article_title": "TEI and cultural heritage ontologies: Exchange of information?",
 "authors": [
 {
 "given": " Christian-Emil",
 "family": "Ore",
 "affiliation": [
 {
 "original_name": "ILN/EDD, University of Oslo, PO Box 1123, Blindern, NO-0317 Oslo, Norway",
 "normalized_name": "University of Oslo",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/01xtthb56",
 "GRID": "grid.5510.1"
 }
 }
 ]
 },
 {
 "given": " Øyvind",
 "family": "Eide",
 "affiliation": [
 {
 "original_name": "ILN/EDD, University of Oslo, PO Box 1123, Blindern, NO-0317 Oslo, Norway",
 "normalized_name": "University of Oslo",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/01xtthb56",
 "GRID": "grid.5510.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-05-05",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp008",
 "identifier": {
 "string_id": "10.1093/llc/fqp008",
 "id_scheme": "DOI"
 },
 "abstract": "Annotated Facsimile Edition (AFED) is a high-level model for representing macro-level structure in digital facsimiles. AFED models a facsimile as a set of images with multiple orderings or collations. The structure of these collations are encoded by ‘annotations’ that define a range of images in the collation and describe the properties of the content object identified by the annotations (for example, chapter, paragraph, page, poem). Separate annotation streams encode multiple analytical perspectives, for example, the physical structure of the edition (volumes, pages, and lines) and the poetic structure (poems, titles, epigraphs, and stanzas). Annotations within a single analytical perspective—but not those from different perspectives—follow a hierarchical structure. We discuss our initial results in implementing AFED and using it to deploy a reading interface for AJAX enabled rich-client Web applications. The primary contribution of our work is a general-purpose model for representing digital facsimiles that focuses on the major conceptual structures present among the contents of documents drawn from a wide range of sources. AFED provides a highly flexible model that can serve as a substrate for developing tools designed to support visual document editing during the exploratory stages of scholarly research.",
 "article_title": "Annotated Facsimile Editions: Defining macro-level structure for image-based electronic editions",
 "authors": [
 {
 "given": " Neal",
 "family": "Audenaert",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, Texas A&M University, College Station, TX 77843, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Richard",
 "family": "Furuta",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, Texas A&M University, College Station, TX 77843, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-04-27",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp005",
 "identifier": {
 "string_id": "10.1093/llc/fqp005",
 "id_scheme": "DOI"
 },
 "abstract": "For the purposes of large-scale analysis of XML/SGML files, converting humanities texts into a common form of markup represents a technical challenge. The MONK (Metadata Offer New Knowledge) Project has developed both a common format, TEI Analytics (a TEI subset designed to facilitate interoperability of text archives) and a command-line tool, Abbot, that performs the conversion. Abbot relies upon a new technique, schema harvesting, developed by the author to convert text documents into TEI-A. This article has two aims: first, to describe the TEI-A format itself and, second, to outline the methods used to convert files. More generally, it is hoped that the techniques described will lead to greater interoperability of text documents for text analysis in a wider context.",
 "article_title": "TEI Analytics: converting documents into a TEI format for cross-collection text analysis",
 "authors": [
 {
 "given": " Brian L.",
 "family": "Pytlik Zillig",
 "affiliation": [
 {
 "original_name": "Center for Digital Research in the Humanities, University of Nebraska, Lincoln, NE, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-04-15",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp009",
 "identifier": {
 "string_id": "10.1093/llc/fqp009",
 "id_scheme": "DOI"
 },
 "abstract": "Given that the nature of research work involves computers and a variety of skills and expertise, Digital Humanities researchers are working collaboratively within their institutions and with others nationally and internationallly to undertake the research. This work typically involves the need to coordinate efforts between academics, undergraduate and graduate students, research assistants, computer programmers, librarians, and other individuals as well as the need to manage financial and other resources. Despite this use of collaboration, there has been little formal research on team development within this community. This article reports on a research project exploring the nature of Digital Humanities research teams. Drawing upon interviews with members of the community, a series of exemplary patterns and models of research collaboration are identified and outlined. Important themes include a definition of team which focuses on common tasks and outcomes as well as a need for responsibility and accountability to the team as a whole; elements of a successful team which include clear task definition and productive working relationships over the life of the project and beyond, a need for balance between digital and face-to-face communication and collaboration tools, and potential for more deliberate training in collaboration and team work. The article concludes with recommendations for the individual team members, project leaders, and teams.",
 "article_title": "'It's a team if you use \"reply all\" ': An exploration of research teams in digital humanities environments",
 "authors": [
 {
 "given": " Lynne",
 "family": "Siemens",
 "affiliation": [
 {
 "original_name": "Faculty of Business/School of Public Administration, University of Victoria, Victoria, BC Canada",
 "normalized_name": "University of Victoria",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04s5mat29",
 "GRID": "grid.143640.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-04-14",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn035",
 "identifier": {
 "string_id": "10.1093/llc/fqn035",
 "id_scheme": "DOI"
 },
 "abstract": "While letters and correspondence materials serve as (in)valuable sources of information for historians, philologists, (socio-)linguists, biographers, and textual critics, modern editorial theory merely assigns them a secondary role. Contrary to this traditional documentary view, the authors of this article argue for a treatment of epistolary materials as primary sources in their own right. They propose a generalized text-base approach of encoded and annotated correspondence materials that can accomodate the generation of versatile user-driven electronic editions. This approach needs to address current lacunae in markup theory and practice, resulting in a lack for either provisions for the encoding of letter-specific phenomena in texts, or encoding features for such generative editions. A closer look at broader editorial theories reveals a deeper lack of understanding of the nature and hence definition of correspondence materials. The authors propose a Jakobsonian communicative definition of letters that to a great deal can be mapped onto the textual model of the Text Encoding Initiative (TEI). The second part of this article discusses the motivation for and practical realization of Digital Archive of Letters in Flanders (DALF), a formal framework for encoding correspondence materials which is defined as a TEI customization. Its most important features for capturing detailed metadata as well as letter-specific source phenomena are analysed and discussed against the text-ontological background sketched out before.",
 "article_title": "Describing, transcribing, encoding, and editing modern correspondence material: a textbase approach",
 "authors": [
 {
 "given": " Edward",
 "family": "Vanhoutte",
 "affiliation": [
 {
 "original_name": "Centre for Scholarly Editing and Document Studies, Royal Academy of Dutch Language and Literature, Belgium",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Ron Van",
 "family": "den Branden",
 "affiliation": [
 {
 "original_name": "Centre for Scholarly Editing and Document Studies, Royal Academy of Dutch Language and Literature, Belgium",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-04-13",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn033",
 "identifier": {
 "string_id": "10.1093/llc/fqn033",
 "id_scheme": "DOI"
 },
 "abstract": "Digital modes of editing ask us to re-examine the past century of editorial theory and to situate emerging editorial approaches within this history. Using the computer as a new textual medium has brought about a renewed interest in the conditions for representation. This article concerns itself with how books and computers, respectively, represent texts, and how critical editing mediates or organizes those representations. It was written in 1997 as a critical response to J.J. McGann's essay ‘The Rationale of Hypertext’.",
 "article_title": "Material text, immaterial text, and the electronic environment",
 "authors": [
 {
 "given": " Kathryn",
 "family": "Sutherland",
 "affiliation": [
 {
 "original_name": "St Anne's College, University of Oxford, UK",
 "normalized_name": "University of Oxford",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/052gg0110",
 "GRID": "grid.4991.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-04-13",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn038",
 "identifier": {
 "string_id": "10.1093/llc/fqn038",
 "id_scheme": "DOI"
 },
 "abstract": "Digital editions have some distinct features that are not present in digital libraries. Therefore it is somewhat worrisome that there are far more digital libraries than digital editions. This essay argues that the reason for this is not only a pressure towards all-inclusiveness but also the fact that scholarly editions are addressing both scholars and common readers, each of them having their own expectations of what a digital edition should actually offer. The essay suggests that we should get away from the idea of access to data as the principal merit of the edition and suggests a model of criticism instead, meaning that editors should represent their work as providing critical points of view on the texts they are offering, with their actual contents thrown in.",
 "article_title": "Access",
 "authors": [
 {
 "given": " John",
 "family": "Lavagnino",
 "affiliation": [
 {
 "original_name": "King's College London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-04-13",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn030",
 "identifier": {
 "string_id": "10.1093/llc/fqn030",
 "id_scheme": "DOI"
 },
 "abstract": "This article attempts to ask some fundamental questions about editing in the digital age, and give some answers to these questions. It is argued that a concentration on digital methods, for themselves, may neglect the base questions facing any editor: why is the editor making this edition; from whom is the editor making this edition? Indeed, in some respects thinking about text encoding for digital purposes has been built on assumptions which are, for editors, simply wrong. In particular, the concept of what ‘text’ is, upon which (for instance) the Text Encoding Initiative principles are based (what Renear calls ‘realist’), is positivist, overconfident, simplistic and neglects the materiality of actual text instances. This view is opposed by what Renear calls ‘anti-realism’: texts do not have an independent existence, but are constructed by individual and collective acts of perception. In concrete terms, ‘anti-realism’ sees editions as made to serve the needs of the reader, as acts of interpretation and not as representations of some concrete reality: this is Pichler's view of the Wittgenstein transcripts, and the author's views of the Canterbury Tales project transcripts. However, it is argued that both realist and anti-realist extremes are dangerous: ‘realism’ can lead to editions which are arrogant and out-of-touch; anti-realism to editions which are reductionist and etiolated. In place of either extreme, we should substitute a different aim: to challenge readers to make new texts for themselves as they read, by finding new ways of presenting material so that both we editors and those who use our editions become better readers.",
 "article_title": "What text really is not, and why editors have to learn to swim",
 "authors": [
 {
 "given": " Peter",
 "family": "Robinson",
 "affiliation": [
 {
 "original_name": "Institute for Textual Scholarship and Electronic Editing, University of Birmingham, UK",
 "normalized_name": "University of Birmingham",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/03angcq70",
 "GRID": "grid.6572.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-04-13",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn039",
 "identifier": {
 "string_id": "10.1093/llc/fqn039",
 "id_scheme": "DOI"
 },
 "abstract": "This article revisits the question of the intellectual adequacy of the print critical edition. Contemporary theory and current digital practice have encouraged editors and users of editions to dismiss various aspects of the print critical edition–particularly the reading text and the critical apparatus–as artifacts of an obsolete technology. Using database theory, the author shows how many of these basic elements in fact represent the most intellectually efficient possible way of organizing information about texts and the readings of their underlying witnesses. By recognizing the inherent sophistication of the classical model, digital editors can improve of print practice by exploiting features of the new medium that make it easier to present such data in interactive ways.",
 "article_title": "Back to the future: what digital editors can learn from print editorial practice",
 "authors": [
 {
 "given": " Daniel Paul",
 "family": "O’Donnell",
 "affiliation": [
 {
 "original_name": "Department of English, University of Lethbridge, Canada",
 "normalized_name": "University of Lethbridge",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/044j76961",
 "GRID": "grid.47609.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-04-13",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp003",
 "identifier": {
 "string_id": "10.1093/llc/fqp003",
 "id_scheme": "DOI"
 },
 "abstract": "We report on finished work in a project that is concerned with providing methods, tools, best practice guidelines, and solutions for sustainable linguistic resources. The article discusses several general aspects of sustainability and introduces an approach to normalizing corpus data and metadata records. Moreover, the architecture of the sustainability platform implemented by the authors is described.",
 "article_title": "Sustainability of annotated resources in linguistics: A web-platform for exploring, querying, and distributing linguistic corpora and other resources",
 "authors": [
 {
 "given": " Georg",
 "family": "Rehm",
 "affiliation": [
 {
 "original_name": "vionto GmbH, Berlin, Germany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Oliver",
 "family": "Schonefeld",
 "affiliation": [
 {
 "original_name": "German National Library of Medicine (ZB MED), Cologne, Germany",
 "normalized_name": "Deutsche Nationalbibliothek",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/01n7gem85",
 "GRID": "grid.424174.0"
 }
 }
 ]
 },
 {
 "given": " Andreas",
 "family": "Witt",
 "affiliation": [
 {
 "original_name": "Institute for the German Language (IDS), Mannheim, Germany",
 "normalized_name": "Institute for the German Language",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/00hvwkt50",
 "GRID": "grid.443960.c"
 }
 }
 ]
 },
 {
 "given": " Erhard",
 "family": "Hinrichs",
 "affiliation": [
 {
 "original_name": "General and Computational Linguistics, Tübingen University, Tübingen, Germany",
 "normalized_name": "University of Tübingen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/03a1kwz48",
 "GRID": "grid.10392.39"
 }
 }
 ]
 },
 {
 "given": " Marga",
 "family": "Reis",
 "affiliation": [
 {
 "original_name": "Deutsches Seminar, Tübingen University, Tübingen, Germany",
 "normalized_name": "University of Tübingen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/03a1kwz48",
 "GRID": "grid.10392.39"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-03-21",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp002",
 "identifier": {
 "string_id": "10.1093/llc/fqp002",
 "id_scheme": "DOI"
 },
 "abstract": "Given a collection of imperfect copies of a textual document, the aim of stemmatology is to reconstruct the history of the text, indicating for each variant the source text from it was copied. We describe an experiment involving three artificial benchmark data sets to which a number of computer-assisted stemmatology methods were applied. Contrary to earlier similar experiments, we propose and use a numerical criterion to evaluate all the solutions. Moreover, our primary data set is significantly larger than used before. The results suggest the superiority of two computer-assisted methods amongst those tested: the maximum parsimony method implemented in the PAUP* software package and a related compression-based method we have proposed in earlier work.",
 "article_title": "Evaluating methods for computer-assisted stemmatology using artificial benchmark data sets",
 "authors": [
 {
 "given": " Teemu",
 "family": "Roos",
 "affiliation": [
 {
 "original_name": "Department of Computer Science and the National Library of Finland, University of Helsinki, Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 }
 ]
 },
 {
 "given": " Tuomas",
 "family": "Heikkilä",
 "affiliation": [
 {
 "original_name": "Department of History, University of Helsinki, Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-03-15",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqp001",
 "identifier": {
 "string_id": "10.1093/llc/fqp001",
 "id_scheme": "DOI"
 },
 "abstract": "The purpose of this article is to introduce and explore forensic philology in the context of electronic text editing. Drawing primarily on the example provided by the development of a TEI P5 conformant edition of Hafgeirs saga Flateyings, an alleged Icelandic saga forgery attested in a single, unsigned eighteenth century paper manuscript, this discussion explains how literary, linguistic, and transmission-level interpretations can be employed to describe the saga text and to bear witness to its origin and transmission process. It further explains how encoding the metadata described in these interpretations beside the data described in (near)zero-level text can be accomplished without sacrificing the role of the manuscript as artefact and without sacrificing the appearance of the text as it occurs on the page.",
 "article_title": "The TEI as luminol: Forensic philology in a digital age",
 "authors": [
 {
 "given": " Stephanie A.",
 "family": "Schlitz",
 "affiliation": [
 {
 "original_name": "Bloomsburg University, Bloomsburg, PA 17815, USA",
 "normalized_name": "Bloomsburg University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/007dga614",
 "GRID": "grid.253165.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-03-14",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn044",
 "identifier": {
 "string_id": "10.1093/llc/fqn044",
 "id_scheme": "DOI"
 },
 "abstract": "This research1 evaluates the extent to which lexical diversity, measured by frequent content words, hapax legomena, and type-token ratios (TTRs), is dependent on three features of the genre of the oral Indo-Aryan cultic poetry represented by the literary corpus of the Ṛgveda (ca. 165,000 tokens): characteristic choice of subject matter, usage of refrains, and the attribution of hymns to distinct poetic collectives. Analysis of 255 texts of 200 tokens showed that hymns on popular topics and where refrains were attested have a significantly higher rate of high-frequency content words and a lower ratio of once-occurring types. A higher TTR is observed in the hymns of specific family origin. Complexity of genre can be interpreted as a result of different discourse strategies of the poets. Overall, conservative mythological texts are characterized by regularity in word usage. Occurrence of content words, in the entire corpus, with lexemes denoting ‘deities’ on the one side and ‘nature’ on the other is accounted for by the factor of semantics, which deals with the structure of narrative.",
 "article_title": "Lexical Diversity in a Literary Genre: A Corpus Study of the Rgveda",
 "authors": [
 {
 "given": " Alexandre",
 "family": "Sotov",
 "affiliation": [
 {
 "original_name": "St. Petersburg State University",
 "normalized_name": "St Petersburg University",
 "country": "Russia",
 "identifiers": {
 "ror": "https://ror.org/023znxa73",
 "GRID": "grid.15447.33"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-01-12",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn034",
 "identifier": {
 "string_id": "10.1093/llc/fqn034",
 "id_scheme": "DOI"
 },
 "abstract": "The mutability of electronic editions confronts editors with a new world, in which large parts of current editorial theory must be re-thought, based as it often is on assumptions based on the properties of paper editions. Software can adapt more easily than paper to the needs and interests of the reader, which means many choices about the selection of information in an edition and its presentation to the reader no longer need to be fixed for all time, but can be left open for the reader. Software also tends to have a very short lifetime compared to paper; in order to remain usable for more than a few years, electronic editions must find ways of representing the essential information of the edition in software-independent, non-proprietary ways.",
 "article_title": "How to teach your edition how to swim",
 "authors": [
 {
 "given": " C. M.",
 "family": "Sperberg-McQueen",
 "affiliation": [
 {
 "original_name": "World Wide Web Consortium",
 "normalized_name": "World Wide Web Consortium",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0059y1582",
 "GRID": "grid.507688.4"
 }
 },
 {
 "original_name": "MIT Computer Science and Artificial Intelligence Laboratory, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-01-09",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn043",
 "identifier": {
 "string_id": "10.1093/llc/fqn043",
 "id_scheme": "DOI"
 },
 "abstract": "Indian alchemy, a branch of traditional Indian medicine (Āyurveda), has produced a corpus of texts that are difficult to date using regular philological techniques. This article describes a contents-based computational method that is capable of calculating the relative chronology of these texts. Central parts of alchemical literature are encoded in a language model that can be understood by a computer and then compared with an alignment algorithm. Phylogenetic trees derived from these alignments show regularities in the ordering of alchemical texts, and these may be interpreted as temporal patterns. Processing these patterns with a minimization algorithm, we are able to compute a relative chronology of the corpus, which is largely consistent with results obtained using traditional philological techniques.",
 "article_title": "A chronometric approach to Indian alchemical literature",
 "authors": [
 {
 "given": " Oliver",
 "family": "Hellwig",
 "affiliation": [
 {
 "original_name": "Institut für Sprachen und Kulturen Südasiens, Freie Universität, Berlin",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2009-01-09",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn040",
 "identifier": {
 "string_id": "10.1093/llc/fqn040",
 "id_scheme": "DOI"
 },
 "abstract": "Mormon prophet Joseph Smith (1805–44) claimed that more than two-dozen ancient individuals (Nephi, Mormon, Alma, etc.) living from around 2200 BC to 421 AD authored the Book of Mormon (1830), and that he translated their inscriptions into English. Later researchers who analyzed selections from the Book of Mormon concluded that differences between selections supported Smith's claim of multiple authorship and ancient origins. We offer a new approach that employs two classification techniques: ‘delta’ commonly used to determine probable authorship and ‘nearest shrunken centroid’ (NSC), a more generally applicable classifier. We use both methods to determine, on a chapter-by-chapter basis, the probability that each of seven potential authors wrote or contributed to the Book of Mormon. Five of the seven have known or alleged connections to the Book of Mormon, two do not, and were added as controls based on their thematic, linguistic, and historical similarity to the Book of Mormon. Our results indicate that likely nineteenth century contributors were Solomon Spalding, a writer of historical fantasies; Sidney Rigdon, an eloquent but perhaps unstable preacher; and Oliver Cowdery, a schoolteacher with editing experience. Our findings support the hypothesis that Rigdon was the main architect of the Book of Mormon and are consistent with historical evidence suggesting that he fabricated the book by adding theology to the unpublished writings of Spalding (then deceased).",
 "article_title": "Reassessing authorship of the Book of Mormon using delta and nearest shrunken centroid classification",
 "authors": [
 {
 "given": " Matthew L.",
 "family": "Jockers",
 "affiliation": [
 {
 "original_name": "Department of English, Stanford University, Stanford, CA 94305, USA",
 "normalized_name": "Stanford University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00f54p054",
 "GRID": "grid.168010.e"
 }
 }
 ]
 },
 {
 "given": " Daniela M.",
 "family": "Witten",
 "affiliation": [
 {
 "original_name": "Department of Statistics, Stanford University, Stanford, CA 94305, USA",
 "normalized_name": "Stanford University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00f54p054",
 "GRID": "grid.168010.e"
 }
 }
 ]
 },
 {
 "given": " Craig S.",
 "family": "Criddle",
 "affiliation": [
 {
 "original_name": "Department of Civil and Environmental Engineering, Stanford University, Stanford, CA 94305, USA",
 "normalized_name": "Stanford University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00f54p054",
 "GRID": "grid.168010.e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-12-07",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn031",
 "identifier": {
 "string_id": "10.1093/llc/fqn031",
 "id_scheme": "DOI"
 },
 "abstract": "The dank cellar surveys rather critically the litter of casualty electronic editions and the false bases and limited goals that informed so many early—that is, current—efforts; and it points hopefully to the best early, though still inadequate, efforts to provide electronic texts responsibly and with added scholarly value. It looks at some problems of representing Victorian fiction.",
 "article_title": "The dank cellar of electronic texts",
 "authors": [
 {
 "given": " Peter",
 "family": "Shillingsburg",
 "affiliation": [
 {
 "original_name": "Department of English, Loyola University Chicago, USA",
 "normalized_name": "Loyola University Chicago",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/04b6x2g63",
 "GRID": "grid.164971.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-12-03",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn036",
 "identifier": {
 "string_id": "10.1093/llc/fqn036",
 "id_scheme": "DOI"
 },
 "abstract": "The concept of data in the humanistic academy carries a heavy cultural freight: as a reductionist yet efficient representation of complex textual significance. Far from being an invention of the digital age, this conception of the role of quantification has a prehistory whose terms continue to resonate in modern debates about digital editing and digitally mediated scholarship. This essay explores these terms and the anxieties they reflect, concluding that digital representation is no less textually and methodologically rich, and no less a production of knowledge, than its print counterpart.",
 "article_title": "Data and Wisdom: Electronic Editing and the Quantification of Knowledge",
 "authors": [
 {
 "given": " Julia",
 "family": "Flanders",
 "affiliation": [
 {
 "original_name": "Brown University, USA",
 "normalized_name": "Brown University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05gq02987",
 "GRID": "grid.40263.33"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-11-25",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn032",
 "identifier": {
 "string_id": "10.1093/llc/fqn032",
 "id_scheme": "DOI"
 },
 "abstract": "Immersive multimedia performances, especially in the theater, installation art, and computer games, suggest to us interesting models for reconceiving the possibilities of textual editing in digital media. Traditionally, textual editions have taken different forms for different audiences of readers. Editing protocols, including the critical apparatus, are determined in part by those forms. Mostly this has meant conceiving of a given text as produced for a scholarly, classroom, or popular audience. However different these types of editions, they share familiar textual ontologies, developed primarily over the past 200 years and based on print technology. We suggest instead that editors begin thinking of digital editions primarily as ‘editorial environments’, with spatial, temporal, procedural, performative, and participatory properties. An electronic edition is always already a virtual world. A digital edition is an electronic environment. Citing as an example our experiment in the MOO with Shelley's sonnet ‘Ozymandias’, we imagine the role of the editor as textual ecologist/dramaturge/gamemaster, maximizing the resources of digital environments.",
 "article_title": "Editing Environments: The Architecture of Electronic Texts",
 "authors": [
 {
 "given": " Neil",
 "family": "Fraistat",
 "affiliation": [
 {
 "original_name": "Maryland Institute for Technology in the Humanities (MITH), University of Maryland",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Steven E.",
 "family": "Jones",
 "affiliation": [
 {
 "original_name": "Department of English, Loyola University",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-11-21",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn013",
 "identifier": {
 "string_id": "10.1093/llc/fqn013",
 "id_scheme": "DOI"
 },
 "abstract": "This paper describes preliminary sketches for a formal account of transcription as it is performed in scholarly editing and in the creation of digital resources. After a general outline of our approach, we present two formal models of transcription. The first addresses only the very simplest cases, the second addresses some but not all of the gaps in the first. Finally, we mention some less simple cases and discuss some elaborations of the model which we hope to develop in future work.",
 "article_title": "What is transcription?",
 "authors": [
 {
 "given": " Claus",
 "family": "Huitfeldt",
 "affiliation": [
 {
 "original_name": "Department of Philosophy, University of Bergen, Norway",
 "normalized_name": "University of Bergen",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/03zga2b32",
 "GRID": "grid.7914.b"
 }
 }
 ]
 },
 {
 "given": " C. M.",
 "family": "Sperberg-McQueen",
 "affiliation": [
 {
 "original_name": "World Wide Web Consortium",
 "normalized_name": "World Wide Web Consortium",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0059y1582",
 "GRID": "grid.507688.4"
 }
 },
 {
 "original_name": "MIT Computer Science and Artificial Intelligence Laboratory",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-10-23",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn022",
 "identifier": {
 "string_id": "10.1093/llc/fqn022",
 "id_scheme": "DOI"
 },
 "abstract": "We present an algorithm as evidence of the possibility of a truly automated stylometric authorship attribution tool, based on committees of artificial neural networks. Neural networks have an advantage over traditional statistical stylometry in that they are inherently nonlinear, and therefore can consider nonlinear interactions between stylometric variables. The algorithm presented (1) is intended to demonstrate the feasibility of an automated approach using neural networks and (2) highlights important areas for further research. We present results of two separate test experiments—Shakespeare and Marlowe, and the Federalist Papers—as a demonstration of the method's; generality. In both cases, our algorithm produces committees that correctly predict the test works, without requiring the usual precursory statistical study to determine efficacious stylometric measures.",
 "article_title": "An algorithm for automated authorship attribution using neural networks",
 "authors": [
 {
 "given": " Matt",
 "family": "Tearle",
 "affiliation": [
 {
 "original_name": "University of Colorado, Boulder, CO, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Kye",
 "family": "Taylor",
 "affiliation": [
 {
 "original_name": "University of Colorado, Boulder, CO, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Howard",
 "family": "Demuth",
 "affiliation": [
 {
 "original_name": "University of Colorado, Boulder, CO, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-10-22",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn014",
 "identifier": {
 "string_id": "10.1093/llc/fqn014",
 "id_scheme": "DOI"
 },
 "abstract": "Here I survey activities in the digital humanities as a primary source for our conceptualization of the field. I argue for the fundamental nature of modelling to these humanities and describe three varieties: analytical, synthetic and improvisational. I argue that these three kinds are distributed unevenly over the affected fields according to the degree to which each primarily reports on its objects of study, interprets them or invents new genres of expression. The changes in the disciplines are of course incremental—old things done better, more thoroughly and so forth. But what requires our attention and effort is the refiguration of them, of disciplinarity itself and of the conflicted economies in which academic work is increasingly taking place. I conclude by recommending that the institutional structures we build for the digital humanities should reflect the nature of the practice as it has emerged in the last few decades.",
 "article_title": "What's going on?",
 "authors": [
 {
 "given": " Willard",
 "family": "McCarty",
 "affiliation": [
 {
 "original_name": "Centre for Computing in the Humanities, King's College London, London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-10-23",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn023",
 "identifier": {
 "string_id": "10.1093/llc/fqn023",
 "id_scheme": "DOI"
 },
 "abstract": "Dante's Monarchia, a fourteenth century treatise on political theory which survives in 20 manuscripts and the editio princeps, has been studied extensively by scholars using traditional analytical methods to establish textual transmission. It was selected as a suitable tradition for a blind study to test the application of computer-based phylogenetic methods to the stemmatic analysis of manuscript relationships. Our results show that these methods—maximum parsimony, NeighborNet and the Supernetwork algorithm—are capable of producing stemmata in very close agreement with those produced by traditional stemmatic analysis, including the identification of texts that change exemplar in the course of copying. The phylogenetic methods can correctly indicate the affiliations both before and after the point of exemplar change. The maximum chi-squared method (developed to detect recombination in DNA sequences) is able to indicate the region of exemplar change, allowing the precise location to be ascertained by textual analysis.",
 "article_title": "Dante's Monarchia as a test case for the use of phylogenetic methods in stemmatic analysis",
 "authors": [
 {
 "given": " Heather F.",
 "family": "Windram",
 "affiliation": [
 {
 "original_name": "Department of Biochemistry, University of Cambridge, Cambridge, UK",
 "normalized_name": "University of Cambridge",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/013meh722",
 "GRID": "grid.5335.0"
 }
 }
 ]
 },
 {
 "given": " Prue",
 "family": "Shaw",
 "affiliation": [
 {
 "original_name": "Department of Italian, University College London, London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Peter",
 "family": "Robinson",
 "affiliation": [
 {
 "original_name": "Institute for Textual Scholarship and Electronic Editing, Graduate Institute of Theology and Religion, University of Birmingham, Birmingham, UK",
 "normalized_name": "University of Birmingham",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/03angcq70",
 "GRID": "grid.6572.6"
 }
 }
 ]
 },
 {
 "given": " Christopher J.",
 "family": "Howe",
 "affiliation": [
 {
 "original_name": "Department of Biochemistry, University of Cambridge, Cambridge, UK",
 "normalized_name": "University of Cambridge",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/013meh722",
 "GRID": "grid.5335.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-10-03",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn021",
 "identifier": {
 "string_id": "10.1093/llc/fqn021",
 "id_scheme": "DOI"
 },
 "abstract": "Pliny is a piece of software that is meant to stimulate discussion within the Digital Humanities (DH) about how tools might be built that could find greater acceptance within the wider humanities community; something that has eluded the DH to date. Unlike many other tool projects within the DH, which are meant to show new and novel ways to apply technology to transform scholarly practice, Pliny is designed to support the act of conventional scholarly interpretation. It is meant to be a tool that blends so well into the task of the development of an interpretation, as scholars actually conventionally practice it, as to be almost invisible. In this, it follows some of the H-LAM/T design principles of Douglas Englebart, some of whose principles can be seen in software such as the word processor. In this article, several of the principle elements of conventional scholarly practice are described—centred on the act of annotation, notetaking, and the using of these notes as the basis for exploring ideas that emerge from working with the objects of study. Pliny's design is then discussed in the context of how aspects of its design—its affordances—support the scholar who is working with these elements. In particular, it illustrates an approach to the modelling of notes and associated ideas at the time when they are still largely un- or only partially structured.",
 "article_title": "Thinking about interpretation: Pliny and scholarship in the humanities",
 "authors": [
 {
 "given": " John",
 "family": "Bradley",
 "affiliation": [
 {
 "original_name": "Centre for Computing in the Humanities, King's College London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-09-30",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn011",
 "identifier": {
 "string_id": "10.1093/llc/fqn011",
 "id_scheme": "DOI"
 },
 "abstract": "The new drama analysis program IDAP provided charts containing frequency distributions of speech lengths in Shakespeare's plays. Following previous investigations that showed maximum values at the length of four words for plays produced after the opening of the Globe in 1599, and nine words for plays produced before 1599, the present analysis turned to the four plays The Merry Wives of Windsor, King Henry IV, 2, Much Ado About Nothing and King Henry V which already indicate changes in style. Composite curves not only characterize the four texts as transitional plays that embody the old style expressed by a maximum of nine words, but also impending changes expressed by a maximum of four words while the transition was indicated by the maximum of six words. Statistical results thus confirm the theories of stylistic and biographical changes before 1599 that James Shapiro had put down in his work 1599: A Year in the Life Of William Shakespeare. London: Faber & Faber, 2005.",
 "article_title": "More statistical observations on speech lengths in Shakespeare's plays",
 "authors": [
 {
 "given": " Hartmut",
 "family": "Ilsemann",
 "affiliation": [
 {
 "original_name": "English Department, Leibniz University of Hannover, Germany",
 "normalized_name": "University of Hannover",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/0304hq317",
 "GRID": "grid.9122.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-09-29",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn020",
 "identifier": {
 "string_id": "10.1093/llc/fqn020",
 "id_scheme": "DOI"
 },
 "abstract": "The particular reading difficulties engendered by the complicated patterns of repetition in The Making of Americans by Gertrude Stein make it almost impossible to read this text in a traditional, linear manner. However, by visualizing certain patterns and looking at the text ‘from a distance’ through textual analytics and visualizations, we are enabled to make readings that were formerly inhibited. Initial analysis on Making within the MONK (metadata offer new knowledge) project (http://www.monkproject.org/) has yielded evidence which suggests that the text is intricately and purposefully structured. Using text mining to retrieve repetitive patterns and treating each as a single object makes it possible to visualize and compare the three dimensions upon which these repetitions co-occur—by length, frequency, and location—in a single view. Certainly, reading The Making of Americans in a traditional way appears to have yielded limited material for scholarly work, but reading the text differently, as an object of pairings or as parts of combinations, ultimately works in contrast to the supposition that the text is only meaningful to the extent that it defeats making meaning. A distant view of the text's structure allows us to read the text as an object that becomes, as it continues to turn in on itself with a centrifugal force, a whole history without beginning or ending.",
 "article_title": "'A thing not beginning and not ending': using digital tools to distant-read Gertrude Stein's The Making of Americans",
 "authors": [
 {
 "given": " Tanya E.",
 "family": "Clement",
 "affiliation": [
 {
 "original_name": "University of Maryland, College Park, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-09-17",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn019",
 "identifier": {
 "string_id": "10.1093/llc/fqn019",
 "id_scheme": "DOI"
 },
 "abstract": "As the use of data mining and machine learning methods in the humanities becomes more common, it will be increasingly important to examine implicit biases, assumptions, and limitations these methods bring with them. This article makes explicit some of the foundational assumptions of machine learning methods, and presents a series of experiments as a case study and object lesson in the potential pitfalls in the use of data mining methods for hypothesis testing in literary scholarship. The worst dangers may lie in the humanist's; ability to interpret nearly any result, projecting his or her own biases into the outcome of an experiment—perhaps all the more unwittingly due to the superficial objectivity of computational methods. We argue that in the digital humanities, the standards for the initial production of evidence should be even more rigorous than in the empirical sciences because of the subjective nature of the work that follows. Thus, we conclude with a discussion of recommended best practices for making results from data mining in the humanities domain as meaningful as possible. These include methods for keeping the the boundary between computational results and subsequent interpretation as clearly delineated as possible.",
 "article_title": "Meaning and mining: the impact of implicit assumptions in data mining for the humanities",
 "authors": [
 {
 "given": " D.",
 "family": "Sculley",
 "affiliation": [
 {
 "original_name": "Tufts University, Somerville, MA, USA",
 "normalized_name": "Tufts University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05wvpxv85",
 "GRID": "grid.429997.8"
 }
 }
 ]
 },
 {
 "given": " Bradley M.",
 "family": "Pasanek",
 "affiliation": [
 {
 "original_name": "University of Virginia, Charlottesville, VA, USA",
 "normalized_name": "University of Virginia",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0153tk833",
 "GRID": "grid.27755.32"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-09-13",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn017",
 "identifier": {
 "string_id": "10.1093/llc/fqn017",
 "id_scheme": "DOI"
 },
 "abstract": "Although many digital humanities resources are being developed for online use, there is little understanding of why some become popular, whilst others are neglected. Through log analysis techniques, the LAIRAH project identified twenty-one popular and well-used digital humanities projects, and in order to ascertain the factors they had in common, which predisposed them to be well used, conducted in-depth interviews with the creators of these resources. This article presents the findings of the study, highlighting areas that developers should be aware of, and providing a set of recommendations for both funders and creators, which should ensure that a digital humanities resource will have the best possible chance of being used in the long term.",
 "article_title": "The master builders: LAIRAH research on good practice in the construction of digital humanities projects",
 "authors": [
 {
 "given": " Claire",
 "family": "Warwick",
 "affiliation": [
 {
 "original_name": "School of Library, Archive and Information Studies, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Isabel",
 "family": "Galina",
 "affiliation": [
 {
 "original_name": "School of Library, Archive and Information Studies, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Melissa",
 "family": "Terras",
 "affiliation": [
 {
 "original_name": "School of Library, Archive and Information Studies, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Paul",
 "family": "Huntington",
 "affiliation": [
 {
 "original_name": "School of Library, Archive and Information Studies, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Nikoleta",
 "family": "Pappa",
 "affiliation": [
 {
 "original_name": "School of Library, Archive and Information Studies, University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-09-13",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn018",
 "identifier": {
 "string_id": "10.1093/llc/fqn018",
 "id_scheme": "DOI"
 },
 "abstract": "This article focuses on the use of technologies traditionally associated with knowledge representation to express complex associations between entities in historical texts that have been marked up in XML, according to the Text Encoding Initiative guidelines. In particular, we describe our exploration of the potential role of an ontology in facilitating the interpretation of implicit and hidden associations in the sources of interest, examining its use, and limits in a digital humanities project in connection with editing tools and delivery issues. We demonstrate our findings based on the Henry III Fine Rolls project, where an ontology—built using the RDF (Resource Description Framework)/OWL (Web Ontology Language) technologies—is being developed to make explicit information about person, place, and subject entities marked up as instances in the core texts themselves. For any historian, there is a natural tension between primary sources (as documentary records) and the analysis that produces a context for interpretation. We will argue that the combination of core mark-up (encoded in TEI) and an ontology (in RDF/OWL) provides a powerful model for representing the complexity of this tension and facilitates the necessarily dynamic process of scholarly interpretation.",
 "article_title": "Expressing complex associations in medieval historical documents: the Henry III Fine Rolls Project",
 "authors": [
 {
 "given": " Arianna",
 "family": "Ciula",
 "affiliation": [
 {
 "original_name": "Centre for Computing in the Humanities, King's College London, London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 },
 {
 "given": " Paul",
 "family": "Spence",
 "affiliation": [
 {
 "original_name": "Centre for Computing in the Humanities, King's College London, London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 },
 {
 "given": " José Miguel",
 "family": "Vieira",
 "affiliation": [
 {
 "original_name": "Centre for Computing in the Humanities, King's College London, London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-09-13",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn010",
 "identifier": {
 "string_id": "10.1093/llc/fqn010",
 "id_scheme": "DOI"
 },
 "abstract": "One of the first decisions made in any research concerns the selection of an appropriate scale of analysis—are we looking out into the heavens, or down into atoms? To conceive a digital library as a collection of a million books may restrict analysis to only one level of granularity. In this article, we examine the consequences and opportunities resulting from a shift in scale, where the desired unit of interpretation is something smaller than a text: it is a keyword, a motif, or a metaphor. A million books distilled into a billion meaningful components become raw material for a history of language, literature, and thought that has never before been possible. While books herded into genres and organized by period remain irregular, idiosyncratic, and meaningful in only the most shifting and context-dependent ways, keywords or metaphors are lowest common denominators. At the semantic level—the level of words, images, and metaphors—long-term regularity and patterns emerge in collection, analysis, and taxonomy. This article follows the foregoing course of thought through three stages: first, the manual curation of a high quality database of metaphors; second, the expansion of this database through automated and human-assisted techniques; finally, the description of future experiments and opportunities for the application of machine learning, data mining, and natural language processing techniques to help find patterns and meaning concealed at this important level of granularity.",
 "article_title": "Mining millions of metaphors",
 "authors": [
 {
 "given": " Brad",
 "family": "Pasanek",
 "affiliation": [
 {
 "original_name": "University of Virginia, Charlottesville, USA",
 "normalized_name": "University of Virginia",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0153tk833",
 "GRID": "grid.27755.32"
 }
 }
 ]
 },
 {
 "given": " D.",
 "family": "Sculley",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, Tufts University, Medford, USA",
 "normalized_name": "Tufts University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05wvpxv85",
 "GRID": "grid.429997.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-09-06",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn016",
 "identifier": {
 "string_id": "10.1093/llc/fqn016",
 "id_scheme": "DOI"
 },
 "abstract": "Thought processes are enhanced when ways are found to link external perception with internal mental processes by the use of graphic aids. Such aids range from scribbled diagrams to sophisticated linkages between thought, images, and text such as those employed by Leonardo da Vinci. These tools allow visual perception to be harnessed in the dynamic processes associated with the creation or discovery of new knowledge. Digital humanists are applying digital versions of these age-old tools in many areas of research, from the graphs generated by text analysis applications to virtual reality models of ancient buildings, methods known collectively as ‘digital visualization’. This article begins with a brief review of the current application of visualization in the digital humanities before moving on to establish a context for digital visualization within ‘traditional’ humanities scholarship. This provides a context for an examination of what is required in order to ensure that digital visualization work is performed with identifiable intellectual rigour. The London Charter is used as a case study for a possible framework for the development of appropriate methods and standards. Digital visualization as a scholarly methodology is discussed and demonstrated as being part of a continuum of established academic practice rather than something that is in some way new, ‘revolutionary’, or lacking in rigorous scholarly value.",
 "article_title": "Digital visualization as a scholarly activity",
 "authors": [
 {
 "given": " Martyn",
 "family": "Jessop",
 "affiliation": [
 {
 "original_name": "Centre for Computing in the Humanities, King's College London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-09-06",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn012",
 "identifier": {
 "string_id": "10.1093/llc/fqn012",
 "id_scheme": "DOI"
 },
 "abstract": "The use of corpora that are divided into temporally ordered stages is becoming increasingly wide-spread in historical corpus linguistics. This development is partly due to the fact that more and more resources of this kind are being developed. Since the assessment of frequency changes over multiple periods of time is a relatively recent practice, there are few agreed-upon standards of how such trends should be statistically interpreted. This article addresses the need for a basic analytical toolbox that is specifically tailored to the interpretation of frequency changes in multistage diachronic corpora. We present a number of suggestions for the analysis of data that analysts commonly face in historical studies, but also in the study of language acquisition.",
 "article_title": "Assessing frequency changes in multistage diachronic corpora: Applications for historical corpus linguistics and the study of language acquisition",
 "authors": [
 {
 "given": " Martin",
 "family": "Hilpert",
 "affiliation": [
 {
 "original_name": "Freiburg Institute for Advanced Studies (FRIAS), Freiburg, Germany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Stefan Th.",
 "family": "Gries",
 "affiliation": [
 {
 "original_name": "University of California, Santa Barbara, USA",
 "normalized_name": "California Coast University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05t99sp05",
 "GRID": "grid.468726.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-09-02",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "24",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn015",
 "identifier": {
 "string_id": "10.1093/llc/fqn015",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents an empirical evaluation of text classification methods in literary domain. This study compared the performance of two popular algorithms, naïve Bayes and support vector machines (SVMs) in two literary text classification tasks: the eroticism classification of Dickinson's poems and the sentimentalism classification of chapters in early American novels. The algorithms were also combined with three text pre-processing tools, namely stemming, stopword removal, and statistical feature selection, to study the impact of these tools on the classifiers’ performance in the literary setting. Existing studies outside the literary domain indicated that SVMs are generally better than naïve Bayes classifiers. However, in this study SVMs were not all winners. Both algorithms achieved high accuracy in sentimental chapter classification, but the naïve Bayes classifier outperformed the SVM classifier in erotic poem classification. Self-feature selection helped both algorithms improve their performance in both tasks. However, the two algorithms selected relevant features in different frequency ranges, and therefore captured different characteristics of the target classes. The evaluation results in this study also suggest that arbitrary feature-reduction steps such as stemming and stopword removal should be taken very carefully. Some stopwords were highly discriminative features for Dickinson's erotic poem classification. In sentimental chapter classification, stemming undermined subsequent feature selection by aggressively conflating and neutralizing discriminative features.",
 "article_title": "An evaluation of text classification methods for literary study",
 "authors": [
 {
 "given": " Bei",
 "family": "Yu",
 "affiliation": [
 {
 "original_name": "Graduate School of Library and Information Science, University of Illinois at Urbana-Champaign, USA",
 "normalized_name": "University of Illinois at Urbana-Champaign",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047426m28",
 "GRID": "grid.35403.31"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-09-02",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn005",
 "identifier": {
 "string_id": "10.1093/llc/fqn005",
 "id_scheme": "DOI"
 },
 "abstract": "Princeton—Stanford Working Papers in Classics (PSWPC) is a web-based series of work-in-progress scripts by members of two leading departments of classics. It introduces the humanities to a new form of scholarly communication and represents a major advance in the free availability of classical-studies scholarship in cyberspace. This article both reviews the initial performance of this open-access experiment and the benefits and challenges of working papers more generally for classical studies. After 2 years of operation PSWPC has proven to be a clear success. This series has built up a large international readership and a sizeable body of pre-prints and performs important scholarly and community-outreach functions. As this performance is largely due to its congruency with the working arrangements of ancient historians and classicists and the global demand for open-access scholarship, the series confirms the viability of this means of scholarly communication, and the likelihood of its expansion in our discipline. But modifications are required to increase the benefits this series brings and the amount of scholarship it makes freely available online. Finally, departments wishing to replicate its success will have to consider other important developments, such as the increasing availability of post-prints, the linking of research funding to open access, and the emergence of new cyber-infrastructure.",
 "article_title": "Working Papers, Open Access, and Cyber-infrastructure in Classical Studies",
 "authors": [
 {
 "given": "D.",
 "family": "Pritchard",
 "affiliation": [
 {
 "original_name": "Department of Classics and Ancient History, School of Philosophical and Historical Inquiry, The University of Sydney, Australia",
 "normalized_name": "University of Sydney",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/0384j8v12",
 "GRID": "grid.1013.3"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-03-28",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn004",
 "identifier": {
 "string_id": "10.1093/llc/fqn004",
 "id_scheme": "DOI"
 },
 "abstract": "Today's corpus tools offer the user a wide range of features that greatly facilitate the linguistic analysis of large amounts of authentic language data (e.g. frequency distributions, collocations, keywords, etc.). However, these tools typically fail to address the fundamental need of the linguist to add interpretive information to a concordance or query result, by coding individual concordance lines for structural, functional, discoursal, and other features in a flexible way. The ability to add such qualitative data is indispensable to a fuller understanding of the phenomenon under investigation as it allows the linguist to produce more rigorous descriptions—and theories—about language in use. Our article has two aims: first, to assess the merits and drawbacks of existing solutions, by surveying what can be achieved using state-of-the-art corpus tools and generic database software; second, we draw up a set of desiderata and recommendations for the incorporation of flexible encoding features into future corpus tools. We describe an initial step in this direction, with a recent enhancement to the BNCweb corpus analysis software. More generally, we hope our suggestions will lead to linguists and software developers working together more closely to ensure that the needs of the former are provided for by the available technology.",
 "article_title": "Corpus Tools and Methods, Today and Tomorrow: Incorporating Linguists' Manual Annotations",
 "authors": [
 {
 "given": "N.",
 "family": "Smith",
 "affiliation": [
 {
 "original_name": "School of English, Sociology, Politics & Contemporary History, University of Salford, Manchester, UK",
 "normalized_name": "University of Salford",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01tmqtf75",
 "GRID": "grid.8752.8"
 }
 }
 ]
 },
 {
 "given": "S.",
 "family": "Hoffmann",
 "affiliation": [
 {
 "original_name": "Department of Linguistics & English Language, Lancaster University, Lancaster, UK",
 "normalized_name": "Lancaster University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04f2nsd36",
 "GRID": "grid.9835.7"
 }
 }
 ]
 },
 {
 "given": "P.",
 "family": "Rayson",
 "affiliation": [
 {
 "original_name": "Department of Computing, Lancaster University, Lancaster, UK",
 "normalized_name": "Lancaster University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04f2nsd36",
 "GRID": "grid.9835.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-03-18",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqn003",
 "identifier": {
 "string_id": "10.1093/llc/fqn003",
 "id_scheme": "DOI"
 },
 "abstract": "While Burrows's intuitive and elegant ‘Delta’ measure for authorship attribution has proven to be extremely useful for authorship attribution, a theoretical understanding of its operation has remained somewhat obscure. In this article, I address this issue by introducing a geometric interpretation of Delta, which further allows us to interpret Delta as a probabilistic ranking principle. This interpretation gives us a better understanding of the method's fundamental assumptions and potential limitations, as well as leading to several well-founded variations and extensions.",
 "article_title": "Interpreting Burrows's Delta: Geometric and Probabilistic Foundations",
 "authors": [
 {
 "given": " Shlomo",
 "family": "Argamon",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, Illinois Institute of Technology, Chicago",
 "normalized_name": "Illinois Institute of Technology",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/037t3ry66",
 "GRID": "grid.62813.3e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-03-02",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm042",
 "identifier": {
 "string_id": "10.1093/llc/fqm042",
 "id_scheme": "DOI"
 },
 "abstract": "The emerging discipline of ‘digital humanities’ has been plagued by a perceived neglect on the part of the broader humanities community. The community as a whole tends not to be aware of the tools developed by DH practitioners (as documented by the recent surveys by Siemens et al.), and tends not to take seriously many of the results of scholarship obtained by DH methods and tools. This article argues for a focus on deliverable results in the form of useful solutions to common problems that humanities scholars share, instead of simply new representations. The question to address is what needs the humanities community has that can be dealt with using DH tools and techniques, or equivalently what incentive humanists have to take up and to use new methods. This can be treated in some respects like the computational quest for the ‘killer application’—a need of the user group that can be filled, and by filling it, create an acceptance of that tool and the supporting methods/results. Some definitions and examples are provided both to illustrate the idea and to support why this is necessary. The apparent alternative is the status quo, where digital research tools are brilliantly developed, only to languish in neglect and disuse.",
 "article_title": "Killer Applications in Digital Humanities",
 "authors": [
 {
 "given": " Patrick",
 "family": "Juola",
 "affiliation": [
 {
 "original_name": "Duquesne University, Pittsburgh, PA 15282, USA",
 "normalized_name": "Duquesne University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/02336z538",
 "GRID": "grid.255272.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-02-14",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm048",
 "identifier": {
 "string_id": "10.1093/llc/fqm048",
 "id_scheme": "DOI"
 },
 "abstract": "The DATABASE OF ELECTRONIC TEXTS of the LEXICON OF BAVARIAN DIALECTS IN AUSTRIA (WBÖ) (TEXTKORPUS zum WBÖ)—The Lexicon of Bavarian Dialects in Austria (Wörterbuch der bairischen Mundarten in Österrreich [WBÖ]) is based on a collection of about 4 million single records. They represent the variety of the regional, social and historical Bavarian dialects. About 10% of all entries are excerpts from texts of various types. The lexicographer has to draw the illustrative quotations from the original texts. The digitized full-texts have been dated and localized, thus each quotation can be placed in time and area enabling the lexicogapher to choose a representative number of examples. For the definitions, the most appropriate and illustrative quotations have to be found, in order to actively support the lexicographer's work, the Institute of Lexicography of Austrian Dialects and Names / Institut für Österreichische Dialekt- und Namenlexika (http://www.oeaw.ac.at/dinamlex) started a new project: the so-called DBÖ (Database of the Bavarian Dialects in Austria / Datenbank der bairischen Mundarten in Österreich), financed by the Österreichische Akademie der Wissenschaften / Austrian Academy of Sciences. One main database includes the so-called Hauptkatalog, the main archive; there are additional databases which are necessary to retrieve correct information about the questionnaire, the localization of the word and the date of its recording. One component of the DBÖ is the database of electronic texts of the WBÖ, including some 90 Austrian texts spanning several centuries, representing the Austrian dialects. The original texts are scanned using the Austrian OCR-programme proLector V1.20 (A.1) which allows the training of various fonts. The machine-readable texts are converted in TUSTEP (Tübinger System von Textverarbeitungs-Programmen / Tübingen System of Text Processing Programmes). The TUSTEP-files get an alphanumeric key, which allows one to retrieve each quotation from the database in a chronological order and to sort it according to its localization. Finally the texts are broken down into the requisite sized pieces for quoting in the WBÖ-entries. Using a special programme the quotations can easily be reconnected and replaced in the proper context from which they were drawn. The digital texts are a valuable source for the lexicographer freeing him from the monotony of checking over and over again, thus leaving him more time for his proper work, namely the writing of entries for the WBÖ. Furthermore, the digital texts are important for speeding up the dictionary's publication in accordance with the guidelines of the Straffungskonzept 1993 and 1998.",
 "article_title": "Zitate per Mausklick? Das Textkorpus zum WORTERBUCH DER BAIRISCHEN MUNDARTEN IN OSTERREICH (WBO) als leistungsstarkes Werkzeug fur die lexikographische Praxis",
 "authors": [
 {
 "given": " Eveline",
 "family": "Wandl-Vogt",
 "affiliation": [
 {
 "original_name": "Institut für Österreichische Dialekt- und Namenlexika, Österreichische Akademie der Wissenschaften, Wohllebengasse 12-14/2, A-1040 Wien, Österreich",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-02-13",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm038",
 "identifier": {
 "string_id": "10.1093/llc/fqm038",
 "id_scheme": "DOI"
 },
 "abstract": "The Corpus of Electronic Texts (CELT) project at University College Cork is an on-line corpus of multilingual texts that are encoded in TEI conformant SGML/XML. As of September 2006, the corpus has 9.3 million words online. Over the last five years, doctoral work carried out at the project has focused on the development of lexicographical resources spanning the years c. AD 700–1700, and on the development of tools to integrate the corpus with these resources. This research has been further complimented by the Linking Dictionaries and Text project, a North–South Ireland collaboration between the University of Ulster, Coleraine, and University College Cork. The Linking Dictionaries and Text project will reach completion in October 2006. This article focuses on CELT's latest research project, the Digital Dinneen project, that aims to create an integrated edition of Patrick S. Dinneen's Foclóir Gaedhilge agus Béarla (Irish-English Dictionary). In this article, the newly developed research infrastructure—that is the culmination of the doctoral research carried out at CELT and the Linking Dictionaries and Text collaboration—will be described, and ways that the Digital Dinneen will be integrated into this infrastructure established. Finally, avenues of future research will be pointed to.",
 "article_title": "Developing Integrated Editions of Minority Language Dictionaries: The Irish Example",
 "authors": [
 {
 "given": " Julianne",
 "family": "Nyhan",
 "affiliation": [
 {
 "original_name": "Corpus of Electronic Texts, University College Cork, Ireland",
 "normalized_name": "University College Cork",
 "country": "Ireland",
 "identifiers": {
 "ror": "https://ror.org/03265fv13",
 "GRID": "grid.7872.a"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2008-02-03",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm037",
 "identifier": {
 "string_id": "10.1093/llc/fqm037",
 "id_scheme": "DOI"
 },
 "abstract": "The First International Conference of the Alliance of Digital Humanities Organizations (ADHO) was special in many ways, not least because it was the first time that the Association for Computers and the Humanities (ACH) and the Association for Literary and Linguistic Computing (ALLC) convened their joint conference under this new name. Held at the Université Paris-Sorbonne, Digital Humanities 2006 (to give it its shorter title) was organized by Liliane Gallet-Blanchard, Marie-Madeleine Martinet and other members of Cultures Anglophones et Technologies de l’Information (CATI). There were 214 participants from twenty-four countries. One hundred and twenty papers and sessions and thirty-one posters were presented.",
 "article_title": "Digital Humanities 2006: When Two Became Many",
 "authors": [
 {
 "given": " Dawn",
 "family": "Archer",
 "affiliation": [
 {
 "original_name": "Department of Humanities, University of Central Lancashire",
 "normalized_name": "University of Central Lancashire",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/010jbqd54",
 "GRID": "grid.7943.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-12-16",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm039",
 "identifier": {
 "string_id": "10.1093/llc/fqm039",
 "id_scheme": "DOI"
 },
 "abstract": "As digital libraries have expanded to absorb existing collections as well as to create new ones, it has become clear that cross collection discovery is not simply desirable, but is increasingly a necessity demanded by users. Similarly, in the digital humanities community, thematic research collections once distinct from one another now would seem to benefit from interoperability. However, efforts to aggregate disparate resources are often stymied by differing metadata schema and controlled vocabulary. Using the lessons learned from the Thomas MacGreevy Archive, The University of Maryland Libraries designed its digital repository to provide for discovery across object types and collections using Fedora as the underlying architecture. To facilitate access to multiple collections within one repository, University of Maryland developed a flexible metadata standard. This metadata schema is used to describe varying types of materials at varying levels of granularity, while allowing for controlled vocabularies appropriate to specific collections.",
 "article_title": "Cross-collection Searching: A Pandora's Box or the Holy Grail?",
 "authors": [
 {
 "given": " Susan",
 "family": "Schreibman",
 "affiliation": [
 {
 "original_name": "University of Maryland Libraries, University of Maryland, College Park, MD, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Jennifer",
 "family": "O’Brien Roper",
 "affiliation": [
 {
 "original_name": "University of Maryland Libraries, University of Maryland, College Park, MD, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Gretchen",
 "family": "Gueguen",
 "affiliation": [
 {
 "original_name": "University of Maryland Libraries, University of Maryland, College Park, MD, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-12-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm040",
 "identifier": {
 "string_id": "10.1093/llc/fqm040",
 "id_scheme": "DOI"
 },
 "abstract": "As the number of scholarly encoded digital texts is increasing, creating models of these kinds of texts with the help of digital tools is becoming more and more interesting. In connection with this type of work, it is important to have a clear understanding of what these particular models are based on. They will clearly be based on certain readings of the source texts, but we need to keep track of the relationships between the texts, readings of the texts and the models based on such readings.In this article, a problem of potentially great significance for this kind of modelling is discussed. The problem is called the exhibition problem and is based on the difference in ordinary linguistic communication between asserting a fact, e.g. that a certain person has a certain name, and exhibiting the same fact. In many cases, the latter is modelled as if it was the former. As a solution to this problem, an event-oriented modelling method is proposed.",
 "article_title": "The Exhibition Problem. A Real-life Example with a Suggested Solution",
 "authors": [
 {
 "given": " Øyvind",
 "family": "Eide",
 "affiliation": [
 {
 "original_name": "Unit for Digital Documentation, University of Oslo",
 "normalized_name": "University of Oslo",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/01xtthb56",
 "GRID": "grid.5510.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-11-24",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm044",
 "identifier": {
 "string_id": "10.1093/llc/fqm044",
 "id_scheme": "DOI"
 },
 "abstract": "In this article, we describe the respective approaches we have taken when addressing issues of spelling variation in German and English historical texts. More specifically, we describe an experiment to evaluate automatic techniques for the development of letter replacement heuristics against manually created gold standards of known letter replacements rules. As will become clear, the motivation for the research differs according to the team of researchers: the German researchers are seeking to develop a search engine for historical texts; the English researchers want to improve the results obtained when applying corpus linguistic techniques (developed for modern language) to historical data. However, the respective teams do share a longer term goal of assessing whether it is possible to develop a generic spelling detection tool for Indo-European languages.",
 "article_title": "The Identification of Spelling Variants in English and German Historical Texts: Manual or Automatic?",
 "authors": [
 {
 "given": " Thomas",
 "family": "Pilz",
 "affiliation": [
 {
 "original_name": "Department of Computer Science and Applied Cognitive Science, Faculty of Engineering, University of Duisburg-Essen, D-47048 Duisburg, Lotharstr. 65, Germany",
 "normalized_name": "University of Duisburg-Essen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/04mz5ra38",
 "GRID": "grid.5718.b"
 }
 }
 ]
 },
 {
 "given": " Andrea",
 "family": "Ernst-Gerlach",
 "affiliation": [
 {
 "original_name": "Department of Computer Science and Applied Cognitive Science, Faculty of Engineering, University of Duisburg-Essen, D-47048 Duisburg, Lotharstr. 65, Germany",
 "normalized_name": "University of Duisburg-Essen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/04mz5ra38",
 "GRID": "grid.5718.b"
 }
 }
 ]
 },
 {
 "given": " Sebastian",
 "family": "Kempken",
 "affiliation": [
 {
 "original_name": "Department of Computer Science and Applied Cognitive Science, Faculty of Engineering, University of Duisburg-Essen, D-47048 Duisburg, Lotharstr. 65, Germany",
 "normalized_name": "University of Duisburg-Essen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/04mz5ra38",
 "GRID": "grid.5718.b"
 }
 }
 ]
 },
 {
 "given": " Paul",
 "family": "Rayson",
 "affiliation": [
 {
 "original_name": "Computing Department, Infolab21, Lancaster University, Lancaster LA1 4WA, UK",
 "normalized_name": "Lancaster University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04f2nsd36",
 "GRID": "grid.9835.7"
 }
 }
 ]
 },
 {
 "given": " Dawn",
 "family": "Archer",
 "affiliation": [
 {
 "original_name": "Department of Humanities, University of Central Lancashire, Preston PR1 2HE, UK",
 "normalized_name": "University of Central Lancashire",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/010jbqd54",
 "GRID": "grid.7943.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-11-25",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm043",
 "identifier": {
 "string_id": "10.1093/llc/fqm043",
 "id_scheme": "DOI"
 },
 "abstract": "This article examines the hypothesis that a speaker uses the HAVE + noun construction when (s)he wants to express somebody's positive qualities. This hypothesis was tested with two different corpora using two different retrieval programs. The numerous steps that are necessary show that it can take a considerable amount of time to reach sound conclusions and suggests the need to improve the building of those corpora or their retrieval software programs. χ2 and z-score tests were used to analyse the results. The above hypothesis proves to be too strong: although the verb HAVE is never significantly associated more frequently with shortcomings, the verb BE is sometimes associated more frequently with qualities. The lists of qualities and shortcomings expressed with HAVE or with BE show that BE collocates with a wider range of qualities than shortcomings. These lists also indicate that the qualities often quoted by the theoretical linguist are not those most frequently found in corpora. They also point to differences between the qualities that collocate with HAVE and those that collocate with BE. The use of corpora enabled me to widen the range of qualities or shortcomings that are said to collocate with HAVE or BE, and revealed that, contrary to the hypothesis, the HAVE + noun construction can apply to inanimate subject referents.",
 "article_title": "BE and HAVE: Qualities and Shortcomings",
 "authors": [
 {
 "given": " Pierre",
 "family": "Labrosse",
 "affiliation": [
 {
 "original_name": "E.A. Formes-Discours-Cognition and C.A.T.I., Université de Paris IV-Sorbonne, Paris, France",
 "normalized_name": "University of Paris",
 "country": "France",
 "identifiers": {
 "ror": "https://ror.org/05f82e368",
 "GRID": "grid.508487.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-11-22",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm041",
 "identifier": {
 "string_id": "10.1093/llc/fqm041",
 "id_scheme": "DOI"
 },
 "abstract": "Information about place and location is an essential part of research in the humanities. There are many ways that methods and tools for structuring, visualizing and analysing space, spatial behaviour, and spatial relationships can benefit humanities research but the use of spatial information in digital scholarship by humanists remains very limited. The developing role of the study of place and location through geographical information systems (GIS) and other digital tools is discussed briefly before examining the factors that are inhibiting the use of spatial data in our research. The influences of current research practice and the attitudes of scholarly institutions in the humanities are examined. This article will explore some of the potential research applications but, possibly more importantly; it will also examine why that potential is being developed so slowly and discuss a possible way forward for the community.",
 "article_title": "The Inhibition of Geographical Information in Digital Humanities Scholarship",
 "authors": [
 {
 "given": " Martyn",
 "family": "Jessop",
 "affiliation": [
 {
 "original_name": "Centre for Computing in the Humanities, King's College London, Strand, London WC2R 2LS, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-11-21",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm045",
 "identifier": {
 "string_id": "10.1093/llc/fqm045",
 "id_scheme": "DOI"
 },
 "abstract": "There are now many online, digital resources in the humanities, and their creation is funded by various governmental, academic, and philanthropic sources. What happens to these resources after completion is very poorly understood. No systematic survey of digital resource usage in the humanities has ever been undertaken—and the factors for use and non-use of digital resources are unknown. The LAIRAH (Log Analysis of Internet Resources in the Arts and Humanities) Project is a 15-month long study into the factors which determine long-term use and neglect of digital resources in the Arts and Humanities. Using quantitative Deep Log Analysis techniques to understand real-time user behaviour and qualitative user workshops to gain an understanding of user approaches to digital resources in the arts and humanities, the study identifies factors that may predispose a digital resource to become used or neglected in the long-term. This article provides an overview of the techniques used in the LAIRAH project, and presents some preliminary results that may be of use to both the creators of digital resources in the humanities, and the funders of these projects, to ensure that significant intellectual effort and time, and financial resources, are not wasted in the creation of projects that are then neglected by the user community.",
 "article_title": "If You Build It Will They Come? The LAIRAH Study: Quantifying the Use of Online Resources in the Arts and Humanities through Statistical Analysis of User Log Data",
 "authors": [
 {
 "given": " Claire",
 "family": "Warwick",
 "affiliation": [
 {
 "original_name": "School of Library, Archive and Information Studies, University College London, London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Melissa",
 "family": "Terras",
 "affiliation": [
 {
 "original_name": "School of Library, Archive and Information Studies, University College London, London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Paul",
 "family": "Huntington",
 "affiliation": [
 {
 "original_name": "School of Library, Archive and Information Studies, University College London, London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 },
 {
 "given": " Nikoleta",
 "family": "Pappa",
 "affiliation": [
 {
 "original_name": "School of Library, Archive and Information Studies, University College London, London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-11-21",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "23",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm028",
 "identifier": {
 "string_id": "10.1093/llc/fqm028",
 "id_scheme": "DOI"
 },
 "abstract": "Assessments of Goldsmith's contribution to the Busy Body have fluctuated widely. We examine the ten possible attributions, gathering evidence from verbal parallels, selected linguistic features, and measures of sentence-length, together with idiosyncrasies of vocabulary and syntax in the ‘doubtful’ essays themselves. We conclude that apart from the essay on London clubs, which he later acknowledged, only one piece can be attributed to Goldsmith with any confidence.",
 "article_title": "Goldsmith and the Busy Body",
 "authors": [
 {
 "given": " Peter",
 "family": "Dixon",
 "affiliation": [
 {
 "original_name": "Formerly of Queen Mary, University of London, UK",
 "normalized_name": "University of London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04cw6st05",
 "GRID": "grid.4464.2"
 }
 }
 ]
 },
 {
 "given": " David",
 "family": "Mannion",
 "affiliation": [
 {
 "original_name": "Formerly of Royal Holloway, University of London, UK",
 "normalized_name": "University of London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04cw6st05",
 "GRID": "grid.4464.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-10-26",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm026",
 "identifier": {
 "string_id": "10.1093/llc/fqm026",
 "id_scheme": "DOI"
 },
 "abstract": "We introduce a systematic approach to language change quantification by studying unconsciously used language features in time-separated parallel translations. For this purpose, we use objective style markers such as vocabulary richness and lengths of words, word stems and suffixes, and employ statistical methods to measure their changes over time. In this study, we focus on the change in Turkish in the second half of the twentieth century. To obtain word stems, we first introduce various stemming techniques and show that they are highly effective. Our statistical analyses show that over time, for both text and lexicon, the length of Turkish words has become significantly longer, and word stems have become significantly shorter. We also show that suffix lengths have become significantly longer for types and the vocabulary richness based on word stems has shrunk significantly. These observations indicate that in contemporary Turkish one would use more suffixes to compensate for the fewer stems to preserve the expressive power of the language at the same level. Our approach can be adapted for quantifying the change in other languages.",
 "article_title": "Language Change Quantification Using Time-separated Parallel Translations",
 "authors": [
 {
 "given": " Kemal",
 "family": "Altintas",
 "affiliation": [
 {
 "original_name": "Computer Science Department, University of California, Irvine, Irvine, CA 92612, USA",
 "normalized_name": "California Coast University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05t99sp05",
 "GRID": "grid.468726.9"
 }
 }
 ]
 },
 {
 "given": " Fazli",
 "family": "Can",
 "affiliation": [
 {
 "original_name": "Computer Science and Systems Analysis Department, Miami University, Oxford, OH 45056, USA",
 "normalized_name": "Miami University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05nbqxr67",
 "GRID": "grid.259956.4"
 }
 }
 ]
 },
 {
 "given": " Jon M.",
 "family": "Patton",
 "affiliation": [
 {
 "original_name": "Information Technology Services, Miami University, Oxford, OH 45056, USA",
 "normalized_name": "Miami University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/05nbqxr67",
 "GRID": "grid.259956.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-09-22",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm017",
 "identifier": {
 "string_id": "10.1093/llc/fqm017",
 "id_scheme": "DOI"
 },
 "abstract": "This paper reports the completion of the first expansion phase of the Sheffield Corpus of Chinese (SCC). We describe the major improvements we made in expanding the corpus. They involve the coverage of time periods, choice of text types and categories, and selection of individual texts; the mark up scheme and the integral search and analysis tool. We use the developing SCC to examine Li and Thompson's; (1974, 1975, 1976) controversial postverbal predominance hypothesis for prepositional phrases (PPs) in Archaic Chinese and their word order change hypothesis for PPs in general in the history of the Chinese language. Our study provides no evidence for the postverbal predominance hypothesis for PPs in Archaic Chinese and the word order change hypothesis for PPs in general from postverbal in Archaic Chinese to preverbal in Modern Chinese. Our findings show that postverbal and preverbal PPs have been in coexistence and there have always been more occurrences of preverbal PPs than postverbal PPs in all the time periods covered in the current SCC. Although use of some PPs declined in some time periods and use of others emerged in other time periods, there was never a predominant position for PPs in any time period in the history of Chinese. We show differences in the distribution of PPs in different time periods and provide an account of the syntactic positions of PPs in those time periods.",
 "article_title": "Syntactic Positions of Prepositional Phrases in the History of Chinese: Using the Developing Sheffield Corpus of Chinese for Diachronic Linguistic Studies",
 "authors": [
 {
 "given": " Xiaoling",
 "family": "Hu",
 "affiliation": [
 {
 "original_name": "University of Sheffield, UK",
 "normalized_name": "University of Sheffield",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05krs5044",
 "GRID": "grid.11835.3e"
 }
 }
 ]
 },
 {
 "given": " Jamie",
 "family": "McLaughlin",
 "affiliation": [
 {
 "original_name": "University of Sheffield, UK",
 "normalized_name": "University of Sheffield",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05krs5044",
 "GRID": "grid.11835.3e"
 }
 }
 ]
 },
 {
 "given": " Nigel",
 "family": "Williamson",
 "affiliation": [
 {
 "original_name": "Sheffield Hallam University, UK",
 "normalized_name": "Sheffield Hallam University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/019wt1929",
 "GRID": "grid.5884.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-09-14",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm019",
 "identifier": {
 "string_id": "10.1093/llc/fqm019",
 "id_scheme": "DOI"
 },
 "abstract": "Fifteen items in the Weekly Magazine have been attributed to Goldsmith. Our study uses traditional kinds of internal evidence (mainly verbal parallels) together with evidence from selected linguistic features. A preliminary analysis identifies features which best distinguish Goldsmith samples from those of a number of contemporary authors. Using this selection of features, we calculate the distances of the fifteen Weekly items from the cluster of Goldsmith samples; an item at too large a distance is unlikely to be his. A parallel investigation is based on sentence-length statistics. We conclude that seven essays may plausibly be assigned to Goldsmith, that he probably co-authored two pieces, and that in three cases he merely made minor additions to material from other sources.",
 "article_title": "Goldsmith's Contributions to the Weekly Magazine",
 "authors": [
 {
 "given": " Peter",
 "family": "Dixon",
 "affiliation": [
 {
 "original_name": "Queen Mary, University of London, UK",
 "normalized_name": "University of London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04cw6st05",
 "GRID": "grid.4464.2"
 }
 }
 ]
 },
 {
 "given": " David",
 "family": "Mannion",
 "affiliation": [
 {
 "original_name": "Royal Holloway, University of London, UK",
 "normalized_name": "University of London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04cw6st05",
 "GRID": "grid.4464.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-09-07",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm020",
 "identifier": {
 "string_id": "10.1093/llc/fqm020",
 "id_scheme": "DOI"
 },
 "abstract": "The basic assumption of quantitative authorship attribution is that the author of a text can be selected from a set of possible authors by comparing the values of textual measurements in that text to their corresponding values in each possible author's writing sample. Over the past three centuries, many types of textual measurements have been proposed, but never before have the majority of these measurements been tested on the same dataset. A large-scale comparison of textual measurements is crucial if current techniques are to be used effectively and if new and more powerful techniques are to be developed. This article presents the results of a comparison of thirty-nine different types of textual measurements commonly used in attribution studies, in order to determine which are the best indicators of authorship. Based on the results of these tests, a more accurate approach to quantitative authorship attribution is proposed, which involves the analysis of many different textual measurements.",
 "article_title": "Quantitative Authorship Attribution: An Evaluation of Techniques",
 "authors": [
 {
 "given": " Jack",
 "family": "Grieve",
 "affiliation": [
 {
 "original_name": "English Department Northern Arizona University",
 "normalized_name": "Northern Arizona University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0272j5188",
 "GRID": "grid.261120.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-07-27",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm021",
 "identifier": {
 "string_id": "10.1093/llc/fqm021",
 "id_scheme": "DOI"
 },
 "abstract": "This article examines the actual and potential use of software tools in research in the arts and humanities focusing on audiovisual (AV) materials such as recorded speech, music, video and film. The quantity of such materials available to researchers is massive and rapidly expanding. Researchers need to locate the material of interest in the vast quantity available, and to organize and process the material once collected. Locating and organizing often depend on metadata and tags to describe the actual content, but standards for metadata for AV materials are not widely adopted. Content-based search is becoming possible for speech, but is still beyond the horizon for music, and even more distant for video. Copyright protection hampers research with AV materials, and Digital Rights Management (DRM) systems threaten to prevent research altogether. Once material has been located and accessed, much research proceeds by annotation, for which many tools exist. Many researchers make some kind of transcription of materials, and would value tools to automate this process. Such tools exist for speech, though with important limits to their accuracy and applicability. For music and video, researchers can make use of visualizations. A better understanding (in general terms) by researchers of the processes carried out by computer software and of the limitations of its results would lead to more effective use of Information and Communications Technology (ICT).",
 "article_title": "Tools for Searching, Annotation and Analysis of Speech, Music, Film and Video A Survey",
 "authors": [
 {
 "given": " Alan",
 "family": "Marsden",
 "affiliation": [
 {
 "original_name": "Lancaster Institute for the Contemporary Arts",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "Institute for Cultural Research, Lancaster University",
 "normalized_name": "Lancaster University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04f2nsd36",
 "GRID": "grid.9835.7"
 }
 }
 ]
 },
 {
 "given": " Adrian",
 "family": "Mackenzie",
 "affiliation": [
 {
 "original_name": "Lancaster Institute for the Contemporary Arts",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "Institute for Cultural Research, Lancaster University",
 "normalized_name": "Lancaster University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04f2nsd36",
 "GRID": "grid.9835.7"
 }
 }
 ]
 },
 {
 "given": " Adam",
 "family": "Lindsay",
 "affiliation": [
 {
 "original_name": "Lancaster Institute for the Contemporary Arts",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "Institute for Cultural Research, Lancaster University",
 "normalized_name": "Lancaster University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04f2nsd36",
 "GRID": "grid.9835.7"
 }
 }
 ]
 },
 {
 "given": " Harriet",
 "family": "Nock",
 "affiliation": [
 {
 "original_name": "Phonetics Laboratory, University of Oxford",
 "normalized_name": "University of Oxford",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/052gg0110",
 "GRID": "grid.4991.5"
 }
 }
 ]
 },
 {
 "given": " John",
 "family": "Coleman",
 "affiliation": [
 {
 "original_name": "Phonetics Laboratory, University of Oxford",
 "normalized_name": "University of Oxford",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/052gg0110",
 "GRID": "grid.4991.5"
 }
 }
 ]
 },
 {
 "given": " Greg",
 "family": "Kochanski",
 "affiliation": [
 {
 "original_name": "Phonetics Laboratory, University of Oxford",
 "normalized_name": "University of Oxford",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/052gg0110",
 "GRID": "grid.4991.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-07-21",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm018",
 "identifier": {
 "string_id": "10.1093/llc/fqm018",
 "id_scheme": "DOI"
 },
 "abstract": "Remediation refers to the re-presentation of old media in new media. This article studies remediation in electronic products in library collections, especially the digital facsimile. Early English Books Online (EEBO) is a particularly interesting example, not only because of its scholarly importance, but also because of its multi-layered genesis from printed work to microfilm (Early English Books (EEB)) to digital (EEBO) facsimile, and to the text encoding initiative EEBO-TCP, a joint ProQuest and Text Creation Partnership (TCP) project. The article analyses the impact of filters and limits of remediation in relation to EEBO and its predecessor EEB, such as the choice to duplicate a single copy of a work as bi-tonal black and white images, and to scholarly work.",
 "article_title": "Metamorphosis: Remediation in Early English Books Online (EEBO)",
 "authors": [
 {
 "given": " Diana",
 "family": "Kichuk",
 "affiliation": [
 {
 "original_name": "University of Saskatchewan Library, University of Saskatchewan, Canada",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-06-19",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm012",
 "identifier": {
 "string_id": "10.1093/llc/fqm012",
 "id_scheme": "DOI"
 },
 "abstract": "The Middle Dutch Arthurian romance Roman van Walewein (‘Romance of Gawain’) is attributed in the text itself to two authors, Penninc and Vostaert. Very little quantitative research into this dual authorship has been done. This article describes our progress in applying different non-traditional authorship attribution methods to the text of Walewein. After providing an introduction to the romance and an overview of earlier research, we evaluate previous statements on authorship and stylistics by applying both Yule's measure of lexical richness and Burrows's Delta. To find out whether these new methods would confirm or even enhance our present knowledge about the differences between the two authors, we applied an adapted version of John Burrows's Delta procedure. The adapted version seems to be able to distinguish the double authorship of the romance. It also helps us to confirm some and to reject other earlier statements about the position in the text where the second author started his work.",
 "article_title": "Delta for Middle Dutch Author and Copyist Distinction in Walewein",
 "authors": [
 {
 "given": " Karina",
 "family": "van Dalen-Oskam",
 "affiliation": [
 {
 "original_name": "Huygens Instituut, The Hague, The Netherlands",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Joris",
 "family": "van Zundert",
 "affiliation": [
 {
 "original_name": "Huygens Instituut, The Hague, The Netherlands",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-06-03",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm008",
 "identifier": {
 "string_id": "10.1093/llc/fqm008",
 "id_scheme": "DOI"
 },
 "abstract": "The model described here relies on the key concepts of topology, i.e. neighbourhood and equivalence of shape. A linguistic object L is studied in text T by means of one or several local questions Q. The set of successive local answers is processed so as to provide a global function characterizing the textual space under scrutiny. We begin with short sequences of tenses to illustrate the way in which to explore originally Emile Benveniste's concepts of history and discourse.1 We then supply life-size examples of other objects selected for their heuristic value. We go on to demonstrate the model at work on the distribution of strings of finite (F) and non-finite (n) verbal forms in the LOB Corpus of English. A topological chart is produced as the synthetic image mirroring the locations of the relevant linguistic entities throughout the text. All the individual strings concatenating any number of F and n are classified in a table. Alternatively, individual full-text strings can be extracted. We then proceed to refine the notion of lexical distribution in ‘rafales’ in a lemmatized corpus of Latin texts, the purpose being to test the stability of the distributions in individual texts of selected verbs and assess whether a verb's behaviour is related to its semantic status. The final section is devoted to other Latin texts. The use of segments of equal length makes it possible to draw up the narrative profile of each author as revealed by his handling of tenses in main clauses.",
 "article_title": "Trees and After: The Concept of Text Topology. Some Applications to Verb-Form Distributions in Language Corpora",
 "authors": [
 {
 "given": " Xuan",
 "family": "Luong",
 "affiliation": [
 {
 "original_name": "Université de Nice-Sophia Antipolis, France",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Michel",
 "family": "Juillard",
 "affiliation": [
 {
 "original_name": "Université de Nice-Sophia Antipolis, France",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Sylvie",
 "family": "Mellet",
 "affiliation": [
 {
 "original_name": "Université de Nice-Sophia Antipolis, France",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Dominique",
 "family": "Longrée",
 "affiliation": [
 {
 "original_name": "Université de Liège, UMR 6039 Bases, Corpus et Langage, Belgium",
 "normalized_name": "University of Liège",
 "country": "Belgium",
 "identifiers": {
 "ror": "https://ror.org/00afp2z80",
 "GRID": "grid.4861.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-05-04",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm004",
 "identifier": {
 "string_id": "10.1093/llc/fqm004",
 "id_scheme": "DOI"
 },
 "abstract": "We apply default inheritance hierarchies to generating the morphology of Hebrew verbs. This approach represents inflectional exponents as markings associated with the application of rules by which complex word forms are deduced from simpler roots or stems. The high degree of similarity among verbs of different conjugation classes allows us to formulate general rules; these general rules are, however, sometimes overridden by conjugation-specific rules. Similarly, a verb's form within a particular conjugation is determined both by default rules and by overriding rules specific to lexical stem peculiarities. Our result is a concise set of rules defining the morphology of Hebrew verbs in all conjugations. We express these rules in KATR, both a formalism for default inheritance hierarchies and associated software for generating the forms specified by those rules. As we describe the rules, we point out general strategies for expressing morphology in KATR. We conclude by discussing KATR's advantages over ordinary DATR for the representation of morphological systems and our plans for KATR's successor, LATR.",
 "article_title": "A Default Inheritance Hierarchy for Computing Hebrew Verb Morphology",
 "authors": [
 {
 "given": " Raphael",
 "family": "Finkel",
 "affiliation": [
 {
 "original_name": "University of Kentucky, USA",
 "normalized_name": "University of Kentucky",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/02k3smh20",
 "GRID": "grid.266539.d"
 }
 }
 ]
 },
 {
 "given": " Gregory",
 "family": "Stump",
 "affiliation": [
 {
 "original_name": "University of Kentucky, USA",
 "normalized_name": "University of Kentucky",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/02k3smh20",
 "GRID": "grid.266539.d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-05-25",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm009",
 "identifier": {
 "string_id": "10.1093/llc/fqm009",
 "id_scheme": "DOI"
 },
 "abstract": "During the process of writing a comprehensive dictionary of Finnish dialects, a large set of maps describing the regional distribution of the dialect words have been compiled in electronic form. In this article, we set out to analyse this corpus of data in order to gain new insight on the variation of Finnish dialects. We use a wide range of multivariate data analysis methods, including principal components analysis, independent components analysis, clustering, and multidimensional scaling. We explain how to preprocess the data to overcome the problem of uneven sampling caused by the way the data has been collected. We discuss the results obtained by these methods and compare them to the traditional view of Finnish dialect groups.",
 "article_title": "Multivariate Analysis of Finnish Dialect Data An Overview of Lexical Variation",
 "authors": [
 {
 "given": " Saara",
 "family": "Hyvönen",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, Helsinki Institute for Information Technology, University of Helsinki, P.O. Box 68, FI–00014, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 }
 ]
 },
 {
 "given": " Antti",
 "family": "Leino",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, University of Helsinki, Research Institute for the Languages of Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 }
 ]
 },
 {
 "given": " Marko",
 "family": "Salmenkivi",
 "affiliation": [
 {
 "original_name": "Research Institute for the Languages of Finland",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-05-04",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm011",
 "identifier": {
 "string_id": "10.1093/llc/fqm011",
 "id_scheme": "DOI"
 },
 "abstract": "We present a quantitative analysis of 442 pieces of fiction published between 5 October 1992 and 17 September 2001 in the New Yorker magazine. We address two independent questions using the same data set. First, we examine whether changes in the Executive Editor or Fiction Editor are associated with significant changes in the type of fiction published at the New Yorker. Second, we examine whether New Yorker authors write fiction more often than not about characters with whom they share demographic traits. We find that changes in Fiction Editor at the New Yorker are associated with numerous significant, quantifiable changes in the magazine's fiction and that these effects are greater than those associated with a change in the New Yorker's Executive Editor. We also find that authors of New Yorker fiction write significantly more often than not about protagonists who share their race, gender, and country of origin and who are within or below their age range. The same is true of secondary characters except in the case of gender.",
 "article_title": "A Statistical Analysis of Editorial Influence and Author Character Similarities in 1990s New Yorker Fiction",
 "authors": [
 {
 "given": " Katherine L.",
 "family": "Milkman",
 "affiliation": [
 {
 "original_name": "Harvard University, Boston, MA 02138, USA",
 "normalized_name": "Harvard University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/03vek6s52",
 "GRID": "grid.38142.3c"
 }
 }
 ]
 },
 {
 "given": " René",
 "family": "Carmona",
 "affiliation": [
 {
 "original_name": "Princeton University, Princeton, NJ 08544, USA",
 "normalized_name": "Princeton University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00hx57361",
 "GRID": "grid.16750.35"
 }
 }
 ]
 },
 {
 "given": " William",
 "family": "Gleason",
 "affiliation": [
 {
 "original_name": "Princeton University, Princeton, NJ 08544, USA",
 "normalized_name": "Princeton University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00hx57361",
 "GRID": "grid.16750.35"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-05-04",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm010",
 "identifier": {
 "string_id": "10.1093/llc/fqm010",
 "id_scheme": "DOI"
 },
 "abstract": "The present article is concerned with the problem of automatic database population via information extraction (IE) from web pages obtained from heterogeneous sources, such as those retrieved by a domain crawler. Specifically, we address the task of filling single multi-field templates from individual documents, a common scenario that involves free-format documents with the same communicative goal such as job adverts, CVs, or meeting/seminar announcements. We discuss challenges that arise in this scenario and propose solutions to them at different levels of the processing of web page content. Our main focus is on the issue of information extraction, which we address with a two-step machine learning approach that first aims to determine segments of a page that are likely to contain relevant facts and then delimits specific natural language expressions with which to fill template fields. We also present a range of techniques for the enrichment of web pages with semantic annotations, such as recognition of named entities, domain terminology and coreference resolution, and examine their effect on the information extraction method. We evaluate the developed IE system on the task of automatically populating a database with information on language resources available on the web.",
 "article_title": "Discovery of Language Resources on the Web: Information Extraction from Heterogeneous Documents",
 "authors": [
 {
 "given": " Viktor",
 "family": "Pekar",
 "affiliation": [
 {
 "original_name": "School of Humanities, Languages, and Social Sciences, University of Wolverhampton, Stafford Street, Wolverhampton, WV1 1SB, UK",
 "normalized_name": "University of Wolverhampton",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01k2y1055",
 "GRID": "grid.6374.6"
 }
 }
 ]
 },
 {
 "given": " Richard",
 "family": "Evans",
 "affiliation": [
 {
 "original_name": "School of Humanities, Languages, and Social Sciences, University of Wolverhampton, Stafford Street, Wolverhampton, WV1 1SB, UK",
 "normalized_name": "University of Wolverhampton",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01k2y1055",
 "GRID": "grid.6374.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-04-20",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm006",
 "identifier": {
 "string_id": "10.1093/llc/fqm006",
 "id_scheme": "DOI"
 },
 "abstract": "Estimating the relative frequencies of linguistic features is a fundamental task in linguistic computation. As the amount of text or speech that is available from a given user of the language typically varies greatly, and the sample sizes tend to be small, the most straightforward methods do not always give the most informative answers. Bootstrap and Bayesian methods provide techniques for handling the uncertainty in small samples. We describe these techniques for estimating frequencies from small samples, and show how they can be applied to the study of linguistic change. As a test case, we use the introduction of the pronoun you as subject in the data provided by the Corpus of Early English Correspondence (c. 1410–1681).",
 "article_title": "How to Handle Small Samples: Bootstrap and Bayesian Methods in the Analysis of Linguistic Change",
 "authors": [
 {
 "given": " Alexander",
 "family": "Hinneburg",
 "affiliation": [
 {
 "original_name": "Institute for Informatics, Martin-Luther University, Halle/Saal, Germany",
 "normalized_name": "Luther University",
 "country": "South Korea",
 "identifiers": {
 "ror": "https://ror.org/015dhy417",
 "GRID": "grid.444157.7"
 }
 }
 ]
 },
 {
 "given": " Heikki",
 "family": "Mannila",
 "affiliation": [
 {
 "original_name": "HIIT Basic Research Unit, University of Helsinki",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 },
 {
 "original_name": "Helsinki University of Technology, Finland",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Samuli",
 "family": "Kaislaniemi",
 "affiliation": [
 {
 "original_name": "Department of English, University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 }
 ]
 },
 {
 "given": " Terttu",
 "family": "Nevalainen",
 "affiliation": [
 {
 "original_name": "Department of English, University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 }
 ]
 },
 {
 "given": " Helena",
 "family": "Raumolin-Brunberg",
 "affiliation": [
 {
 "original_name": "Department of English, University of Helsinki, Finland",
 "normalized_name": "University of Helsinki",
 "country": "Finland",
 "identifiers": {
 "ror": "https://ror.org/040af2s02",
 "GRID": "grid.7737.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-04-13",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm003",
 "identifier": {
 "string_id": "10.1093/llc/fqm003",
 "id_scheme": "DOI"
 },
 "abstract": "This article reports on experiments performed with a large corpus, aiming at separating texts according to the author style. The study initially focusses on whether the classification accuracy regarding the author identity may be improved, if the text topic is known in advance. The experimental results indicate that this kind of information contributes to more accurate author recognition. Furthermore, as the diversity of a topic set increases, the classification accuracy is reduced. In general, the experimental results indicate that taking into account knowledge regarding the text topic can lead to the construction of specialized models for each author with higher classification accuracy. For example, by focussing on a specific topic, the accuracy with which the author identity is determined increases, the exact amount depending on the specific topic. This also applies when the topic of the text is more broadly determined, as a set of topic categories.In an associated task, the most salient parameters within an 85-parameter vector are studied, for a number of subsets of the corpus, where each subset contains speeches from a single topic. These studies indicate that the salient parameters are the same for the different subsets. Two fixed data vectors have been defined, using 16 and 25 parameters, respectively. The classification accuracy obtained, even with the smallest data vector, is only 5% less than with the complete vector. This indicates that the parameters retained in the reduced vectors bear a large amount of discriminatory information and suffice for an accurate classification of the corpus.",
 "article_title": "Employing Thematic Variables for Enhancing Classification Accuracy Within Author Discrimination Experiments",
 "authors": [
 {
 "given": " George",
 "family": "Tambouratzis",
 "affiliation": [
 {
 "original_name": "Institute for Language and Speech Processing, Greece",
 "normalized_name": "Institute for Language and Speech Processing",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/00z24kr14",
 "GRID": "grid.424851.e"
 }
 }
 ]
 },
 {
 "given": " Marina",
 "family": "Vassiliou",
 "affiliation": [
 {
 "original_name": "Institute for Language and Speech Processing, Greece",
 "normalized_name": "Institute for Language and Speech Processing",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/00z24kr14",
 "GRID": "grid.424851.e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-03-19",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm002",
 "identifier": {
 "string_id": "10.1093/llc/fqm002",
 "id_scheme": "DOI"
 },
 "abstract": "In recent years, linguists have become increasingly interested in the language of the Internet—both as an object of investigation as well as a source of authentic data to complement traditional electronic corpora. However, Internet-derived data is typically very messy data and a conversion process is often required in order to enable researchers to carry out a reliable quantitative investigation of the patterns observed with the help of standard corpus tools. In this article, I discuss the technical and methodological aspects involved in creating a large corpus of asynchronous computer-mediated communication by downloading and post-processing hundreds of thousands messages posted in twelve Usenet newsgroups. After describing how messages can be arranged into hierarchically structured discussion threads, I focus at some length on the strategies that are required to correctly assign authorship to the different textual elements in individual messages. My algorithms have a success rate of well over 90% for most newsgroups and the resulting corpus can thus serve as a suitable basis for an investigation into the interactive strategies employed in this particular type of written communication.",
 "article_title": "Processing Internet-derived Text--Creating a Corpus of Usenet Messages",
 "authors": [
 {
 "given": " Sebastian",
 "family": "Hoffmann",
 "affiliation": [
 {
 "original_name": "Department of Linguistics and English Language, Bowland College, Lancaster University",
 "normalized_name": "Lancaster University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04f2nsd36",
 "GRID": "grid.9835.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-03-01",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqm001",
 "identifier": {
 "string_id": "10.1093/llc/fqm001",
 "id_scheme": "DOI"
 },
 "abstract": "In a meeting at King's College London in May 2000, John Unsworth proposed a list of seven ‘scholarly primitives’ which he claimed were ‘self-understood’ functions forming the basis for ‘higher-level scholarly projects, arguments, statements [and] interpretations’ (Unsworth, 2000). He claimed that his list summarized activities that were ‘basic to scholarship across eras and across media’, and went on to say that an analysis of these scholarly primitives might result in a clearer sense of how computing tools could support the scholarly endeavour. Here we focus on the primitive that was second on Unsworth's list, after ‘Discovering’: ‘Annotation’.Our work on annotation arises out of a developing awareness that established Humanities Computing (HC) areas of interest, do not seem always to connect with the actual process of the research work being carried out by most humanists. We claimed in Bradley (2005) that a fundamentally different usage paradigm than those in operation in established HC was necessary to even notice, and then follow-up on, the potential of scholarly annotation as a computer-supported activity.This article presents our experiences, and the eventual outcomes, of the process of developing annotations tools for the Online Chopin Variorum Edition project (OCVE).1 Beginning with a brief overview of activities related to annotation in Humanities Computing and Computing Science, we introduce the visible parts of the OCVE project, and address some discussion to the structures behind the scenes that support what it does, reporting what worked and what did not. We conclude by analysing the significance of our findings and describing the direction we think our annotation tool will take.",
 "article_title": "Supporting Annotation as a Scholarly Tool--Experiences From the Online Chopin Variorum Edition",
 "authors": [
 {
 "given": " John",
 "family": "Bradley",
 "affiliation": [
 {
 "original_name": "Centre for Computing in the Humanities, King's College London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 },
 {
 "given": " Paul",
 "family": "Vetch",
 "affiliation": [
 {
 "original_name": "Centre for Computing in the Humanities, King's College London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2007-02-22",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql049",
 "identifier": {
 "string_id": "10.1093/llc/fql049",
 "id_scheme": "DOI"
 },
 "abstract": "This article discusses the development of integrated multilingual Web databases to help the preservation of the Native American language East Cree. The creation of digital online resources for threatened aboriginal languages presents many technical, educational and ethical challenges. We focus here on the technical challenges in order to discuss both the problems encountered in this particular context, and the solutions we have considered and explored. We illustrate our discussion with examples from an Oral Stories Database we developed in collaboration with Cree education consultants and speakers in 2002–04. We advocate an approach that includes fast-prototyping, open-source development, and design for the database engine that balances speed, availability, features, and resources. We discuss the impact the combination of this technical approach and the participatory action research method is having on language maintenance.",
 "article_title": "Developing Web Databases for Aboriginal Language Preservation",
 "authors": [
 {
 "given": " Marie-Odile",
 "family": "Junker",
 "affiliation": [
 {
 "original_name": "Institute of Cognitive Science, Carleton University, Canada",
 "normalized_name": "Carleton University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/02qtvee93",
 "GRID": "grid.34428.39"
 }
 }
 ]
 },
 {
 "given": " Radu",
 "family": "Luchian",
 "affiliation": [
 {
 "original_name": "Institute of Cognitive Science, Carleton University, Canada",
 "normalized_name": "Carleton University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/02qtvee93",
 "GRID": "grid.34428.39"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-12-09",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql048",
 "identifier": {
 "string_id": "10.1093/llc/fql048",
 "id_scheme": "DOI"
 },
 "abstract": "The search for a reliable expression to measure an author's lexical richness has constituted many statisticians' holy grail over the last decades in their attempt to solve some controversial authorship attributions. The greatest effort has been devoted to find a formula grounded on the computation of tokens, word-types, most-frequent-word(s), hapax legomena, hapax dislegomena, etc., such that it would characterize a text successfully, independent of its length. In this line, Yule's K and Zipf 's Z seem to be generally accepted by scholars as reliable measures of lexical repetition and lexical richness by computing content and function words altogether.1 Given the latter's higher frequency, they prove to be more reliable identifiers when isolatedly computed in p.c.a. and Delta-based attribution studies, and their rate to the former also measures the functional density of a text. In this paper, we aim to show that each constant serves to measure a specific feature and, as such, they are thought to complement one another since a supposedly rich text (in terms of its lemmas) does necessarily have to characterize by its low functional density, and vice versa. For this purpose, an annotated corpus of the West Saxon Gospels (WSG) and Apollonius of Tyre (AoT) has been used along with a huge raw corpus.",
 "article_title": "Function Words in Authorship Attribution Studies",
 "authors": [
 {
 "given": " Antonio Miranda",
 "family": "García",
 "affiliation": [
 {
 "original_name": "Department of English, School of Engineering, University of Málaga, Spain",
 "normalized_name": "University of Malaga",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/036b2ww28",
 "GRID": "grid.10215.37"
 }
 }
 ]
 },
 {
 "given": " Javier Calle",
 "family": "Martín",
 "affiliation": [
 {
 "original_name": "Department of English, Faculty of Arts, University of Málaga, Spain",
 "normalized_name": "University of Malaga",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/036b2ww28",
 "GRID": "grid.10215.37"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-11-16",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql042",
 "identifier": {
 "string_id": "10.1093/llc/fql042",
 "id_scheme": "DOI"
 },
 "abstract": "This paper documents the many taxometric and cartographic achievements of the Salzburg school of dialectometry. The paper discusses the following topics: (1) problems of measurement of linguistic atlas data (with particular consideration of Romance linguistic atlases), (2) establishment of the data matrix, (3) choice of the similarity index (Relative and Weighted Identity Value), (4) generation of the respective similarity and distance matrices, (5) their subsequent cartographic exploitation, which encompasses the following cartographic tools: similarity maps, parameter maps, dendrograms (and their spatial projection), and correlation maps. The ultimate purpose of these highly sophisticated cartographic techniques (choropleth and isopleth maps) is to increase our knowledge of the complex mechanisms of the dialectal management of space by man. From a methodological point of view our paper deals with problems related to (Romance) dialectology and linguistic geography, historical linguistics, numerical classification, statistics and statistical cartography. The examples are drawn from the French linguistic atlas ALF (Atlas linguistique de la France) published by Jules Gilliéron and Edmond Edmont (Paris: Champion, 1902–1910, 10 volumes) more than one hundred years ago. The taxometric calculations and their respective visualizations are realized by a powerful computer program called ‘Visual DialectoMetry’ (VDM), created by Edgar Haimerl (Blaustein, Germany) between 1997 and 2000 in Salzburg, which is freely available for research purposes.",
 "article_title": "Recent Advances in Salzburg Dialectometry",
 "authors": [
 {
 "given": " Hans",
 "family": "Goebl",
 "affiliation": [
 {
 "original_name": "Department of Romance Philology, University of Salzburg, Austria",
 "normalized_name": "University of Salzburg",
 "country": "Austria",
 "identifiers": {
 "ror": "https://ror.org/05gs8cd61",
 "GRID": "grid.7039.d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-10-20",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql044",
 "identifier": {
 "string_id": "10.1093/llc/fql044",
 "id_scheme": "DOI"
 },
 "abstract": "The chi-squared test is used to find the vocabulary most typical of seven different ICAME corpora, each representing the English used in a particular country. In a closely related study, Leech and Fallon (1992, Computer corpora – what do they tell us about culture? ICAME Journal, 16: 29–50) found differences in the vocabulary used in the Brown Corpus of American English and that the Lancaster–Oslo–Bergen Corpus of British English. They were mainly interested in those vocabulary differences which they assumed to be due to cultural differences between the United States and Britain, but we are equally interested in vocabulary differences which reveal linguistic preferences in the various countries in which English is spoken. Whether vocabulary differences are cultural or linguistic in nature, they can be used for the automatic classification according to variety of English of texts of unknown provenance. The extent to which the vocabulary differences between the corpora represent vocabulary differences between the varieties of English as a whole depends on the extent to which the corpora represent the full range of topics typical of their associated cultures, and thus there is a need for corpora designed to represent the topics and vocabulary of cultures or dialects, rather than stratified across a set range of topics and genres. This will require methods to determine the range of topics addressed in each culture, then methods to sample adequately from each topical domain.",
 "article_title": "Use of the Chi-Squared Test to Examine Vocabulary Differences in English Language Corpora Representing Seven Different Countries",
 "authors": [
 {
 "given": " Michael P.",
 "family": "Oakes",
 "affiliation": [
 {
 "original_name": "University of Sunderland, UK",
 "normalized_name": "University of Sunderland",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04p55hr04",
 "GRID": "grid.7110.7"
 }
 }
 ]
 },
 {
 "given": " Malcolm",
 "family": "Farrow",
 "affiliation": [
 {
 "original_name": "University of Newcastle upon Tyne, UK",
 "normalized_name": "Newcastle University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01kj2bm70",
 "GRID": "grid.1006.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-10-01",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql043",
 "identifier": {
 "string_id": "10.1093/llc/fql043",
 "id_scheme": "DOI"
 },
 "abstract": "This research applies dialectometric methods to purely syntactic dialect data. It will be shown that there is geographic cohesion in syntactic variation when viewed in the aggregate. The amount of syntactic variation which can be accounted for by geography will be determined. Dialectometric techniques will be used to develop an additive measure of syntactic differences. Multidimensional scaling will be applied to visualise the geographic distribution of the Dutch dialects with respect to syntactic variation in the aggregate. The Dutch dialect map based on a syntactic measure will be compared with a dialect map based on subjective judgements and a dialect map based on pronunciation differences to put the syntactic measurement results into perspective. An alternative way to measure syntactic distance will be presented and will provide indications for future research to more accurately quantify syntactic variation.",
 "article_title": "Measuring Syntactic Variation in Dutch Dialects",
 "authors": [
 {
 "given": " Marco René",
 "family": "Spruit",
 "affiliation": [
 {
 "original_name": "Meertens Instituut, Joan Muyskenweg 25, Postbus 94264, 1090 GG Amsterdam, The Netherlands",
 "normalized_name": "Meertens Institute",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/05kaxyq51",
 "GRID": "grid.450081.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-09-22",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql037",
 "identifier": {
 "string_id": "10.1093/llc/fql037",
 "id_scheme": "DOI"
 },
 "abstract": "Within the scope of the dialectometry project at Salzburg University, a windows application was developed that implements algorithms to support the dialectometric evaluation of altas data. Visual DialectoMetry (VDM) covers all the steps of the dialectometric evaluation procedure: management of preclassified atlas data, calculation of matrices, visualizations using different types of maps, and cluster analysis. This article assumes basic knowledge of VDMs features, but differs from the linguistic interpretations given in Goebl's article by concentrating on the application technology. VDM is written in C++ and uses the Microsoft Foundation Classes (MFC), a library that wraps the Windows application programming interface (API) and the JET library in C++ classes. It holds the data for every project in one MS ACCESS database file which is accessible via MFC. Users can choose from different projects—different linguistic atlases—or they may evaluate their own data with VDM after having converted and imported their data into the VDM database format. This article outlines the design of the VDM database as far as the storage of the data matrix is concerned. It discusses possibilities of performance optimization by distinguishing calculations that can be done in real time from calculations that have to be performed off-line (ahead of time). Despite the large number of geographical information systems (GIS) on the market the generation of thematic maps in real time is not a trivial task. The technical solution implemented in VDM generates maps from two layers: a Windows Meta File (WMF) and a view of polygon objects whose color is recalculated as response to user actions.",
 "article_title": "Database Design and Technical Solutions for the Management, Calculation, and Visualization of Dialect Mass Data",
 "authors": [
 {
 "given": " Edgar",
 "family": "Haimerl",
 "affiliation": [
 {
 "original_name": "Salzburg University, Dialectometry Project",
 "normalized_name": "University of Salzburg",
 "country": "Austria",
 "identifiers": {
 "ror": "https://ror.org/05gs8cd61",
 "GRID": "grid.7039.d"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-09-15",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql041",
 "identifier": {
 "string_id": "10.1093/llc/fql041",
 "id_scheme": "DOI"
 },
 "abstract": "Dialectometric techniques for analyzing variation in the aggregate are maturing rapidly, but there is still little agreement on how to extract linguistic structure from aggregate comparison. The present study explores one means of comparing aggregate analyses in order to determine linguistically concise characterizations of restrictions, essentially the use of factor analysis (FA). Using the Southern states data which Guy Lowman collected as part of LAMSAS, we apply FA to the vowels involved in aggregate analyses in order to determine which alternations in pronunciation tend most to co-occur.",
 "article_title": "Identifying Linguistic Structure in Aggregate Comparison",
 "authors": [
 {
 "given": " John",
 "family": "Nerbonne",
 "affiliation": [
 {
 "original_name": "Rijksuniversiteit Groningen, 9700 AS Groningen, The Netherlands",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-09-09",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql034",
 "identifier": {
 "string_id": "10.1093/llc/fql034",
 "id_scheme": "DOI"
 },
 "abstract": "Dialectometric techniques analyze linguistic variation quantitatively, allowing one to aggregate over what are frequently rebarbative geographic patterns of individual linguistic variants, such as which word is used for a particular concept in a language area, or which sounds are used in particular words. This leads to general formulations of the relation between linguistic variation and explanatory factors. Dialectometric techniques are maturing continuously, paving the way to genuinely new opportunities for the explanation of linguistic variation. These include, most prominently, techniques for analyzing syntactic variation, techniques for comparing the relative importance of different individual linguistic variables, techniques for comparing the relative importance of linguistic levels such as pronunciation, vocabulary, and/or prosody, and many more. This article serves as an introduction to a special issue of Literary and Linguistic Computing devoted to presenting a new work constituting Progress in Dialectometry: Toward Explanation.",
 "article_title": "Progress in Dialectometry: Toward Explanation",
 "authors": [
 {
 "given": " John",
 "family": "Nerbonne",
 "affiliation": [
 {
 "original_name": "University of Groningen, 9700 AS Groningen, The Netherlands",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 }
 ]
 },
 {
 "given": " William",
 "family": "Kretzschmar",
 "affiliation": [
 {
 "original_name": "University of Georgia, Athens, Georgia 30602, USA",
 "normalized_name": "University of Georgia",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00te3t702",
 "GRID": "grid.213876.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-09-09",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql040",
 "identifier": {
 "string_id": "10.1093/llc/fql040",
 "id_scheme": "DOI"
 },
 "abstract": "Since the early studies by Sokal (1988) and Cavalli-Sforza et al. (1989), there has been an increasing interest in depicting the history of human migrations by comparing genetic and linguistic differences that mirror different aspects of human history. Most of the literature concerns continental or macroregional patterns of variation, while regional and microregional scales were investigated less successfully. In this article we concentrate on the Netherlands, an area of only 40,000 km2.The focus of the article is on the analysis of surnames, which have been proven to be reliable genetic markers since in patrilineal systems they are transmitted—virtually unchanged—along generations, similar to a genetic locus on the Y-chromosome. We shall compare their distribution to that of dialect pronunciations, which are clearly culturally transmitted (children learn one of the linguistic varieties they are exposed to, normally that of their peers in the same area or that of their families). Since surnames, at the time of their introduction, were words subject to the same linguistic processes that otherwise result in dialect differences, one might expect the distribution of surnames to be correlated with dialect pronunciation differences. But we shall argue that once the collinear effects of geography on both genetics and cultural transmission are taken into account, there is in fact no statistically significant association between the two. We show that surnames cannot be taken as a proxy for dialect variation, even though they can be safely used as a proxy to Y-chromosome genetic variation.We work primarily with regression analyses, which show that both surname and dialect variation are strongly correlated with geographic distance. In view of this strong correlation, we focus on the residuals of the regression, which seeks to explain genetic and linguistic variation on the basis of geography (where geographic distance is the independent variable, and surname diversity or linguistic diversity is the dependent variable). We then seek a more detailed portrait of the geographic patterns of variation by identifying the ‘barriers’ (namely the areas where the residuals are greatest) by applying the Monmonier algorithm.We find the results historically and geographically insightful, hopefully leading to a deeper understanding of the role of the local migrations and cultural diffusion that are responsible for surname and dialect diversity.",
 "article_title": "To What Extent are Surnames Words? Comparing Geographic Patterns of Surname and Dialect Variation in the Netherlands",
 "authors": [
 {
 "given": " Franz",
 "family": "Manni",
 "affiliation": [
 {
 "original_name": "UMR 5145 CNRS, Musée de l'Homme MNHN, Paris, France",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Wilbert",
 "family": "Heeringa",
 "affiliation": [
 {
 "original_name": "Alfa-Informatica, Faculty of Arts, University of Groningen, The Netherlands",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 }
 ]
 },
 {
 "given": " John",
 "family": "Nerbonne",
 "affiliation": [
 {
 "original_name": "Alfa-Informatica, Faculty of Arts, University of Groningen, The Netherlands",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-09-09",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql032",
 "identifier": {
 "string_id": "10.1093/llc/fql032",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents elements of a Correspondence Analysis (CA) approach to the measurement of linguistic distances in dialectology. It argues that both linguistic and spatial factors are part of an explanation of geolinguistic variation, and it shows how the exploratory and graphical properties of CA can contribute to such an explanation. The application is a study of the different realizations of the phoneme /r/ in Acadian French, a dialect spoken in Canada. Data are from the Atlas linguistique du vocabulaire maritime acadien and include over 5,000 tokens from eighteen localities. Using chi-square distances, the analysis results in a two-dimensional space that arranges the localities along continua. Linguistic interpretation of this space, based on those features of /r/ that are identified as accounting for the structuring of these continua, suggests a hierarchy of phonological processes—including alternation between apical and dorsal articulations (in French words), and replacement of the retroflex rhotic found in English-origin words by apical and dorsal variants. Two external spatial factors, local concentration of francophone speakers and spheres of activity, are shown to correlate with the linguistic distances among localities.",
 "article_title": "Geographic Variation in Acadian French /r /: What Can Correspondence Analysis Contribute Toward Explanation?",
 "authors": [
 {
 "given": " Wladyslaw",
 "family": "Cichocki",
 "affiliation": [
 {
 "original_name": "University of New Brunswick, Canada",
 "normalized_name": "University of New Brunswick",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/05nkf0n29",
 "GRID": "grid.266820.8"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-09-07",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql033",
 "identifier": {
 "string_id": "10.1093/llc/fql033",
 "id_scheme": "DOI"
 },
 "abstract": "Aristotle long ago divided kinds of study into technē and epistēmē, which we can roughly translate into the modern terms ‘art’ and ‘science’. It is certainly the case that computational dialectologists do well with the Art (technē), in our technical construction and execution of statistical experiments, and we have two different prominent models to choose from, each one corresponding to a mode of scientific discovery, either to deductive or to inductive scientific procedure. But that in itself should not be the whole story. The Science (epistēmē) of computational dialectology lies in the creation of arguments from our statistical results that are appropriate to the scientific procedure that motivates us. It is not so clear that computational dialectologists have done so well with their Science. What do the results of the technical work really mean? In what way are they associated with particular choices of linguistic theory? Is it the case that, after all of our technical hard work, we find only what we are looking for? In this paper, I will suggest that an appropriate use of the technical results of computational dialectology requires that practitioners take a more subtle approach to the theory that motivates the study in the first place, especially to the relationship between perception and production of language.",
 "article_title": "Art and Science in Computational Dialectology",
 "authors": [
 {
 "given": "W. A.",
 "family": "Kretzschmar",
 "affiliation": [
 {
 "original_name": "University of Georgia, Athens, GA, USA",
 "normalized_name": "University of Georgia",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00te3t702",
 "GRID": "grid.213876.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-09-07",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql038",
 "identifier": {
 "string_id": "10.1093/llc/fql038",
 "id_scheme": "DOI"
 },
 "abstract": "In the period between 1999 and 2002, Jørn Almberg and Kristian Skarbø compiled a database which consists of recordings and phonetic transcriptions of translations of the fable ‘The North Wind and the Sun’ in about fifty Norwegian dialects. On the basis of fifteen of these recordings, Charlotte Gooskens carried out a perception experiment (Gooskens and Heeringa, 2004). In this experiment she investigated the distances between the fifteen dialects as perceived by the speakers themselves.On the basis of the phonetic transcriptions, Wilbert Heeringa (2004) measured computational linguistic distances between the fifteen Norwegian varieties (Gooskens and Heeringa, 2004). Distances were calculated by means of Levenshtein distance, which finds the minimum cost of changing one pronunciation into another by inserting, substituting or deleting phonetic segments. Gooskens and Heeringa (2004) correlated the perceptual distances with these computational distances and found a significant correlation of r = 0.67. In the computational distances, pronunciational, lexical, and morphological variation is processed, but these levels are not studied separately.The contribution of this article is that we measure pronunciational, lexical, and prosodic distances separately. Within pronunciational distances we distinguish between consonants and vowels on the one hand, and between substitutions and insertions/deletions on the other hand. When correlating the separate levels with perception and using multiple linear regression analyses we found that pronunciation is most important in perception and especially vowel substitutions play a major role.",
 "article_title": "The Relative Contribution of Pronunciational, Lexical, and Prosodic Differences to the Perceived Distances between Norwegian Dialects",
 "authors": [
 {
 "given": " Charlotte",
 "family": "Gooskens",
 "affiliation": [
 {
 "original_name": "Scandinavian Languages and Cultures, University of Groningen, Groningen, The Netherlands",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 }
 ]
 },
 {
 "given": " Wilbert",
 "family": "Heeringa",
 "affiliation": [
 {
 "original_name": "Humanities Computing, University of Groningen, Groningen, The Netherlands",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-09-07",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql039",
 "identifier": {
 "string_id": "10.1093/llc/fql039",
 "id_scheme": "DOI"
 },
 "abstract": "Previous studies of American English have identified a number of robust patterns involving the vowel system, such as the Northern Cities Chain Shift and the Southern Vowel Shift. These studies primarily employ methods which treat separately the phonetic properties of specific vowels as produced by individual speakers which are later assembled into complete vowel systems. While this provides a useful picture of production, it is not adequate for comparison with dialect perception studies, where interpretation of the results often requires some understanding of the correlations among linguistic features and between those features and individual talkers. We conducted a factor analysis of the duration and first and second formant frequencies of each of the fourteen vowels produced by forty-eight speakers representing six regional varieties of American English and both genders. The data were submitted to factor analysis using maximum likelihood estimation and Varimax rotation. Results confirmed significant correlations between regional dialect and acoustic–phonetic properties of the vowel systems, although these patterns are complicated by interactions with gender. These results illustrate the utility of factor analytic methods in examining systematic variation across an entire linguistic system such as the vowels.",
 "article_title": "North American English Vowels: A Factor-analytic Perspective",
 "authors": [
 {
 "given": " Cynthia G.",
 "family": "Clopper",
 "affiliation": [
 {
 "original_name": "Indiana University, Bloomington, IN 47405, USA",
 "normalized_name": "Indiana University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/01kg8sb98",
 "GRID": "grid.257410.5"
 }
 }
 ]
 },
 {
 "given": " John C.",
 "family": "Paolillo",
 "affiliation": [
 {
 "original_name": "Indiana University, Bloomington, IN 47405, USA",
 "normalized_name": "Indiana University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/01kg8sb98",
 "GRID": "grid.257410.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-09-06",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql036",
 "identifier": {
 "string_id": "10.1093/llc/fql036",
 "id_scheme": "DOI"
 },
 "abstract": "The two West-Germanic languages Dutch and Afrikaans are so closely related that they can be expected to be mutually intelligible to a large extent. The present investigation focuses on written language. Comprehension was established by means of cloze tests on the basis of two newspaper articles. Results suggest that it is easier for Dutch subjects to understand written Afrikaans than it is for South African subjects to understand written Dutch. In order to explain the results, attitudes as well as several types of linguistic distances were assessed. The relations between attitude scales and intelligibility scores were few and weak. Asymmetries in the linguistic relationships between the two languages are probably more important, especially the asymmetries in the number of noncognates and the opacity of the relatedness of cognates. These asymmetries are caused by historical developments in Dutch and Afrikaans, with respect to the lexicon, grammar, and spelling.",
 "article_title": "Mutual Comprehensibility of Written Afrikaans and Dutch: Symmetrical or Asymmetrical?",
 "authors": [
 {
 "given": " Charlotte",
 "family": "Gooskens",
 "affiliation": [
 {
 "original_name": "Department of Scandinavian Studies, University of Groningen, Groningen, The Netherlands",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 }
 ]
 },
 {
 "given": " Renée",
 "family": "van Bezooijen",
 "affiliation": [
 {
 "original_name": "Department of Linguistics, Radboud University Nijmegen, Nijmegen, The Netherlands",
 "normalized_name": "Radboud University Nijmegen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/016xsfp80",
 "GRID": "grid.5590.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-08-27",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql016",
 "identifier": {
 "string_id": "10.1093/llc/fql016",
 "id_scheme": "DOI"
 },
 "abstract": "This article presents a disambiguation method which diminishes the functional combinations of the words of a sentence taking into account the context in which they appear. This process is built in two phases: the first phase is based on the local syntactic structures of the Spanish language and reaches an average yield of 87%. The second one is supported by syntactic tree representation and pushes the results up to an approximate high end of 96%. This process constitutes the starting point towards an automated syntactic analysis.",
 "article_title": "Functional Disambiguation Based on Syntactic Structures",
 "authors": [
 {
 "given": " Octavio",
 "family": "Santana Suárez",
 "affiliation": [
 {
 "original_name": "University of Las Palmas de Gran Canaria",
 "normalized_name": "University of Las Palmas de Gran Canaria",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01teme464",
 "GRID": "grid.4521.2"
 }
 }
 ]
 },
 {
 "given": " José Rafael",
 "family": "Pérez Aguiar",
 "affiliation": [
 {
 "original_name": "University of Las Palmas de Gran Canaria",
 "normalized_name": "University of Las Palmas de Gran Canaria",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01teme464",
 "GRID": "grid.4521.2"
 }
 }
 ]
 },
 {
 "given": " Luis",
 "family": "Losada García",
 "affiliation": [
 {
 "original_name": "University of Las Palmas de Gran Canaria",
 "normalized_name": "University of Las Palmas de Gran Canaria",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01teme464",
 "GRID": "grid.4521.2"
 }
 }
 ]
 },
 {
 "given": " Francisco Javier",
 "family": "Carreras Riudavets",
 "affiliation": [
 {
 "original_name": "University of Las Palmas de Gran Canaria",
 "normalized_name": "University of Las Palmas de Gran Canaria",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01teme464",
 "GRID": "grid.4521.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-06-24",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "21",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql031",
 "identifier": {
 "string_id": "10.1093/llc/fql031",
 "id_scheme": "DOI"
 },
 "abstract": "This special edition of Literary and Linguistic Computing comprises a selection of the papers presented at the 17th Joint International Conference of the Association for Computers and the Humanities (ACH) and the Association for Literary and Linguistic Computing (ALLC), which took place at the University of Victoria, British Columbia (Canada), from 15–18 June 2005. The conference was a great success thanks to the efforts of the local organizing team headed by Peter Liddell and including Scott Gerrity, Stewart Arneil, Martin Holmes, Greg Newton, Judy Nazar and Ray Siemens. The academic programme was compiled by an international programme committee chaired by Alejandro Bia and comprising Julia Flanders, Neil Fraistat, Simon Horobin, Joseph Jones, Lisa Lena Opas-Hänninen, Concha Sanz-Miguel, Susan Schreibman and Michael Sperberg-McQueen.",
 "article_title": "Introduction",
 "authors": [
 {
 "given": " Alejandro G.",
 "family": "Bia",
 "affiliation": [
 {
 "original_name": "Guest Editors of this Special Issue",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Lisa Lena",
 "family": "Opas-Hänninen",
 "affiliation": [
 {
 "original_name": "Guest Editors of this Special Issue",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-06-24",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "21",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql023",
 "identifier": {
 "string_id": "10.1093/llc/fql023",
 "id_scheme": "DOI"
 },
 "abstract": "Ever since its initial publication four hundred years ago, thousands of editions, most often illustrated, have been published of Cervantes' masterpiece, Don Quixote. Imagery has become an integral part of the reception and interpretation of the text. To date, a comprehensive collection of these images, the textual iconography of the Quixote, has not been published. We report in this paper on overcoming two key obstacles: limitations on the availability of materials and limitations due to the technical and financial characteristics of print-based dissemination. Our digital iconography makes a rich artistic tradition accessible to readers for the first time, and reveals a wealth of information about the historical, cultural, and literary contexts into which the Quixote has been placed.",
 "article_title": "Visual Knowledge: Textual Iconography of the Quixote, a Hypertextual Archive",
 "authors": [
 {
 "given": " Eduardo",
 "family": "Urbina",
 "affiliation": [
 {
 "original_name": "Texas A&M University, College Station, TX, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Richard",
 "family": "Furuta",
 "affiliation": [
 {
 "original_name": "Texas A&M University, College Station, TX, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Steven Escar",
 "family": "Smith",
 "affiliation": [
 {
 "original_name": "Texas A&M University, College Station, TX, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Neal",
 "family": "Audenaert",
 "affiliation": [
 {
 "original_name": "Texas A&M University, College Station, TX, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Jie",
 "family": "Deng",
 "affiliation": [
 {
 "original_name": "Texas A&M University, College Station, TX, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Carlos",
 "family": "Monroy",
 "affiliation": [
 {
 "original_name": "Texas A&M University, College Station, TX, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-04-21",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "21",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql021",
 "identifier": {
 "string_id": "10.1093/llc/fql021",
 "id_scheme": "DOI"
 },
 "abstract": "We present our experience in developing an on-line infrastructure to support collaborative analysis of text, which we distinguish from existing, well-explored efforts to create annotative electronic editions. Using Faulkner's The Sound and the Fury as our primary text case, we outline the features and rationale of our collaborative framework, called Callimachus. We present our findings concerning that text and explore how these findings only became possible after breaking with the received wisdom concerning the application of XML and the Text Encoding Initiative to such analytical projects.",
 "article_title": "Callimachus—Avoiding the Pitfalls of XML for Collaborative Text Analysis",
 "authors": [
 {
 "given": " Jeff",
 "family": "Smith",
 "affiliation": [
 {
 "original_name": "University of Saskatchewan, Canada",
 "normalized_name": "University of Saskatchewan",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/010x8gc63",
 "GRID": "grid.25152.31"
 }
 }
 ]
 },
 {
 "given": " Joel",
 "family": "Deshaye",
 "affiliation": [
 {
 "original_name": "University of Saskatchewan, Canada",
 "normalized_name": "University of Saskatchewan",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/010x8gc63",
 "GRID": "grid.25152.31"
 }
 }
 ]
 },
 {
 "given": " Peter",
 "family": "Stoicheff",
 "affiliation": [
 {
 "original_name": "University of Saskatchewan, Canada",
 "normalized_name": "University of Saskatchewan",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/010x8gc63",
 "GRID": "grid.25152.31"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-04-21",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "21",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql020",
 "identifier": {
 "string_id": "10.1093/llc/fql020",
 "id_scheme": "DOI"
 },
 "abstract": "In this article, we describe our interdisciplinary project ‘Rule-based search in text databases with nonstandard orthography (RSNSR)’ in support of the conservation of cultural heritage, especially for the German reception of the philosopher Nietzsche. We present a rule-based fuzzy search engine that allows users to retrieve text data independently of its orthographical realization. The rules used are derived from statistical analyses, historical publications, linguistic principles, and expert knowledge. Our Web-based tool is intended for experts as well as interested amateurs. Along with its present features, further functions are currently worked out. Among them are automatic rule derivation and finer result classification through a generalized Levenshtein similarity measure. Our work is associated with the recently launched project Deutsch Diachron Digital (DDD) to build a complete diachronic corpus of German for the first time with texts from the ninth century (Old High German) to the present (Modern German).",
 "article_title": "Rule-based Search in Text Databases with Nonstandard Orthography",
 "authors": [
 {
 "given": " Thomas",
 "family": "Pilz",
 "affiliation": [
 {
 "original_name": "Institute of Computer Science and Interactive Systems, University of Duisburg-Essen, Germany",
 "normalized_name": "University of Duisburg-Essen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/04mz5ra38",
 "GRID": "grid.5718.b"
 }
 }
 ]
 },
 {
 "given": " Wolfram",
 "family": "Luther",
 "affiliation": [
 {
 "original_name": "Institute of Computer Science and Interactive Systems, University of Duisburg-Essen, Germany",
 "normalized_name": "University of Duisburg-Essen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/04mz5ra38",
 "GRID": "grid.5718.b"
 }
 }
 ]
 },
 {
 "given": " Norbert",
 "family": "Fuhr",
 "affiliation": [
 {
 "original_name": "Institute of Computer Science and Interactive Systems, University of Duisburg-Essen, Germany",
 "normalized_name": "University of Duisburg-Essen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/04mz5ra38",
 "GRID": "grid.5718.b"
 }
 }
 ]
 },
 {
 "given": " Ulrich",
 "family": "Ammon",
 "affiliation": [
 {
 "original_name": "Institute of German Language and Literature Studies, University of Duisburg-Essen, Germany",
 "normalized_name": "University of Duisburg-Essen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/04mz5ra38",
 "GRID": "grid.5718.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-04-21",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql015",
 "identifier": {
 "string_id": "10.1093/llc/fql015",
 "id_scheme": "DOI"
 },
 "abstract": "This article is based on a session given by the authors at the ACH/ALLC conference at the University of Victoria in June 2005. It discusses the prospects for partnership between the humanities and computing from the alternative perspective afforded by Empirical Modelling (EM). Perceived dualities that separate the two cultures of science and art are identified as the primary impediment to this partnership. A vision for ‘human computing’ that promises to dissolve these dualities is outlined. The key characteristics and potential for EM for the humanities are illustrated with reference to a modelling exercise on the theme of Schubert's Erlkönig. This highlights how each of the six varieties of modelling identified by McCarty can be represented within an EM model. The implications of EM are discussed with reference to McCarty's account of the key role for modelling in the humanities, in relation to James's ‘philosophic attitude’ of Radical Empiricism and to ideas from phenomenological sources.",
 "article_title": "Human Computing--Modelling with Meaning",
 "authors": [
 {
 "given": " Meurig",
 "family": "Beynon",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, University of Warwick, Coventry, UK",
 "normalized_name": "University of Warwick",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01a77tt86",
 "GRID": "grid.7372.1"
 }
 }
 ]
 },
 {
 "given": " Steve",
 "family": "Russ",
 "affiliation": [
 {
 "original_name": "Department of Computer Science, University of Warwick, Coventry, UK",
 "normalized_name": "University of Warwick",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01a77tt86",
 "GRID": "grid.7372.1"
 }
 }
 ]
 },
 {
 "given": " Willard",
 "family": "McCarty",
 "affiliation": [
 {
 "original_name": "Centre for Computing in the Humanities, King's College London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-04-14",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql017",
 "identifier": {
 "string_id": "10.1093/llc/fql017",
 "id_scheme": "DOI"
 },
 "abstract": "The text ontology debates inspired by the descriptive encoding practices of the Text Encoding Initiative (TEI) community have been conducted between literary theorists concerned with the adequacy of such encoding to capture the interpretative and playful aspects of literary appreciation on the one hand, and those who regard encoding as one of the formal sciences and seek greater disambiguation in the interests of more efficient machine processing. We argue for a practice-oriented view that has not been represented adequately by either of these poles. Our position has received unexpected support from the systematic realist philosophy of John Anderson which we encountered in digitizing his lecture notes held by the University of Sydney Archives. The process of encoding the lecture notes informed our understanding of the problems of encoding primary source materials, but Anderson's realism also located the space we sought to occupy in the TEI debates between the technical, formal model of encoding and the anti-realist preferences of many literary scholars. In this article, we argue on the basis of our reflections the need for further empirical studies of real world encoding practices as these new documentary forms are integrated into existing institutional and informational processes.",
 "article_title": "In the Philosophy Room: Australian Realism and Digital Content Development",
 "authors": [
 {
 "given": " Creagh",
 "family": "Cole",
 "affiliation": [
 {
 "original_name": "Scholarly Electronic Text & Image Service, The University of Sydney",
 "normalized_name": "University of Sydney",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/0384j8v12",
 "GRID": "grid.1013.3"
 }
 }
 ]
 },
 {
 "given": " Paul",
 "family": "Scifleet",
 "affiliation": [
 {
 "original_name": "Discipline of Information Systems, Faculty of Economics & Business, The University of Sydney",
 "normalized_name": "University of Sydney",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/0384j8v12",
 "GRID": "grid.1013.3"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-04-13",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql022",
 "identifier": {
 "string_id": "10.1093/llc/fql022",
 "id_scheme": "DOI"
 },
 "abstract": "Humanities Computing is an emergent field. The activities described as ‘Humanities Computing’ continue to expand in number and sophistication, yet no concrete definition of the field exists, and there are few academic departments that specialize in this area. Most introspection regarding the role, meaning, and focus of “Humanities Computing” has come from a practical and pragmatic perspective from scholars and educators within the field itself. This article provides an alternative, externalized, viewpoint of the focus of Humanities Computing, by analysing the discipline through its community, research, curriculum, teaching programmes, and the message they deliver, either consciously or unconsciously, about the scope of the discipline. It engages with Educational Theory to provide a means to analyse, measure, and define the field, and focuses specifically on the ACH/ALLC 2005 Conference to identify and analyse those who are involved with the humanities computing community.",
 "article_title": "Disciplined: Using Educational Studies to Analyse ‘Humanities Computing’",
 "authors": [
 {
 "given": " Melissa",
 "family": "Terras",
 "affiliation": [
 {
 "original_name": "School of Library, Archive and Information Studies, University College",
 "normalized_name": "Moravská Vysoká Skola Olomouc",
 "country": "Czechia",
 "identifiers": {
 "ror": "https://ror.org/00mwh6v70",
 "GRID": "grid.466028.e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-04-13",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "21",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql019",
 "identifier": {
 "string_id": "10.1093/llc/fql019",
 "id_scheme": "DOI"
 },
 "abstract": "Despite a century of research, statistical and computational methods for authorship attribution are neither reliable, well-regarded, widely used, or well-understood. This article presents a survey of the current state of the art as well as a framework for uniform and unified development of a tool to apply the state of the art, despite the wide variety of methods and techniques used. The usefulness of the framework is confirmed by the development of a tool using that framework that can be applied to authorship analysis by researchers without a computing specialization. Using this tool, it may be possible both to expand the pool of available researchers as well as to enhance the quality of the overall solutions [for example, by incorporating improved algorithms as discovered through empirical analysis (Juola, P. (2004a). Ad-hoc Authorship Attribution Competition. In Proceedings 2004 Joint International Conference of the Association for Literary and Linguistic Computing and the Association for Computers and the Humanities (ALLC/ACH 2004), Göteborg, Sweden)].",
 "article_title": "A Prototype for Authorship Attribution Studies",
 "authors": [
 {
 "given": " Patrick",
 "family": "Juola",
 "affiliation": [
 {
 "original_name": "Duquesne University, Pittsburgh",
 "normalized_name": "Duquesne University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/02336z538",
 "GRID": "grid.255272.5"
 }
 }
 ]
 },
 {
 "given": " John",
 "family": "Sofko",
 "affiliation": [
 {
 "original_name": "Duquesne University, Pittsburgh",
 "normalized_name": "Duquesne University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/02336z538",
 "GRID": "grid.255272.5"
 }
 }
 ]
 },
 {
 "given": " Patrick",
 "family": "Brennan",
 "affiliation": [
 {
 "original_name": "Duquesne University, Pittsburgh",
 "normalized_name": "Duquesne University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/02336z538",
 "GRID": "grid.255272.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-04-13",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "21",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql018",
 "identifier": {
 "string_id": "10.1093/llc/fql018",
 "id_scheme": "DOI"
 },
 "abstract": "PériCulture is the name of a research project at the Université de Montréal which is part of a larger project based at the Université de Sherbrooke. The parent project aimed to form a research network for managing Canadian digital cultural content. The general research objective of PériCulture was to study indexing methods for web-based non-textual cultural content, specifically still images. The research results reported here build on work in image indexing and automatic (text) indexing by studying properties of text associated with images in a networked environment to try to gain some understanding of how the ancillary text associated with images on web pages can be exploited to index the corresponding images. We studied this question in the context of selected web sites, i.e. that contained multimedia objects, that had text associated with these objects (broader than file names and captions), that were bilingual (English and French), and that housed Canadian digital cultural content. We identified keywords that were useful in indexing and studied their proximity to the object described. Potential indexing terms were identified in various HTML tags and full text (each considered a different source of ancillary text). Our study found that a large number of useful indexing terms are available in the ancillary text of many web sites with cultural content, and that ancillary text of different sources have variable usefulness in retrieval. Our results suggest that these terms can be manipulated in a number of ways in automated retrieval systems to improve search results.",
 "article_title": "Using Ancillary Text to Index Web-based Multimedia Objects",
 "authors": [
 {
 "given": " Lyne",
 "family": "Da Sylva",
 "affiliation": [
 {
 "original_name": "École de bibliothéconomie et des sciences de l’information, Université de Montréal",
 "normalized_name": "University of Montreal",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/0161xgx34",
 "GRID": "grid.14848.31"
 }
 }
 ]
 },
 {
 "given": " James M.",
 "family": "Turner",
 "affiliation": [
 {
 "original_name": "École de bibliothéconomie et des sciences de l’information, Université de Montréal",
 "normalized_name": "University of Montreal",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/0161xgx34",
 "GRID": "grid.14848.31"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-04-11",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "21",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fql014",
 "identifier": {
 "string_id": "10.1093/llc/fql014",
 "id_scheme": "DOI"
 },
 "abstract": "This study investigated the automatic modelling of space and time in narratives involving dining in a restaurant. We built a program that (1) uses information extraction techniques to convert narrative texts into templates containing key information about the dining episodes discussed in the narratives, (2) constructs commonsense reasoning problems from the templates, (3) uses commonsense reasoning and a commonsense knowledge base to build models of the dining episodes, and (4) generates and answers questions by consulting the models. We describe the program and present the results of running it on a corpus of web texts and American literature.",
 "article_title": "Modelling Space and Time in Narratives about Restaurants",
 "authors": [
 {
 "given": " Erik T.",
 "family": "Mueller",
 "affiliation": [
 {
 "original_name": "IBM Thomas J. Watson Research Center, PO Box 704, Yorktown Heights, NY 10598, USA",
 "normalized_name": "IBM Research – Thomas J. Watson Research Center",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0265w5591",
 "GRID": "grid.481554.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-04-05",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi067",
 "identifier": {
 "string_id": "10.1093/llc/fqi067",
 "id_scheme": "DOI"
 },
 "abstract": "This article describes the operation of two new tests of authorship and offers some results. Both tests rely on controlled contrasts of word-frequency and both exclude the very common words, which have been put to such good use in recent years. One test treats of words used with some consistency by a target-author but more sporadically by others. The second treats of words used sporadically by the target-author but not by most others. (The inclusion of words that some other authors use avoids the strict constraint that has impoverished this form of evidence.) In suitable cases, both tests prove very accurate. The fact that evidence of authorship can be detected in these three distinct frequency-strata helps to explain why such tests should work at all and so encourages the development of even better ones.",
 "article_title": "All the Way Through: Testing for Authorship in Different Frequency Strata",
 "authors": [
 {
 "given": " John",
 "family": "Burrows",
 "affiliation": [
 {
 "original_name": "University of Newcastle, Australia",
 "normalized_name": "University of Newcastle Australia",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00eae9z71",
 "GRID": "grid.266842.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2006-01-07",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi047",
 "identifier": {
 "string_id": "10.1093/llc/fqi047",
 "id_scheme": "DOI"
 },
 "abstract": "Accuracy of transcription is vital when preparing a scholarly version of an existing document. This process has not changed with the advent of electronic editions. In fact, ensuring the continued accuracy of a transcription in the digital realm is more difficult because a file, unlike a piece of paper, does not retain information about its previous states and it is therefore possible that accidental changes can go undetected unless the content is continually checked against the original.This article presents a new, character-set-independent, programming algorithm that allows for the ongoing authentication of the textual content of files being marked up with SGML-like languages. The study also describes an implementation of this algorithm and how it can be used with existing software tools to provide a more efficient and trusted editing environment for creating and editing marked-up files.The Just In Time Authentication Mechanism (JITAM) algorithm was developed in response to the need for some form of automated authentication mechanism for projects already employing embedded markup and is seen as a preparatory step that editors can take with their projects before making the leap to the more versatile Just In Time Markup (JITM) system.",
 "article_title": "A New Technique for Authenticating Content in Evolving Marked-up Documents",
 "authors": [
 {
 "given": " Phillip",
 "family": "Berrie",
 "affiliation": [
 {
 "original_name": "University of New South Wales at ADFA, Australia",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-11-04",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "22",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi050",
 "identifier": {
 "string_id": "10.1093/llc/fqi050",
 "id_scheme": "DOI"
 },
 "abstract": "This essay emerges from the recent debates in editorial theory and, on the practical level, from a project for producing electronic scholarly editions. It reflects on the nature of text, explores the implications for text encoding in relation to recent debate, and outlines a methodology using stand-off markup within which text encoding can respond to the theoretically enunciated problems.",
 "article_title": "Text-encoding, Theories of the Text, and the ‘Work-Site’",
 "authors": [
 {
 "given": "Paul",
 "family": "Eggert",
 "affiliation": [
 {
 "original_name": "University of New South Wales at ADFA, Canberra, Australia",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-10-26",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "20",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi049",
 "identifier": {
 "string_id": "10.1093/llc/fqi049",
 "id_scheme": "DOI"
 },
 "abstract": "Imitative texts of high quality are of some importance to students of attribution, especially those who use computational methods. The authorship of such texts is always likely to be difficult to demonstrate. In some cases, the identity of the author is a question of interest to literary scholars. Even when that is not so, students of attribution face a challenge. If we cannot distinguish between original and imitation in such cases, we must always concede that an imitator may have been at work. Shamela (1741) has always been regarded as a brilliant parody. When it is subjected to our standard common-words tests of authorship, it yields mixed results. A new procedure, in which special word-lists are established according to a predetermined set of rules, proves more effective. It needs, however, to be tried in other cases.",
 "article_title": "Who wrote Shamela? Verifying the Authorship of a Parodic Text",
 "authors": [
 {
 "given": " John",
 "family": "Burrows",
 "affiliation": [
 {
 "original_name": "University of Newcastle, Shortland, Australia",
 "normalized_name": "University of Newcastle Australia",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00eae9z71",
 "GRID": "grid.266842.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-10-26",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "20",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi048",
 "identifier": {
 "string_id": "10.1093/llc/fqi048",
 "id_scheme": "DOI"
 },
 "abstract": "Linguistics and musicology, along with other fieldwork-based disciplines, have obligations to facilitate access to research results by the communities whose cultural heritage is recorded and analysed, especially when the languages and musics in question are otherwise little documented, have few speakers or performers, and are threatened by the global dominance of English. This article presents the early results of our planning for establishment of a digital resource to preserve and make accessible recordings and other documentation of Murrinh-patha public dance-songs at Wadeye, a remote Indigenous community in Australia's Northern Territory. With the recent establishment of the Wadeye Knowledge Centre, copies of recordings previously left in the community by researchers have been digitized and made available through computer workstations. Many of these digitized recordings, however, have poor or no documentation and thus are difficult to locate and access. The most urgent task is to work with elderly performers and composers to assemble metadata about the oldest recordings of songs and who composed and performed them. In order to maximise local accessibility and use, both elders and young people will be involved in planning and creation of a bilingual search interface to the collection. Planning must also consider sustainability issues through integration with other local initiatives, appropriate use of open standards and formats, locally sustainable technical platforms, and regular backup and maintenance.",
 "article_title": "Communities of Interest: Issues in Establishing a Digital Resource on Murrinh-patha song at Wadeye (Port Keats), NT",
 "authors": [
 {
 "given": " Linda",
 "family": "Barwick",
 "affiliation": [
 {
 "original_name": "University of Sydney, Australia",
 "normalized_name": "University of Sydney",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/0384j8v12",
 "GRID": "grid.1013.3"
 }
 }
 ]
 },
 {
 "given": " Allan",
 "family": "Marett",
 "affiliation": [
 {
 "original_name": "University of Sydney, Australia",
 "normalized_name": "University of Sydney",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/0384j8v12",
 "GRID": "grid.1013.3"
 }
 }
 ]
 },
 {
 "given": " Michael",
 "family": "Walsh",
 "affiliation": [
 {
 "original_name": "University of Sydney, Australia",
 "normalized_name": "University of Sydney",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/0384j8v12",
 "GRID": "grid.1013.3"
 }
 }
 ]
 },
 {
 "given": " Nicholas",
 "family": "Reid",
 "affiliation": [
 {
 "original_name": "University of New England, Australia",
 "normalized_name": "University of New England",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/02n2ava60",
 "GRID": "grid.266826.e"
 }
 }
 ]
 },
 {
 "given": " Lysbeth",
 "family": "Ford",
 "affiliation": [
 {
 "original_name": "Batchelor Institute of Indigenous Tertiary Education. Australia",
 "normalized_name": "Batchelor Institute of Indigenous Tertiary Education",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/03n0gvg35",
 "GRID": "grid.431331.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-10-26",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "20",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi046",
 "identifier": {
 "string_id": "10.1093/llc/fqi046",
 "id_scheme": "DOI"
 },
 "abstract": "This article focuses on the conceptual issues faced by scholarly editors and textual studies specialists. Theoretical debate in this general field is still active as digital texts present special problems and magnify others. Older theory and methodology are hampered by unacknowledged, sometimes inappropriate cultural values and other limitations, and are not always useful in connection with digital texts. Nevertheless, the distinction between the abstract work and its concrete expression is influential both within and outside the field. In this approach, the concept of authenticity relates to the degree of change a work undergoes or the accuracy of the ‘instructions’ for its reconstitution. Whether the digital text is best thought of as immaterial or material is not as crucial as might first appear. The way a digital text is made visible is important, though potentially paradoxical. In order to be workable, the concept of authentication by instructions needs further technical assistance, like that provided by the Just-in-Time Markup System. But, despite its limitations, traditional textual scholarship still has much to offer textual studies in digital environments.",
 "article_title": "Original, Authentic, Copy: Conceptual Issues in Digital Texts",
 "authors": [
 {
 "given": " Graham",
 "family": "Barwell",
 "affiliation": [
 {
 "original_name": "University of Wollongong, Australia",
 "normalized_name": "University of Wollongong",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00jtmb277",
 "GRID": "grid.1007.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-10-26",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "20",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi064",
 "identifier": {
 "string_id": "10.1093/llc/fqi064",
 "id_scheme": "DOI"
 },
 "abstract": "The emergence of new media technologies and their integration into the creative process has led to an explosion of hybrid works whose complexities (both conceptual and material) challenge received ideas about the nature of art and its relationship with the future. ‘Variable media’ has been coined as a descriptor for creative projects incorporating elements whose viability within future incarnations of the same works may be compromised. The flexible and imaginative approach taken by the innovative new media arts community has much to offer information professionals facing the conservation challenges presented by digital materials. By the same token, the potential application of principles emerging in the field of digital preservation extends well beyond digital resources to encompass works of art and creative enterprises whose material constitution paradoxically threatens them with extinction. The paramount role played by ‘process’ (as opposed to ‘object’) has led us to explore various metadata development initiatives, including an extensive online questionnaire developed by the Variable Media Initiative at the Guggenheim Museum in New York, and the IFLA Requirements of Bibliographic Standards, with a view to combining elements of each and developing a new model to accommodate the complex documentation of the life cycles of new media artworks and of digital objects.",
 "article_title": "Cryogenics and Creativity: The Frankenstein Factor in Cultural Preservation",
 "authors": [
 {
 "given": " Eileen",
 "family": "Maitland",
 "affiliation": [
 {
 "original_name": "University of Glasgow",
 "normalized_name": "University of Glasgow",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/00vtgdb53",
 "GRID": "grid.8756.c"
 }
 }
 ]
 },
 {
 "given": " Cordelia",
 "family": "Hall",
 "affiliation": [
 {
 "original_name": "University of Glasgow",
 "normalized_name": "University of Glasgow",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/00vtgdb53",
 "GRID": "grid.8756.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-10-31",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi062",
 "identifier": {
 "string_id": "10.1093/llc/fqi062",
 "id_scheme": "DOI"
 },
 "abstract": "Stemming from the precomputer era, respectable historical dictionaries like those originating from the 19th century, often need considerable adaptation to make their wealth of linguistic material as fully exploitable as digital dictionaries of modern design do. With a view to increasing retrieval possibilities, two combined improvements will be given particular attention here, viz. uniformization of both source references and dates, mainly accompanying the numerous quotations which serve as evidence in lexicographical articles, and the insertion of new dates, wherever still missing. In this article, we shall study the case of the Dutch Woordenboek der Nederlandsche Taal, where strategies to cope with the problem may be illustrated well. The focus of the article is on how regular expressions, in the form of prefabricated templates and scripts, allow to bring about a gradual but effective transformation.",
 "article_title": "Computerized Restoration of Historical Dictionaries: Uniformization and Date-assigning in Dictionary Quotations of the Woordenboek der Nederlandsche Taal",
 "authors": [
 {
 "given": " Dirk",
 "family": "Kinable",
 "affiliation": [
 {
 "original_name": "Institute for Dutch Lexicology, Leiden, The Netherlands",
 "normalized_name": "Instituut voor Nederlandse Lexicologie",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/04m5bjk54",
 "GRID": "grid.425282.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-10-28",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi063",
 "identifier": {
 "string_id": "10.1093/llc/fqi063",
 "id_scheme": "DOI"
 },
 "abstract": "How to measure proximities and oppositions in large text corpora? Intertextual distance provides a simple and interesting solution. Its properties make it a good tool for text classification, and especially for tree-analysis which is fully presented and discussed here. In order to measure the quality of this classification, two indices are proposed. The method presented provides an accurate tool for literary studies—as is demonstrated by applying it to two areas of French literature, Racine's tragedies and an authorship attribution experiment.",
 "article_title": "A Tool for Literary Studies: Intertextual Distance and Tree Classification",
 "authors": [
 {
 "given": " Cyril",
 "family": "Labbé",
 "affiliation": [
 {
 "original_name": "Grenoble I University, France",
 "normalized_name": "Joseph Fourier University",
 "country": "France",
 "identifiers": {
 "ror": "https://ror.org/02aj0kh94",
 "GRID": "grid.9621.c"
 }
 }
 ]
 },
 {
 "given": " Dominique",
 "family": "Labbé",
 "affiliation": [
 {
 "original_name": "Grenoble II University, France",
 "normalized_name": "Joseph Fourier University",
 "country": "France",
 "identifiers": {
 "ror": "https://ror.org/02aj0kh94",
 "GRID": "grid.9621.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-10-28",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi051",
 "identifier": {
 "string_id": "10.1093/llc/fqi051",
 "id_scheme": "DOI"
 },
 "abstract": "Te Ara, the Encyclopedia of New Zealand was launched in 2005, funded by the New Zealand government. It was designed from the beginning to be published online, perhaps the first national encyclopedia to be born digital. It complements the works of M. McKinnon (1997, The New Zealand Historical Atlas. Auckland: David Bateman Ltd.) and W. H. Oliver and C. Orange (1990–2000, The Dictionary of New Zealand Biography, five volumes. Wellington: Allen & Unwin and Department of Internal Affairs). The encyclopedia is designed to be the first port of call for reliable information about New Zealand and a gateway to the country's natural and cultural treasures. Its digital form allows searchability, linking to other sites, cumulative publication (one ‘theme’ a year), regular updating, and a parallel publication of a digitized 1966 encyclopedia, as well as multimedia content and interactive aspects such as user-defined graphs. In addition, it allows material to be layered for different audiences, from younger school children to scholars and researchers, and with sections in Maori as well as English. Eventually, as attitudes change and new discoveries are made, some of the earliest entries will need rewriting. The encyclopedia will mutate and be in a constant state of revision and self-criticism. The online encyclopedia of a nation is a project full of promise, which it is hoped others will soon emulate.",
 "article_title": "Planning an Online Encyclopedia of a Nation: The Example of Te Ara, the Encyclopedia of New Zealand",
 "authors": [
 {
 "given": " Jock",
 "family": "Phillips",
 "affiliation": [
 {
 "original_name": "Ministry for Culture and Heritage, Wellington, New Zealand",
 "normalized_name": "Ministry for Culture and Heritage",
 "country": "New Zealand",
 "identifiers": {
 "ror": "https://ror.org/04600bt44",
 "GRID": "grid.453502.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-10-01",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "20",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi040",
 "identifier": {
 "string_id": "10.1093/llc/fqi040",
 "id_scheme": "DOI"
 },
 "abstract": "Existing software for handling textual variants suffers from a number of faults, and is generally designed for a narrow range of text types. This paper develops a new data structure for variants, suitable for a wider range of texts, which also solves most of the problems associated with the representation of variant data. A prototype applet, which can graphically display the new data structure is described, as also the current state of the editor being developed from it.",
 "article_title": "Graphical Editor for Manuscripts",
 "authors": [
 {
 "given": " Desmond",
 "family": "Schmidt",
 "affiliation": [
 {
 "original_name": "University of Queensland, Brisbane, Australia",
 "normalized_name": "University of Queensland",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/00rqy9422",
 "GRID": "grid.1003.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-09-16",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi045",
 "identifier": {
 "string_id": "10.1093/llc/fqi045",
 "id_scheme": "DOI"
 },
 "abstract": "Digital-only subscription is increasingly popular as a means of journal and book delivery among our major libraries. The advantages of digital delivery are apparent, but unlike traditional publications, digital subscriptions are commonly not housed within national boundaries. With an increasingly large proportion of book and journal subscriptions being digital only, this presents an as yet unquantified risk to the collections of the major research and state libraries. At present very little attention is directed to the continuity of access to increasingly important research resources through periods of economic, social or military instability. This is typical of long-term resource management on the Internet. A model for managing the risks associated with these new directions must address both business risks of digital collection continuity and systems issues of content discovery, sharing and reuse. Escrow contracts are an established method to guarantee continuity of business when licensing business-critical software applications. The article examines low cost community driven resource sharing networks (the GratisNe case study) and new approaches to content syndication. A case for the establishment of a digital escrow database at the community level is presented with an architecture that embraces both the business and systems issues of long-term management of the digital resource supply.",
 "article_title": "Systematic Approaches to Long Term Digital Collection Management",
 "authors": [
 {
 "given": "Edmund",
 "family": "Balnaves",
 "affiliation": [
 {
 "original_name": "University of Sydney, Australia",
 "normalized_name": "University of Sydney",
 "country": "Australia",
 "identifiers": {
 "ror": "https://ror.org/0384j8v12",
 "GRID": "grid.1013.3"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-09-17",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "20",
 "issue": "4",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi032",
 "identifier": {
 "string_id": "10.1093/llc/fqi032",
 "id_scheme": "DOI"
 },
 "abstract": "The article studies the interaction between technical choices in virtual reality (VR) models and approaches to cultural history, for teaching and research. It is based on an ongoing project undertaken by ‘Cultures Anglophones et Technologies de l'Information’ at Paris-Sorbonne: ‘Montmartre in the jazz age’, a model of Montmartre in the late 1920s, when African-American musicians brought jazz to cabarets. Integrating it into the curriculum modifies the research/teaching interaction: it involves students in projects in progress; it encourages them to undertake interdisciplinary studies, involving computing skills and research in topography or music history. The issues that arise in the authoring of the project are a contribution to the problematics of cultural history; modelling the Montmartre environment from early documents (maps, photographs, which have to be edited with specialized software) shows how relative and incomplete they are—and thus how relative and composite our own modelling is. This composite character is in keeping with the ‘spirit of place’ of a multicultural area; VR is an elaborate structure, starting from a 3D model, with interior and exterior views, wireframes and textures; the medium is suited to the message: the recreation of a complex environment of spaces and subspaces throwing into focus contact points between French traditional songs and American jazz. The VR projects underline issues in the humanities; involving students increases their awareness of new problematics. The present article shows how new methods in humanities computing, in the field of visualization, alter and enrich humanities disciplines. It documents the authoring of a VR model, and the introduction of an Information Technology research project into the university teaching process: ‘Montmartre in the jazz age’, a multidisciplinary humanities adventure involving a digital reconstruction of part of this famous Paris area, the ‘Lapin Agile’ cabaret in the first instance. It argues that the involvement of research students in such projects not only gives them IT skills, but also adds to their critical understanding of humanities issues.",
 "article_title": "‘VR “Montmartre in the Jazz Age” ’: The Problematics of Virtual Reality in Researching and Teaching Multicultural History",
 "authors": [
 {
 "given": " Liliane",
 "family": "Gallet-Blanchard",
 "affiliation": [
 {
 "original_name": "Université Paris-Sorbonne (Paris IV), France",
 "normalized_name": "University of Paris-Sud",
 "country": "France",
 "identifiers": {
 "ror": "https://ror.org/028rypz17",
 "GRID": "grid.5842.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-07-23",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "20",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi036",
 "identifier": {
 "string_id": "10.1093/llc/fqi036",
 "id_scheme": "DOI"
 },
 "abstract": "Although there has been an increased uptake of technology-based outputs and methods in humanities research, substantial barriers remain to the full realization of potential benefits in this area. Some of these barriers resonate with the most basic challenges defined by the field of Human–Computer Interaction, including the move from computational to faciliatory computing, non-user-centred industrial design of research tools, the application of inappropriate experience models by users, and a cultural mismatch between researchers and technicians. This article develops a model of digital development in the humanities as a ‘value chain’, along which critical gaps appear when the only actors in the chain are the researcher and the technical support staff. Having identified these gaps, the article then goes on to suggest ways in which a dedicated Digital Humanities Intermediary (DHI) is able to provide much needed skills and support of a non-specifically technical nature at critical moments in the projects' development. This kind of intermediary can be instrumental in increasing technology use among humanities research staff, providing a wide range of technical knowledge and other support functions to the relevant faculties in a form that fits well with their own language and preferred ways of working. The success of the position is dependant on solid networks and the enlightened support of the University, however, as it is still very much at the stage of reacting and capitalizing on opportunities as they are encountered, rather than simply slotting in to a stable, static, proven structure.",
 "article_title": "The Role of the Professional Intermediary in Expanding the Humanities Computing Base",
 "authors": [
 {
 "given": " Jennifer",
 "family": "Edmond",
 "affiliation": [
 {
 "original_name": "University of Nottingham, UK",
 "normalized_name": "University of Nottingham",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01ee9ar58",
 "GRID": "grid.4563.4"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-07-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "20",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi037",
 "identifier": {
 "string_id": "10.1093/llc/fqi037",
 "id_scheme": "DOI"
 },
 "abstract": "Semantic Web applications in the humanities that visualize knowledge are still few and far between. The Visual Contextualization of Digital Content (VICODI) project brought together Semantic Web technologies with the concepts of contextualization and visualization of knowledge, an approach which we term visual contextualization. The goal was to enhance users' understanding of digital content in the domain of history. It succeeded in doing this by creating an ontology-based web portal of European history where extra historical knowledge or ‘context’ is added to resources and visualized through textual hyperlinks and interactive Scalable Vector Graphics historical maps. VICODI also created a history-specific ontology. In this article the novel approach of visual contextualization is introduced in conjunction with a detailed explanation of the core elements of the VICODI portal. The article also addresses several of the problems encountered in developing a Semantic Web application for a humanities domain.",
 "article_title": "Applying the Semantic Web: The VICODI Experience in Creating Visual Contextualization for History",
 "authors": [
 {
 "given": " Gábor",
 "family": "Nagypál",
 "affiliation": [
 {
 "original_name": "FZI Research Center for Information Technologies, Germany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "University of East Anglia, UK",
 "normalized_name": "University of East Anglia",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/026k5mg93",
 "GRID": "grid.8273.e"
 }
 },
 {
 "original_name": "University of Newcastle upon Tyne, UK",
 "normalized_name": "Newcastle University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01kj2bm70",
 "GRID": "grid.1006.7"
 }
 }
 ]
 },
 {
 "given": " Richard",
 "family": "Deswarte",
 "affiliation": [
 {
 "original_name": "FZI Research Center for Information Technologies, Germany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "University of East Anglia, UK",
 "normalized_name": "University of East Anglia",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/026k5mg93",
 "GRID": "grid.8273.e"
 }
 },
 {
 "original_name": "University of Newcastle upon Tyne, UK",
 "normalized_name": "Newcastle University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01kj2bm70",
 "GRID": "grid.1006.7"
 }
 }
 ]
 },
 {
 "given": " Jan",
 "family": "Oosthoek",
 "affiliation": [
 {
 "original_name": "FZI Research Center for Information Technologies, Germany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "University of East Anglia, UK",
 "normalized_name": "University of East Anglia",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/026k5mg93",
 "GRID": "grid.8273.e"
 }
 },
 {
 "original_name": "University of Newcastle upon Tyne, UK",
 "normalized_name": "Newcastle University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01kj2bm70",
 "GRID": "grid.1006.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-07-23",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "20",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi035",
 "identifier": {
 "string_id": "10.1093/llc/fqi035",
 "id_scheme": "DOI"
 },
 "abstract": "This article discusses the teaching and learning that takes place during the project work performed by final year students on a B.A. Humanities with Applied Computing degree course. This is perhaps the first time that the student has had to tackle a large piece of independent research work. It marks a period of transition between the much more constrained and often unavoidably artificial exercises of earlier undergraduate years and the ill-defined and open-ended problems of the real world. As such it acts as a valuable preparation for the independent analytical thinking required in every profession. The pedagogy of the project work, methods of assessment and details of the support offered to students are explored. The article also discusses the students' experiences of research processes in the humanities and humanities computing. It is illustrated with two case study projects. The experiences of students and staff during the projects raise many issues concerning humanities computing as a field of study and are used as a starting point for exploring the nature of the discipline.",
 "article_title": "Teaching, Learning and Research in Final Year Humanities Computing Student Projects",
 "authors": [
 {
 "given": " Martyn",
 "family": "Jessop",
 "affiliation": [
 {
 "original_name": "King's College London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-07-16",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "20",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi033",
 "identifier": {
 "string_id": "10.1093/llc/fqi033",
 "id_scheme": "DOI"
 },
 "abstract": "In recent years, Latin America has been one of the world's fastest growing areas for Internet connectivity. While numerous studies have examined the factors contributing to this communications explosion, this article concentrates upon one of its effects—the proliferation of freely available, scholarly, peer-reviewed electronic journals in the fields of literary, cultural and area studies. This article argues that in the field of Latin American studies, the majority of e-journals are being produced in Latin American countries, rather than in the US or the UK for example. It is Latin American academics, rather than their US and UK counterparts, who are embracing new technologies and the opportunities facilitated for effective dissemination of research. In order to understand this marked move towards electronic scholarly journals, this article outlines the state of Internet connectivity in the region, the financial and material constraints and other restrictions placed upon academic publication, and the lack of international visibility of Latin American scholarly print journals. While questions need to be addressed as to the future sustainability and preservation of these free journals, many of them managed by individual academics and funded by their universities, this article argues that electronic publishing offers Latin American academics an unprecedented opportunity to disseminate their research. Furthermore, this model gives international academics immediate, free access to important research that is emerging from the continent, which is the subject of study. Such access has the potential to revolutionize the way that international academics approach Latin American studies and to encourage a greater degree of international academic debate.",
 "article_title": "E-Journal Proliferation in Emerging Economies: The Case of Latin America",
 "authors": [
 {
 "given": " Shoshannah",
 "family": "Holdom",
 "affiliation": [
 {
 "original_name": "Humbul Humanities Hub, Research Technologies Service, Oxford University, UK",
 "normalized_name": "University of Oxford",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/052gg0110",
 "GRID": "grid.4991.5"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-07-30",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "20",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi034",
 "identifier": {
 "string_id": "10.1093/llc/fqi034",
 "id_scheme": "DOI"
 },
 "abstract": "The paper presents the outcome of the pilot phase of a major project which aims to build a digital resource for the study of historical Chinese texts with a view to facilitating linguistic analysis of the language, particularly from a diachronic point of view. The approach to general problems for a diachronic corpus is discussed. Details of the tag set and the tagging system devised are given. The development of a sophisticated automatic mark-up scheme for Chinese texts from widely different time periods and genres is indicated.",
 "article_title": "Sheffield Corpus of Chinese for Diachronic Linguistic Study1",
 "authors": [
 {
 "given": " Xiaoling",
 "family": "Hu",
 "affiliation": [
 {
 "original_name": "University of Sheffield, UK",
 "normalized_name": "University of Sheffield",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05krs5044",
 "GRID": "grid.11835.3e"
 }
 }
 ]
 },
 {
 "given": " Nigel",
 "family": "Williamson",
 "affiliation": [
 {
 "original_name": "University of Sheffield, UK",
 "normalized_name": "University of Sheffield",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05krs5044",
 "GRID": "grid.11835.3e"
 }
 }
 ]
 },
 {
 "given": " Jamie",
 "family": "McLaughlin",
 "affiliation": [
 {
 "original_name": "University of Sheffield, UK",
 "normalized_name": "University of Sheffield",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/05krs5044",
 "GRID": "grid.11835.3e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-08-12",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "20",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi031",
 "identifier": {
 "string_id": "10.1093/llc/fqi031",
 "id_scheme": "DOI"
 },
 "abstract": "Charters are of crucial importance as a source when studying the history of the Middle Ages and the early modern era. There are a number of projects aiming at making charters available in digital format. All of these projects, as far as they use XML as the technological basis for their work, were represented at a conference in April 2004. It was found that, despite some structural differences in the individual approaches, there is considerable potential for integration as regards the individual charter as a legally relevant text. This potential can be tapped by using common standards for the tagging/encoding of charters. This article presents a proposal for such a standard. The proposed standard follows the existing TEI standard, but also contains a number of significant enhancements. The article also looks at the problems caused by overlapping structures and presents an architecture for a search engine that could help to bring together charters from all over Europe.",
 "article_title": "Towards a Standard of Encoding Medieval Charters with XML",
 "authors": [
 {
 "given": " Georg",
 "family": "Vogeler",
 "affiliation": [
 {
 "original_name": "Ludwig-Maximilians-Universität, Germany",
 "normalized_name": "Ludwig-Maximilians-Universität München",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/05591te55",
 "GRID": "grid.5252.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-07-16",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "20",
 "issue": "3",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi044",
 "identifier": {
 "string_id": "10.1093/llc/fqi044",
 "id_scheme": "DOI"
 },
 "abstract": "Recently prominent readers in Shakespeare have embraced Warren B. Austin's 1969 computer-based study which concludes that Henry Chettle wrote Greene's Groatsworth of Wit. However, Austin's study is flawed primarily because Austin excludes hosts of data related to his conclusion, while also misreading the data that continuously point to Robert Greene as Groatsworth's author. Austin studies just five of Greene's thirty-two known prose works and rules out studying many of Greene's words on the sole basis of their subject matter, words like repent that connect Greene to the writing of Groatsworth. Austin is also silent about Chettle's stated role as copyist and overseer in preparing and printing Groatsworth. Prominent in this discussion are the six ‘Greene plus’ words Austin identifies, but does not analyse, that appear often in Groatsworth and Greene's other prose writings, but never in Chettle. Especially important are the forty-one rare and unique words presented here that Austin excludes from his study and which constitute direct evidence of Greene's hand in writing the complete text of Groatsworth. Nor does Austin study the orthography of Groatsworth, which differs significantly from Chettle's Kind Harts Dreame and suggests different authors for each work. Austin's findings should, therefore, be set aside, while renewed consideration is given to the lexical and orthographical evidence presented in this article that continues to identify Greene as Groatsworth's author, that is, as someone familiar enough with Shakespeare's early theatre practices to criticize them.",
 "article_title": "Computing Error: Reassessing Austin's Study of Groatsworth of Wit",
 "authors": [
 {
 "given": " Richard",
 "family": "Westley",
 "affiliation": [
 {
 "original_name": "English Instructor, Cheverus High School, Portland, Maine, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-08-26",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi042",
 "identifier": {
 "string_id": "10.1093/llc/fqi042",
 "id_scheme": "DOI"
 },
 "abstract": "This paper is a case study for examining how a small-corpus-based approach can contribute to research in stylistics. Specifically, we have built small corpora of the two Alice books and retrieved, using WordSmith Tools suite, first, verbs of saying and their adverbials to elucidate how Alice speaks to others in the stories, and secondly, modifiers of ‘Alice’ to get the images of the main character. An analysis of these data reveals that Alice's role in each book is quite distinct: an unexpected visitor thrown into the passive state in Wonderland and an active explorer in Looking-Glass. These findings objectively serve to reinforce our argument over what Alice is called through the perusal of the texts. Alice's roles in the two books are thus interactively supported by the small-corpus-based approach and the non-corpus-based approach, which may explore the validity of the interfaced approach, the collaborative work of quantitative processing and qualitative speculation.",
 "article_title": "A Small-Corpus-Based Approach to Alice's Roles",
 "authors": [
 {
 "given": " Akiko",
 "family": "Inaki",
 "affiliation": [
 {
 "original_name": "Otemon Gakuin University, Japan",
 "normalized_name": "Otemon Gakuin University",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/009mysd22",
 "GRID": "grid.443761.3"
 }
 }
 ]
 },
 {
 "given": " Tomoko",
 "family": "Okita",
 "affiliation": [
 {
 "original_name": "Osaka University, Japan",
 "normalized_name": "Osaka University",
 "country": "Japan",
 "identifiers": {
 "ror": "https://ror.org/035t8zc32",
 "GRID": "grid.136593.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-08-26",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi041",
 "identifier": {
 "string_id": "10.1093/llc/fqi041",
 "id_scheme": "DOI"
 },
 "abstract": "This paper presents the results of a statistical analysis performed on the forty-seven novels of Anthony Trollope. It is shown that there is a trend in the distribution of chapter lengths for each novel towards a state of increased evenness. Some possible causes of the trend are considered, although the most probable explanation is conjectural.",
 "article_title": "The Evolution of Order in the Chapter Lengths of Trollope's Novels",
 "authors": [
 {
 "given": "P.",
 "family": "Fink",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-08-13",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi039",
 "identifier": {
 "string_id": "10.1093/llc/fqi039",
 "id_scheme": "DOI"
 },
 "abstract": "In this article we describe an approach to the identification of ‘translationese’ based on monolingual comparable corpora and machine learning techniques for text categorization. The article reports on experiments in which support vector machines (SVMs) are employed to recognize translated text in a corpus of Italian articles from the geopolitical domain. An ensemble of SVMs reaches 86.7% accuracy with 89.3% precision and 83.3% recall on this task. A preliminary analysis of the features used by the SVMs suggests that the distribution of function words and morphosyntactic categories in general, and personal pronouns and adverbs in particular, are among the cues used by the SVMs to perform the discrimination task. A follow-up experiment shows that the performance attained by SVMs is well above the average performance of ten human subjects, including five professional translators, on the same task. Our results offer solid evidence supporting the translationese hypothesis, and our method seems to have promising applications in translation studies and in quantitative style analysis in general. Implications for the machine learning/text categorization community are equally important, both because this is a novel application and especially because we provide explicit evidence that a relatively knowledge-poor machine learning algorithm can outperform human beings in a text classification task.",
 "article_title": "A New Approach to the Study of Translationese: Machine-learning the Difference between Original and Translated Text",
 "authors": [
 {
 "given": " Marco",
 "family": "Baroni",
 "affiliation": [
 {
 "original_name": "SSLMIT, University of Bologna",
 "normalized_name": "University of Bologna",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/01111rn36",
 "GRID": "grid.6292.f"
 }
 }
 ]
 },
 {
 "given": " Silvia",
 "family": "Bernardini",
 "affiliation": [
 {
 "original_name": "SSLMIT, University of Bologna",
 "normalized_name": "University of Bologna",
 "country": "Italy",
 "identifiers": {
 "ror": "https://ror.org/01111rn36",
 "GRID": "grid.6292.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-08-06",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi030",
 "identifier": {
 "string_id": "10.1093/llc/fqi030",
 "id_scheme": "DOI"
 },
 "abstract": "Accurate transcription is difficult and time-consuming. It is therefore worth choosing the transcription strategy that will yield the smallest number of errors for a given total effort. We use a mathematical model of the transcription process to compare two basic strategies: a single transcription with repeated checking, and a pair of transcriptions with a smaller amount of checking. Our model for checking is an adequate description of the rate of error detection in a real transcription. We show how to optimize the proportion of effort allocated to checking locations where the two transcriptions disagree, and discuss the factors that favour either of the strategies. We suggest how one might design an optimal transcription strategy in practice.",
 "article_title": "Optimal Strategies for Accurate Transcription",
 "authors": [
 {
 "given": " Matthew",
 "family": "Spencer",
 "affiliation": [
 {
 "original_name": "University of Cambridge, UK",
 "normalized_name": "University of Cambridge",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/013meh722",
 "GRID": "grid.5335.0"
 }
 }
 ]
 },
 {
 "given": " Christopher J.",
 "family": "Howe",
 "affiliation": [
 {
 "original_name": "University of Cambridge, UK",
 "normalized_name": "University of Cambridge",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/013meh722",
 "GRID": "grid.5335.0"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-07-29",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "21",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi001",
 "identifier": {
 "string_id": "10.1093/llc/fqi001",
 "id_scheme": "DOI"
 },
 "abstract": "Chaucer's Wife of Bath's Prologue survives in both hand-written and early print witnesses dating from the 15th century. The introduction of material from more than one exemplar into a new copy results in contamination of a textual tradition. This contamination causes problems in standard phylogenetic analysis. We use an application of the maximum χ2 method (developed for the detection of recombination in DNA sequences) to identify locations where scribes may have changed their exemplar whilst copying the tale. Our results are largely in agreement with other published sources, indicating that this method may prove useful in the analysis of a contaminated tradition.",
 "article_title": "The Identification of Exemplar Change in the Wife of Bath's Prologue Using the Maximum Chi-Squared Method",
 "authors": [
 {
 "given": " Heather F.",
 "family": "Windram",
 "affiliation": [
 {
 "original_name": "Department of Biochemistry, University of Cambridge, UK",
 "normalized_name": "University of Cambridge",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/013meh722",
 "GRID": "grid.5335.0"
 }
 },
 {
 "original_name": "Department of Mathematics and Statistics, Dalhousie University, Nova Scotia, Canada",
 "normalized_name": "Dalhousie University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/01e6qks80",
 "GRID": "grid.55602.34"
 }
 }
 ]
 },
 {
 "given": " Christopher J.",
 "family": "Howe",
 "affiliation": [
 {
 "original_name": "Department of Biochemistry, University of Cambridge, UK",
 "normalized_name": "University of Cambridge",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/013meh722",
 "GRID": "grid.5335.0"
 }
 },
 {
 "original_name": "Department of Mathematics and Statistics, Dalhousie University, Nova Scotia, Canada",
 "normalized_name": "Dalhousie University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/01e6qks80",
 "GRID": "grid.55602.34"
 }
 }
 ]
 },
 {
 "given": " Matthew",
 "family": "Spencer",
 "affiliation": [
 {
 "original_name": "Department of Biochemistry, University of Cambridge, UK",
 "normalized_name": "University of Cambridge",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/013meh722",
 "GRID": "grid.5335.0"
 }
 },
 {
 "original_name": "Department of Mathematics and Statistics, Dalhousie University, Nova Scotia, Canada",
 "normalized_name": "Dalhousie University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/01e6qks80",
 "GRID": "grid.55602.34"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-03-25",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "20",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi002",
 "identifier": {
 "string_id": "10.1093/llc/fqi002",
 "id_scheme": "DOI"
 },
 "abstract": "In order to organize the widely dispersed manuscripts of Walt Whitman, The Walt Whitman Archive, in partnership with the University of Nebraska-Lincoln Libraries, has utilized the power of Encoded Archival Description (EAD) to create a single, scholarly enhanced guide to Whitman's poetry manuscripts. This integrated finding guide to Whitman's poetry manuscripts includes item-level description, links to repository guides that provide both location information and collection context, links to digital images of the manuscripts, and links to Text Encoding Initiative (TEI) transcriptions. In creating such a guide, we had to work cooperatively across disciplines and institutions, expand the use of EAD, and address how best to integrate description and transcription (EAD and TEI files). This essay describes our procedure as we created the integrated guide. From collecting finding aids and creating partnerships with other institutions, to developing a proper encoding standard and establishing good cross-department working relations, our project has embodied many of the benefits and challenges of digital work in the humanities. By identifying our procedures, and by laying out our future hurdles, we hope we can advance knowledge about Whitman and about how scholars and archivists can collaborate effectively to advance research, improve access, and realize the potential of EAD.",
 "article_title": "Ordering Chaos: An Integrated Guide and Online Archive of Walt Whitman's Poetry Manuscripts",
 "authors": [
 {
 "given": " Brett",
 "family": "Barney",
 "affiliation": [
 {
 "original_name": "University of Nebraska-Lincoln, USA",
 "normalized_name": "University of Nebraska–Lincoln",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/043mer456",
 "GRID": "grid.24434.35"
 }
 }
 ]
 },
 {
 "given": " Mary Ellen",
 "family": "Ducey",
 "affiliation": [
 {
 "original_name": "University of Nebraska-Lincoln, USA",
 "normalized_name": "University of Nebraska–Lincoln",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/043mer456",
 "GRID": "grid.24434.35"
 }
 }
 ]
 },
 {
 "given": " Andrew",
 "family": "Jewell",
 "affiliation": [
 {
 "original_name": "University of Nebraska-Lincoln, USA",
 "normalized_name": "University of Nebraska–Lincoln",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/043mer456",
 "GRID": "grid.24434.35"
 }
 }
 ]
 },
 {
 "given": " Kenneth M.",
 "family": "Price",
 "affiliation": [
 {
 "original_name": "University of Nebraska-Lincoln, USA",
 "normalized_name": "University of Nebraska–Lincoln",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/043mer456",
 "GRID": "grid.24434.35"
 }
 }
 ]
 },
 {
 "given": " Brian Pytlik",
 "family": "Zillig",
 "affiliation": [
 {
 "original_name": "University of Nebraska-Lincoln, USA",
 "normalized_name": "University of Nebraska–Lincoln",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/043mer456",
 "GRID": "grid.24434.35"
 }
 }
 ]
 },
 {
 "given": " Katherine L.",
 "family": "Walter",
 "affiliation": [
 {
 "original_name": "University of Nebraska-Lincoln, USA",
 "normalized_name": "University of Nebraska–Lincoln",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/043mer456",
 "GRID": "grid.24434.35"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-03-24",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "20",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi029",
 "identifier": {
 "string_id": "10.1093/llc/fqi029",
 "id_scheme": "DOI"
 },
 "abstract": "This article studies different aspects of a new approach to word sense disambiguation using statistical information gained from a monolingual corpus of the target language. Here, the source language is English and the target is Persian, and the disambiguation method can be directly applied in the system of English-to-Persian machine translation for solving lexical ambiguity problems in this system. Unlike other disambiguation approaches, using corpora for handling the problem, which use the Most Likelihood Model in their statistical works, this article proposes the Random Numbers Model. We believe that this model is more reasonable from the scientific point of view and find that it offers the most precise and accurate results. This method has been tested for a selected set of English texts containing multiple-meaning words with respect to Persian language and the results are encouraging.",
 "article_title": "Word Sense Disambiguation Using Target Language Corpus in a Machine Translation System",
 "authors": [
 {
 "given": " Tayebeh Mosavi",
 "family": "Miangah",
 "affiliation": [
 {
 "original_name": "Shahre Kord University, Iran",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Ali Delavar",
 "family": "Khalafi",
 "affiliation": [
 {
 "original_name": "Shahre Kord University, Iran",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-05-11",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "20",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqh032",
 "identifier": {
 "string_id": "10.1093/llc/fqh032",
 "id_scheme": "DOI"
 },
 "abstract": "In this paper, we present a system performing morphological analysis and synthesis for the Greek language. Its main features are the use of a single framework to describe and classify morphological data into well-defined classes characterized by their own set of properties and mechanisms and the structuring of the database into distinct levels corresponding to the different levels of morphological information present in the above framework. The resulting system is characterized by simple and flexible algorithms with 100% success in the recognition and generation of morphological forms of the language independently of the complexity of the data they are handling.",
 "article_title": "The Computational Modern Greek Morphological Lexicon—An Efficient and Comprehensive System for Morphological Analysis and Synthesis",
 "authors": [
 {
 "given": " S. D.",
 "family": "Baldzis",
 "affiliation": [
 {
 "original_name": "University of Ioannina, Greece",
 "normalized_name": "University of Ioannina",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/01qg3j183",
 "GRID": "grid.9594.1"
 }
 }
 ]
 },
 {
 "given": " S. A.",
 "family": "Kolalas",
 "affiliation": [
 {
 "original_name": "University of Ioannina, Greece",
 "normalized_name": "University of Ioannina",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/01qg3j183",
 "GRID": "grid.9594.1"
 }
 }
 ]
 },
 {
 "given": " E.",
 "family": "Eumeridou",
 "affiliation": [
 {
 "original_name": "University of Ioannina, Greece",
 "normalized_name": "University of Ioannina",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/01qg3j183",
 "GRID": "grid.9594.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-02-07",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "20",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi021",
 "identifier": {
 "string_id": "10.1093/llc/fqi021",
 "id_scheme": "DOI"
 },
 "abstract": "This paper explores the Greek participle and its use in the works of Lysias. I will argue that in Lysias' works, narrative descriptions of violence are characterized by the unusually frequent use of the participle. I will further show that the association of high participle density and narratives about violence are a subset of a larger pattern relating to use of the participle in Lysias' works. In this pattern, Lysias uses unusually large numbers of participles: (1) only within the narrative and argumentative sections of the speeches; (2) to structure the work and mark the conclusion of narrative arcs and lines of argument; (3) in their role as a structuring device, these passages also provide immediacy and momentum to the argument or narrative descriptions of events; and (4) to mark a return in subject matter to the case at hand and to focus the attention of the jury on the question that is before them.",
 "article_title": "Talking About Violence: Clustered Participles in the Speeches of Lysias",
 "authors": [
 {
 "given": " Jeff",
 "family": "Rydberg-Cox",
 "affiliation": [
 {
 "original_name": "Department of English, University of Missouri-Kansas City",
 "normalized_name": "University of Missouri–Kansas City",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/01w0d5g70",
 "GRID": "grid.266756.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-05-11",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "20",
 "issue": "2",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi028",
 "identifier": {
 "string_id": "10.1093/llc/fqi028",
 "id_scheme": "DOI"
 },
 "abstract": "This article is concerned with the study of register variation, the process of focusing on the similarities and dissimilarities between register categories in terms of various linguistic phenomena. The British National Corpus World Edition, which is a 100 million word collection of British English, will be used to study the characterization of register variation by identifying their linguistic characteristics. By means of multivariate analysis, the variation of the occurrence of selected linguistic features among registers will be classified. A multivariate analysis holds out the promise of being able to systematize the register categories in the corpus while also revealing the characteristic linguistic features of the groups classified.In this article, by focusing on a sociolinguistic variable which is fairly systematically associated with ‘social class’ in the British National Corpus, the dimensions revealed by the multivariate analysis were interpreted linguistically. That is, the linguistic dimension concerned with ‘formal style’ versus ‘casual style’ proved the validity of the social variable in the British National Corpus and enabled its characterization in the light of linguistic features. Furthermore, several words which pertain to interjection, filler, modal auxiliary verb, and negation, i.e. hmm, ay, may, ’d, not, nae, and so on turned out to be crucial markers to characterize the register in which texts are used.",
 "article_title": "A Study of Register Variation in the British National Corpus",
 "authors": [
 {
 "given": " Kaoru",
 "family": "Takahashi",
 "affiliation": [
 {
 "original_name": "Toyota National College of Technology, Japan",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-05-19",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "21",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqi014",
 "identifier": {
 "string_id": "10.1093/llc/fqi014",
 "id_scheme": "DOI"
 },
 "abstract": "Body image—especially self-perceptions of body boundaries—can have a significant impact on emotional well-being, personality, and behaviour. Fisher and Cleveland developed a scoring system for identifying two categories of body boundary imagery (Barrier and Penetration) in Rorschach test protocols, which Newbold has since extended to the analysis of narrative text. This paper describes the initial development of a content analysis dictionary (the Body Type Dictionary) for automating Barrier and Penetration scoring on English-language texts. To demonstrate its use and to provide a preliminary measure of validation, the dictionary is applied to a set of fictional fetish narratives and to samples from mainstream romantic fiction. The results demonstrate that the fetish narratives contain a significantly greater amount of Barrier imagery than the mainstream writing samples, which tallies with previous observations about body boundaries and appears to support the claim that writers with uncertain self-perceived boundaries will use more body boundary imagery in their writing. Suggestions for further validation studies and applications are given.",
 "article_title": "Development and Application of a Content Analysis Dictionary for Body Boundary Research",
 "authors": [
 {
 "given": " Andrew",
 "family": "Wilson",
 "affiliation": [
 {
 "original_name": "Lancaster University, UK",
 "normalized_name": "Lancaster University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04f2nsd36",
 "GRID": "grid.9835.7"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-05-05",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "21",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqh050",
 "identifier": {
 "string_id": "10.1093/llc/fqh050",
 "id_scheme": "DOI"
 },
 "abstract": "The Centre for Irish and Celtic Studies at the University of Ulster is currently producing a digital dictionary of medieval Irish (eDIL) based on the standard Dictionary of the Irish Language published by the Royal Irish Academy, Dublin. This paper addresses some of the problems encountered in the digitization process, including data capture, processing non-standard characters, modifications to the TEI guidelines, automatic generation of tags, and the establishment of a lexical view while preserving the original format of the paper dictionary.",
 "article_title": "Digitizing a Dictionary of Medieval Irish: the eDIL Project",
 "authors": [
 {
 "given": " Maxim",
 "family": "Fomin",
 "affiliation": [
 {
 "original_name": "Centre for Irish and Celtic Studies, University of Ulster",
 "normalized_name": "University of Ulster",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01yp9g959",
 "GRID": "grid.12641.30"
 }
 }
 ]
 },
 {
 "given": " Gregory",
 "family": "Toner",
 "affiliation": [
 {
 "original_name": "Centre for Irish and Celtic Studies, University of Ulster",
 "normalized_name": "University of Ulster",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01yp9g959",
 "GRID": "grid.12641.30"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-04-14",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "21",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqh049",
 "identifier": {
 "string_id": "10.1093/llc/fqh049",
 "id_scheme": "DOI"
 },
 "abstract": "An increasing number of scholars think a new instrument to publish academic work is needed. In fact, the scientific journals are in a monopoly market that makes access to scientific information very expensive. The richest university libraries use 80–90% of their budgets for the purchase of scientific journals and nevertheless are able to afford only a small part of academic literature. For scholarly publications in the Humanities there is not a monopoly market—there is no market at all. Public libraries have less and less money for monographs. The Humanities are in constant crisis as far as the publication of scholarly editions is concerned. This is especially true of genetic and facsimile editions, but it is also the case for all projects where the requirements of scholarly work are in conflict with the realities of the book market. Furthermore, the access to libraries and archives holding the primary sources for scholarly work is often difficult, expensive and unsatisfactory. The HyperLearning project is an extension of the HyperNietzsche project, which tries to solve the difficulties outlined above. This short research report describes the HyperLearning project, focusing on its technological activities. In the first part we will delineate the path from HyperNietzsche to HyperLearning. The following parts are an overview of three major technical research areas of HyperLearning.",
 "article_title": "The HyperLearning Project: Towards a Distributed and Semantically Structured e-research and e-learning Platform",
 "authors": [
 {
 "given": " Michele",
 "family": "Barbera",
 "affiliation": [
 {
 "original_name": "Projekt HyperNietzsche, Ludwig-Maximilians-Universität München, Germany",
 "normalized_name": "Ludwig-Maximilians-Universität München",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/05591te55",
 "GRID": "grid.5252.0"
 }
 },
 {
 "original_name": "Net7 – Internet Open Solutions–, Italy",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-04-13",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "21",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqh051",
 "identifier": {
 "string_id": "10.1093/llc/fqh051",
 "id_scheme": "DOI"
 },
 "abstract": "Character idiolects in Henryk Sienkiewicz's trilogy were studied in the original and in two English translations by Jeremiah Curtin and W. S. Kuniczak. The method used was Burrows's technique of multivariate analysis of correlation matrices of relative frequencies of the most frequent words in the dialogue. The aim of the study was to verify the intuitions of traditional interpretations, to acquire a more comprehensive view of the phenomenon, and to obtain new insights into the nature of idiolect differentiation in Sienkiewicz. Multidimensional scaling plots for the original yielded patterns of idiolect differentiation by nationality, social status, gender, and age. Corresponding plots for the two translations preserved many of these patterns and exhibited strong similarities to each other. More studies including modified methods (including Burrows's Delta) are needed to observe further and explain why exactly patterns of similarity/difference between character idiolects are so strongly preserved in translation.",
 "article_title": "Burrowing into Translation: Character Idiolects in Henryk Sienkiewicz's Trilogy and its Two English Translations",
 "authors": [
 {
 "given": " Jan",
 "family": "Rybicki",
 "affiliation": [
 {
 "original_name": "Kraków Pedagogical University, Poland",
 "normalized_name": "Pedagogical University of Kraków",
 "country": "Poland",
 "identifiers": {
 "ror": "https://ror.org/030mz2444",
 "GRID": "grid.412464.1"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-03-25",
 "keywords": null,
 "journal_title": "Digital Scholarship in the Humanities",
 "volume": "21",
 "issue": "1",
 "ISSN": [
 {
 "value": "2055-7671",
 "type": "print"
 },
 {
 "value": "2055-768X",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqh040",
 "identifier": {
 "string_id": "10.1093/llc/fqh040",
 "id_scheme": "DOI"
 },
 "abstract": null,
 "article_title": "Living with Google: Perspectives on Humanities Computing and Digital Libraries: Busa Award Lecture, June 2004",
 "authors": [
 {
 "given": " Susan",
 "family": "Hockey",
 "affiliation": [
 {
 "original_name": "University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-03-16",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "20",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqh041",
 "identifier": {
 "string_id": "10.1093/llc/fqh041",
 "id_scheme": "DOI"
 },
 "abstract": "At the University of Groningen we have emphasized a simple view of humanities computing as computing in service of the humanities. This means that we seek to answer scholarly questions in linguistics, history, and art history by using the computer, exploiting especially its ability to process large amounts of data and the transparency of its processing. We have shied away from questions of digital culture, avoided overemphasis on pedagogical applications of computers, and eschewed visions of scientific revolution—including, in particular, the revolutionary idea that humanities computing is a discipline, preferring to think of it instead as a federation of disciplines, whose practitioners find it opportune to collaborate for reasons of some common problems. We have discovered that our ability to deal with large amounts of data marks the distinctive contributions we can make to humanities scholarship.",
 "article_title": "Computational Contributions to the Humanities",
 "authors": [
 {
 "given": " John",
 "family": "Nerbonne",
 "affiliation": [
 {
 "original_name": "Rijksuniversiteit Groningen, The Netherlands",
 "normalized_name": "University of Groningen",
 "country": "Netherlands",
 "identifiers": {
 "ror": "https://ror.org/012p63287",
 "GRID": "grid.4830.f"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-02-23",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "20",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqh042",
 "identifier": {
 "string_id": "10.1093/llc/fqh042",
 "id_scheme": "DOI"
 },
 "abstract": "The ink and stylus tablets discovered at the Roman Fort of Vindolanda are a unique resource for scholars of ancient history. However, the stylus tablets have proved particularly difficult to read. This paper describes the initial stages in the development of a computer system designed to aid historians in the reading of the stylus tablets. A detailed investigation was undertaken, using Knowledge Elicitation techniques borrowed from Artificial Intelligence, Cognitive Psychology, and Computational Linguistics, to elicit the processes experts use whilst reading an ancient text. The resulting model was used as the basis of a computer architecture to construct a system which takes in images of the tablets and outputs plausible interpretations of the documents. It is demonstrated that using Knowledge Elicitation techniques can further the understanding of complex processes in the humanities, and that these techniques can provide an underlying structure for the basis of a computer system that replicates that process. As such it provides significant insight into how experts work in the humanities, whilst providing the means to develop tools to assist them in their complex task.",
 "article_title": "Reading the Readers: Modelling Complex Humanities Processes to Build Cognitive Systems",
 "authors": [
 {
 "given": " Melissa",
 "family": "Terras",
 "affiliation": [
 {
 "original_name": "University College London, UK",
 "normalized_name": "University College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/02jx3x895",
 "GRID": "grid.83440.3b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-02-22",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "20",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqh047",
 "identifier": {
 "string_id": "10.1093/llc/fqh047",
 "id_scheme": "DOI"
 },
 "abstract": "Digital Humanities (DH) and Digital Library (DL) projects are complex systems that require specialized programming skills. Many encoders cannot take their work to the next level by transforming their collections of structured XML texts into a web searchable and browsable database. Often teams of text encoders are able to encode their texts with a high degree of sophistication, but unless they have funds to hire a programmer, their collections far too often remain on local disk storage away from public access. <teiPublisher> aims to relieve some of this burden by providing the tools to manage an extensible, modular and configurable XML-based repository which will house, search, browse, and display documents encoded in TEI-Lite on the world wide web. <teiPublisher> provides an administrative interface that allows DL and DH administrators to upload and delete documents from a web accessible repository; analyze XML documents to determine elements for searching and browsing; refine ontology development; select inter and intra document links; partition the repository into collections; create backups; generate search, browse, and display pages; customize the interface; and associate XSL transformation scripts and CSS stylesheets to obtain different target outputs (HTML, PDF, etc.).",
 "article_title": "<teiPublisher>: A Repository Management System for TEI Documents",
 "authors": [
 {
 "given": " Amit",
 "family": "Kumar",
 "affiliation": [
 {
 "original_name": "Graduate School of Library Information Sciences, University of Illinois at Urbana-Champaign, USA",
 "normalized_name": "University of Illinois at Urbana-Champaign",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047426m28",
 "GRID": "grid.35403.31"
 }
 },
 {
 "original_name": "University of Maryland Libraries, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "University of Victoria, Humanities Computing and Media Centre, Canada",
 "normalized_name": "University of Victoria",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04s5mat29",
 "GRID": "grid.143640.4"
 }
 },
 {
 "original_name": "Operating Research Center, Miguel Hernández University, Spain",
 "normalized_name": "Miguel Hernandez University",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01azzms13",
 "GRID": "grid.26811.3c"
 }
 },
 {
 "original_name": "Digital Library Program/University Information Technology Services, Indiana University",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Susan",
 "family": "Schreibman",
 "affiliation": [
 {
 "original_name": "Graduate School of Library Information Sciences, University of Illinois at Urbana-Champaign, USA",
 "normalized_name": "University of Illinois at Urbana-Champaign",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047426m28",
 "GRID": "grid.35403.31"
 }
 },
 {
 "original_name": "University of Maryland Libraries, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "University of Victoria, Humanities Computing and Media Centre, Canada",
 "normalized_name": "University of Victoria",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04s5mat29",
 "GRID": "grid.143640.4"
 }
 },
 {
 "original_name": "Operating Research Center, Miguel Hernández University, Spain",
 "normalized_name": "Miguel Hernandez University",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01azzms13",
 "GRID": "grid.26811.3c"
 }
 },
 {
 "original_name": "Digital Library Program/University Information Technology Services, Indiana University",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Stewart",
 "family": "Arneil",
 "affiliation": [
 {
 "original_name": "Graduate School of Library Information Sciences, University of Illinois at Urbana-Champaign, USA",
 "normalized_name": "University of Illinois at Urbana-Champaign",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047426m28",
 "GRID": "grid.35403.31"
 }
 },
 {
 "original_name": "University of Maryland Libraries, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "University of Victoria, Humanities Computing and Media Centre, Canada",
 "normalized_name": "University of Victoria",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04s5mat29",
 "GRID": "grid.143640.4"
 }
 },
 {
 "original_name": "Operating Research Center, Miguel Hernández University, Spain",
 "normalized_name": "Miguel Hernandez University",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01azzms13",
 "GRID": "grid.26811.3c"
 }
 },
 {
 "original_name": "Digital Library Program/University Information Technology Services, Indiana University",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Martin",
 "family": "Holmes",
 "affiliation": [
 {
 "original_name": "Graduate School of Library Information Sciences, University of Illinois at Urbana-Champaign, USA",
 "normalized_name": "University of Illinois at Urbana-Champaign",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047426m28",
 "GRID": "grid.35403.31"
 }
 },
 {
 "original_name": "University of Maryland Libraries, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "University of Victoria, Humanities Computing and Media Centre, Canada",
 "normalized_name": "University of Victoria",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04s5mat29",
 "GRID": "grid.143640.4"
 }
 },
 {
 "original_name": "Operating Research Center, Miguel Hernández University, Spain",
 "normalized_name": "Miguel Hernandez University",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01azzms13",
 "GRID": "grid.26811.3c"
 }
 },
 {
 "original_name": "Digital Library Program/University Information Technology Services, Indiana University",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Alejandro",
 "family": "Bia",
 "affiliation": [
 {
 "original_name": "Graduate School of Library Information Sciences, University of Illinois at Urbana-Champaign, USA",
 "normalized_name": "University of Illinois at Urbana-Champaign",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047426m28",
 "GRID": "grid.35403.31"
 }
 },
 {
 "original_name": "University of Maryland Libraries, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "University of Victoria, Humanities Computing and Media Centre, Canada",
 "normalized_name": "University of Victoria",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04s5mat29",
 "GRID": "grid.143640.4"
 }
 },
 {
 "original_name": "Operating Research Center, Miguel Hernández University, Spain",
 "normalized_name": "Miguel Hernandez University",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01azzms13",
 "GRID": "grid.26811.3c"
 }
 },
 {
 "original_name": "Digital Library Program/University Information Technology Services, Indiana University",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " John",
 "family": "Walsh",
 "affiliation": [
 {
 "original_name": "Graduate School of Library Information Sciences, University of Illinois at Urbana-Champaign, USA",
 "normalized_name": "University of Illinois at Urbana-Champaign",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/047426m28",
 "GRID": "grid.35403.31"
 }
 },
 {
 "original_name": "University of Maryland Libraries, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 },
 {
 "original_name": "University of Victoria, Humanities Computing and Media Centre, Canada",
 "normalized_name": "University of Victoria",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/04s5mat29",
 "GRID": "grid.143640.4"
 }
 },
 {
 "original_name": "Operating Research Center, Miguel Hernández University, Spain",
 "normalized_name": "Miguel Hernandez University",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/01azzms13",
 "GRID": "grid.26811.3c"
 }
 },
 {
 "original_name": "Digital Library Program/University Information Technology Services, Indiana University",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-03-02",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "20",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqh048",
 "identifier": {
 "string_id": "10.1093/llc/fqh048",
 "id_scheme": "DOI"
 },
 "abstract": "In this paper we describe the mix of text-oriented and data-oriented materials that have arisen during the process of conceptualising the Durham Liber Vitae (DLV) project. We have found a mixing of text- and data-oriented materials common in our projects, and that some aspects of SGML and XML markup's conceptual orientation—particularly the strong preference for asserting associations between elements by hierarchy and containment (the OHCO model)—have often obscured the presence of data-oriented (non-hierarchical) elements in the materials, and or encouraged inadequate ways to represent them. Although discussion of XML and its modelling abilities within the Computing Humanities community have tended to focus on issues arising in the OHCO model, the OHCO model itself is not the only modelling approach that XML markup provides. This paper demonstrates a way of taking conventional data modelling diagrams (inherently not OHCO in orientation) and modelling them for XML markup in a way that uses XML's preferred OCHO/containment approach where-ever possible, and XML's link-oriented association (e.g. ID/IDREF) approach between different hierarchies when essential. It then touches on aspects of ownership and reference that seem to lie behind XML's containment and linking association strategies. Finally, it describes some of the difficulties that standard XML tools such as XSLT and XPath (obviously primarily designed with the OHCO model in mind) have when dealing with links in XML, and shows an example of where XQuery's syntax—born out of work with relational databases—better handles queries based around linking.",
 "article_title": "Documents and Data: Modelling Materials for Humanities Research in XML and Relational Databases",
 "authors": [
 {
 "given": " John",
 "family": "Bradley",
 "affiliation": [
 {
 "original_name": "King's College London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-02-26",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "20",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqh046",
 "identifier": {
 "string_id": "10.1093/llc/fqh046",
 "id_scheme": "DOI"
 },
 "abstract": "An approach to the unification of XML (Extensible Markup Language) documents with identical textual content and concurrent markup in the framework of XML-based multi-layer annotation is introduced. A Prolog program allows the possible relationships between element instances on two annotation layers that share PCDATA to be explored and also the computing of a target node hierarchy for a well-formed, merged XML document. Special attention is paid to identity conflicts between element instances, for which a default solution that takes into account metarelations that hold between element types on the different annotation layers is provided. In addition, rules can be specified by a user to prescribe how identity conflicts should be solved for certain element types.",
 "article_title": "Unification of XML Documents with Concurrent Markup",
 "authors": [
 {
 "given": " Andreas",
 "family": "Witt",
 "affiliation": [
 {
 "original_name": "Bielefeld University, Bielefeld",
 "normalized_name": "Bielefeld University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/02hpadn98",
 "GRID": "grid.7491.b"
 }
 },
 {
 "original_name": "Justus-Liebig-Universität Gießen",
 "normalized_name": "University of Giessen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/033eqas34",
 "GRID": "grid.8664.c"
 }
 }
 ]
 },
 {
 "given": " Daniela",
 "family": "Goecke",
 "affiliation": [
 {
 "original_name": "Bielefeld University, Bielefeld",
 "normalized_name": "Bielefeld University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/02hpadn98",
 "GRID": "grid.7491.b"
 }
 },
 {
 "original_name": "Justus-Liebig-Universität Gießen",
 "normalized_name": "University of Giessen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/033eqas34",
 "GRID": "grid.8664.c"
 }
 }
 ]
 },
 {
 "given": " Felix",
 "family": "Sasaki",
 "affiliation": [
 {
 "original_name": "Bielefeld University, Bielefeld",
 "normalized_name": "Bielefeld University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/02hpadn98",
 "GRID": "grid.7491.b"
 }
 },
 {
 "original_name": "Justus-Liebig-Universität Gießen",
 "normalized_name": "University of Giessen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/033eqas34",
 "GRID": "grid.8664.c"
 }
 }
 ]
 },
 {
 "given": " Harald",
 "family": "Lüngen",
 "affiliation": [
 {
 "original_name": "Bielefeld University, Bielefeld",
 "normalized_name": "Bielefeld University",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/02hpadn98",
 "GRID": "grid.7491.b"
 }
 },
 {
 "original_name": "Justus-Liebig-Universität Gießen",
 "normalized_name": "University of Giessen",
 "country": "Germany",
 "identifiers": {
 "ror": "https://ror.org/033eqas34",
 "GRID": "grid.8664.c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-03-03",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "20",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqh044",
 "identifier": {
 "string_id": "10.1093/llc/fqh044",
 "id_scheme": "DOI"
 },
 "abstract": "This paper describes a pilot project to evaluate the use of Geographical Information System (GIS) and website technology to explore, integrate, and display quantative and qualitative information about forced migration in a region of Macedonia from 1880 to the present day. Approaches, techniques, and technologies that would be required for a potential large-scale project were explored and challenges that would be encountered and possible novel solutions that could be applied were identified. The project demonstrated that a great deal could be achieved in the visualization of spatial data at a relatively low cost in terms of finance, time and expertise. It concluded that current GIS technology has many weaknesses when applied to humanities data. However, there is considerable potential for applying existing methods in new and imaginative ways. The project gave an indication of some of this potential and the possible future development of Geographical Information Science approaches specifically for the humanities. The project is one of a new style of digital projects in the humanities that make use of image, spatial database, and text-based technologies. By taking a range of unpublished material and exploring ways of producing a digital museum of cultural heritage aimed primarily at the communities of its subject matter it exhibits the broader social role of humanities computing and the resources it develops.",
 "article_title": "The Application of a Geographical Information System to the Creation of a Cultural Heritage Digital Resource",
 "authors": [
 {
 "given": " Martyn",
 "family": "Jessop",
 "affiliation": [
 {
 "original_name": "King's College London, UK",
 "normalized_name": "King's College London",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0220mzb33",
 "GRID": "grid.13097.3c"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-02-23",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "20",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqh043",
 "identifier": {
 "string_id": "10.1093/llc/fqh043",
 "id_scheme": "DOI"
 },
 "abstract": "The term document is used in various contexts, often referring to very different things. This article argues that we need to avoid a restrictive, essentialist definition of the concept and instead study the cognitive models that guide our way of viewing documents in different situations. Examples are drawn from the Library and Information field to show how the view of documents is influenced by different cognitive models and how more complex understandings may be described in terms of clusters of models. Such a set of tools for discussing the concept will be particularly useful as we are facing a whole range of new types of ‘documents’ made possible by digital media.",
 "article_title": "What's in a Name? Contextualizing the Document Concept1",
 "authors": [
 {
 "given": " Helena",
 "family": "Francke",
 "affiliation": [
 {
 "original_name": "University College of Borås, Sweden",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-02-25",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "20",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/fqh045",
 "identifier": {
 "string_id": "10.1093/llc/fqh045",
 "id_scheme": "DOI"
 },
 "abstract": "In this paper we discuss the results of the Nomen Nescio Named Entity Recognition project, a joint effort for the mainland Scandinavian languages—Norwegian, Swedish, and Danish. Five research groups have been involved, and developed NE recognizers using rule-based as well as statistical methods. We focus particularly on the choice of semantic categories and the problems regarding metonymy and semantic polysemy. Furthermore, we discuss the extent to which different approaches to these problems have different effects on the different types of systems, and look at two strategies, which we call Function over Form, and Form over Function.",
 "article_title": "Named Entity Recognition for the Mainland Scandinavian Languages",
 "authors": [
 {
 "given": " Janne Bondi",
 "family": "Johannessen",
 "affiliation": [
 {
 "original_name": "University of Oslo, Norway",
 "normalized_name": "University of Oslo",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/01xtthb56",
 "GRID": "grid.5510.1"
 }
 },
 {
 "original_name": "Gothenburg University, Sweden",
 "normalized_name": "University of Gothenburg",
 "country": "Sweden",
 "identifiers": {
 "ror": "https://ror.org/01tm6cn81",
 "GRID": "grid.8761.8"
 }
 },
 {
 "original_name": "University of Bergen, Norway",
 "normalized_name": "University of Bergen",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/03zga2b32",
 "GRID": "grid.7914.b"
 }
 },
 {
 "original_name": "University of Southern Denmark, Denmark",
 "normalized_name": "University of Southern Denmark",
 "country": "Denmark",
 "identifiers": {
 "ror": "https://ror.org/03yrrjy16",
 "GRID": "grid.10825.3e"
 }
 },
 {
 "original_name": "Centre for Language Technology, Denmark",
 "normalized_name": "Language Technology Centre",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/00qkqnk52",
 "GRID": "grid.425769.b"
 }
 }
 ]
 },
 {
 "given": " Kristin",
 "family": "Hagen",
 "affiliation": [
 {
 "original_name": "University of Oslo, Norway",
 "normalized_name": "University of Oslo",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/01xtthb56",
 "GRID": "grid.5510.1"
 }
 },
 {
 "original_name": "Gothenburg University, Sweden",
 "normalized_name": "University of Gothenburg",
 "country": "Sweden",
 "identifiers": {
 "ror": "https://ror.org/01tm6cn81",
 "GRID": "grid.8761.8"
 }
 },
 {
 "original_name": "University of Bergen, Norway",
 "normalized_name": "University of Bergen",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/03zga2b32",
 "GRID": "grid.7914.b"
 }
 },
 {
 "original_name": "University of Southern Denmark, Denmark",
 "normalized_name": "University of Southern Denmark",
 "country": "Denmark",
 "identifiers": {
 "ror": "https://ror.org/03yrrjy16",
 "GRID": "grid.10825.3e"
 }
 },
 {
 "original_name": "Centre for Language Technology, Denmark",
 "normalized_name": "Language Technology Centre",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/00qkqnk52",
 "GRID": "grid.425769.b"
 }
 }
 ]
 },
 {
 "given": " Åsne",
 "family": "Haaland",
 "affiliation": [
 {
 "original_name": "University of Oslo, Norway",
 "normalized_name": "University of Oslo",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/01xtthb56",
 "GRID": "grid.5510.1"
 }
 },
 {
 "original_name": "Gothenburg University, Sweden",
 "normalized_name": "University of Gothenburg",
 "country": "Sweden",
 "identifiers": {
 "ror": "https://ror.org/01tm6cn81",
 "GRID": "grid.8761.8"
 }
 },
 {
 "original_name": "University of Bergen, Norway",
 "normalized_name": "University of Bergen",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/03zga2b32",
 "GRID": "grid.7914.b"
 }
 },
 {
 "original_name": "University of Southern Denmark, Denmark",
 "normalized_name": "University of Southern Denmark",
 "country": "Denmark",
 "identifiers": {
 "ror": "https://ror.org/03yrrjy16",
 "GRID": "grid.10825.3e"
 }
 },
 {
 "original_name": "Centre for Language Technology, Denmark",
 "normalized_name": "Language Technology Centre",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/00qkqnk52",
 "GRID": "grid.425769.b"
 }
 }
 ]
 },
 {
 "given": " Andra Björk",
 "family": "Jónsdottir",
 "affiliation": [
 {
 "original_name": "University of Oslo, Norway",
 "normalized_name": "University of Oslo",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/01xtthb56",
 "GRID": "grid.5510.1"
 }
 },
 {
 "original_name": "Gothenburg University, Sweden",
 "normalized_name": "University of Gothenburg",
 "country": "Sweden",
 "identifiers": {
 "ror": "https://ror.org/01tm6cn81",
 "GRID": "grid.8761.8"
 }
 },
 {
 "original_name": "University of Bergen, Norway",
 "normalized_name": "University of Bergen",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/03zga2b32",
 "GRID": "grid.7914.b"
 }
 },
 {
 "original_name": "University of Southern Denmark, Denmark",
 "normalized_name": "University of Southern Denmark",
 "country": "Denmark",
 "identifiers": {
 "ror": "https://ror.org/03yrrjy16",
 "GRID": "grid.10825.3e"
 }
 },
 {
 "original_name": "Centre for Language Technology, Denmark",
 "normalized_name": "Language Technology Centre",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/00qkqnk52",
 "GRID": "grid.425769.b"
 }
 }
 ]
 },
 {
 "given": " Anders",
 "family": "Nøklestad",
 "affiliation": [
 {
 "original_name": "University of Oslo, Norway",
 "normalized_name": "University of Oslo",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/01xtthb56",
 "GRID": "grid.5510.1"
 }
 },
 {
 "original_name": "Gothenburg University, Sweden",
 "normalized_name": "University of Gothenburg",
 "country": "Sweden",
 "identifiers": {
 "ror": "https://ror.org/01tm6cn81",
 "GRID": "grid.8761.8"
 }
 },
 {
 "original_name": "University of Bergen, Norway",
 "normalized_name": "University of Bergen",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/03zga2b32",
 "GRID": "grid.7914.b"
 }
 },
 {
 "original_name": "University of Southern Denmark, Denmark",
 "normalized_name": "University of Southern Denmark",
 "country": "Denmark",
 "identifiers": {
 "ror": "https://ror.org/03yrrjy16",
 "GRID": "grid.10825.3e"
 }
 },
 {
 "original_name": "Centre for Language Technology, Denmark",
 "normalized_name": "Language Technology Centre",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/00qkqnk52",
 "GRID": "grid.425769.b"
 }
 }
 ]
 },
 {
 "given": " Dimitris",
 "family": "Kokkinakis",
 "affiliation": [
 {
 "original_name": "University of Oslo, Norway",
 "normalized_name": "University of Oslo",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/01xtthb56",
 "GRID": "grid.5510.1"
 }
 },
 {
 "original_name": "Gothenburg University, Sweden",
 "normalized_name": "University of Gothenburg",
 "country": "Sweden",
 "identifiers": {
 "ror": "https://ror.org/01tm6cn81",
 "GRID": "grid.8761.8"
 }
 },
 {
 "original_name": "University of Bergen, Norway",
 "normalized_name": "University of Bergen",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/03zga2b32",
 "GRID": "grid.7914.b"
 }
 },
 {
 "original_name": "University of Southern Denmark, Denmark",
 "normalized_name": "University of Southern Denmark",
 "country": "Denmark",
 "identifiers": {
 "ror": "https://ror.org/03yrrjy16",
 "GRID": "grid.10825.3e"
 }
 },
 {
 "original_name": "Centre for Language Technology, Denmark",
 "normalized_name": "Language Technology Centre",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/00qkqnk52",
 "GRID": "grid.425769.b"
 }
 }
 ]
 },
 {
 "given": " Paul",
 "family": "Meurer",
 "affiliation": [
 {
 "original_name": "University of Oslo, Norway",
 "normalized_name": "University of Oslo",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/01xtthb56",
 "GRID": "grid.5510.1"
 }
 },
 {
 "original_name": "Gothenburg University, Sweden",
 "normalized_name": "University of Gothenburg",
 "country": "Sweden",
 "identifiers": {
 "ror": "https://ror.org/01tm6cn81",
 "GRID": "grid.8761.8"
 }
 },
 {
 "original_name": "University of Bergen, Norway",
 "normalized_name": "University of Bergen",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/03zga2b32",
 "GRID": "grid.7914.b"
 }
 },
 {
 "original_name": "University of Southern Denmark, Denmark",
 "normalized_name": "University of Southern Denmark",
 "country": "Denmark",
 "identifiers": {
 "ror": "https://ror.org/03yrrjy16",
 "GRID": "grid.10825.3e"
 }
 },
 {
 "original_name": "Centre for Language Technology, Denmark",
 "normalized_name": "Language Technology Centre",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/00qkqnk52",
 "GRID": "grid.425769.b"
 }
 }
 ]
 },
 {
 "given": " Eckhard",
 "family": "Bick",
 "affiliation": [
 {
 "original_name": "University of Oslo, Norway",
 "normalized_name": "University of Oslo",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/01xtthb56",
 "GRID": "grid.5510.1"
 }
 },
 {
 "original_name": "Gothenburg University, Sweden",
 "normalized_name": "University of Gothenburg",
 "country": "Sweden",
 "identifiers": {
 "ror": "https://ror.org/01tm6cn81",
 "GRID": "grid.8761.8"
 }
 },
 {
 "original_name": "University of Bergen, Norway",
 "normalized_name": "University of Bergen",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/03zga2b32",
 "GRID": "grid.7914.b"
 }
 },
 {
 "original_name": "University of Southern Denmark, Denmark",
 "normalized_name": "University of Southern Denmark",
 "country": "Denmark",
 "identifiers": {
 "ror": "https://ror.org/03yrrjy16",
 "GRID": "grid.10825.3e"
 }
 },
 {
 "original_name": "Centre for Language Technology, Denmark",
 "normalized_name": "Language Technology Centre",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/00qkqnk52",
 "GRID": "grid.425769.b"
 }
 }
 ]
 },
 {
 "given": " Dorte",
 "family": "Haltrup",
 "affiliation": [
 {
 "original_name": "University of Oslo, Norway",
 "normalized_name": "University of Oslo",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/01xtthb56",
 "GRID": "grid.5510.1"
 }
 },
 {
 "original_name": "Gothenburg University, Sweden",
 "normalized_name": "University of Gothenburg",
 "country": "Sweden",
 "identifiers": {
 "ror": "https://ror.org/01tm6cn81",
 "GRID": "grid.8761.8"
 }
 },
 {
 "original_name": "University of Bergen, Norway",
 "normalized_name": "University of Bergen",
 "country": "Norway",
 "identifiers": {
 "ror": "https://ror.org/03zga2b32",
 "GRID": "grid.7914.b"
 }
 },
 {
 "original_name": "University of Southern Denmark, Denmark",
 "normalized_name": "University of Southern Denmark",
 "country": "Denmark",
 "identifiers": {
 "ror": "https://ror.org/03yrrjy16",
 "GRID": "grid.10825.3e"
 }
 },
 {
 "original_name": "Centre for Language Technology, Denmark",
 "normalized_name": "Language Technology Centre",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/00qkqnk52",
 "GRID": "grid.425769.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2005-02-22",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "20",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.4.477",
 "identifier": {
 "string_id": "10.1093/llc/19.4.477",
 "id_scheme": "DOI"
 },
 "abstract": "John F. Burrows has proposed Delta, a simple new measure of textual difference, as a tool for authorship attribution, and has shown that it has great potential, especially in attribution problems where the possible authors are numerous and difficult to limit by traditional methods. In tests on prose, Delta has performed nearly as well as for Burrows's verse texts. A series of further tests using automated methods, however, shows that two modified methods of calculating Delta and three alternatives to or transformations of Delta produce results that are even more accurate. Four of these five new measures produce much better results than Delta both on a very diverse group of 104 novels and on a group of forty-four smaller contemporary literary critical texts. Although further testing is needed, Delta and its modifications should prove valuable and effective tools for authorship attribution.",
 "article_title": "Delta Prime?",
 "authors": [
 {
 "given": " David L.",
 "family": "Hoover",
 "affiliation": [
 {
 "original_name": "New York University, USA",
 "normalized_name": "New York University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0190ak572",
 "GRID": "grid.137628.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-05",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.4.497",
 "identifier": {
 "string_id": "10.1093/llc/19.4.497",
 "id_scheme": "DOI"
 },
 "abstract": "The sentence-lengths of sixteen essays by Goldsmith are examined in relation to data from ten essays (we call these ‘doubtfuls’) which have been attributed to him. Comparisons between the ‘doubtfuls’ and the known Goldsmiths are made with reference to the χ2 goodness-of-fit test, and the method of reciprocal averaging. The Goldsmith essays form a close group, with four of the ‘doubtful’ essays well outside, two less remote and four within the Goldsmith cluster. Comparison with fifty essays by nine of Goldsmith's contemporaries reveals the distinctiveness of his sentence-length patterns, and strengthens the probability that the four least doubtful essays are his. In the case of Goldsmith, then, sentence-length may be considered a reliable stylistic marker.",
 "article_title": "Sentence-length and Authorship Attribution: the Case of Oliver Goldsmith",
 "authors": [
 {
 "given": "D.",
 "family": "Mannion",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-05",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.4.431",
 "identifier": {
 "string_id": "10.1093/llc/19.4.431",
 "id_scheme": "DOI"
 },
 "abstract": "We present a computational system for morphological analysis and annotation of the Qur'an, for research and teaching purposes. The system facilitates a variety of queries on the Qur'anic text that make reference not only to the words, but also to their linguistic attributes. The core of the system is a set of finite-state based rules which describe the morpho-phonological and morpho-syntactic phenomena of the Qur'anic language. Using a finite-state toolbox we apply the rules to the Qur'anic text and obtain full morphological analysis of its words. The results of the analysis are stored in an efficient database and are accessed through a graphical user interface which facilitates the presentation of complex queries. The system is currently being used for teaching and research purposes; we exemplify its usefulness for investigating several morphological, syntactic, semantic, and stylistic aspects of the Qur'anic text.",
 "article_title": "Morphological Analysis of the Qur'an",
 "authors": [
 {
 "given": " Judith",
 "family": "Dror",
 "affiliation": [
 {
 "original_name": "University of Haifa, Israel",
 "normalized_name": "University of Haifa",
 "country": "Israel",
 "identifiers": {
 "ror": "https://ror.org/02f009v59",
 "GRID": "grid.18098.38"
 }
 }
 ]
 },
 {
 "given": " Dudu",
 "family": "Shaharabani",
 "affiliation": [
 {
 "original_name": "University of Haifa, Israel",
 "normalized_name": "University of Haifa",
 "country": "Israel",
 "identifiers": {
 "ror": "https://ror.org/02f009v59",
 "GRID": "grid.18098.38"
 }
 }
 ]
 },
 {
 "given": " Rafi",
 "family": "Talmon",
 "affiliation": [
 {
 "original_name": "University of Haifa, Israel",
 "normalized_name": "University of Haifa",
 "country": "Israel",
 "identifiers": {
 "ror": "https://ror.org/02f009v59",
 "GRID": "grid.18098.38"
 }
 }
 ]
 },
 {
 "given": " Shuly",
 "family": "Wintner",
 "affiliation": [
 {
 "original_name": "University of Haifa, Israel",
 "normalized_name": "University of Haifa",
 "country": "Israel",
 "identifiers": {
 "ror": "https://ror.org/02f009v59",
 "GRID": "grid.18098.38"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-05",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.4.509",
 "identifier": {
 "string_id": "10.1093/llc/19.4.509",
 "id_scheme": "DOI"
 },
 "abstract": "This paper describes the work carried out on the EMILLE Project (Enabling Minority Language Engineering), which was undertaken by the Universities of Lancaster and Sheffield. The primary resource developed by the project is the EMILLE Corpus, which consists of a series of monolingual corpora for fourteen South Asian languages, totalling more than 96 million words, and a parallel corpus of English and five of these languages. The EMILLE Corpus also includes an annotated component, namely, part-of-speech tagged Urdu data, together with twenty written Hindi corpus files annotated to show the nature of demonstrative use in Hindi. In addition, the project has had to address a number of issues related to establishing a language engineering (LE) environment for South Asian language processing, such as translating 8-bit language data into Unicode and producing a number of basic LE tools. The development of tools for EMILLE has contributed to the ongoing development of the LE architecture GATE, which has been extended to make use of Unicode. GATE thus plugs some of the gaps for language processing R&D necessary for the exploitation of the EMILLE corpora.",
 "article_title": "Corpus Linguistics and South Asian Languages: Corpus Creation and Tool Development",
 "authors": [
 {
 "given": "P.",
 "family": "Baker",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-05",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.4.453",
 "identifier": {
 "string_id": "10.1093/llc/19.4.453",
 "id_scheme": "DOI"
 },
 "abstract": "Delta, a simple measure of the difference between two texts, has been proposed by John F. Burrows as a tool in authorship attribution problems, particularly in large ‘open’ problems in which conventional methods of attribution are not able to limit the claimants effectively. This paper tests Delta's effectiveness and accuracy, and shows that it works nearly as well on prose as it does on poetry. It also shows that much larger numbers of frequent words are even more accurate than the 150 that Burrows tested. Automated methods that allow for tests on large numbers of differently selected words show that removing personal pronouns and words for which a single text supplies most of the occurrences greatly increases the accuracy of Delta tests. Further tests suggest that large changes in Delta and Delta z-scores from the likeliest to the second likeliest author typically characterize correct attributions, that differences in point of view among the texts are more significant than differences in nationality, and that combining several texts for each author in the primary set reduces the effect of intra-author variability. Although Delta occasionally produces errors in attribution with characteristics that would normally lead to a great deal of confidence, the results presented here confirm its usefulness in the preliminary stages of authorship attribution problems.",
 "article_title": "Testing Burrows's Delta",
 "authors": [
 {
 "given": " David L.",
 "family": "Hoover",
 "affiliation": [
 {
 "original_name": "New York University, USA",
 "normalized_name": "New York University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0190ak572",
 "GRID": "grid.137628.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-05",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.3.385",
 "identifier": {
 "string_id": "10.1093/llc/19.3.385",
 "id_scheme": "DOI"
 },
 "abstract": "This paper describes the work of The Elements of Drawing, a project to digitize the teaching collection assembled by John Ruskin at the University of Oxford. It outlines John Ruskin’s links with Oxford, his reasons for creating the collection as an aid to his teaching of drawing at the University, and the ways in which he organized and catalogued the collection. It then discusses the particular benefits which digitization brings to the collection, and outlines the methods being used to digitize the collection as a series of images, texts, catalogue data, and associated metadata, and how it is being made available over the world wide web.",
 "article_title": "The Elements of Drawing",
 "authors": [
 {
 "given": "J.",
 "family": "Miller",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.3.321",
 "identifier": {
 "string_id": "10.1093/llc/19.3.321",
 "id_scheme": "DOI"
 },
 "abstract": "This paper discusses the utilization of content‐based image retrieval (CBIR) for searching and retrieving images, to enhance access to digital image collections. Organizations have taken advantage of new technologies and funding opportunities to digitize their image collections, resulting in a greater need for efficient storage and retrieval systems. Images are used by a wide and diverse group of people, including picture researchers, historians and design professionals. Research into image use indicates that some image users have very specific needs, others are more interested in material conveying abstract concepts, and some do not want specific images but want to browse for inspiration. Cataloguing and indexing practices vary considerably, despite the existence of several tools to aid the process. Many organizations use in‐house schemes or no formal methods at all. Manual indexing effectiveness is a problem area that affects both practitioners and users. Image seeking behaviour is a complex interaction between contextual factors that ultimately affect how a user searches, selects, and uses images. CBIR is a technique in which images are selected via features automatically extracted from the images. Research into CBIR in practice found that, whilst user views were mixed, there was sufficient evidence that visual searching for images could be a useful feature of a digital image library, particularly if used in combination with text‐based descriptors.",
 "article_title": "Enhancing Visual Resources for Searching and Retrieval--Is Content-based Image Retrieval a Solution?",
 "authors": [
 {
 "given": "M. E.",
 "family": "Graham",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.3.289",
 "identifier": {
 "string_id": "10.1093/llc/19.3.289",
 "id_scheme": "DOI"
 },
 "abstract": "In the context of ongoing research into new methods and techniques for literary research we describe a primary implementation of a web application called Autonom, intended to be developed into a framework for textual parsing algorithms that may be used by literary researchers to trace literary phenomena in texts. We describe the technical parsing fundamentals and good practices the development of the framework is based upon, we clarify different design considerations and choices and we present an overview of the current state of implementation and functionality. We also demonstrate the application of a proper name parsing algorithm implemented within the framework, meant to be the first step in a new method for the research of names in literary texts. The algorithm is tested on Karel Glastra van Loon’s novel Lisa’s adem (Lisa’s Breath, 2001). We go into the results that this test has yielded so far and summarily describe some of the consequences for the analysis of the names in the novel. We conclude with a short description of the directions new developments could take.",
 "article_title": "Modelling Features of Characters: Some Digital Ways to Look at Names in Literary Texts",
 "authors": [
 {
 "given": "K.",
 "family": "van-Oskam",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.3.253",
 "identifier": {
 "string_id": "10.1093/llc/19.3.253",
 "id_scheme": "DOI"
 },
 "abstract": "What could and should be the relationship between research archives of endangered cultural heritage materials and the originating community? This paper argues that recent developments in distributed computing in a networked environment have allowed us to re‐imagine this relationship in a way that profoundly changes the role of the archive and reinforces the desirability of establishing ongoing reciprocal relationships with cultural heritage communities. Some possibilities are suggested drawing from experience with PARADISEC (the Pacific and Regional Archive for Digital Sources in Endangered Cultures, established in 2003 as a collaborative venture between the University of Sydney, the University of Melbourne, and the Australian National University) and with local community‐based digital archives in the remote Australian communities of Belyuen and Wadeye. Repatriation and rights, planning principles for establishment and sustainability of local digital archives in community cultural centres, and models for a staged approach in setting up ongoing relationships with rights holders are discussed. The paper argues that digital archives, as distributed virtual institutions, need to engage with a number of different communities of interest: not only the individuals, communities, and institutions that own the cultural heritage objects we preserve, but also the wider academic community and international standards‐setting bodies. Planning for our archives’ digital future means imagining ourselves as actors and creators within that virtual society.",
 "article_title": "Turning It All Upside Down . . . Imagining a distributed digital audiovisual archive",
 "authors": [
 {
 "given": "L.",
 "family": "Barwick",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.3.415",
 "identifier": {
 "string_id": "10.1093/llc/19.3.415",
 "id_scheme": "DOI"
 },
 "abstract": "The New Comedy Masks project deals with objects—miniature ancient theatre masks—of immense cultural significance, and with texts—the comedies of Menander—that are at the origins of the European comic tradition. By 3D scanning the miniatures and enlarging them to life‐size, the project has initiated a programme of practice‐based research in the studio, leading to live performances that are the first to use objectively reconstructed ancient masks. The paper describes the considerations that apply at different stages of the process, from the digitization of the artifact to mask‐construction and performance experimentation.",
 "article_title": "Digital Resources for Practice-based Research: The New Comedy Masks Project",
 "authors": [
 {
 "given": "R.",
 "family": "Williams",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.3.397",
 "identifier": {
 "string_id": "10.1093/llc/19.3.397",
 "id_scheme": "DOI"
 },
 "abstract": "Textual encoding is one of the main focuses of Humanities Computing. However, existing encoding schemes and initiatives focus on ‘text’ from the character level upwards, and are of little use to scholars, such as papyrologists and palaeographers, who study the constituent strokes of individual characters. This paper discusses the development of a markup system used to annotate a corpus of images of Roman texts, resulting in an XML representation of each character on a stroke by stroke basis. The XML data generated allows further interrogation of the palaeographic data, increasing the knowledge available regarding the palaeography of the documentation produced by the Roman Army. Additionally, the corpus was used to train an Artificial Intelligence system to effectively ‘read’ in stroke data of unknown text and output possible, reliable, interpretations of that text: the next step in aiding historians in the reading of ancient texts. The development and implementation of the markup scheme is introduced, the results of our initial encoding effort are presented, and it is demonstrated that textual markup on a stroke level can extend the remit of marked‐up digital texts in the humanities.",
 "article_title": "Downs and Acrosses: Textual Markup on a Stroke Level",
 "authors": [
 {
 "given": "M.",
 "family": "Terras",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.3.351",
 "identifier": {
 "string_id": "10.1093/llc/19.3.351",
 "id_scheme": "DOI"
 },
 "abstract": "E‐CITIES is a concept for a system that would bring research knowledge of the cultural heritage, in particular the history of cities, into popular use. The idea was developed as a model of multilingual cultural content management and dissemination. The system could be implemented as a fully functional and reproducible system applicable to any city, anywhere. Much of the technology is being or has been developed for use in other applications. E‐CITIES would offer important political, economic, and cultural benefits. This paper explores the technologies that would be required and identifies those that are available and developing. It puts the case that an E‐CITIES system is not just desirable but, increasingly, necessary.",
 "article_title": "City Histories Revealed",
 "authors": [
 {
 "given": "S.",
 "family": "Keene",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.3.373",
 "identifier": {
 "string_id": "10.1093/llc/19.3.373",
 "id_scheme": "DOI"
 },
 "abstract": "As the physical building of a national library can serve as a tangible expression of political and cultural philosophy, a given digital archive manifests ideological features of the national legacy it preserves and disseminates electronically. Millennial discourses have influenced national library building projects in both physical and digital archives. However, a simple analogy between conventional and electronic spaces is inadequate, because national policies on digitizing documents and regulating access engender contradictory impulses in archivists and policy makers. Although considerable attention has recently focused on the ‘right to read’, the physical space of a document archive is constituted by prohibitions on reading. In a 2002 survey, the degree of regulation varied greatly depending on national context. The Bibliothèque Nationale de France made its digital collection widely and anonymously available, but closely surveiled readers in its physical space. The Library of Congress offered democratic access and embraced an ‘open source’ approach to cataloguing, but corporate and public interests were in conflict, and ‘born digital’ documents created a policy crisis. The British Library offered an interface that emulated turning pages of rare tomes but came late to prioritize searchable text encoding. In contrast, the Danvers Archival Center offered a model of a ‘local’ archive that asserted its social function in a particular community but also claimed a role in shaping digital resources.",
 "article_title": "Reading Room(s): Building a National Archive in Digital Spaces and Physical Places",
 "authors": [
 {
 "given": "E.",
 "family": "Losh",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.3.335",
 "identifier": {
 "string_id": "10.1093/llc/19.3.335",
 "id_scheme": "DOI"
 },
 "abstract": "The visualization and analysis of spatial data can shed new light on the nature and meaning of data throughout the Humanities. However such work is often avoided because it is seen as requiring expensive new hardware and software resources or involving a substantial expenditure of time and effort overcoming a steep learning curve before worthwhile results can be obtained. The Centre for Computing in the Humanities at King’s College London collaborates with researchers in a variety of humanities disciplines on a range of projects that often involve a component of spatial data. This has given the Centre an opportunity to explore methods of visualizing, analysing and displaying spatial data in a range of humanities disciplines. This paper discusses some of the intellectual, research and practical issues affecting the use of spatial data in Humanities Computing projects. It is illustrated by examples from a number of projects at King’s College. Although it is grounded on specific examples to support the points being made the main aim is to draw out a series of general themes which affect the use of spatial data by researchers throughout the Humanities and increase awareness of what can be achieved with minimal resources and a little creative thought.",
 "article_title": "The Visualization of Spatial Data in the Humanities",
 "authors": [
 {
 "given": "M.",
 "family": "Jessop",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.3.303",
 "identifier": {
 "string_id": "10.1093/llc/19.3.303",
 "id_scheme": "DOI"
 },
 "abstract": "The aim of this paper is to show that the appropriation of ICTs is determined by a field’s specific cultural identity. Knowledge is not a homogeneous whole, but a patchwork of heterogeneous fields. These fields are most visible as embodied in academic disciplines, which have distinct cultural identities shaped by intellectual and social considerations. Scholarly communication systems evolve over time within the context of these cultural identities. The paper discusses the cultural shaping of ICTs by drawing on an ongoing ethnographic study within corpus‐based linguistics. The findings suggest that cultural elements such as ‘task‐uncertainty’, ‘mutual‐dependency’, heterogeneity, and institutional configurations will influence the appropriateness of a specific ICT infrastructure for a particular intellectual community. For example, fields that have a highly politicized and tightly controlled research culture will develop a coherent field‐based strategy for the uptake and use of ICTs, whereas domains that are pluralistic and have a loosely organized research culture will appropriate ICTs in an ad‐hoc localized manner. These findings demonstrate that overlooking cultural diversity in the development and implementation of ICT infrastructures and policies could prove detrimental for fields that do not map onto ‘big science’ conceptualizations of knowledge production. Furthermore, the paper demonstrates that effective understanding similarity and difference in patterns of scholarly communication needs to take the fine‐grain of specialist fields as the unit of analysis, rather than the course‐grain of the discipline.",
 "article_title": "The Cultural Shaping of ICTs within Academic Fields: Corpus-based Linguistics as a Case Study",
 "authors": [
 {
 "given": "J.",
 "family": "Fry",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.2.145",
 "identifier": {
 "string_id": "10.1093/llc/19.2.145",
 "id_scheme": "DOI"
 },
 "abstract": "Empirical analysis of any natural language needs to be substantiated with the statistical findings because without adequate knowledge from statistics any linguistic study can fall into the quicksand of mistaken data handling and false observation. Recent introduction of various sub‐disciplines (computational linguistics, corpus linguistics, forensic linguistics, applied linguistics, lexicology, stylometrics, lexicography, and language teaching, etc.) requires various statistical results of language properties to understand the language as well as to design sophisticated tools and software for language technology. Keeping this in mind, we present here some simple frequency counts of characters found in the Bangla text corpus. Also, we empirically evaluate their functional behaviours in the language with close reference to the corpus. Here we verify previously made observations, as well as make some new observations required for various works of language technology in Bangla.",
 "article_title": "Frequency and Function of Characters Used in the Bangla Text Corpus",
 "authors": [
 {
 "given": "N. S.",
 "family": "Dash",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.2.221",
 "identifier": {
 "string_id": "10.1093/llc/19.2.221",
 "id_scheme": "DOI"
 },
 "abstract": "This article describes a method for discriminating among authors within a given register of Modern Greek. The focus here is to determine to what extent the stylistic differences among authors can be detected with a high degree of accuracy for a set of texts belonging to a well‐defined register. To that end, the chosen register is characterized by a well‐defined sub‐language, from which a corpus of more than 1,000 documents has been created. To discriminate the texts according to author style, a series of experiments have been performed using statistical techniques. Each text has been represented by a vector covering several linguistic aspects, in an effort to determine the most effective style markers. The experimental results indicate that the proposed approach can successfully separate the author styles for a given register. An extensive study of the effectiveness of the different variable categories has been performed. For instance, diglossia information on its own is not sufficient for author discrimination. Instead, a systematic evaluation process indicates that part‐of‐speech, structural and algorithmically derived lemma‐frequency variables are the most important style markers, their use leading to an author discrimination accuracy exceeding 90%.",
 "article_title": "Discriminating the Registers and Styles in the Modern Greek Language-Part 2: Extending the Feature Vector to Optimize Author Discrimination",
 "authors": [
 {
 "given": "G.",
 "family": "Tambouratzis",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.2.181",
 "identifier": {
 "string_id": "10.1093/llc/19.2.181",
 "id_scheme": "DOI"
 },
 "abstract": "Among the history plays, King John is historically prior to the two Shakespeare tetralogies. Partly for this reason it is the least well‐known of the early history plays. Despite an increasing recognition by scholars that collaboration was the norm before the mid‐1590s, the Shakespearean integrity of King John has been hitherto unquestioned. Stylistic markers, previously recognized for their ability to discriminate authors, however, consistently differentiate two bodies of text within the play, one of which is unmistakably Shakespeare’s. Marlowe’s authorship of the non‐Shakespeare text, though improvable, is a plausible inference.",
 "article_title": "King John Divided",
 "authors": [
 {
 "given": "T.",
 "family": "Merriam",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.2.161",
 "identifier": {
 "string_id": "10.1093/llc/19.2.161",
 "id_scheme": "DOI"
 },
 "abstract": "Within the last twenty years historians of science and technology have asked how a recent history might be written, and within the last ten interest has significantly increased, culminating in an online project at MIT. Since humanities computing owes its existence to developments in recent technology, and needs to become historically self‐aware to be fully of the humanities, work toward an historiography of recent things is deeply relevant. In this essay I draw on this work to highlight the difficulties and opportunities of such an historiography, in particular its ethnographic character and the tempting lure of prediction. I focus on the crucial question of tacit object‐knowledge, concluding that it is gained by concernful action. I recommend that we awaken from a progress‐and‐democratization chronicle to a genuine history of scholarly technology.",
 "article_title": "As It Almost Was: Historiography of Recent Things",
 "authors": [
 {
 "given": "W.",
 "family": "McCarty",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.2.197",
 "identifier": {
 "string_id": "10.1093/llc/19.2.197",
 "id_scheme": "DOI"
 },
 "abstract": "This article describes a method for discriminating among registers of Modern Greek and among authors within a given register. Two issues have been investigated: (a) whether register discrimination can successfully exploit linguistic information reflecting the evolution of a language (such as diglossia features of the Modern Greek language) and (b) what kind of linguistic information and which statistical techniques may be applied to author discrimination within one register. Using clustering techniques and variables reflecting the diglossia situation, we have successfully discriminated registers in Modern Greek. However, diglossia information on its own has not been shown sufficient for author discrimination within one register. Instead, other linguistic features, including PoS distribution and discourse tendencies, have been combined with methods such as discriminant analysis in order to obtain a high degree of accuracy.",
 "article_title": "Discriminating the Registers and Styles in the Modern Greek Language-Part 1: Diglossia in Stylistic Analysis",
 "authors": [
 {
 "given": "G.",
 "family": "Tambouratzis",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.1.17",
 "identifier": {
 "string_id": "10.1093/llc/19.1.17",
 "id_scheme": "DOI"
 },
 "abstract": "The nature of a scholarly edition, as of any bibliographical tool, is determined by the historical, medial, social, and rhetorical dimensions of the genre. This ‘situatedness’ puts constraints on the force of scholarly editions: what they can and what they cannot do. Claims have been made for the potent reproductive force of scholarly editions, as well as for the making of massive digital facsimile and transcription archives that can be used as platforms for producing new critical editions. This article questions the legitimacy of such assumptions when combined with idealist notions of documents, texts, and editions. That the nature of editions is rhetorical rather than neutral, social rather than individualistic, and one of complex translation rather than simple transmission, for instance, suggests that the versatility and reproductivity of the edited material itself will be limited by significant factors. Recognizing this makes us better equipped at subjecting digital archives and editions, and the claims some of their surrounding discourses make, to critical inquiry.",
 "article_title": "How Reproductive is a Scholarly Edition?",
 "authors": [
 {
 "given": "M.",
 "family": "Dahlstrom",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.1.45",
 "identifier": {
 "string_id": "10.1093/llc/19.1.45",
 "id_scheme": "DOI"
 },
 "abstract": "When theorizing about correspondence reconstruction and sorting, we first need both a definition of ‘a letter’ and of ‘correspondence’. In this article, we propose such definitions and investigate the impact of our understanding of what correspondence reconstruction is on the production of the DALF formal framework for the transcription of epistolary material. The focus of the paper is on the instruments built into DALF for allowing all types of sorting and classification, hence correspondence reconstruction.",
 "article_title": "Presentational and Representational Issues in Correspondence Reconstruction and Sorting",
 "authors": [
 {
 "given": "E.",
 "family": "Vanhoutte",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.1.35",
 "identifier": {
 "string_id": "10.1093/llc/19.1.35",
 "id_scheme": "DOI"
 },
 "abstract": "Digital editions make it possible to create a collection of all existing copies of a text including digital facsimiles. Is this a problem if it means that there will be editions that are in fact collections of full variant texts with no selected or edited reading text? This paper argues that both archival editions with digital facsimiles and encoded source texts (digital diplomatic editions) and digital critical texts can and must exist side by side. It is also suggested that from high quality diplomatically encoded source texts it is possible to automatically extract texts that either directly or with some further encoding/editing can function as a base text for editions of different types and which build on different editorial philosophies. The editions produced at the Wittgenstein Archives in Bergen and in the project Henrik Ibsen’s Writings in Oslo are used as examples of projects supporting the author’s arguments.",
 "article_title": "Monkey Business--or What is an Edition?",
 "authors": [
 {
 "given": "E. S.",
 "family": "Ore",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.1.9",
 "identifier": {
 "string_id": "10.1093/llc/19.1.9",
 "id_scheme": "DOI"
 },
 "abstract": "For the benefit of the readers and the authors of this special issue on electronic scholarly editing, this short article introduces the Text Encoding Initiative (TEI) and the TEI Consortium (TEI‐C), which are mentioned and referred to throughout this issue and it provides many suggestions for further reading.",
 "article_title": "An Introduction to the TEI and the TEI Consortium",
 "authors": [
 {
 "given": "E.",
 "family": "Vanhoutte",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.1.119",
 "identifier": {
 "string_id": "10.1093/llc/19.1.119",
 "id_scheme": "DOI"
 },
 "abstract": "After Professor Marcel De Smedt of the University of Leuven introduced scholarly editing of modern texts as a discipline in Flanders in the 1980s, the worrying fact emerged during the last decade of the twentieth century that Flemish universities and scholarly research groups were falling well behind in the field of scholarly editing. As a reaction, the inter-university task force Genese was founded in 1993 with its main goal to promote and coordinate the theories and practice of scholarly editing in Flanders. The next decisive step was taken by the Royal Academy of Dutch Language and Literature (Koninklijke Academie voor Nederlandse Taal‐ en Letterkunde—KANTL) when they decided to make scholarly editing their primary objective as of January 1998. That decision paved the way for the founding of the Centre for Scholarly Editing and Document Studies (Centrum voor Teksteditie en Bronnenstudie—CTB), which started on 1 August 2000 as a research institute of the Academy, and which has become the centre of expertise in the field of (electronic) scholarly editing in the Low Countries.",
 "article_title": "Editorial Theory and Practice in Flanders and the Centre for Scholarly Editing and Document Studies",
 "authors": [
 {
 "given": "B.",
 "family": "Van Raemdonck",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.1.105",
 "identifier": {
 "string_id": "10.1093/llc/19.1.105",
 "id_scheme": "DOI"
 },
 "abstract": "How was a medieval manuscript meant to be read? This is a question that has concerned me for a long time in my work with Old Swedish manuscripts from Vadstena Abbey. In many manuscripts we can find traces of the historical reading situation; for example, pointing hands, marginal notes, etc. Such signals had an important function for the medieval reader, but they are rarely put forward in modern printed editions. I maintain that many of these paratextual notes can be explained with the help of hypertext theory, and be emphasized in a digital edition. I discuss this possibility by giving some examples from Scandinavian composite manuscripts. I show how digital technology together with new philological theory can give new life to medieval manuscripts, as digital editions together with the use of linking give the modern reader a deeper understanding of manuscript culture. This is possible because new philology revalues the concrete textual witnesses of a manuscript and takes each single version of a text into discussion. A printed edition is a much too clumsy tool if the aim is to give the modern reader a clear view of the uses of manuscript during the Middle Ages, but with digital technology an edition can be more complete by applying different layers of information.",
 "article_title": "Medieval Manuscripts, Hypertext and Reading. Visions of Digital Editions",
 "authors": [
 {
 "given": "J.",
 "family": "Carlquist",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.1.93",
 "identifier": {
 "string_id": "10.1093/llc/19.1.93",
 "id_scheme": "DOI"
 },
 "abstract": "This article has two aims. First I argue that the old habits of the printed book often have influence on our way of thinking in our work with electronic texts. I stress here the importance of evaluating the new possibilities that the new technological tools provide for philological work. In the second part I present a project that is currently working with the Old Swedish material from the Vadstena monastery in Sweden. Central to this project is to provide electronically encoded transcriptions of the primary sources from Vadstena.",
 "article_title": "Computing Medieval Primary Sources from the Vadstena Monastery: Arguments for the Primary Source Text",
 "authors": [
 {
 "given": "K. G.",
 "family": "Johansson",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.1.73",
 "identifier": {
 "string_id": "10.1093/llc/19.1.73",
 "id_scheme": "DOI"
 },
 "abstract": "This article discusses three principal types of transcription with reference to vernacular Medieval Nordic sources: a facsimile transcription with graphic details, a diplomatic transcription with few graphic details, but with all phonemic distinctions upheld, and a normalized transcription with regularized orthography. The article argues that all three levels of transcription can be accommodated in a single multi-level encoding, using the flexibility of Extensible Markup Language (XML) and the Text Encoding Initiative (TEI) guidelines. Special characters and abbreviation marks are encoded using entities and linking these to Unicode characters, partly in the Private Use Area. Words are encoded on one or more levels using specified elements and supplied with lexicographical and grammatical information by way of attributes. Display in various formats such as HTML and PDF is managed by stylesheets. Thus, a single XML file allows for several views of the text, suitable for different user groups, such as linguists, historians, and literary critics.",
 "article_title": "Parallel Views: Multi-level Encoding of Medieval Nordic Primary Sources",
 "authors": [
 {
 "given": "O. E.",
 "family": "Haugen",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/19.1.55",
 "identifier": {
 "string_id": "10.1093/llc/19.1.55",
 "id_scheme": "DOI"
 },
 "abstract": "In Norway, the project Henrik Ibsen’s Writings is currently establishing a new historical–critical edition (both electronically and in print) of the complete writings of playwright Henrik Ibsen. In the years the project has existed, there has been a continuing internal discussion on the relationship between philology and text encoding. This paper outlines the philological principles of the project and describes its methods of establishing texts and ensuring quality. It also looks at and describes, in detail, the consequences of combining philology and text encoding through examples of problems solved in the encoding of complex changes in manuscripts as well as parallel structures in verse dramas. The paper concludes that it is very important, in a project such as Henrik Ibsen’s Writings, to focus on the relationship between philology and text encoding because of the influence, even in the smallest details, of these on each other.",
 "article_title": "Philology Meets Text Encoding in the New Scholarly Edition of Henrik Ibsen's Writings",
 "authors": [
 {
 "given": "H.",
 "family": "Boe",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "19",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.4.361",
 "identifier": {
 "string_id": "10.1093/llc/18.4.361",
 "id_scheme": "DOI"
 },
 "abstract": "This paper presents the newly released Lancaster Corpus of Mandarin Chinese (LCMC), a Chinese match for the FLOB and Frown corpora of British and American English. We first discuss the major decisions we took when building the corpus. These relate to sampling, text collection, mark-up, and annotation. Following from this we use the corpus to study aspect marking in Chinese and British/American English. The study shows that although Chinese and English are typologically different, aspect markers in the two languages show a strikingly similar distribution pattern, especially across the two broad categories of narrative and expository texts. The study also reveals some important differences in the distribution of aspect markers in Chinese versus English and British versus American English across fifteen text categories, and provides an account of these differences.",
 "article_title": "Aspect Marking in English and Chinese: Using the Lancaster Corpus of Mandarin Chinese for Contrastive Language Study",
 "authors": [
 {
 "given": "A.",
 "family": "McEnery",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.4.407",
 "identifier": {
 "string_id": "10.1093/llc/18.4.407",
 "id_scheme": "DOI"
 },
 "abstract": "Biological techniques can be used to reconstruct the stemmata of text traditions. Here, we describe methods for assessing the reliability of the results. We use compatibility matrices to detect sections of the text with different patterns of transmission. By constructing stemmata from subsets of increasing size, we estimate the minimum amount of data needed to produce a reliable stemma. We use consistency indices to assess the overall reliability of the stemma and the level of support that individual variants give to the stemma. Bootstrap analyses allow us to reject features of the stemma that result from only a few variants. We apply these techniques to the stemma for the Miller's Tale in Chaucer's Canterbury Tales.",
 "article_title": "How Reliable is a Stemma? An Analysis of Chaucer's Miller's Tale",
 "authors": [
 {
 "given": "M.",
 "family": "Spencer",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.4.379",
 "identifier": {
 "string_id": "10.1093/llc/18.4.379",
 "id_scheme": "DOI"
 },
 "abstract": "Using an adaptation of C. and D. Labbé's method of intertextual distances, fourteen short texts by three literary scholars are shown to be distinguishable by author. Of equal interest is the proximity of texts which treat similar themes, or employ similar sub-genres. The interaction of the factors which contribute to intertextual distances enriches the approach and goes some way towards bridging the gap between computational stylistics and traditional literary criticism.",
 "article_title": "Intertextual Distances, Three Authors",
 "authors": [
 {
 "given": " Thomas",
 "family": "Merriam",
 "affiliation": [
 {
 "original_name": " Basingstoke, UK ",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.4.389",
 "identifier": {
 "string_id": "10.1093/llc/18.4.389",
 "id_scheme": "DOI"
 },
 "abstract": "Large-scale corpus-based research within translation studies is just taking its first steps. The paper begins by discussing some fundamental ideas and concepts underlying descriptive, corpus-based translation studies. These include translationese, translation-specific language, which refers to linguistic features that are either specific to translations or occur with a significantly higher or lower frequency in translations than in target-language originals, and universals of translation, i.e. features which are hypothesized to be common to all translated texts regardless of text type and language pair. The paper reports some research findings based on the children's literature subcorpus of the larger Corpus of Translated Finnish compiled at the Savonlinna School of Translation Studies, University of Joensuu. The aim of the research was to find potential features of translationese in Finnish translations of children's books. The features discussed include complex nonfinite constructions, clause connectives, and keywords. It was discovered that high frequencies of nonfinite constructions, lack of colloquial words, and specific uses of certain conjunctions are qualities which distinguish Finnish translations from non-translations and can hence be considered features of translationese in Finnish children's literature. The findings are also looked at from the perspective of translation universals, which are both supported and contradicted. Finally, the paper touches upon the difficulties caused to computer analysis by Finnish, a synthetic language, and the problems of creating a balanced corpus.",
 "article_title": "Genre-specific Features of Translationese? Linguistic Differences between Translated and Non-translated Finnish Children's Literature",
 "authors": [
 {
 "given": " Tiina",
 "family": "Puurtinen",
 "affiliation": [
 {
 "original_name": " University of Joensuu, Savonlinna, Finland ",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.4.423",
 "identifier": {
 "string_id": "10.1093/llc/18.4.423",
 "id_scheme": "DOI"
 },
 "abstract": "Large, real world, data sets have been investigated in the context of Authorship Attribution of real world documents. Ngram measures can be used to accurately assign authorship for long documents such as novels. A number of 5 (authors) × 5 (movies) arrays of movie reviews were acquired from the Internet Movie Database. Both ngram and naive Bayes classifiers were used to classify along both the authorship and topic (movie) axes. Both approaches yielded similar results, and authorship was as accurately detected, or more accurately detected, than topic. Part of speech tagging and function-word lists were used to investigate the influence of structure on classification tasks on documents with meaning removed but grammatical structure intact.",
 "article_title": "Ngram and Bayesian Classification of Documents for Topic and Authorship",
 "authors": [
 {
 "given": "Ross",
 "family": "Clement",
 "affiliation": [
 {
 "original_name": " Harrow School of Computer Science, University of Westminster, UK ",
 "normalized_name": "University of Westminster",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04ycpbx82",
 "GRID": "grid.12896.34"
 }
 }
 ]
 },
 {
 "given": "David",
 "family": "Sharp",
 "affiliation": [
 {
 "original_name": " Harrow School of Computer Science, University of Westminster, UK ",
 "normalized_name": "University of Westminster",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/04ycpbx82",
 "GRID": "grid.12896.34"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.4.341",
 "identifier": {
 "string_id": "10.1093/llc/18.4.341",
 "id_scheme": "DOI"
 },
 "abstract": "This paper investigates style variation in George Orwell's Nineteen Eighty-Four and William Golding's The Inheritors using multivariate analysis, specifically, cluster analysis of the frequencies of frequent words. Baseline tests on a corpus including these and four other novels show that traditional authorship attribution techniques correctly distinguish all sections of each novel from all sections of the other five and correctly cluster all sections of each novel. They are also very successful in distinguishing the section of Nineteen Eighty-Four that purports to be a political tract by Emmanuel Goldstein from the rest of the novel. They are less successful in distinguishing the style of the final chapter of The Inheritors, where critics have argued that a sudden shift of point of view leads to a radical variation in style. The nature of this stylistic variation suggests a modification in the way that frequent words are selected for analysis—a modification that gives improved results for both novels and sharply distinguishes the final chapter from the rest of The Inheritors. A further test of the modified technique on an unusual section of The Picture of Dorian Gray suggests that it may be more widely useful in studies of style variation.",
 "article_title": "Multivariate Analysis and the Study of Style Variation",
 "authors": [
 {
 "given": " David L.",
 "family": "Hoover",
 "affiliation": [
 {
 "original_name": " New York University, New York, NY, USA ",
 "normalized_name": "New York University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0190ak572",
 "GRID": "grid.137628.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.3.261",
 "identifier": {
 "string_id": "10.1093/llc/18.3.261",
 "id_scheme": "DOI"
 },
 "abstract": "This paper examines the effectiveness of multivariate analysis of the frequencies of frequent collocations in characterizing authorial style. Cluster analyses of collocations over various spans, types, and linkages are performed on groups of texts by known authors to determine how well the frequencies of those collocations correctly attribute the texts to their authors and distinguish them from texts by other authors. In each case the results are compared with those based on the frequencies of frequent words and the frequencies of frequent sequences of words. Cluster analyses based on frequent words and sequences ascribe many of the texts to their correct authors. However, analyses based on frequent collocations are more accurate for several groups of texts, sometimes producing more completely correct attributions than analyses based on either words or sequences and sometimes producing the only completely correct attributions. They also produce results for small groups of problematic novels and critical texts extracted from the larger corpora that are often superior to those based on frequent words or frequent sequences. Finally, they perform better than analyses based on frequent words or sequences in simulated authorship attribution scenarios. Cluster analysis based on frequent collocations provides a robust and effective method of authorship attribution.",
 "article_title": "Frequent Collocations and Authorial Style",
 "authors": [
 {
 "given": "D. L.",
 "family": "Hoover",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.3.315",
 "identifier": {
 "string_id": "10.1093/llc/18.3.315",
 "id_scheme": "DOI"
 },
 "abstract": "The usefulness of corpora in the study of syntagmatic relations has often been advocated. Without underestimating its importance, this paper aims at showing another advantage of monolingual corpora: the comparison of the behaviour of different word‐forms derived from the same lexeme. Two corpora have been chosen to illustrate this point, COBUILD's Bank of English and CREA (Reference Corpus of Contemporary Spanish), and two different but related case studies are thus presented by way of examples. Apparently, the differences between the variants selected in each language concern only gender and number, as is the case with the Spanish samples, or they are compounds with synonymous meanings, as happens with the English examples. But the observation of the data from the corpora has revealed some relevant characteristics concerning frequency rates and functions that contradict, in a considerable number of cases, our initial expectations—the assumption that all the forms of a lexeme differ from one another only formally (in the case of Spanish because of grammatical agreement) but not in their uses and meanings.",
 "article_title": "The Role of Corpora in the Study of Paradigmatic Relations; the Cases of COBUILD's Bank of English and CREA (Reference Corpus of Contemporary Spanish)",
 "authors": [
 {
 "given": "B. L.",
 "family": "de la Cruz",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.3.287",
 "identifier": {
 "string_id": "10.1093/llc/18.3.287",
 "id_scheme": "DOI"
 },
 "abstract": "This paper aims to show that model validation is of great importance to ensure the predictive accuracy of a statistical model. By extending the use of logistic regression analysis, it further demonstrates the value of logistic modelling of non‐discrete linguistic categories in language performance. This statistical technique is illustrated on a corpus‐based study of the theory on the grammatical factors for the oscillation between the use and omission of the definite article preceding multi‐word organization names (e.g. the Foreign Office, Mansfield College) in the English language. By validating the preliminary model on fresh corpora, the final logistic model can capture more precisely the gradience in the grammatical factors that affect article usage preceding multi‐word organization names. As the logistic model is a model of language in use rather than a purely statistical model, this paper further translates the regression coefficients into the probability statements that a name is favouring the use of the definite article.",
 "article_title": "Validating the Logistic Model of Article Usage Preceding Multi-word Organization Names with the Aid of Computer Corpora",
 "authors": [
 {
 "given": " Grace Y. W.",
 "family": "Tse",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.3.235",
 "identifier": {
 "string_id": "10.1093/llc/18.3.235",
 "id_scheme": "DOI"
 },
 "abstract": "Stylometric studies have revealed differences between the first four Pauline epistles and the Pastoral Epistles. They also show that there is some kind of affinity between the Pastorals and the Petrine Epistles. Scalometric analysis suggests that this affinity is due to stylistic features. The identification of the linguistic features that separate the first four epistles from the Pastorals and the Petrines provides a method of distinguishing between two styles in the epistles. Differences that were previously thought to point to differences in authorship are now seen to refer to differences in style that may be found within the works of one author.",
 "article_title": "Two Styles in the New Testament Epistles",
 "authors": [
 {
 "given": "G. K.",
 "family": "Barr",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.3.249",
 "identifier": {
 "string_id": "10.1093/llc/18.3.249",
 "id_scheme": "DOI"
 },
 "abstract": "The goal of this paper is to present a procedure for the automatic retrieval of idiomatic expressions from large text corpora. The procedure combines text segmentation techniques and Latent Semantic Analysis. Three indices were computed on the basis of the three‐fold hypothesis that: (1) idiomatic expressions should have few neighbours; (2) idiomatic expressions should demonstrate low semantic proximity between the words composing them; (3) idiomatic expressions should demonstrate low semantic proximity between the expression and the preceding and subsequent segments. The result of this procedure shows that we have not yet reached a fully automatic retrieval of idioms from large corpora, but this first trial has shown that we are on the way. The procedure reduces the amount of data to consider to less than a quarter (23.8 per cent) of the original data, of which one‐fifth (20.9 per cent) is idiomatic, and nearly 60 per cent (58.8 per cent) is phraseological in nature. In other words, this procedure drastically improves and facilitates hand‐based retrieval. In addition, these first results already permit some linguistic exploitation of the retrieved idioms.",
 "article_title": "Towards Automatic Retrieval of Idioms in French Newspaper Corpora",
 "authors": [
 {
 "given": "L.",
 "family": "Degand",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.2.175",
 "identifier": {
 "string_id": "10.1093/llc/18.2.175",
 "id_scheme": "DOI"
 },
 "abstract": "The strengths of current text‐analysis tools lie in their ability to perform a variety of formal, enumerative, or statistical functions. These functions concord well with scientific perspectives of textual criticism. Much less evident is how current text‐analysis tools help read and experience literature. Design of new tools, it is argued, should give full space to how literary critics interact with texts, rather than simply focus on what computers can do well. Principles of reading, synthesis, and play are explored in relation to a prototype version of HyperPo: Text Analysis and Exploration Tools.",
 "article_title": "Computer-Assisted Reading: Reconceiving Text Analysis",
 "authors": [
 {
 "given": "S.",
 "family": "Sinclair",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.2.117",
 "identifier": {
 "string_id": "10.1093/llc/18.2.117",
 "id_scheme": "DOI"
 },
 "abstract": "New ways of documenting and describing language via electronic media coupled with new ways of distributing the results via the World‐Wide Web offer a degree of access to language resources that is unparalleled in history. At the same time, the proliferation of approaches to using these new technologies is causing serious problems relating to resource discovery and resource creation. This paper describes the infrastructure that the Open Language Archives Community (OLAC) has built to address these problems. Its technical and usage infrastructures address problems of resource discovery by constructing a single virtual library of distributed resources. Its governance infrastructure addresses problems of resource creation by providing a mechanism through which the language‐resource community can express its consensus on recommended best practices.",
 "article_title": "The Open Language Archives Community: An Infrastructure for Distributed Archiving of Language Resources",
 "authors": [
 {
 "given": "G.",
 "family": "Simons",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.2.209",
 "identifier": {
 "string_id": "10.1093/llc/18.2.209",
 "id_scheme": "DOI"
 },
 "abstract": "The author revisits the question of what text analysis could be. He traces the tools from their origin in the concordance. He argues that text‐analysis tools produce new texts generated from queries through processes implemented on the computer. These new texts come from the decomposition of original texts and recomposition into hybrid new works for interpretation. The author ends by presenting a portal model for how text‐analysis tools can be made available to the community.",
 "article_title": "What is Text Analysis, Really?",
 "authors": [
 {
 "given": "G.",
 "family": "Rockwell",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.2.185",
 "identifier": {
 "string_id": "10.1093/llc/18.2.185",
 "id_scheme": "DOI"
 },
 "abstract": "This paper is intended to begin a discussion about the need for a future text analysis software tool to model a number of aspects of text analysis as it is practised by critics who are not computing humanists, and that have been barely considered by most developers. It begins by putting this analysis in the context of Douglas Englebart's famous model of computer–human interaction expressed originally by his Augment system. It continues by examining a number of examples of how technology (ranging from 3 × 5 cards to topic maps) is currently used to support critical analyses, and points out that an important aspect of the critical process, which is recognized at least in part by the 3 × 5 card model but not by mainstream humanities computing methods, is the sense of critical analysis as a process rather than merely the presentation of a finished product. The paper finishes by examining some of the underlying concepts present in text‐analysis tools used within the social sciences that attempt to deal with this temporal aspect of analysis, and proposes a need to examine the real practices of critics in the light of these issues.",
 "article_title": "Finding a Middle Ground between 'Determinism' and 'Aesthetic Indeterminacy': a Model for Text Analysis Tools",
 "authors": [
 {
 "given": "J.",
 "family": "Bradley",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.2.167",
 "identifier": {
 "string_id": "10.1093/llc/18.2.167",
 "id_scheme": "DOI"
 },
 "abstract": "The inability of computing humanists to break into the mainstream of literary critical scholarship may be attributed to the prevalence of scientific methodologies and metaphors in humanities computing research—methodologies and metaphors that are wholly foreign not only the language of literary criticism, but to its entire purpose. Breaking out of this unfortunate misalignment entails reaching for more appropriate paradigms. The ‘algorithmic criticism’ here proposed rejects the empiricist vision of the computer as a means by which critical interpretations may be verified, and instead seeks to locate computational processes within the rich tradition of interpretive endeavours (usually aligned more with art than criticism), which seek not to constrain meaning, but to guarantee its multiplicity. Computational processes, which are perhaps more conformable to this latter purpose, may be usefully viewed as ways of providing the necessary conditions for interpretive insight. Algorithmic criticism seeks, therefore, in the narrowing forces of constraint embodied and instantiated in the strictures of algorithmic processing, an analogue to the liberating potentialities of art and the ludic values of humanistic inquiry. It proposes that we reconceive computer‐assisted text analysis as an activity best employed not in the service of a heightened critical objectivity, but as one that embraces the possibilities of that deepened subjectivity upon which critical insight depends.",
 "article_title": "Special Section: Reconceiving Text Analysis: Toward an Algorithmic Criticism",
 "authors": [
 {
 "given": "S.",
 "family": "Ramsay",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.2.151",
 "identifier": {
 "string_id": "10.1093/llc/18.2.151",
 "id_scheme": "DOI"
 },
 "abstract": "Emily Dickinson's experimental poetic compositions present exceptional challenges to the textual editor using TEI to mark up Dickinson's manuscript writings, particularly in the realm of tagging variants and versions. Focusing in particular on her use of intratextual and subtextual variant words, phrases, lines, and line groups, this paper examines several different scenarios for tagging variants and discusses each strategy's strengths and weaknesses. Bearing in mind textual theories that stress the autonomous nature of textual versions produced by variation, this essay also imagines future computing tools that rely upon TEI‐conformant tagging to automate visual representations of variant versions. Ultimately, no entirely satisfactory method of encoding Dickinson's variants emerges, as more simple encoding strategies fail to capture Dickinson's complexities in a way that can generate automated display, and more complicated strategies produce awkward, cumbersome code and retain TEI's known difficulties with tagging multiple and overlapping hierarchies.",
 "article_title": "Witnessing Dickinson's Witnesses",
 "authors": [
 {
 "given": "L.",
 "family": "Vetter",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "Jarom",
 "family": "McDonald",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.2.139",
 "identifier": {
 "string_id": "10.1093/llc/18.2.139",
 "id_scheme": "DOI"
 },
 "abstract": "Karl Lachmann's edition from 1833 still provides the basis for Parzival scholarship. Although the text has subsequently been revised in parts, a fundamentally new edition considering all extant manuscripts is required. Computer technology offers means for tackling this task in an effective and reliable manner. A critical electronic edition will give access to the manuscript material, which may be published stage by stage, corresponding to different sections of the text. Such an edition will allow users to consult a base text, electronically linked to an apparatus of variants, to manuscript transcriptions, and to facsimiles. Browsing among these components, readers will experience the extent to which the Parzival romance was open to textual variance in the course of its transmission (an aspect stressed by theories of the so‐called ‘New Philology’). Furthermore, new stemmatological methods borrowed from evolutionary biology (phylogeny) will provide insight into manuscript groupings that may reflect early textual versions that relate to the semi‐oral status of vernacular literary culture. Thus, an electronic edition will be the essential prerequisite of any new Parzival book edition. But it also constitutes an edition in its own right, revealing the discursive and visual richness of medieval text traditions and involving the readers in the editorial process.",
 "article_title": "New Philology and New Phylogeny: Aspects of a Critical Electronic Edition of Wolfram's Parzival",
 "authors": [
 {
 "given": "M.",
 "family": "Stolz",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.2.129",
 "identifier": {
 "string_id": "10.1093/llc/18.2.129",
 "id_scheme": "DOI"
 },
 "abstract": "This study is a test case in the use of stylometric techniques to provide an entrance into questions of literary criticism and interpretation. The study applies multivariate analysis to two texts of Charles Brockden Brown, sometimes considered the first professional writer in the United States. Both a scatter graph of a principal components analysis and a cluster analysis show that individual chapters from each of two novels (Wieland and Carwin) group together, except for three chapters of Wieland that cluster with the Carwin chapters. One chapter of Wieland that clusters with the Carwin chapters is narrated by the same character who narrates all of Carwin, thus providing statistical evidence that Brown has created a narrator with a distinctive voice. Accounting for the clustering of the other two chapters calls for a consideration of several of the more crucial and problematic interpretative issues in the novel, and suggests that quantitative analysis can indeed provide background and evidence for literary critical discussion and understanding.",
 "article_title": "Charles Brockden Brown: Quantitative Analysis and Literary Interpretation",
 "authors": [
 {
 "given": "L. L.",
 "family": "Stewart",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.1.11",
 "identifier": {
 "string_id": "10.1093/llc/18.1.11",
 "id_scheme": "DOI"
 },
 "abstract": "Since February 2002, a first version of the Deutsche Wörterbuch (DWB) by Jacob and Wilhelm Grimm has been available on the web. A CD‐ROM beta version has been available since December 2002. This paper will focus on the steps involved in drawing up an electronic version of the DWB and, by demonstrating the design of the Graphical User Interface (GUI), will show how common standards of digitization were taken into account and user needs were anticipated during the production process. The history and structure of the DWB will be outlined first to point out some characteristics of the dictionary. The process of retrodigitization from printed page to electronic dictionary will be briefly described and, while giving an overview of the DWB GUI, the importance of content‐based markup and a user‐friendly but powerful GUI as a necessary precondition for sensible and effective access to the dictionary contents will be stressed. The title of this paper, Towards the User, can thus be interpreted in two ways: during the digitization of the DWB, we consider the needs of the users, and by digitization, we hope to open up this huge amount of data and lexicological information for researchers.",
 "article_title": "Towards the User: The Digital Edition of the Deutsche Worterbuch by Jacob and Wilhelm Grimm",
 "authors": [
 {
 "given": "R.",
 "family": "Christmann",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.1.23",
 "identifier": {
 "string_id": "10.1093/llc/18.1.23",
 "id_scheme": "DOI"
 },
 "abstract": "In recent years, the use of large corpora has revolutionized the way we study language. There are now numerous well‐established corpus projects, which have set the standard for future corpus‐based research. As more and more corpora are developed and technology continues to offer greater and greater scope, the emphasis has shifted from corpus size to establishing norms of good practice. There is also an increasingly critical appreciation of the crucial role played by corpus design. Corpus design can, however, present peculiar problems for particular types of source material. The Scottish Corpus of Texts and Speech (SCOTS) is the first large‐scale corpus project specifically dedicated to the languages of Scotland, and therefore it faces many unanswered questions, which will have a direct impact on the corpus design. The first phase of the project will focus on the language varieties Scots and Scottish English, varieties that are themselves notoriously difficult to define. This paper outlines the complexities of the Scottish linguistic situation, before going on to examine the problematic issue of how to construct a well‐balanced and representative corpus in what is largely uncharted territory. It argues that a well‐formed corpus cannot be constructed in a linguistic vacuum, and that familiarity with the overall language population is essential before effective corpus sampling techniques, methodologies, and categorization schema can be devised. It also offers some preliminary methodologies that will be adopted by SCOTS.",
 "article_title": "The Scottish Corpus of Texts and Speech: Problems of Corpus Design",
 "authors": [
 {
 "given": "F. M.",
 "family": "Douglas",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.1.39",
 "identifier": {
 "string_id": "10.1093/llc/18.1.39",
 "id_scheme": "DOI"
 },
 "abstract": "Markup licenses inferences about a text. But the information warranting such inferences may not be entirely explicit in the syntax of the markup language used to encode the text. This paper describes a Prolog environment for exploring alternative approaches to representing facts and rules of inference about structured documents. It builds on earlier work proposing an account of how markup licenses inferences, and of what is needed in a specification of the meaning of a markup language. Our system permits an analyst to specify facts and rules of inference about domain entities and properties as well as facts about the markup syntax, and to construct and test alternative approaches to translation between representation layers. The system provides a level of abstraction at which the performative or interpretive meaning of the markup can be explicitly represented in machine‐readable and executable form.",
 "article_title": "A Logic Programming Environment for Document Semantics and Inference",
 "authors": [
 {
 "given": "D.",
 "family": "Dubin",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.1.49",
 "identifier": {
 "string_id": "10.1093/llc/18.1.49",
 "id_scheme": "DOI"
 },
 "abstract": "The paper is a report on a case in forensic linguistics in which linguistic and computational approaches are combined to answer the question whether it can be proved if a digital recording has been tampered with. With the growing use of digital applications, the chances of digital forgery are increasing significantly. Accordingly, the detection of tampering with audio recordings is also becoming an important task for forensic linguists. In the given case, we assumed that the most straightforward way of tampering with the given digital audio recording might have been the removal of some material and so our aim was to identify the location of this kind of tampering in the file. Due to the complexity of the given task the approach presented is interdisciplinary: first, it uses a traditional semantic analysis to identify possible discontinuous segments of the recorded text; secondly, it introduces an experimental phonetic approach to identify cues of the digital cutting of the audio signal; thirdly, it applies statistical calculations to specify the bit‐level characteristics of audio recordings. The combination of these measurements proved to be quite helpful in answering the initial question, and the proposed new methodologies can be used in further areas of linguistics and computation.",
 "article_title": "Forensic Linguistics: its Contribution to Humanities Computing",
 "authors": [
 {
 "given": "L.",
 "family": "Hunyadi",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.1.63",
 "identifier": {
 "string_id": "10.1093/llc/18.1.63",
 "id_scheme": "DOI"
 },
 "abstract": "This paper looks at the usability of XML for the electronic publication of field reports by commercial archaeological units. The field reports fall into the field of grey literature as they are produced as client reports by commercial units as part of the planning process and do not receive official publication or widespread dissemination. The paper uses a small commercial unit called ARCUS at the University of Sheffield as a case study and to mark up a sample of excavation report using XML and the TEI Lite DTD. It also looks at the possibility of incorporating controlled archaeological vocabulary into the DTD. The paper comes to the conclusion that the electronic publication of grey reports would be very useful as it would allow a quicker response time and a rapid dissemination of information within the fast‐moving and changing environment of commercial archaeology. XML would be a useful tool for the publication of field reports as it would allow practitioners to selectively download separate sections of field reports that are of particular importance to them and to improve the searchability of reports on the web. It is recognized that national archaeological institutions will also have to accept electronic versions of field reports in order for them to be able to be built into the financial framework of a commercial project design.",
 "article_title": "The Publication of Archaeological Excavation Reports Using XML",
 "authors": [
 {
 "given": "C.",
 "family": "Meckseper",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.1.77",
 "identifier": {
 "string_id": "10.1093/llc/18.1.77",
 "id_scheme": "DOI"
 },
 "abstract": "This paper explains why and how the digitization project METAe applies METS (Metadata Encoding and Transmission Standard) as encoding scheme for automatically extracted metadata. In contrast to TEI (Text Encoding Initiative) and other markup languages, METS allows encoding of the whole range of structural, descriptive, and administrative metadata in a systematic way. As the METS schema permits the integration of other existing standards, it provides a highly flexible output that can be converted easily to the individual needs of digital libraries. An innovative aspect of the METAe data structure is the ALTO file (‘Analysed layout and text object’), which contains the layout structures as well as the text passages of book pages. Structural maps of the METS schema are used to compose the logical and the physical structures out of ALTO and image files.",
 "article_title": "METAe--Automated Encoding of Digitized Texts",
 "authors": [
 {
 "given": "B.",
 "family": "Stehno",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.1.89",
 "identifier": {
 "string_id": "10.1093/llc/18.1.89",
 "id_scheme": "DOI"
 },
 "abstract": "Schema languages concentrate on grammatical constraints on document structures, i.e. hierarchical relations between elements in a tree‐like structure. In this paper, we complement this concept with a methodology for defining and applying structural constraints from the perspective of a single element. These constraints can be used in addition to the existing constraints of a document grammar. There is no need to change the document grammar. Using a hierarchy of descriptions of such constraints allows for a classification of elements. These are important features for tasks such as visualizing, modelling, querying, and checking consistency in textual data. A document containing descriptions of such constraints we call a ‘context specification document’ (CSD). We describe the basic ideas of a CSD, its formal properties, the path language we are currently using, and related approaches. Then we show how to create and use a CSD. We give two example applications for a CSD. Modelling co‐referential relations between textual units with a CSD can help to maintain consistency in textual data and to explore the linguistic properties of co‐reference. In the area of textual, non‐hierarchical annotation, several annotations can be held in one document and interrelated by the CSD. In the future we want to explore the relation and interaction between the underlying path language of the CSD and document grammars.",
 "article_title": "Testing Structural Properties in Textual Data: Beyond Document Grammars",
 "authors": [
 {
 "given": "F.",
 "family": "Sasaki",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.1.112",
 "identifier": {
 "string_id": "10.1093/llc/18.1.112",
 "id_scheme": "DOI"
 },
 "abstract": null,
 "article_title": "Treasurer's Report: Financial year January to December 2002",
 "authors": [
 {
 "given": "J.",
 "family": "Anderson",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/18.1.101",
 "identifier": {
 "string_id": "10.1093/llc/18.1.101",
 "id_scheme": "DOI"
 },
 "abstract": "This article describes the background and architecture of The Versioning Machine, a software tool designed to display and compare multiple versions of texts. The display environment provides for features traditionally found in codex‐based critical editions, such as annotation and introductory material. It also takes advantage of opportunities afforded by electronic publishing, such as providing a frame to compare diplomatic versions of witnesses side by side, allowing for manipulatable images of the witness to be viewed alongside the diplomatic edition, and providing users with an enhanced typology of notes.",
 "article_title": "The Versioning Machine",
 "authors": [
 {
 "given": "S.",
 "family": "Schreibman",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "18",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.4.439",
 "identifier": {
 "string_id": "10.1093/llc/17.4.439",
 "id_scheme": "DOI"
 },
 "abstract": "Scale‐related patterns are found in all thirteen Pauline epistles. To test their distinctiveness, graphs of other texts, ancient and modern, comprising more than a million words, have been scrutinized; this survey has failed to detect any similar patterns. They may therefore be related to Pauline authorship. The longer passages claimed to be interpolations are tested against these scale‐related patterns and are found to be essential parts of the original texts. Further scale‐related patterns are found in 1 and 2 Peter (which received wisdom claims are pseudonymous writings) and in Hebrews. Consideration of these patterns and of the partnership of Paul and Silvanus in mission, leads to a possible solution to the problem of the hapaxes and throws light on the points of contact between the Paulines (including the Pastorals), 1 and 2 Peter, and Hebrews.",
 "article_title": "Interpolations, Pseudographs, and the New Testament Epistles",
 "authors": [
 {
 "given": "G. K.",
 "family": "Barr",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.4.427",
 "identifier": {
 "string_id": "10.1093/llc/17.4.427",
 "id_scheme": "DOI"
 },
 "abstract": "This paper outlines a project currently under way in the Linguistics Department at the University of Arizona to create electronic dictionaries of indigenous languages of the south‐west USA and make them available over the Web for language instruction as well as for linguistic, psycholinguistic, and anthropological research. Working with three languages—Tohono O'odham, Navajo, and Hiaki—we have created an XML scheme that serves as a general template for structuring and archiving language databases. We describe the process of compiling databases for different languages and converting these databases to XML, which contains all the relevant information in a manner that is easily accessible. We discuss the general programming scheme used for searching, and the interfaces used for presenting the dictionary on the Web, which include several front ends for different user groups. We end with a discussion of how to ensure that special characters are displayed properly on the Web.",
 "article_title": "Web-based Dictionaries for Languages of the South-west USA",
 "authors": [
 {
 "given": "S.",
 "family": "Bird",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.4.401",
 "identifier": {
 "string_id": "10.1093/llc/17.4.401",
 "id_scheme": "DOI"
 },
 "abstract": "The problem of automatically determining the gender of a document's author would appear to be a more subtle problem than those of categorization by topic or authorship attribution. Nevertheless, it is shown that automated text categorization techniques can exploit combinations of simple lexical and syntactic features to infer the gender of the author of an unseen formal written document with approximately 80 per cent accuracy. The same techniques can be used to determine if a document is fiction or non‐fiction with approximately 98 per cent accuracy.",
 "article_title": "Automatically Categorizing Written Texts by Author Gender",
 "authors": [
 {
 "given": "M.",
 "family": "Koppel",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.4.373",
 "identifier": {
 "string_id": "10.1093/llc/17.4.373",
 "id_scheme": "DOI"
 },
 "abstract": "In this paper, we put forward a fully developed system for the teaching of Modern Greek Language (MGL). The system comprises a parser and generator for Modern Greek sentences as well as a computational lexicon, encoding morphological, syntactic, and semantic information for words. In this paper, we present the major components of the system, highlighting their suitability for the teaching of MGL in an experimental, open, and cooperative educational environment. The proposed system can be used either in a classroom environment or by Internet correspondence for the teaching of MGL as a native or foreign language.",
 "article_title": "A Complete and Comprehensive System for Modern Greek Language Processing Proposed as a Modern Greek Language Call Method Developer",
 "authors": [
 {
 "given": "S. D.",
 "family": "Baldzis",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.4.475",
 "identifier": {
 "string_id": "10.1093/llc/17.4.475",
 "id_scheme": "DOI"
 },
 "abstract": "This paper presents a method for designing and organizing a multi‐purpose morpheme‐based lexical database for Modern Greek. The authors are in favour of multi‐purpose lexical databases, to avoid a repetition of effort from one application to another, and of morpheme‐based lexica, to achieve flexibility, reusability, expandability, and compact representation of data for future developments. The suggested method for modelling the lexical database in the word‐processing function is the Entity/Relationship model, according to the linguistic theory of Generative Lexical Morphology. In the framework of this model, which depicts rich linguistic information, we can introduce new data structures for storing the morphemes. These new data structures are matrix encoding schemes; one type, called the Cartesian Lexicon, has been designed as a part of our research. The matrix data structures combine the advantages of hash‐tables and tries, which are very popular data structures in supporting machine readable dictionaries. Our system was tested on the Modern Greek language, and demonstrated a satisfactory overall performance in word‐processing. These methods could also be applicable to other languages having morphological systems similar to Modern Greek.",
 "article_title": "Modelling a Morpheme-based Lexicon for Modern Greek",
 "authors": [
 {
 "given": "E.",
 "family": "Papakitsos",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.4.457",
 "identifier": {
 "string_id": "10.1093/llc/17.4.457",
 "id_scheme": "DOI"
 },
 "abstract": "We describe an attempt to analyse the temporal structure of discourse in Modern Greek following the principles of Asher's Segmented Discourse Representation Theory. We focus on discourse relations of a temporal and causal interest and the use of linguistic knowledge for the determination of these relations. This analysis is applied to a corpus of short newspaper articles reporting car accidents in Modern Greek and the discourse grammar is implemented using the Attribute Logic Engine.",
 "article_title": "An SDRT Approach to the Temporal Structure of Modern Greek Narrative Texts",
 "authors": [
 {
 "given": "E.",
 "family": "Galiotou",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.4.413",
 "identifier": {
 "string_id": "10.1093/llc/17.4.413",
 "id_scheme": "DOI"
 },
 "abstract": "A conceptual glossary is a textual reference work that combines the features of a thesaurus and an index verborum. In it, the word occurrences within a given text are classified, disambiguated, and indexed according to their membership of a set of conceptual (i.e. semantic) fields. Since 1994, we have been working towards building a set of conceptual glossaries for the Latin Vulgate Bible. So far, we have published a conceptual glossary to the Gospel according to John and are at present completing the analysis of the Gospel according to Mark and the minor epistles. This paper describes the background to our project and outlines the steps by which the glossaries are developed within a relational database framework.",
 "article_title": "Developing Conceptual Glossaries for the Latin Vulgate Bible",
 "authors": [
 {
 "given": "A.",
 "family": "Wilson",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.3.267",
 "identifier": {
 "string_id": "10.1093/llc/17.3.267",
 "id_scheme": "DOI"
 },
 "abstract": "This paper is a companion to my ‘Questions of authorship: attribution and beyond’, in which I sketched a new way of using the relative frequencies of the very common words for comparing written texts and testing their likely authorship. The main emphasis of that paper was not on the new procedure but on the broader consequences of our increasing sophistication in making such comparisons and the increasing (although never absolute) reliability of our inferences about authorship. My present objects, accordingly, are to give a more complete account of the procedure itself; to report the outcome of an extensive set of trials; and to consider the strengths and limitations of the new procedure. The procedure offers a simple but comparatively accurate addition to our current methods of distinguishing the most likely author of texts exceeding about 1,500 words in length. It is of even greater value as a method of reducing the field of likely candidates for texts of as little as 100 words in length. Not unexpectedly, it works least well with texts of a genre uncharacteristic of their author and, in one case, with texts far separated in time across a long literary career. Its possible use for other classificatory tasks has not yet been investigated.",
 "article_title": "'Delta': a Measure of Stylistic Difference and a Guide to Likely Authorship",
 "authors": [
 {
 "given": "J.",
 "family": "Burrows",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.3.345",
 "identifier": {
 "string_id": "10.1093/llc/17.3.345",
 "id_scheme": "DOI"
 },
 "abstract": "This paper proposes a solution to the problem of handling scribal abbreviations in TEI‐conformant transcriptions of medieval texts, following a conservative editorial strategy. A key distinction is drawn between alphabetic abbreviations, which represent sequences of letters, and logographic abbreviations which represent whole words. The TEI elements 〈expan〉 and 〈abbrev〉 can be used systematically to separate these two types: alphabetic abbreviations will be expanded in the main text, recording the abbreviated form (including TEI entities representing the main abbreviation marks) as an attribute of 〈expan〉, while logographic abbreviations will be represented in their abbreviated form, with the expanded form recorded as an attribute of 〈abbrev〉. The proposals are illustrated from common abbreviations and short text samples from tenth‐century Latin–Portuguese and thirteenth‐century Old Portuguese.",
 "article_title": "Encoding Medieval Abbreviations for Computer Analysis (from Latin-Portuguese and Portuguese Non-literary Sources)",
 "authors": [
 {
 "given": "S. R.",
 "family": "Parkinson",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.3.289",
 "identifier": {
 "string_id": "10.1093/llc/17.3.289",
 "id_scheme": "DOI"
 },
 "abstract": "This paper presents an overview of the Pascal Database System. The Pascal Database includes all the text from the Œuvres complèetes de Blaise Pascal in four volumes. The online database was released experimentally in October 2000. It is possible to display material, perform a vocabulary search, and make frequency lists of material in the database via the Internet. The content display can access each volume, plus manuscript data, edition, references, annotations of J. Mesnard, and other documents, which is a great advantage when studying the material. The vocabulary search can perform Boolean searches with ‘And’, ‘Or’, and ‘Not’, and can also use the wild card ‘★’. Frequency lists can be made using alphabetical or frequency order, and it is even possible to create a list based on the alphabetical order of the reversed words. Finally, we comment on the personal pronouns in Pascal's letters and discuss the uses of the word figure in the second volume of Pascal's work.",
 "article_title": "The Pascal Digital Archive",
 "authors": [
 {
 "given": "S.",
 "family": "Shiraishi",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.3.323",
 "identifier": {
 "string_id": "10.1093/llc/17.3.323",
 "id_scheme": "DOI"
 },
 "abstract": "This paper introduces an intelligent tutoring system designed to help student translators learn to appreciate the distinction between literal translation and liberal translation, an important and forever debated point in the literature of translation, and some other methods of translation lying between these two extremes. We identify four prominent kinds of translation methods commonly discussed in the translation literature—word‐for‐word translation, literal translation, semantic translation, and communicative translation—and attempt to extract computationally expedient definitions for them from two researchers' discussions on them. We then apply these computational definitions to the preparation of our translation corpus to be used in the intelligent tutoring system. In the basic working mode the system offers a source sentence for the student to translate, compares it with the inbuilt versions, and decides on the most likely method of translation used through a translation unit matching algorithm. The student can guess where on the literal and liberal continuum their translation stands by viewing this verdict and by comparing their translation with other versions for the same sentence. In the advanced working mode, the student learns some translation techniques such as the contrastive analysis approach to teaching translation, while appreciating the working of translation methods in relation to these techniques.",
 "article_title": "Computer-Assisted Teaching of Translation Methods",
 "authors": [
 {
 "given": "C.-C.",
 "family": "Shei",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.3.311",
 "identifier": {
 "string_id": "10.1093/llc/17.3.311",
 "id_scheme": "DOI"
 },
 "abstract": "Until printing was invented, texts were copied by hand. The probability with which changes were introduced during copying was affected by the kind of text and society. We cannot usually estimate the probability of change directly. Instead, we develop an indirect method. We derive a relationship between the number of manuscripts in the tradition and the mean number of copies separating a randomly chosen pair of manuscripts. Given the rate at which the proportion of words that are different increases with the mean number of copies separating two manuscripts, we can then estimate the probability of change. We illustrate our method with an analysis of Lydgate's medieval poem The Kings of England.",
 "article_title": "How Accurate Were Scribes? A Mathematical Model",
 "authors": [
 {
 "given": "M.",
 "family": "Spencer",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.2.245",
 "identifier": {
 "string_id": "10.1093/llc/17.2.245",
 "id_scheme": "DOI"
 },
 "abstract": "This paper describes the general principles, design, and present state of the Czech National Corpus (CNC) project. The corpus has been designed to provide a firm basis for the study of both the contemporary written Czech (a goal well attainable with the present resources) and the Czech language beyond the limits of contemporary written texts (a long‐term commitment including the building of a corpus of spoken Czech and diachronic and dialectal corpora). The work on the CNC project, now in the eighth year of its official existence, has resulted in the completion of SYN2000, a 100‐million‐word corpus of contemporary written Czech, the organization of the cores of spoken, diachronic, and dialectal corpora, and the finding of workable solutions to some general theoretical problems involved in the building of these corpora.",
 "article_title": "The Czech National Corpus: Principles, Design, and Results",
 "authors": [
 {
 "given": "K.",
 "family": "Kucera",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.2.193",
 "identifier": {
 "string_id": "10.1093/llc/17.2.193",
 "id_scheme": "DOI"
 },
 "abstract": "Many manuscripts of the Saddharmapundarika, which are among the most important manuscripts for the study of Buddhism, have been discovered in very different localities and are classified according to their place of discovery into the following three groups: Nepalese, Kashmirian, and Central Asian manuscripts. For the genealogical classification of these manuscripts, principal component analysis and cluster analysis, which describe the similarities between the verses of the different manuscripts, were applied to the data. As a result, we could successfully classify these manuscripts into two large groups and several smaller groups: one large group consists of ten paper manuscripts from Nepal and the other comprises nine palm‐leaf plus two paper manuscripts. The Kashmir and Central Asian manuscripts and a few of the Nepal manuscripts belong to the small groups.",
 "article_title": "Genealogical Classification of Saddharmapundarika Manuscripts Based on Many-Variable Analysis",
 "authors": [
 {
 "given": "Y.",
 "family": "Ousaka",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.2.133",
 "identifier": {
 "string_id": "10.1093/llc/17.2.133",
 "id_scheme": "DOI"
 },
 "abstract": "In this essay I explore a variety of experimental poetic tendencies produced in Spain during the twentienth century. Some of the most popular experimental poetic practices are visual poetry, sound poetry, phonetic poetry, computer poetry, video poetry, and mail art. Because these tendencies were not born in Spain we have to take into consideration international and historical avantgarde practices such as concretism, phonetic poetry, and others. I also study the different interests between multiple artistic languages employed in historical avant‐garde poetry and in more recent experimental poetry. Another aspect studied is the political background especially in the sixties and seventies in Spain and how it conditioned the development and durability of different groups and artistic expressions. Another important factor taken into consideration is the use and development of the different technologies available. Technology is not a medium in this kind of poetry but part of the message and for that purpose it can be used in different ways in the construction of a poem. Because of the complexity of the subject, and the difficulty of getting access to rare books and materials I give a panoramic view – with special attention to selected poems and authors – of the most visible experimental poetic manifestations produced in Spain. But there is a need to do more specialized studies in order to gain a better comprehension of these alternative poetic practices that are becoming more and more popular today.",
 "article_title": "Experimental Poetic Practices in Spain",
 "authors": [
 {
 "given": "L. L.",
 "family": "Fernandez",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.2.231",
 "identifier": {
 "string_id": "10.1093/llc/17.2.231",
 "id_scheme": "DOI"
 },
 "abstract": "Automatic keyword extraction is an extremely interesting prospect for computational humanists because of its potential as a tool to aid scholarship in the humanities. Keyword discovery routines can help organize large collections of texts and perhaps even guide scholars to the discovery of important elements in their source materials. It is not clear, however, that the methods designed to extract keywords from paper abstracts or newswire texts will be effective for literary texts that are not written in English. This paper describes the modifications required to the traditional tf★idf keyword discovery algorithm so that it will extract valid keywords from literary texts written in Ancient Greek.",
 "article_title": "Keyword Extraction from Ancient Greek Literary Texts",
 "authors": [
 {
 "given": " Jeffrey A.",
 "family": "Rydberg‐Cox",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.2.207",
 "identifier": {
 "string_id": "10.1093/llc/17.2.207",
 "id_scheme": "DOI"
 },
 "abstract": "Word alignment in bilingual or multilingual parallel corpora has been a challenging issue for natural language engineering. An efficient algorithm for automatically aligning word translation equivalents across different languages will be of use for a number of practical applications such as multilingual lexical construction, machine translation, etc. This paper presents a hybrid algorithm for English–Chinese word alignment, which incorporates co‐occurrence association measures, word distribution distances, English word lemmatization, and part‐of‐speech information. Eleven co‐occurrence association coefficients and eight distance measures of word distribution are explored to compare their efficiency for word alignment. The paper also describes an experiment in which the algorithm is evaluated on sentence‐aligned English–Chinese parallel corpora. In the experiment, the algorithm produced encouraging success rates on two test corpora, with the highest success rate of 89.37 per cent. It provides a practical tool for extracting word translation equivalents from English–Chinese parallel corpora.",
 "article_title": "Word Alignment in English-Chinese Parallel Corpora",
 "authors": [
 {
 "given": "S. S.",
 "family": "Piao",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.2.181",
 "identifier": {
 "string_id": "10.1093/llc/17.2.181",
 "id_scheme": "DOI"
 },
 "abstract": "Determination of authorship, using methods such as those of Mosteller and Wallace, has been obliquely criticized by literary scholars for years. However, the most radical critique of these methods has, under the umbrella term ‘theory’, emerged since the 1960s in the writings of Barthes, Foucault, and Derrida. Thanks to their influence, authorship attribution is now distinguished from authorship ascription with only the latter applying to literary and linguistic computing. Various criticisms are examined in detail. Useful as these criticisms are, the philosophical roots of the postmodernist critiques are destructive of any attempt to discover who wrote what.",
 "article_title": "Linguistic Computing in the Shadow of Postmodernism",
 "authors": [
 {
 "given": "T.",
 "family": "Merriam",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.2.157",
 "identifier": {
 "string_id": "10.1093/llc/17.2.157",
 "id_scheme": "DOI"
 },
 "abstract": "This paper investigates the relative effectiveness and accuracy of multivariate analysis, specifically cluster analysis, of the frequencies of very frequent words and the frequencies of very frequent word sequences in distinguishing texts by different authors and grouping texts by a single author. Cluster analyses based on frequent words are fairly accurate for groups of texts by known authors, whether the texts are long sections of modern British and US novels or shorter sections of contemporary literary critical texts, but they are only rarely completely accurate. When frequent word sequences are used instead of frequent words or in addition to them, however, the accuracy of the analyses often improves, sometimes dramatically, especially when personal pronouns are eliminated. Analyses based on frequent sequences even provide completely correct results in some cases where analyses based on frequent words fail. They also produce superior results for small groups of problematic novels and critical texts extracted from the larger corpora. Such successes suggest that analyses based on frequent word sequences constitute improved tools for authorship and stylistic studies.",
 "article_title": "Frequent Word Sequences and Statistical Stylistics",
 "authors": [
 {
 "given": "D. L.",
 "family": "Hoover",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.1.103",
 "identifier": {
 "string_id": "10.1093/llc/17.1.103",
 "id_scheme": "DOI"
 },
 "abstract": "The application of computing to the disciplines of the humanities has two principal outcomes: useful results for the field of application and failures completely to demonstrate what is known. These failures, an inevitable feature of modelling, point to the key question for humanities computing, how we know what we know, and so to the beginning of its own scholarly enquiry. This, I argue, proceeds along three branches, the algorithmic, the metatextual, and the representational. Examining the first of these here I argue for research toward an open‐ended, interoperable set of primitives based on previous work in the field and designed for the emerging digital library environment. To set the stage for their further development I argue that the field as a whole does not wait on a theoretical formulation of what humanists do, rather should look to the tradition of experimental knowledge‐making as this has been illuminated in recent years by historians, philosophers, and sociologists of science.",
 "article_title": "Humanities Computing: Essential Problems, Experimental Practice",
 "authors": [
 {
 "given": "Willard",
 "family": "McCarty",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.1.1",
 "identifier": {
 "string_id": "10.1093/llc/17.1.1",
 "id_scheme": "DOI"
 },
 "abstract": "This paper presents a stemmer for processing document and query words to facilitate searching databases of Amharic text. An iterative stemmer has been developed that involves the removal of both prefixes and suffixes and that also takes account of letter inconsistency and reiterative verb forms. Application of the stemmer to a test file of 1221 words suggested that appropriate stems were generated for ca. 95 per cent of them, with only limited overstemming and understemming.",
 "article_title": "Stemming of Amharic Words for Information Retrieval",
 "authors": [
 {
 "given": "N.",
 "family": "Alemayehu",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.1.19",
 "identifier": {
 "string_id": "10.1093/llc/17.1.19",
 "id_scheme": "DOI"
 },
 "abstract": "This paper presents a semi‐automatic ontology construction method using various resources, and an ontology‐based word sense disambiguation method in machine translation. To acquire a reasonably practical ontology in limited time and with less manpower, we extend the Kadokawa thesaurus by inserting additional semantic relations into its hierarchy, which are classified as case relations and other semantic relations. The former can be obtained by converting valency information and case frames from previously built computational dictionaries used in machine translation. The latter can be acquired from concept co‐occurrence information, which is extracted automatically from large corpora. The ontology stores rich semantic constraints among 1110 concepts, and enables a natural language processing system to resolve semantic ambiguities by making inferences with the concept network of the ontology. In practical machine translation systems, our word sense disambiguation method achieved a 6.0 per cent and 7.9 per cent improvement over methods that do not use an ontology for each Japanese and Korean translation.",
 "article_title": "Language Independent and Practical Ontology in Korean-Japanese Machine Translation Systems",
 "authors": [
 {
 "given": "S.-J.",
 "family": "Kang",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.1.61",
 "identifier": {
 "string_id": "10.1093/llc/17.1.61",
 "id_scheme": "DOI"
 },
 "abstract": null,
 "article_title": "Visible and Invisible Books: Hermetic Images in n-Dimensional Space",
 "authors": [
 {
 "given": "J.",
 "family": "McGann",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.1.130",
 "identifier": {
 "string_id": "10.1093/llc/17.1.130",
 "id_scheme": "DOI"
 },
 "abstract": null,
 "article_title": "Treasurer's Report: Financial year January to December 2000",
 "authors": [
 {
 "given": "J.",
 "family": "Anderson",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.1.89",
 "identifier": {
 "string_id": "10.1093/llc/17.1.89",
 "id_scheme": "DOI"
 },
 "abstract": "In any academic field, research advances tend to percolate naturally to higher education in that field. In recent years, there has been a slow but steady increase in the number of courses and degree programmes in humanities computing. This paper presents some reflections on the status of humanities computing in higher education, in terms of curricula, degrees, and international student and staff mobility. The most important issue is the question of what a humanities computing degree should offer, in view of the wide interdisciplinarity of the field. Different institutions have coped with this question in very different ways. With potentially far‐reaching consequences on methodology in the various relevant disciplines, humanities computing is bound to change both what and how humanities students learn. Curriculum innovation that aims to integrate computing in the humanities is a difficult process that requires reflection, co‐operation, teacher training, and other supporting actions.",
 "article_title": "Some Reflections on Studies in Humanities Computing",
 "authors": [
 {
 "given": "K.",
 "family": "de Smedt",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/17.1.49",
 "identifier": {
 "string_id": "10.1093/llc/17.1.49",
 "id_scheme": "DOI"
 },
 "abstract": "Over the last decade, HTML has moved from being the new file format of a new network service—the Web—to a well‐known but often abused barrier to communication. The advantages of changing to more formalized systems in XML are clear, but deployment has been hindered by the slow development of browsers, editors, and other software suitable for academic work. XML has greater potential than HTML for use off the Web, especially in the humanities, so the concept of ‘life beyond the Web’ for textual scholarship can be expressed in terms of opportunities for researchers. This paper is an expansion of a talk given to a Symposium of the Computer Science and English Initiative (COSEI) held in February 2000 at University College Dublin.",
 "article_title": "Is There Life Beyond the Web?",
 "authors": [
 {
 "given": "P.",
 "family": "Flynn",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "17",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.4.353",
 "identifier": {
 "string_id": "10.1093/llc/16.4.353",
 "id_scheme": "DOI"
 },
 "abstract": "The study first establishes a set of formal properties of Ulysses through a computational approach based on frequency counts of the ninety-nine most common words of the text. The common words are first used to discriminate interior monologue, dialogue, and narrative, and then to discriminate between the different narrative styles of the text. The discriminations are achieved by means of multivariate statistics, such as principal component analysis, and by distribution tests (Student's t-test and Mann-Whitney test). Using the linguistic premise that all matter is meaning, as well as Bakhtin's argument that all language is ideologically saturated, the study then explores the relationship between common words, meaning, and ideology. It concentrates on the Gerty MacDowell section of episode 13 of Ulysses in order to show how common words that appear more frequently in that episode than in others—such as two modals, two causal conjunctions, and one preposition—are integral to the various syntactic structures that differentiate styles and contribute to the meaning and ideology of the text. The article links these discriminations to Bakhtin's concept of polyphony and to his discussion of the ‘creation of specific novelistic images of languages’. Its conclusion, therefore, is that computational analysis of style can open interpretation to details of form, meaning, and ideology that enable humanities computing to make a distinctive contribution to literary criticism.",
 "article_title": "The Statistical Analysis of Style: Reflections on Form, Meaning, and Ideology in the 'Nausicaa' Episode of Ulysses",
 "authors": [
 {
 "given": " C. W. F.",
 "family": "McKenna",
 "affiliation": [
 {
 "original_name": "Centre for Literary and Linguistic Computing, Faculty of Arts and Social Science, The University of Newcastle New South Wales 2308, Australia",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " A.",
 "family": "Antonia",
 "affiliation": [
 {
 "original_name": "Centre for Literary and Linguistic Computing, Faculty of Arts and Social Science, The University of Newcastle New South Wales 2308, Australia",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.4.403",
 "identifier": {
 "string_id": "10.1093/llc/16.4.403",
 "id_scheme": "DOI"
 },
 "abstract": "Fifty years after the Confederate assault on the third day of the battle of Gettysburg, the widow of the General after whom the assault is named, George Pickett, published letters purportedly written to her by her husband, many of them from the field of battle itself, during the four-year-long American Civil War. These letters fit into the ‘Lost Cause’ literature of the late nineteenth and early twentieth centuries. There are, however, anachronisms and other factual problems in the published letters, and they have been questioned, at least in part, by writers and historians of the Civil War. Other historians believe them to be essentially genuine. This paper conducts a stylometric investigation of the Pickett Letters as a complement to traditional historical research. Our investigation strongly suggests that Pickett's widow, LaSalle Corbell Pickett, did compose the published letters. Eleven handwritten letters are, however, thought to be from George's hand.",
 "article_title": "A Widow and her Soldier: Stylometry and the American Civil War",
 "authors": [
 {
 "given": " David I.",
 "family": "Holmes",
 "affiliation": [
 {
 "original_name": "The College of New JerseyUSA",
 "normalized_name": "Princeton University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00hx57361",
 "GRID": "grid.16750.35"
 }
 }
 ]
 },
 {
 "given": " Lesley J.",
 "family": "Gordon",
 "affiliation": [
 {
 "original_name": "University of AkronUSA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Christine",
 "family": "Wilson",
 "affiliation": [
 {
 "original_name": "The College of New JerseyUSA",
 "normalized_name": "Princeton University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/00hx57361",
 "GRID": "grid.16750.35"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.4.389",
 "identifier": {
 "string_id": "10.1093/llc/16.4.389",
 "id_scheme": "DOI"
 },
 "abstract": "English has two main sources for words: German and Latin. Distinct from each other, they have polarized our language into high diction and low (‘diglossia’). Latinate words denote the intellectual world; Germanic words, the physical. Latinate words are indicators of status and education. Austen painted and delineated her characters by giving their speeches different densities of Latinate words. Higher densities of Latinate words sometimes indicate intelligence and moral seriousness, at other times, they expose a character's formality or hypocrisy. Lower densities indicate lesser intelligence or, in the case of sailors, humble birth. The characters whose densities are very close to the narrator are Austen's four great heroines, Elinor Dashwood, Elizabeth Bennet, Emma Woodhouse, and Anne Elliot.",
 "article_title": "The Density of Latinate Words in the Speeches of Jane Austen's Characters",
 "authors": [
 {
 "given": " Mary",
 "family": "DeForest",
 "affiliation": [
 {
 "original_name": "University of Colorado at DenverUSA",
 "normalized_name": "University of Colorado Denver",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/02hh7en24",
 "GRID": "grid.241116.1"
 }
 }
 ]
 },
 {
 "given": " Eric",
 "family": "Johnson",
 "affiliation": [
 {
 "original_name": "Dakota State UniversityUSA",
 "normalized_name": "Dakota State University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/016yv6y68",
 "GRID": "grid.254833.b"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.4.421",
 "identifier": {
 "string_id": "10.1093/llc/16.4.421",
 "id_scheme": "DOI"
 },
 "abstract": "This paper investigates the effectiveness and accuracy of multivariate analysis, specifically cluster analysis, of the frequencies of very frequent words in distinguishing texts by different authors and grouping texts by a single author. An examination of groups of texts by known authors shows that cluster analyses typically achieve an accuracy rate of less than 90 per cent for contemporary novels, modern British and American novels, and contemporary literary critical texts, both on relatively large groups of texts and on smaller subsets of those texts. Although limiting the analysis to third-person narration, and disambiguating homographic function words improves the results, inaccuracies remain. Furthermore, small groups of problematic texts extracted from the larger groups in simulated authorship studies also fail to cluster correctly. These failures suggest general rather than local problems with the technique, and cast doubt on the effectiveness of cluster analysis for authorship attribution and stylistic study.",
 "article_title": "Statistical Stylistics and Authorship Attribution: an Empirical Investigation",
 "authors": [
 {
 "given": " David L.",
 "family": "Hoover",
 "affiliation": [
 {
 "original_name": "New York UniversityUSA",
 "normalized_name": "New York University",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/0190ak572",
 "GRID": "grid.137628.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.4.375",
 "identifier": {
 "string_id": "10.1093/llc/16.4.375",
 "id_scheme": "DOI"
 },
 "abstract": "The sentence length distribution curve is modified by three non-rational components: scale, contrast, and monumentality. In this paper these components are isolated using graphical techniques. Combining batches of different types of sentence that are conceived at different scale levels also modifies the distribution. The effect of these variables is to give the sentence length distribution curve of each work of literature a unique profile. In longer composite texts, these variables average out and the curves converge on an ultimate distribution curve.",
 "article_title": "Graphical Analysis of the Sentence Length Distribution Curve and Non-rational Components",
 "authors": [
 {
 "given": " George K.",
 "family": "Barr",
 "affiliation": [
 {
 "original_name": "ComrieUK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.4.445",
 "identifier": {
 "string_id": "10.1093/llc/16.4.445",
 "id_scheme": "DOI"
 },
 "abstract": "In this paper, a system is presented that performs an automated morphological categorization of Greek words extracted from a corpus. This system processes morphologically the words via the repetitive application of a masking-and-matching technique. It is found that the introduction of a priori information regarding the grammar of the Greek language considerably improves the word segmentation accuracy. The system accuracy is evaluated by comparing the word segmentation with the entries of a morphological lexicon of the Greek language. The experimental results indicate that the output of the automated system is—for the majority of words—in agreement with the entries of the morphological lexicon. The proposed system is successfully applied to the generation of specialized morphological lexica on the basis of corpora consisting of term-intensive documents. Finally, possible extensions of the proposed system to other languages as well as to cover the derivation phenomenon for the Greek language are briefly reviewed.",
 "article_title": "Automatic Corpora-based Stemming in Greek",
 "authors": [
 {
 "given": " G.",
 "family": "Tambouratzis",
 "affiliation": [
 {
 "original_name": "Institute for Language and Speech ProcessingGreece",
 "normalized_name": "Institute for Language and Speech Processing",
 "country": "Greece",
 "identifiers": {
 "ror": "https://ror.org/00z24kr14",
 "GRID": "grid.424851.e"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.4.467",
 "identifier": {
 "string_id": "10.1093/llc/16.4.467",
 "id_scheme": "DOI"
 },
 "abstract": "Many stemmatological methods require estimates of pairwise distances between manuscripts, where distance is some measure of the number of changes that have occurred during copying along the path linking the two manuscripts. If a pair of manuscripts are separated from their common ancestor by more than one copy, more than one change may have occurred at some locations in the text, and the observed distance between two manuscripts may underestimate the actual number of changes. We derive a simple estimate of the actual number of changes given the observed number of changes, using a mathematical model for copying errors. This estimate is little affected by the size of the lexicon, the average rate at which copying errors are made, and the number of words for which a given word might be mistaken. Variation in error rates among scribes has no effect, and variation in error rates among words is probably unimportant. We recommend the routine use of this formula. However, variation in error rates among locations in the text can strongly affect the relationships between observed and actual distances. Such variation might easily arise in poetry because of the constraints of rhyme. Two priorities for future work are testing the underlying model for copying errors, and determining patterns of variation in error rates among locations.",
 "article_title": "Estimating Distances between Manuscripts Based on Copying Errors",
 "authors": [
 {
 "given": " Matthew",
 "family": "Spencer",
 "affiliation": [
 {
 "original_name": "University of CambridgeCambridge, UK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Christopher J.",
 "family": "Howe",
 "affiliation": [
 {
 "original_name": "University of CambridgeCambridge, UK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.3.265",
 "identifier": {
 "string_id": "10.1093/llc/16.3.265",
 "id_scheme": "DOI"
 },
 "abstract": "Syntactic analysis often plays an important role in natural language processing application systems such as document processing and question–answering. To use parsed results in the application systems, the parser should be efficient without losing accuracy. In this paper, we present a method for Korean dependency analysis using three types of chunking and lexical co–occurrences extracted from a large corpus. The chunking, which is crucial for reducing disambiguation decisions in the parsing process, is conducted using a finite state transducer and lexical collocation. In addition, lexical information has a great impact on parsing for a free-ordered language such as Korean, as the lexical association is more important than the word order in analysing such languages. The parser that we propose is a hybrid system directed by statistical data and syntactic rules, and based on right–to–left analysis to effectively treat sentences in Korean, which is a head final language. Experiments show that the method is very effective in that it gives accuracy as well as efficiency by reducing irrelevant parsing decisions.",
 "article_title": "Efficient dependency analysis for Korean sentences based on lexical association and multi-layered chunking",
 "authors": [
 {
 "given": " Juntae",
 "family": "Yoon",
 "affiliation": [
 {
 "original_name": "Daumsoft Inc.Seoul, South Korea",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.3.233",
 "identifier": {
 "string_id": "10.1093/llc/16.3.233",
 "id_scheme": "DOI"
 },
 "abstract": "The opening portions of the Pauline epistles display characteristic patterns that are scale related. They are the result of interaction between cycles comprising groups of longer and shorter sentences and the contrast between an opening high-scale section and a following low-scale section of the text. This interaction produces patterns in the several epistles which are not identical but whose features are scale related. Similar patterns may be produced mathematically, and the correspondence of the sentence patterns found in the texts to those of the mathematical model indicates that there are links between epistles that have not hitherto been identified. Studies using traditional or statistical methods have not yet taken into account the scale variable, which is ubiquitous in literature. No longer can texts be assumed to be homogeneous in this respect. The identification of these scale-related patterns is of importance in matters of author determination.",
 "article_title": "A computer model for the Pauline epistles",
 "authors": [
 {
 "given": " George K.",
 "family": "Barr",
 "affiliation": [
 {
 "original_name": "Comrie, UK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.3.251",
 "identifier": {
 "string_id": "10.1093/llc/16.3.251",
 "id_scheme": "DOI"
 },
 "abstract": "Recent research on gender differences in language has mostly addressed cognitive differences. These differences have been observed on different cognitive verbal and non–verbal tasks and conclusions on the variability in language production and comprehension have been drawn from their results. In this paper, a different approach is presented. This pilot study examines lexical richness measures in conversational speech across a total of thirty subjects. All subjects were recorded and transcribed in a conversational setting. Their transcribed speech was analysed using a set of lexical richness measures based on word–frequencies. On the basis of these measurements, statistical discriminant analysis is able to classify the two groups with 90 per cent (74 per cent with leave–one–out cross–validation) correct prediction rate at a statistically significant level (P = 0. 03). The results are discussed in detail, including correlation and principal components analysis. The paper concludes that there are interesting differences across the two groups on the measures studied and further research in this area is needed.",
 "article_title": "A pilot study on gender differences in conversational speech on lexical in richness measures",
 "authors": [
 {
 "given": " Sameer",
 "family": "Singh",
 "affiliation": [
 {
 "original_name": "University of ExeterExeter, UK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.3.205",
 "identifier": {
 "string_id": "10.1093/llc/16.3.205",
 "id_scheme": "DOI"
 },
 "abstract": "American authorities, persuaded by Donald Foster's stylometric evidence, believe that Funeral Elegy by W. S. (FE) is at least possibly, and perhaps indisputably by Shakespeare. British authorities disagree sharply. Brian Vickers, Richard Kennedy, and Gilles Monsarrat argue that John Ford wrote the Elegy. We examine both ascriptions by applying to Ford's poems the same kind of common-authorship, exclusionary-evidence tests that we previously applied to Shakespeare's poems and play verse. We conclude that the odds are strongly against the Americans. If W. S. is either Ford or Shakespeare, Ford seems by far the more likely candidate. Counting firm rejections only, the Elegy fails sixteen of thirty-three Shakespeare tests and only one of twenty-nine Ford tests. If the distinguishing traits of both authors are Poisson-distributed—as some seem to be—the odds that the Elegy's scores could have arisen by chance from one corpus or the other are about 3,000 times better for Ford than they are for Shakespeare.",
 "article_title": "Smoking guns and silver bullets: could John Ford have written the Funeral Elegy?",
 "authors": [
 {
 "given": " Ward E. Y.",
 "family": "Elliott",
 "affiliation": [
 {
 "original_name": "Claremont McKenna College, Claremont, California, USA",
 "normalized_name": "Claremont McKenna College",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/04n1me355",
 "GRID": "grid.254272.4"
 }
 }
 ]
 },
 {
 "given": " Robert J.",
 "family": "Valenza",
 "affiliation": [
 {
 "original_name": "Claremont McKenna CollegeClaremont, California, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.3.287",
 "identifier": {
 "string_id": "10.1093/llc/16.3.287",
 "id_scheme": "DOI"
 },
 "abstract": "The World of Dante [http://www.iath.virginia.edu/dante/] offers a hypermedia environment for the study of the Inferno. Developed under the auspices of the Institute for Advanced Technologies in the Humanities (IATH), the major sections of the project include a visual archive of approximately three hundred images; the TEI-tagged Italian text of the Inferno, presented through Dynaweb; and a text visualization, a VRML model of the Inferno. This paper describes the visual material found on the project, explains the tagging criteria employed in the markup of the poem, and clarifies the type of research that the project makes possible. The project went online in December 1997. Readers have often been struck by the clarity, variety, and complexity of Dante's comparisons. T. S. Eliot considered Dante unequalled in his ability to form ‘clear visual images’ (Eliot, Dante, Faber & Faber, London, 1929, p. 22). In his essay, ‘A Reading of the Inferno’, Eliot singles out for praise the remarkable quality of Dante's ‘visual imagination’, citing as an example the comparison of a group of men who gaze at Dante and Virgil in the dark to an old tailor peering at the eye of his needle (Inf. 15. 21). Eliot's remarks concerning the remarkable nature of Dante's similes arise in the midst of a discussion of the poetics of the Inferno. Hell is the most material of the three realms of the Afterlife. Dante mentions about one hundred places in the Inferno, sixty in the Purgatorio, and twenty in the Paradiso. Dante's Hell is made up of precipitous slopes, barren forests, thunderous waterfalls, bloody rivers, and burning sands. To convey the savage nature of these places, Dante often evokes the landscape of his own Italy. Yet the multitude of natural, architectural, and geographical allusions that constitute Dante's material world are unfamiliar to most readers. One of the principal objectives of The World of Dante is to make Dante's universe more accessible to students of the poem.",
 "article_title": "The World of Dante: a hypermedia archive for the study of the Inferno",
 "authors": [
 {
 "given": " Deborah",
 "family": "Parker",
 "affiliation": [
 {
 "original_name": "University of VirginiaCharlottesville, VA, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.2.179",
 "identifier": {
 "string_id": "10.1093/llc/16.2.179",
 "id_scheme": "DOI"
 },
 "abstract": "What will be the critical editions in the electronic era? Hubert de Phalèse, a research centre in La Sorbonne-Nouvelle University (Paris III), in accordance with its pragmatic approach to literary computing problems, decided to launch this debate by putting on line a critical edition of the complete works of Lautréamont/Isidore Ducasse (http://www.cavi.univ-paris3.fr/phalese). This edition is an integral hypertext (in which nearly every word of the text is linked with a comment), which gathers all that one usually finds in critical editions, but on a scale that does not have equivalents on paper: variants, philological, literary and encyclopedic comments, biography, bibliography, iconography, index, etc. This prototype poses, concretely, a certain number of problems, on several levels:Technical: Which interface is to be used? The purely automatic search engines (including the uses of Java and other script languages) appeared unsuited and a new device of computer-assisted indexing was developed. It makes it possible to provide for the user a lemmatized index and, especially, lexical cards, which can be enriched at will. The current solution of setting on-line presents some inconveniences but it has the advantage of proposing to the greatest number of users the consultation of the edition and of inviting them to take part in it.Contents: The new support is, virtually, infinite. What is a critical edition to contain now that we are no longer concerned with its volume? All the versions of the text, for example, can now be proposed with the reading. But are we to publish the intertexts, contemporary works, criticism, etc. ? How can the interconnection, in a network, of several resources enrich a critical edition? Under which scientific and legal conditions?Validation: Can this type of edition be regarded as more reliable than the paper editions? According to which protocols will such editions be judged? One of the risks is the appearance of a great quantity of work without scientific guarantee. How will the possibilities of collective work and permanent updating modify our design of what a philological work should be?Publication: Who will deal with the building and the diffusion expenses of such electronic products? Will the redistribution of the budget headings in this type of edition lead academics to transform themselves into diffusers, or will traditional editors change their practice? In addition, new prospects open with the critical edition, which it will be necessary to evaluate and explore to determine their real potentialities.Work in group: data processing and. the Internet support the participation of a growing number of speakers around an intellectual work. What will be the roles of each of these (project director, data-processing specialists, humanists, students, active readers, etc.)? The concepts even of authors and readers will no longer have the same direction.Real time: the possibility of permanent update offered by an Internet site makes it possible to revalue the traditional concepts. Indeed, it is no longer essential to put on-line a totally completed work, and the noted errors can be immediately corrected. In addition, this type of edition makes it possible to account for the topicality of research in the field, which connects it with a review (of which the periodicity is much higher than that of any scientific review).Interactivity: the possibility of putting creators and users of electronic publishing in contact by means of electronic mail also connects this type of edition to a permanent conference. It is possible, in the long, term, that scientific communities (specialists in an author, for example) will gather around great electronic projects, which they would make live by publishing the results of their work there.Cost: the very low cost of setting on-line such an edition (I except the working time of researchers) makes it possible at the same time to consider some undertakings that traditional editors would not consider (very large corpus, work of interest only for few specialists) and to allow researchers to publish in good working conditions works of small size or that do not fit the framework of current university editions.Multimedia: what can be the contribution of multimedia to a scientific work like a critical edition? Everything in this field remains to be invented, because the traditional edition accustomed us to purely textual tools, primarily for reasons of cost. The sound and visual illustrations will bring to the literary text a very interesting dimension (publication of manuscripts, interpretations, inconographics documents, contemporary pieces of music, etc.), from the teaching point of view as well as in the research field, but it is necessary to be wary of the easy effects that have accustomed us, the general public, to electronic publishing. It is very urgent to answer these questions because the share of electronic documentation in literary studies would have, as in the other documentary fields, to increase until gradually replacing the traditional supports. Consequently, the survival of the texts and their formal characteristics will be closely related to the devices that will ensure their transmission, their conservation, and their reading.",
 "article_title": "The FALMER Project: an electronic critical edition",
 "authors": [
 {
 "given": " Michel",
 "family": "Bernard",
 "affiliation": [
 {
 "original_name": "Université de la Sorbonne-NouvelleParis, France",
 "normalized_name": "New Sorbonne University",
 "country": "France",
 "identifiers": {
 "ror": "https://ror.org/03z6jp965",
 "GRID": "grid.17689.31"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.2.189",
 "identifier": {
 "string_id": "10.1093/llc/16.2.189",
 "id_scheme": "DOI"
 },
 "abstract": "Any project in the electronic medium that lays claim to scholarly authority will require adaptations in both the presentation and the dissemination of its materials. Work in progress on an electronic edition of Lyrical Ballads illustrates how these changes may be realized, and brings home the lesson that the evolution of electronic publishing will necessitate innovations that are not just technological but also institutional. A new method of marshalling scholarly apparatus called ‘dynamic collation’ has been employed in this project, which reconceptualizes how variant readings can be presented in the digital medium. The real challenge for online publication, however, is what might be called the lack of mature institutional structures on the Internet. So long as anyone can publish anything on WWW, the quality of its materials remains questionable; furthermore, in the absence of independent web-based publishing houses, personal postings are all too often ephemeral. The imprimatur of an established publisher (in this case, the Cambridge University Press) would be a guarantee of the reliability and durability of these immaterial texts, but entails the development of new publication partnerships. It seems the future of electronic publishing depends upon asking questions about more than technical standards. Online scholarly archives must also meet standards of peer evaluation, editorial practice, and institutional backing that have traditionally ensured the quality of print publications.",
 "article_title": "New models for electronic publishing",
 "authors": [
 {
 "given": " Ronald",
 "family": "Tetreault",
 "affiliation": [
 {
 "original_name": "Dalhousie UniversityHalifax, N.S., Canada",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.2.121",
 "identifier": {
 "string_id": "10.1093/llc/16.2.121",
 "id_scheme": "DOI"
 },
 "abstract": "Jacob and Wilhelm Grimm's Deutsches Wörterbuch (DWB) comprises the most extensive documentation of the German language: for more than one hundred years—the longest period of publication for a German dictionary—generations of lexicographers have contributed about 350,000 entries to the DWB, which is divided into sixteen large volumes (thirty-two sections), containing a total of 67,744 columns. The DWB also reflects more than one hundred years of institutional, lexicographical, historical, and political history. This paper describes the project ‘Deutsches Wörterbuch on CD-ROM and on the Internet’, established at the University of Trier in 1998, stressing in particular the significance of the Standard Generalized Markup Language (SGML) and the guidelines developed by the Text Encoding Initiative (TEI) for the creation of a digitized version of the DWB. In addition, a prototype for a CD-ROM version will be introduced, emphasizing the importance of the electronic DWB, via its transformation into the electronic medium, for opening up new possibilities in using the rich dictionary material.",
 "article_title": "Books into bytes: Jacob and Wilhelm Grimm's Deutsches Worterbuch on CD-ROM and on the Internet",
 "authors": [
 {
 "given": " Ruth",
 "family": "Christmann",
 "affiliation": [
 {
 "original_name": "University of TrierTrier, Germany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.2.199",
 "identifier": {
 "string_id": "10.1093/llc/16.2.199",
 "id_scheme": "DOI"
 },
 "abstract": "In a range of courses taught in the English department at The College of Wooster, student use technology to interrogate ideas in ways novel in humanistic study. In an otherwise conventional seminar room, networked computers (to the Internet as well as locally) along the walls and both commercial and locally developed software tools represent the use of technology as ‘equipment for language’. As our description of how student use the tools (from page-layout programs to a new counting program) show, technology in this setting adds power to student' ability to question and therefore to understand—in the context of a kind of discussion as old as learning.",
 "article_title": "A toolbox for the electronic classroom",
 "authors": [
 {
 "given": " Peter",
 "family": "Havholm",
 "affiliation": [
 {
 "original_name": "The College of WoosterWooster, OH, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Larry",
 "family": "Stewart",
 "affiliation": [
 {
 "original_name": "The College of WoosterWooster, OH, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.2.153",
 "identifier": {
 "string_id": "10.1093/llc/16.2.153",
 "id_scheme": "DOI"
 },
 "abstract": "The Scottish National Dictionary (SND) is the standard historical dictionary of modern Scots, covering the period from 1700 to the present. This paper describes the current project to digitize the SND to produce the eSND, which will eventually be output on the Internet. It includes a brief description of the SND itself, outlining its history, content, and structure, and describes how the eSND will differ from the printed text. The various stages of the eSND project are discussed, using examples from the work in progress: (1) the data capture, which is being achieved through scanning and optical character recognition (OCR) of the printed text; (2) the conversion of the OCR data to full Extensible Markup Language mark-up, including details of the actual mark-up scheme (which is based on the Text Encoding Initiative guidelines), and how this has been adapted to suit the SND text; (3) the integration of the original Supplement and new material; (4) the development of search tools and a Web interface. Details are also given of the new proposal to combine the eSND with an electronic version of the Dictionary of the Older Scottish Tongue (eDOST), sharing the same mark-up scheme, search software, and interface, to produce a comprehensive electronic resource covering Scots from the early medieval period to the present day.",
 "article_title": "The Electronic Scottish National Dictionary (eSND): work in progress",
 "authors": [
 {
 "given": " Susan",
 "family": "Rennie",
 "affiliation": [
 {
 "original_name": "University of DundeeUK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.2.135",
 "identifier": {
 "string_id": "10.1093/llc/16.2.135",
 "id_scheme": "DOI"
 },
 "abstract": "This paper presents an overview of the goals, architecture, and usability of Kirrkirr, a Java-based visualization tool for XML dictionaries, currently being used with a dictionary for Warlpiri, an Australian Aboriginal language. It discusses the underlying lexicon structure, and shows how a computer interface can effectively select from and display that content in various ways. The views of the dictionary include a graph view, which shows a network of semantically related words, and a formatted text view that can be customized via XSLT stylesheets. The paper argues that indigenous language dictionaries have normally been written for linguists, whereas the educational needs of other users have not been adequately met. It discusses the strengths of a computer dictionary interface in providing more help to native speaker users than a conventional dictionary, but argues that the possibilities for the visualization of dictionary information on computers have so far been insufficiently exploited. The paper concludes by briefly discussing observational and task-based testing of the dictionary with native speakers and learners.",
 "article_title": "Kirrkirr: software for browsing and visual exploration of a structured Warlpiri",
 "authors": [
 {
 "given": " Christopher D.",
 "family": "Manning",
 "affiliation": [
 {
 "original_name": "Stanford UniversityStanford, CA, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Kevin",
 "family": "Jansz",
 "affiliation": [
 {
 "original_name": "University of SydneySydney, NSW, Australia",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Nitin",
 "family": "Indurkhya",
 "affiliation": [
 {
 "original_name": "Nanyang Technological UniversitySingapore",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.2.161",
 "identifier": {
 "string_id": "10.1093/llc/16.2.161",
 "id_scheme": "DOI"
 },
 "abstract": "This paper describes the philosophy behind what represents one of the most ambitious projects of its kind ever to have been undertaken in the Spanish-speaking world: the Miguel de Cervantes Digital Library (http://cervantesvirtual.com/). It explains the reasons behind its creation, the private–public sector alliance that has made it possible, and the new ground being explored by its creators in terms of the new services it offers to its audience worldwide and of innovative application of digital methods. The final section of the paper deals with the technical underpinnings of this project at present and in the future, reporting continuing research and development activities being carried out at the Miguel de Cervantes Digital Library in the field of text markup and derived applications, such as automatic transformation of documents to different formats and complex searches performed upon the small textual objects defined by the markup scheme. A brief survey of works done on Named Entity Recognition that can be applied to automatic markup is also included. Finally, there are some comments on the research lines we intend to follow concerning information retrieval and filtering from structurally marked-up texts.This is a fascinating period in the history of libraries and publishing. For the first time, it is possible to build large-scale services where collections of information are stored in digital formats and retrieved over the networks (Arms, 2000).",
 "article_title": "The Miguel de Cervantes Digital Library: the Hispanic voice on the web",
 "authors": [
 {
 "given": " Alejandro",
 "family": "Bia",
 "affiliation": [
 {
 "original_name": "University of Alicante, Alicante, Spain",
 "normalized_name": "University of Alicante",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/05t8bcz72",
 "GRID": "grid.5268.9"
 }
 }
 ]
 },
 {
 "given": " Andrés",
 "family": "Pedreño",
 "affiliation": [
 {
 "original_name": "University of Alicante, Alicante, Spain",
 "normalized_name": "University of Alicante",
 "country": "Spain",
 "identifiers": {
 "ror": "https://ror.org/05t8bcz72",
 "GRID": "grid.5268.9"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.1.59",
 "identifier": {
 "string_id": "10.1093/llc/16.1.59",
 "id_scheme": "DOI"
 },
 "abstract": "One of the aims of linguistics is to infer from the ever-growing mass of actualdata available the implicit, virtual organization underlying the apparent disorder and diversity of surface phenomena. The procedure invariably consists in establishing and revealing the latent links between the fundamental entities justifying the dichotomy between language and speech, namely langue and parole (Saussure), competence and performance (Chomsky), system and process, substance and form (Hjelmslev), or sense and signification (GuiJlaume). This ever-present crucial duality is also at work in computational linguistics, where the chief question is how to reach, beyond the surface of observed facts, for the latent abstract organization, thus enabling the observer (i.e. the linguist) to gain access to knowledge that can be generalized. Tree-representation is a powerful means of evincing the inherent structure of mutually dependent data to account for the respective dependence or independence of the represented objects by means of a hierarchic tree where clearly outlined categories are paired and embedded. Frequently, modern linguists tend to be interested more in the relative closeness of objects than in their belonging to this or that closed class. Additive, as opposed to hierarchic, trees do away with watertight partitions between objects and lay the stress on notions such as proximity and opposition. The question of course arises of the possibility of representing any two distinct sets of original data in one tree-figure. The only procedure available is to attempt to achieve a consensus by fuson of the original two trees by means of a new algorithm. The algorithm is explained in detail and applied to various subsets of the tagged version of the LOB Corpus.",
 "article_title": "On consensus between tree-representations of linguistic data",
 "authors": [
 {
 "given": " M.",
 "family": "Juillard",
 "affiliation": [
 {
 "original_name": "Université de Nice–Sophia AntipolisNice, France",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.1.99",
 "identifier": {
 "string_id": "10.1093/llc/16.1.99",
 "id_scheme": "DOI"
 },
 "abstract": "The paper describes the creation of a digital network of the extant Middle High German dictionaries. As these works of reference, i.e. the Mittelhochdeutsches Worterbuch by Benecke-Muller-Zarncke, the Mittelhochdeutsches Handwdrterbuch and its supplement by Lexer, and the Findebuch, are very closely interconnected and can only be used simultaneously, they were ideal candidates for the composition of an electronic dictionary compound. In creating that network, the data have been encoded according to the Guidelines of the Text Encoding Initiative. Such markup when applied to historical dictionaries raised some problems, which are discussed in the second part of this paper. The main section deals with the graphical user interface of the digital dictionary and shows various searches in the dictionary database. Examples of philologjc relevance are not only given as far as full text retrieval is concerned but also for queries with the aid of preclassified criteria such as, for example, parts of speech, specific text types, or word forms in foreign languages. The institutional and organizational preconditions of the digitization are finally outiined. The simultaneous use of the dictionaries closely tied together already in their printed form will be made much easier by the digital network. Moreover, this network might well be a starting point for a web that interlinks all major dictionaries of the historical periods and of the dialects of the German language..",
 "article_title": "New directions in middle high German lexicography: dictionaries interlinked electronically",
 "authors": [
 {
 "given": " Johannes",
 "family": "Fournier",
 "affiliation": [
 {
 "original_name": "University of TrierTrier, Germany",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.1.45",
 "identifier": {
 "string_id": "10.1093/llc/16.1.45",
 "id_scheme": "DOI"
 },
 "abstract": "In the majority of cases, the pronoun it illustrates nominal anaphora, tending to refer back to another noun phrase in the text. However, in a significant minority of cases, the pronoun is used in exceptional ways that fail to demonstrate strict nominal anaphora. The identification of these uses of it is important in all fields where pronoun resolution has an impact After a survey of previous treatments of the pronoun it in the literature, some features of instances of it are proposed that can be used in a novel memory-based learning method to automatically classify those instances. On evaluating the method, it is found that the implemented system performs comparably well with respect to a rule-based system, and with an extended training set it is expected that the accuracy of the system will improve, offering greater coverage than rule-based methods.",
 "article_title": "Applying machine learning toward an automatic classification of It",
 "authors": [
 {
 "given": " Richard",
 "family": "Evans",
 "affiliation": [
 {
 "original_name": "University of WolverhamptonWolverhampton, UK",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.1.5",
 "identifier": {
 "string_id": "10.1093/llc/16.1.5",
 "id_scheme": "DOI"
 },
 "abstract": "From the perspective of a compiler of electronic corpora, one of the major challenges in the attempt to improve their quality is the need to carefully reconsider how language-external variables used to structure them could be defined and conceptualized more precisely to justify references to them as factors conditioning language variation and change. How these variables relate to one another should also be specified. In examining criteria for assessing representativeness of corpora, the concept of range is discussed to stress the evident differences between texts categorized as representatives of a specific genre. Good practices of philological computing are highlighted by illustrating what kind of information can be lost if scholarly rigour is not applied in the process of editing and/or digitizing texts.",
 "article_title": "Structured text corpora in the study of language variation and change",
 "authors": [
 {
 "given": " Anneli",
 "family": "Meurman-Solin",
 "affiliation": [
 {
 "original_name": "University of HelsinkiHelsinki, Finland",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.1.77",
 "identifier": {
 "string_id": "10.1093/llc/16.1.77",
 "id_scheme": "DOI"
 },
 "abstract": "When a noise verb is used to indicate verbal communication, factors from both the source domain of the verb (perception) and the target domain (communication) play a role in determining the argument structure of the sentence. While the target domain supplies a syntactic structure, the source domain's semantics constrain the degree to which that syntactic structure can be exploited. This can be determined by comparing noise verbs in this use with manner-of-communication verbs, which are superficially similar, but native to communication. Data for these two classes of verbs were drawn from the British National Corpus. The data were annotated with frame-semantic markup, as described in the Berkeley FrameNet Project. We compared the presence, type of syntactic realization, and position of the semantically annotated arguments for both classes of verbs. We found that noise and manner verbs show statistically significant differences in these three areas. For instance, noise verbs are more focused on the form of the message than manner verbs: noise verbs appear more frequently with a quoted message. In addition, there are differences other than the complementation patterns: certain noise verbs are biased with respect to speakers' genders, message types, and even orthography in quoted messages.",
 "article_title": "Shouting and screaming: manner and noise verbs in communication",
 "authors": [
 {
 "given": " Margaret",
 "family": "Urban",
 "affiliation": [
 {
 "original_name": "University of CaliforniaBerkeley, CA, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Josef",
 "family": "Ruppenhofer",
 "affiliation": [
 {
 "original_name": "University of CaliforniaBerkeley, CA, USA",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/16.1.29",
 "identifier": {
 "string_id": "10.1093/llc/16.1.29",
 "id_scheme": "DOI"
 },
 "abstract": "In this paper we present a specialized word generator, which has been designed as an assistant tool for Basque troubadours. Such a tool allows verse-writers to generate all the words that match with a given word termination. We deal with some interesting aspects, i.e. the dimension of the generated list and the need to establish an order of relevance among the listed items. This work can be seen as a way of reusing computational hguistic tools in the context of the Basque cultural means of expression. The technical foundations of this tool lie in a two-level morphological processor. The way in which words must be generated (starting from the end of the word) leads us to invert the generation process.",
 "article_title": "An assistant tool for verse-making in Basque based on two-level morphology",
 "authors": [
 {
 "given": " Bertol",
 "family": "Arrieta",
 "affiliation": [
 {
 "original_name": "University of the Basque CountryDonostia, Basque Country",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Iñaki",
 "family": "Alegria",
 "affiliation": [
 {
 "original_name": "University of the Basque CountryDonostia, Basque Country",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": " Xabier",
 "family": "Arregi",
 "affiliation": [
 {
 "original_name": "University of the Basque CountryDonostia, Basque Country",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "16",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.4.421",
 "identifier": {
 "string_id": "10.1093/llc/15.4.421",
 "id_scheme": "DOI"
 },
 "abstract": "This paper describes the construction of a corpus of spoken Sylheti. The corpus was created to examine difficulties in the creation of spoken language corpora in which features such as code switching (simply described here as the process of switching from one language to another during the course of an interaction; however, this description disguises a host of situations, which will be examined in the paper) are common. The paper also presents a transliteration scheme for Sylheti based around the Roman alphabet.",
 "article_title": "The construction of a corpus of spoken Sylheti",
 "authors": [
 {
 "given": "P",
 "family": "Baker",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.4.403",
 "identifier": {
 "string_id": "10.1093/llc/15.4.403",
 "id_scheme": "DOI"
 },
 "abstract": "In this paper we argue that corpus linguistics needs to expand to cover a wider set of languages. While the reasons that some languages have not been provided with corpus data to the date are clear, the intellectual and moral imperative to extend the range of corpus linguistics is strong. However, there are technical problems to be faced in such an extension of corpus linguistics. These problems are reviewed here and possible solutions to them explored. Following on from this, we consider what possible benefits the provision of appropriate corpus data may bring to languages currently untouched by the development of corpus linguistics.",
 "article_title": "A new agenda for corpus linguistics - working with all of the world's languages",
 "authors": [
 {
 "given": "T",
 "family": "McEnery",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.4.445",
 "identifier": {
 "string_id": "10.1093/llc/15.4.445",
 "id_scheme": "DOI"
 },
 "abstract": "The paper describes a method of collecting phonetic and linguistic data while maximizing the efficient use of resources. A speech database of Welsh was recorded and hand-annotated at the level of acoustic phonetic units and intonational units. This annotation file formed the input to a semi-automatic hierarchical annotation at higher linguistic levels. The method used rules to build the structure, followed if necessary by manual editing. The annotated database was then queried for linguistically significant sets of units. The query output was analysed statistically to derive basic descriptive data and answers to phonological questions. A small amount of data yielded answers to a long-standing stress-related question: stress in polysyllabic words does not affect the duration of (non-schwa) monophthongs, which are affected far more by word-final position. In addition, it was found that an intervocalic consonant after a stressed penult vowel was longer than a consonant in other positions. This confirmed earlier measurements and established three durational categories for non-cluster consonants. Finally, it was found that place of articulation and voicing factor both have an effect on voice onset time. It is hoped that this method will be of use to minority language researchers, in facilitating the swift gathering of basic phonetic and linguistic data, and speech technology resources.",
 "article_title": "A practical method for deriving phonetic and linguistic data for minority languages",
 "authors": [
 {
 "given": " B",
 "family": "Williams",
 "affiliation": [
 {
 "original_name": " Centre for Speech Technology Research, University of Edinburgh, 80 South Bridge, Edinburgh EH1 1HN, UK briony.cstr.ed.ac.uk ",
 "normalized_name": "University of Edinburgh",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/01nrxwf90",
 "GRID": "grid.4305.2"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.4.465",
 "identifier": {
 "string_id": "10.1093/llc/15.4.465",
 "id_scheme": "DOI"
 },
 "abstract": "ORCHID (Open Linguistic Resources Chanelled toward InterDisciplinary research) is a project aimed at building linguistic resources to support research in, but not limited to, natural language processing. Based on the concept of an open architecture design, the resources must be fully compatible with those which already exist, and software tools must also be made available. This paper describes the construction of a Thai part-of-speech (POS) tagged corpus, a preliminary stage in the construction of a Thai speech corpus. The paper also details the development of a POS tagger to be used in the construction of the POS-tagged corpus. Additionally, we describe a proposal for a new tagset, based on the results of a prior multilingual machine translation project. The corpus is annotated on three levels: paragraph, sentence, and word. Text information is maintained in the form of the text information lines and the number lines, which are both utilized in data retrieval. Finally, we describe a POS neuro tagger, which consists of a three-layer perceptron with elastic input. Computer experiments show that the neuro tagger has an accuracy of 94.4 per cent for tagging ambiguous words when tested on a small Thai training corpus containing 22,311 ambiguous words. A series of comparative experiments further show that the neuro tagger is superior to the statistical models including the frequency model (a baseline model), a local n-gram model, and HMM (Hidden Markov Model).",
 "article_title": "ORCHID: building linguistic resources in Thai",
 "authors": [
 {
 "given": "H",
 "family": "Isahara",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.4.433",
 "identifier": {
 "string_id": "10.1093/llc/15.4.433",
 "id_scheme": "DOI"
 },
 "abstract": "Bangla is the second most widely spoken language in the Indian subcontinent, yet has not been the focus of much research activity in either corpus linguistics or language engineering to date. This paper describes the automatic processing of pronouns in three and a half million words of Bangla corpus data. A corpus-based analysis of Bangla pronouns is developed, and a new approach to the analysis of Bangla pronouns is taken as a consequence. On the basis of this analysis a system is then developed to identify and analyse Bangla pronouns in corpus data.",
 "article_title": "Bangla pronouns - a corpus based study",
 "authors": [
 {
 "given": " NS",
 "family": "Dash",
 "affiliation": [
 {
 "original_name": " Computer Vision and Pattern Recognition Unit, Indian Statistical Institute, 203, Barrackpore Trunk Road, Calcutta 700035, India E-mail: niladri@www.isical.ac.in ",
 "normalized_name": "Indian Statistical Institute",
 "country": "India",
 "identifiers": {
 "ror": "https://ror.org/00q2w1j53",
 "GRID": "grid.39953.35"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "4",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.3.339",
 "identifier": {
 "string_id": "10.1093/llc/15.3.339",
 "id_scheme": "DOI"
 },
 "abstract": "The production of collections of grammatically analysed linguistic samples, or corpora, entails a parallel research effort in tools for exploiting such collections. This paper summarizes the new one million-word parsed British Component of the International Corpus of English (ICE-GB). We then introduce a tool designed annotating, managing, and investigating the parsed corpus, called ICECUP III. Effective grammatical exploration is driven by a query. We therefore pose the question, what is the optimum representation for expressing queries on a parsed corpus? We review existing grammatical query systems and a feasible representation in logic. We describe ICECUP's query representation, the Fuzzy Tree Fragment (FTF), which has proven extremely effective in supporting the manual correction of automatically annotated material in ICE-GB and is currently used for linguistic research. Central to the idea of FTFs is that they should be as easy to understand as possible and support researchers as they engage with the complexity of the parsed analysis. An FTF, therefore, is a kind of 'abstracted model' of a tree. We argue that FTFs are highly applicable to general linguistic research and teaching with grammatically analysed corpora. They support an exploratory approach that does not presume a detailed knowledge of the grammar in advance of search. Exploration is supported by a number of facilities, including a tool that abstracts a query from part of a corpus tree. Finally, we discuss how FTFs may be used to perform 'key construction in line' concordancing, and the use of logic to combine queries.",
 "article_title": "Exploiting fuzzy tree fragment queries in the investigation of parsed corpora",
 "authors": [
 {
 "given": "S",
 "family": "Wallis",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.3.323",
 "identifier": {
 "string_id": "10.1093/llc/15.3.323",
 "id_scheme": "DOI"
 },
 "abstract": "This paper describes software (vocd) that implements a solution to problems encountered in quantifying vocabulary diversity. Researchers in various fields of linguistic enquiry have calculated vocabulary diversity using the ratio of different words (Types) to total words (Tokens) - the Type-Token Ratio (TTR) - or measures derived from it. Such measures are flawed, however, because the values obtained are related to the number of words in the sample. The paper shows how the relationship between TTR and sample size can be described by a new mathematical model, which in turn leads to an innovative method of measuring vocabulary diversity. The software automates measurement from transcripts prepared in a widely used computer-readable set of conventions: the CHAT format of the CHILDES project. Options in vocd are described to show how the user can determine which linguistic items will count as valid types and tokens in the analysis. The new measure is calculated by, first, randomly sampling words from the transcript to produce a curve of the TTR against Tokens for the empirical data. Then the software finds the best fit between this empirical curve and theoretical curves calculated from the model by adjusting the value of a parameter. The parameter, D, is shown to be a valid and reliable measure of vocabulary diversity without the problems of sample size found with previous methods.",
 "article_title": "Measuring vocabulary diversity using dedicated software",
 "authors": [
 {
 "given": "G",
 "family": "McKee",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.3.291",
 "identifier": {
 "string_id": "10.1093/llc/15.3.291",
 "id_scheme": "DOI"
 },
 "abstract": "This paper presents an implementation of a syntactic parser for the Modern Greek language based on the PC-PATR formalism. The Modern Greek language presents a high flexibility in its syntactic structure. The various phrasal categories (noun phrases, verb phrases, prepositional, and adverbial phrases) can be ordered in almost any permutation so as to build valid sentences. The allowable combinations of lexical categories (nouns, verbs, adjectives, etc.) forming the above phrases, as well as the combinations of these phrases, forming clauses, are encoded according to the PC-PATR formalism and are presented in this paper. The presented rules cover the majority of the syntactic phenomena of the Modern Greek language, adequate for speech and natural language applications.",
 "article_title": "A PC-PATR-Based syntactic description of modern Greek",
 "authors": [
 {
 "given": "K.",
 "family": "Kermanidis",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.3.251",
 "identifier": {
 "string_id": "10.1093/llc/15.3.251",
 "id_scheme": "DOI"
 },
 "abstract": "In this paper, we address the issue of the effective reduction of out-of-vocabulary (OOV) words for automatic speech recognition (ASR) systems. We first of all evaluate the OOV rates produced by different vocabulary sets selected from a corpus of British English according to the raw frequency of occurrence. We demonstrate that OOV rates in realistic input from unlimited domains are much higher than has been reported in the literature for ASR systems that typically deal with only a subset of the English language. To reduce OOV rates, we then propose that the textual dispersion of word types is a more effective selection criterion for the acquisition of lexicons than the conventional method of lexical selection according to raw frequencies of occurrence. We evaluate the performance of the adjusted frequency according to the index of dispersion, and the dispersion of word types among component text categories of the training corpus. With an 80,000-word vocabulary, the estimated frequency per million words adjusted according the index of dispersion achieves and improvement of 7.3 per cent over the frequency-based approach for a large set of testing material from a variety of sources. Vocabulary sets selected according to textual dispersion alone achieve a slightly better overall OOV reduction rate of 7.5 per cent.",
 "article_title": "Out-of-vocabulary rate reduction through dispersion-based lexicon acquisition",
 "authors": [
 {
 "given": "A.",
 "family": "Fang",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.3.313",
 "identifier": {
 "string_id": "10.1093/llc/15.3.313",
 "id_scheme": "DOI"
 },
 "abstract": "A natural language generation system used for computer-aided language learning generates stimuli, or 'questions', along with one or more anticipated learner responses. To provide the learner with intelligent feedback, the system initially compares the actual responses entered by the learner with those produced by the system. The differences discovered in this way may be though of as symptoms; the eventual aim is to diagnose the deeper problems, misunderstandings of the language that underlie the symptoms, to offer corrective advice. This paper considers alternative approaches to the comparison process, and describes a two-level algorithm, based on approximate string matching, which determines and categorizes the differences between learner and system responses. The process detects variations in word order, insertions and deletions. It also reports on the use of synonyms or malwords, errors in morphology, phonological errors and typing slips. In subsequent work, these will form the basis for the adaptive generation of new stimuli, as well as for the deeper diagnosis of learner difficulties. Some typical results are shown.",
 "article_title": "A multi-level approach to the detection of second language learners errors",
 "authors": [
 {
 "given": "M",
 "family": "Levison",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.3.265",
 "identifier": {
 "string_id": "10.1093/llc/15.3.265",
 "id_scheme": "DOI"
 },
 "abstract": null,
 "article_title": "Dates and ChronStructs: dynamic chronology in the Orlando Project",
 "authors": [
 {
 "given": "I",
 "family": "Grundy",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.3.363",
 "identifier": {
 "string_id": "10.1093/llc/15.3.363",
 "id_scheme": "DOI"
 },
 "abstract": null,
 "article_title": "Reports from colloquia at Tubingen",
 "authors": [
 {
 "given": " W",
 "family": "Ott",
 "affiliation": [
 {
 "original_name": " Universität Tübingen, Zentrum für Datenvarebeitung, Wächterstraße 76, D-72074 Tübingen, Germany E-mail: ott@zdv.uni-tuebingen.de ",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "3",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.2.187",
 "identifier": {
 "string_id": "10.1093/llc/15.2.187",
 "id_scheme": "DOI"
 },
 "abstract": "Previous work in using artificial neural networks for computational stylistics has concentrated on using large, arbitrary network structures. This paper examines the use of the Cascade-Correlation algorithm for the construction of minimal networks. We find that a number of problems in computational stylistics with a large number of variables but a limited number of training examples may be solved successfully without resorting to large networks. The issue of redundancy in the data is also considered.",
 "article_title": "Computational stylistics using artificial neural networks",
 "authors": [
 {
 "given": "S",
 "family": "Waugh",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.2.131",
 "identifier": {
 "string_id": "10.1093/llc/15.2.131",
 "id_scheme": "DOI"
 },
 "abstract": "This paper summarizes our experience in optimizing representational models of inflexional (accidence) morphological analysis for different languages. Some of the linguistic engineering questions addressed in the paper include the following: How far can linguistic adequacy be maintained in morphological components of marketable machine translation software on the IBM PC platform? What generalizations can be made contributing to the more uniform approach to morphology for languages of various structures? What are the parameters that can be adjusted quantitatively to allow for general model application to different languages? A generalized approach of treating postfixal languages is proposed, which is supplemented by suggestions on its modification for languages that are clearly not postfixal (e.g. Arabic).",
 "article_title": "Morphological representation in PC-based text processing systems",
 "authors": [
 {
 "given": "S",
 "family": "Koval",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.2.199",
 "identifier": {
 "string_id": "10.1093/llc/15.2.199",
 "id_scheme": "DOI"
 },
 "abstract": "Kathleen Garay teaches in the Department of History and Women's Studies at McMaster University, where she is also an archivist. David Walker is the Project Manager of multimedia instructional computing at McMaster University. With the assistance of a small group of medievalists and a programmer-graphic designer they created a multimedia CD-ROM-based program on Women in the Middle Ages and Renaissance. The CD-ROM was used in class for the first time in the 1996-7 academic year, and a revised version is currently being distributed by an academic multimedia publisher. This paper presents a synthesis of two perspectives on the development of this teaching resource: teacher and computing professional.",
 "article_title": "Bringing computing into the Middle Ages: the making of sybils!, a multimedia CD-ROM",
 "authors": [
 {
 "given": " C",
 "family": "Garay",
 "affiliation": [
 {
 "original_name": " McMaster Working Group on the Middle Ages and Renaissance, Department of French, TSH 522, McMaster University, Hamilton, Ontario, Canada L8S 4L9 E-mail: garay@mcmail.cis.McMaster.ca ",
 "normalized_name": "McMaster University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/02fa3aq29",
 "GRID": "grid.25073.33"
 }
 }
 ]
 },
 {
 "given": " D",
 "family": "Walker",
 "affiliation": [
 {
 "original_name": " McMaster Working Group on the Middle Ages and Renaissance, Department of French, TSH 522, McMaster University, Hamilton, Ontario, Canada L8S 4L9 E-mail: garay@mcmail.cis.McMaster.ca ",
 "normalized_name": "McMaster University",
 "country": "Canada",
 "identifiers": {
 "ror": "https://ror.org/02fa3aq29",
 "GRID": "grid.25073.33"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.2.157",
 "identifier": {
 "string_id": "10.1093/llc/15.2.157",
 "id_scheme": "DOI"
 },
 "abstract": "Two recent editions of the play Edward III have regarded it as belonging to the Shakespeare canon. This paper explores the use of committees of cumulative sum charts based on line-by-line tallies of prosodic features and relative frequencies of both rare-words and common function words, assembled together and focused, as it were, by means of principal component analysis to provide a single best-fit profile of the play. Such a profile casts light, with some amendments, on previously remarked textual features of the play - notably thematic links between Acts II and IV, which contrast with the overall theme of the play. The divergence of Acts II and IV, on the one hand, and Acts I, III, and V on the other, a feature of several other plays with divided authorship, is suggestive of a Marlovian framework, reworked and added to by Shakespeare, possibly after Marlowe's death in 1593. The results of the analysis are compared with recent logometric examinations of the play's authorship. Agreement is greater than disagreement.",
 "article_title": "Edward III",
 "authors": [
 {
 "given": " T",
 "family": "Merriam",
 "affiliation": [
 {
 "original_name": " 35 Richmond Road, Basingstoke, RG21 5NX, UK E-mail: tom@merriam.freeserve.co.uk ",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.2.121",
 "identifier": {
 "string_id": "10.1093/llc/15.2.121",
 "id_scheme": "DOI"
 },
 "abstract": "Many recent studies have demonstrated that the analysis of world co-occurrence patterns can be a valuable tool for the acquisition of lexical knowledge from unstructured texts. The success of these studies raises the question of whether these results can be replicated in other languages and, in particular, in ancient Greek texts. The adaptation of these techniques for the acquisition of lexical knowledge could provide the foundation for useful philological and lexicographical research tools and multi-lingual information retrieval applications. One method that has proven useful in the study of Greek texts is the use of co-occurrence data to calculate mutual information scores. The approaches used for English language texts, however, require some modification for use with ancient Greek. This paper will describe the methods and modifications required for the analysis of collocational data from unstructured ancient Greek texts so that they produce useful results.",
 "article_title": "Co-occurrence patterns and lexical acquisition in ancient Greek texts",
 "authors": [
 {
 "given": " JA",
 "family": "Rydberg-Cox",
 "affiliation": [
 {
 "original_name": " Department of English, University of Missouri at Kansas City, Cockefair Hall, 106 Kansas City, MO 67110, USA E-mail: jrydberg@perseus.tufts.edu ",
 "normalized_name": "University of Missouri–Kansas City",
 "country": "United States",
 "identifiers": {
 "ror": "https://ror.org/01w0d5g70",
 "GRID": "grid.266756.6"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "2",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.1.109",
 "identifier": {
 "string_id": "10.1093/llc/15.1.109",
 "id_scheme": "DOI"
 },
 "abstract": "It is apparent that the presentation of a text in the electronic medium as a string of electronic characters may have advantages for scholarly reading. Because it is dynamic, the text on the screen offers the reader many possible kinds of fragmentation. Study of scholarly uses of such texts shows that the segmentations in the text depend on the computer treatments available, such as indexing or linking commentaries. The hypertextual paths induced in such a way by the constraints of indexing systems or on the adjacent commentaries are different from a so-called 'open' reading (in the sense of a reader's engagement), which aims to permit the reader to define paths according to previously determined units. This statement allows us to reopen the debate on the relationship between digitization and hypertextualization. Moreover, it raises questions about the type of reading that emerges from codification and structuring models. The argument of this paper is that the status as object of electronic forms of canonical texts must be reconsidered according to the specific features of the medium.",
 "article_title": "Pour une lecture ouverte du texte electronique",
 "authors": [
 {
 "given": " A",
 "family": "Crasson",
 "affiliation": [
 {
 "original_name": " Institut des Textes et Manuscrits, Modernes, 45, rue d'Ulm, 75005 Paris, France E-mail: acrasson@club-internet.fr ",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.1.115",
 "identifier": {
 "string_id": "10.1093/llc/15.1.115",
 "id_scheme": "DOI"
 },
 "abstract": "The evolution of data processing, in terms of hardware, software, and communication structures, renders it possible today to conceive of a scholarly text edition as an electronic edition. The essential prerequisite for an electronic edition is the preparation of its object as a computer-assisted edition. The critical and synoptic edition of James Joyce's Ulysses, published in book form in 1984/86, was computer-assisted through the entire range of textual, critical, and presentational preparation. An electronic edition can be designed and realised from that book edition's database. The present contribution surveys the demands to be made of such an electronic edition and indicates what conceptual, editorial and technical operations and operationalizations are required to achieve it.",
 "article_title": "Towards an electronic edition of James Joyce's Ulysses",
 "authors": [
 {
 "given": " HW",
 "family": "Gabler",
 "affiliation": [
 {
 "original_name": " University of München, München, Germany Correspondence address: Schellingstrasse 9, 80799 München, Germany E-mail: hans-walter.gabler@anglistik.uni-muenchen.de ",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.1.15",
 "identifier": {
 "string_id": "10.1093/llc/15.1.15",
 "id_scheme": "DOI"
 },
 "abstract": "The Perseus digital library is a substantial test bed of materials on archaic and classical Greece, the early Roman empire, and early modern Europe. The Perseus architecture includes tools that fit the needs of humanists: linguistic analysis for heavily inflected languages, linking and alignment with canonical citation schemes, and terminological, spatial, and visual databases for document contextualization. These tools provide both the scalability to connect disparate entities in the digital library and a groundwork for performance of the synthetic scholarship of the humanities.",
 "article_title": "The Perseus Project: a digital library for the humanities",
 "authors": [
 {
 "given": "D.",
 "family": "Smith",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "J.",
 "family": "Rydberg-Cox",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "G.",
 "family": "Crane",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.1.51",
 "identifier": {
 "string_id": "10.1093/llc/15.1.51",
 "id_scheme": "DOI"
 },
 "abstract": "The same data as used for creating the new printed Editio Critica Maior of the New Testament, commencing with the Catholic Letters, allows a genealogical analysis of the witness. The objective is to establish a comprehensive theory of the structure of the tradition. Because the tradition of the New Testament is highly contaminated this theory has to handle the problem of contamination, and also the problem of accidental rise of variants, and must be able to be verified at any passage of text. Where there are variants, the witnesses have a relation that can be described by a local stemma of the different readings. These local stemmata allow or restrict relations among witnesses in a global stemma, which must be in harmony with the total of the local stemmata. In the first phase, local stemmata were established only at places where the development of the variants is very clear. The coherencies within each attestation were analysed. This analysis rested upon the agreements of witnesses, for their genealogical relations were unknown. Nevertheless, readings could be excluded from being primary by checking the coherencies of the witnesses. Then the local stemmata must be revised in the light of the total of the genealogical data included in them. Now an analysis of genealogical coherence is possible and may help to find local stemmata for passages unsolved so far. Finally, the global stemma (or stemmata) mirroring all the relations of the local stemmata will be established by combining optimal substemmata, each containing a witness and its immediate ancestors, to produce the simplest possible tree.",
 "article_title": "Editing and genealogical studies: the New Testament",
 "authors": [
 {
 "given": " G",
 "family": "Mink",
 "affiliation": [
 {
 "original_name": " Institut für neutestamentliche Textforschung, Münster, Germany E-mail: mink@uni-muenster.de ",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.1.27",
 "identifier": {
 "string_id": "10.1093/llc/15.1.27",
 "id_scheme": "DOI"
 },
 "abstract": "The materials for editing the New Testament consist of over 5,600 Greek manuscripts, ancient translations and citations by church fathers. Computers are of use in the study and editing of them in eight ways (i) in collating witnesses, especially to improve accuracy; (ii) in being able to alter a base text without having to revise a complicated apparatus criticus; (iii) in analysis of manuscript relationships; (iv) in the selection of the most significant witnesses; (v) in producing an edition; (vi) in the area of collaboration; (vii) they do away with the need to redo good work; (viii) they make possible a wide range of presentations, including change of presentation at will, use of multiple typefaces cheaply, presenting multiple states of the text, and placing information in levels, connected to one another by hyperlinks. Even though the goal of any major critical edition should continue to be a paper edition, it will be worth scholars' while to develop computer-based resources.",
 "article_title": "The text of the New Testament and computers: The International Greek New Testament Project",
 "authors": [
 {
 "given": " DC",
 "family": "Parker",
 "affiliation": [
 {
 "original_name": " Department of Theology, University of Edgbaston, Birmingham B15 2TT, UK E-mail: D.C.Parker@bham.ac.uk ",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.1.93",
 "identifier": {
 "string_id": "10.1093/llc/15.1.93",
 "id_scheme": "DOI"
 },
 "abstract": "Modularity, professionality, portability, and integration are the key features of the TUebingen System for TExt Processing programs (TUSTEP), a professional toolbox for those academic fields where texts are the object of research. Its potential is illustrated by two examples: (i) typesetting a TEI-lite encoded text, using the TEI tags as formatting instructions; (ii) preparing a critical edition, starting from automatic collation, then semi-automatically selecting the 'substantial' variants from the collation results, transforming them into a critical apparatus, and publishing the edition both in print and electronically.",
 "article_title": "Strategies and tools for textual scholarship: the Tubingen system of text processing programs (TUSTEP)",
 "authors": [
 {
 "given": " W",
 "family": "Ott",
 "affiliation": [
 {
 "original_name": " Universität Tübingen, Zentrum für Datenverarbeitung, Wächterstrasse 76, D-72074 Tübingen, Germany E-mail: ott@zdv.uni-tuebingen.de ",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.1.57",
 "identifier": {
 "string_id": "10.1093/llc/15.1.57",
 "id_scheme": "DOI"
 },
 "abstract": "This paper presents two projects involving Biblical texts. The first one aims to produce a critical edition of the Old Slavic New Testament, the second tries to reconstruct the Diatessaron, a harmony of the Gospels, composed in Rome in the second century and transmitted in a great number of languages. The paper briefly describes how computer collation of Slavic manuscripts can form the basis for a critical edition and how Diatessaronic evidence in different languages can be compiled electronically. Common problems of employing modern technologies in these traditional areas of philological research are discussed and, finally, some advice is offered.",
 "article_title": "Some bits of good news: computer collation of the old Slavic New Testament and Tatian's gospel harmony",
 "authors": [
 {
 "given": " M",
 "family": "Bakker",
 "affiliation": [
 {
 "original_name": " Cap Gemini, Public Division, PO Box 2575, 3500 GN Utrecht, The Netherlands E-mail: hette.bakker@capgemini.nl ",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.1.43",
 "identifier": {
 "string_id": "10.1093/llc/15.1.43",
 "id_scheme": "DOI"
 },
 "abstract": "The Editio Critica Maior of the New Testament aims to exhibit the history of the Greek text through its first millennium as documented in more than 5,000 manuscripts from the second century onward. It will provide scholars engaged in the tasks of exegesis and textual criticism with all the relevant materials found in Greek manuscripts, patristic citations, and the early translations. The first instalment of the paper edition containing the Letter of James appeared in 1997. All the material published so far and being prepared for the next instalment is stored in databases. Thus a fundamental requirement of a future electronic edition is met. Further steps in the same direction are being currently undertaken. Transcriptions are meanwhile entered directly using the Collate program. This will help to provide the facilities for external co-editors and coworkers to participate in the Münster edition project. With respect to all the promising prospects of the 'digital age', it is most important to concentrate on what is feasible now and to prepare for the transition to electronic editing at the same time.",
 "article_title": "Editing the Greek New Testament on the threshold of the twenty-first century",
 "authors": [
 {
 "given": " K",
 "family": "Wachtel",
 "affiliation": [
 {
 "original_name": " Institut für neutestamentliche Textforschung, Geogskommende 7, D-48143 Münster, Germany E-mail: wachtel@uni-muenster.de ",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.1.81",
 "identifier": {
 "string_id": "10.1093/llc/15.1.81",
 "id_scheme": "DOI"
 },
 "abstract": "The Text Encoding Initiative's (TEI's) Guidelines for Electronic Text Encoding and Interchange (Chicago, Oxford TEI P3) provide an extremely rich set of mechanisms for the encoding of medieval manuscripts and other primary textual sources. For a number of problems regularly encountered in the transcription of Old Norse/Icelandic materials, however, the solutions offered by the TEI have not proved entirely satisfactory. A group of scholars from several Scandinavian universities has been working for the last 4 years on a set of recommendations for modifications and extensions to the TEI DTD to be used in the encoding of such material. The present paper discusses some of these recommendations.",
 "article_title": "Encoding old Norse/Icelandic primary sources using TEI-conformant SGML",
 "authors": [
 {
 "given": "M.",
 "family": "Driscoll",
 "affiliation": [
 {
 "original_name": " Det Arnamagnaenske Institut, Njalsgade 76, DK-2300 Kobenhavn S, Denmark E-mail: mjd@hum.ku.dk ",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.1.65",
 "identifier": {
 "string_id": "10.1093/llc/15.1.65",
 "id_scheme": "DOI"
 },
 "abstract": "Scholarly editing in the Netherlands is concentrated in the Constantijn Huygens Institut (CHI) in The Hague, which is a research institute of the Royal Netherlands Academy of Arts and Sciences. The CHI produces text editions of works from every period of Dutch literary history. All genres and types of editions are represented. Editorial methods and techniques developed in other countries are adopted according to the needs of the Institute. In the past, most projects at the CHI resulted in printed publications and little consideration was given to production or presentation using electronic media. In the recent planning and development of new projects, however, an important shift can be seen in favour of these media. For two of the projects outlined in this paper this includes or has included the digitization of all relevant versions of a text through scanning and OCR. Computer programs such as TUSTEP and COLLATE will be used to compare all of those versions. The copy of the editions will be stored in SGML to make future reprints possible. Lists of authorial variants and perhaps other research material will be made available on the Internet. The third project discussed here involves the publication in its entirety of a sizeable body of nineteenth-century poetry by means of a CD-ROM/DVD or the Internet. The full-text electronic edition will also contain digital images of the original documents as well as hypertext links to the author's annotations.",
 "article_title": "Scholarly editing in The Netherlands",
 "authors": [
 {
 "given": "H.",
 "family": "van Vliet",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 },
 {
 "given": "A.",
 "family": "Kets-Vree",
 "affiliation": [
 {
 "original_name": null,
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.1.5",
 "identifier": {
 "string_id": "10.1093/llc/15.1.5",
 "id_scheme": "DOI"
 },
 "abstract": "The capacity of electronic editions to present all versions of a text, and the movement in post-modern thinking against all forms of authority, suggest that electronic editions should not present any reconstructed or eclectic text, or privilege any one text over all other texts. However, examination of three actual editions dealing with very large numbers of variant texts (Chaucer's Canterbury Tales, Dante's Commedia, and the Greek New Testament) argues the reverse. In these cases, editors might choose to present a single reconstructed text, and to privilege this text about all other texts. It is not necessary to see this reconstructed text as a precise representation of a lost original: rather, it should be seen as the text that best explains all the extant documents. Its value then lies in its efficiency as a route by which the reader may find his or her own way into the variants themselves. Such editions may then help their users to become better readers, and editions should be measured by their ability to do this rather than by their conformity to any theoretical model.",
 "article_title": "The one text and the many texts",
 "authors": [
 {
 "given": " P",
 "family": "Robinson",
 "affiliation": [
 {
 "original_name": " Centre for Technology and the Arts, De Montfort University, The Gateway, Leicester LE1 5XY, UK E-mail: peter.robinson@dmu.ac.uk ",
 "normalized_name": "De Montfort University",
 "country": "United Kingdom",
 "identifiers": {
 "ror": "https://ror.org/0312pnr83",
 "GRID": "grid.48815.30"
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-10",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 },
 {
 "url": "http://dx.doi.org/10.1093/llc/15.1.73",
 "identifier": {
 "string_id": "10.1093/llc/15.1.73",
 "id_scheme": "DOI"
 },
 "abstract": "In the 1980s a group of scholars in Rome studied the methods of humanities computing, and elaborated a theory of the correct use of the computer in the different disciplines. Concerning electronic editions of texts, it is essential that they preserve all the information present in the representation on paper, which goes beyond the sequence of letters. According to this principle, two enterprises have been initiated, which are described here.",
 "article_title": "Progetti relativi a testi elettronici a Roma, accademia dei lincei e Universita La Sapienza",
 "authors": [
 {
 "given": " T",
 "family": "Orlandi",
 "affiliation": [
 {
 "original_name": " CISADU - Fac. di Lettere, P.zale Aldo Moro 5, 00185 Rome, Italy E-mail: orlandi@rmcisadu.let.uniromal.it ",
 "normalized_name": null,
 "country": null,
 "identifiers": {
 "ror": null,
 "GRID": null
 }
 }
 ]
 }
 ],
 "publisher": "Oxford University Press (OUP)",
 "date": "2004-11-11",
 "keywords": null,
 "journal_title": "Literary and Linguistic Computing",
 "volume": "15",
 "issue": "1",
 "ISSN": [
 {
 "value": "0268-1145",
 "type": "print"
 },
 {
 "value": "1477-4615",
 "type": "electronic"
 }
 ]
 }
]