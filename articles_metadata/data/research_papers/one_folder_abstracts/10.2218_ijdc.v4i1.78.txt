 We characterize long-term preservation of digital content as an extended relay in time, in which repeated handoffs of information occur independently at every architectural layer: at the physical layer, where bits are handed off between storage systems; at the logical layer, where digital objects are handed off between repository systems; and at the administrative layer, where collections of objects and relationships are handed off between archives, curators, and institutions.  We examine the support of current preservation technologies for these handoffs, note shortcomings, and argue that some modest improvements would result in a "relay-supporting" preservation infrastructure, one that provides a baseline level of preservation by mitigating the risk of fundamental information loss.  Finally, we propose a series of tests to validate a relay-supporting infrastructure, including a second Archive Ingest and Handling Test (AIHT).