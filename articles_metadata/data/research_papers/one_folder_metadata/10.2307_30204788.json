{"url": "http://www.jstor.org/stable/30204788", "identifier": {"string_id": "10.2307/30204788", "id_scheme": "DOI"}, "abstract": "SENSEVAL was the first open, community-based evaluation exercise for Word Sense Disambiguation programs. It adopted the quantitative approach to evaluation developed in MUC and other ARPA evaluation exercises. It took place in 1998. In this paper we describe the structure, organisation and results of the SENSEVAL exercise for English. We present and defend various design choices for the exercise, describe the data and gold-standard preparation, consider issues of scoring strategies and baselines, and present the results for the 18 participating systems. The exercise identifies the state-of-the-art for fine-grained word sense disambiguation, where training data is available, as 74-78% correct, with a number of algorithms approaching this level of performance. For systems that did not assume the availability of training data, performance was markedly lower and also more variable. Human inter-tagger agreement was high, with the gold standard taggings being around 95% replicable.", "article_title": "Framework and Results for English SENSEVAL", "authors": [{"given": "A.", "family": "Kilgarriff", "affiliation": [{"original_name": "ITRI, University of Brighton, Bright", "normalized_name": "University of Brighton", "country": "United Kingdom", "identifiers": {"ror": "https://ror.org/04kp2b655", "GRID": "grid.12477.37"}}]}, {"given": "J.", "family": "Rosenzweig", "affiliation": [{"original_name": "University of Pennsylvania, Pennsylvania, USA", "normalized_name": "University of Pennsylvania", "country": "United States", "identifiers": {"ror": "https://ror.org/00b30xv10", "GRID": "grid.25879.31"}}]}], "publisher": "Springer", "date": "2000", "keywords": null, "journal_title": "Computers and the Humanities", "volume": "34", "issue": "1/2", "ISSN": [{"value": "00104817", "type": "print"}]}