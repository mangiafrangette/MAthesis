{"url": "http://dx.doi.org/10.1093/llc/fqm020", "identifier": {"string_id": "10.1093/llc/fqm020", "id_scheme": "DOI"}, "abstract": "The basic assumption of quantitative authorship attribution is that the author of a text can be selected from a set of possible authors by comparing the values of textual measurements in that text to their corresponding values in each possible author's writing sample. Over the past three centuries, many types of textual measurements have been proposed, but never before have the majority of these measurements been tested on the same dataset. A large-scale comparison of textual measurements is crucial if current techniques are to be used effectively and if new and more powerful techniques are to be developed. This article presents the results of a comparison of thirty-nine different types of textual measurements commonly used in attribution studies, in order to determine which are the best indicators of authorship. Based on the results of these tests, a more accurate approach to quantitative authorship attribution is proposed, which involves the analysis of many different textual measurements.", "article_title": "Quantitative Authorship Attribution: An Evaluation of Techniques", "authors": [{"given": " Jack", "family": "Grieve", "affiliation": [{"original_name": "English Department Northern Arizona University", "normalized_name": "Northern Arizona University", "country": "United States", "identifiers": {"ror": "https://ror.org/0272j5188", "GRID": "grid.261120.6"}}]}], "publisher": "Oxford University Press (OUP)", "date": "2007", "keywords": null, "journal_title": "Literary and Linguistic Computing", "volume": "22", "issue": "3", "ISSN": [{"value": "0268-1145", "type": "print"}, {"value": "1477-4615", "type": "electronic"}]}