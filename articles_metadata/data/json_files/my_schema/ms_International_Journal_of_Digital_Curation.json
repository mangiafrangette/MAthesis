[
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v1i1.4",
        "identifier": {
            "string_id": "10.2218/ijdc.v1i1.4",
            "id_scheme": "DOI"
        },
        "abstract": "The use of digital technologies within research has led to a proliferation of data, many new forms of research output and new modes of presentation and analysis. Many scientific communities are struggling with the challenge of how to manage the terabytes of data and new forms of output, they are producing. They are also under increasing pressure from funding organizations to publish their raw data, in addition to their traditional publications, in open archives. In this paper I describe an approach that involves the selective encapsulation of raw data, derived products, algorithms, software and textual publications within “scientific publication packages”. Such packages provide an ideal method for: encapsulating expert knowledge; for publishing and sharing scientific process and results; for teaching complex scientific concepts; and for the selective archival, curation and preservation of scientific data and output. They also provide a bridge between technological advances in the Digital Libraries and eScience domains. In particular, I describe the RDF-based architecture that we are adopting to enable scientists to construct, publish and manage “scientific publication packages” - compound digital objects that encapsulate and relate the raw data to its derived products, publications and the associated contextual, provenance and administrative metadata.",
        "article_title": "Scientific Publication Packages – A Selective Approach to the Communication and Archival of Scientific Output",
        "authors": [
            {
                "given": "Jane",
                "family": "Hunter",
                "affiliation": [
                    "University of Queensland"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "1",
        "issue": "",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v1i1.3",
        "identifier": {
            "string_id": "10.2218/ijdc.v1i1.3",
            "id_scheme": "DOI"
        },
        "abstract": "A defining characteristic of contemporary copyright law is the willingness of governments to accept the argument that the impact of digital technologies requires copyright owners to be given ever greater control over the use of their works, regardless of the detriment to the copyright regime's 'public interest' elements. Yet a one-size-fits-all 'all rights reserved' copyright regime clearly fails to meet the requirements of many rightsholders. One response has been the Creative Commons movement which seeks, through licences based on existing copyright laws, to provide a simple mechanism for rightsholders to disseminate their works under less restrictive conditions. The Creative Commons' initial success has led to suggestions that its principles could be equally applied to scientific research outputs, such as publications, licensing of research materials, and datasets. This article argues that the Science Commons approach, if based on the Creative Commons model, and premised at its root on utilitarian copyright law, will both fail to address contemporary policy drivers in research, or to provide researchers with the type of rights that they actually want. It suggests that constructing an appropriate set of rights for the Science Commons, particularly for datasets, will require a willingness to step outside the utilitarian model and look to the Continental copyright tradition, which sets less store in economic rights and gives greater weight to moral rights.",
        "article_title": "Digital Curation, Copyright, and Academic Research",
        "authors": [
            {
                "given": "Andrew",
                "family": "Charlesworth",
                "affiliation": [
                    "University of Bristol"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "1",
        "issue": "",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v1i1.2",
        "identifier": {
            "string_id": "10.2218/ijdc.v1i1.2",
            "id_scheme": "DOI"
        },
        "abstract": "The creation, management and use of digital materials are of increasing importance for a wide range of activities. Much of the knowledge base and intellectual assets of institutions and individuals are now in digital form. The term digital curation is increasingly being used for the actions needed to add value to and maintain these digital assets over time for current and future generations of users. The paper explores this emerging field of digital curation as an area of inter-disciplinary research and practice, and the trends which are influencing its development. It analyses the genesis of the term and how traditional roles relating to digital assets are in transition. Finally it explores some of the drivers for curation ranging from trends such as exponential growth in digital information, to \"life-caching\", digital preservation, the Grid and new opportunities for publishing, sharing, and re-using data. It concludes that significant effort needs to be put into developing a persistent information infrastructure for digital materials and into developing the digital curation skills of researchers and information professionals. Without this, current investment in digitisation and digital content will only secure short-term rather than lasting benefits.",
        "article_title": "Digital Curation for Science, Digital Libraries, and Individuals",
        "authors": [
            {
                "given": "Neil",
                "family": "Beagrie",
                "affiliation": [
                    "JISC/British Library Partnership Manager"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "1",
        "issue": "",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v2i1.16",
        "identifier": {
            "string_id": "10.2218/ijdc.v2i1.16",
            "id_scheme": "DOI"
        },
        "abstract": "The MIT Libraries, the San Diego Supercomputer Center, and the University of California San Diego Libraries are conducting the PLEDGE Project to determine the set of policies that affect operational digital preservation archives and to develop standardized means of recording and enforcing them using rules engines. This has the potential to allow for automated assessment of “trustworthiness” of digital preservation archives. We are also evaluating the completeness of other efforts to define policies for digital preservation such as the RLG/NARA Trusted Digital Repository checklist and the PREMIS metadata schema. We present our results to date.",
        "article_title": "Digital Archive Policies and Trusted Digital Repositories",
        "authors": [
            {
                "given": "MacKenzie",
                "family": "Smith",
                "affiliation": [
                    "MIT Libraries"
                ]
            },
            {
                "given": "Reagan",
                "family": "Moore",
                "affiliation": [
                    "San Diego Supercomputer Center"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "2",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v2i1.15",
        "identifier": {
            "string_id": "10.2218/ijdc.v2i1.15",
            "id_scheme": "DOI"
        },
        "abstract": "Occupational information resources - data about the characteristics of different occupational positions - are widely used in the social sciences, across a range of disciplines and international contexts. They are available in many formats, most often constituting small electronic files that are made freely downloadable from academic web pages. However there are several challenges associated with how occupational information resources are distributed to, and exploited by, social researchers. In this paper we describe features of occupational information resources, and indicate the role digital curation can play in exploiting them. We report upon the strategies used in the GEODE research project (Grid Enabled Occupational Data Environment1). This project attempts to develop long-term standards for the distribution of occupational information resources, by providing a standardized framework-based electronic depository for occupational information resources, and by providing a data indexing service, based on e-Science middleware, which collates occupational information resources and makes them readily accessible to non-specialist social scientists.",
        "article_title": "Data Curation Standards and Social Science Occupational Information Resources",
        "authors": [
            {
                "given": "Paul",
                "family": "Lambert",
                "affiliation": [
                    "University of Stirling"
                ]
            },
            {
                "given": "Vernon",
                "family": "Gayle",
                "affiliation": [
                    "University of Stirling"
                ]
            },
            {
                "given": "Larry",
                "family": "Tan",
                "affiliation": [
                    "University of Stirling"
                ]
            },
            {
                "given": "Ken",
                "family": "Turner",
                "affiliation": [
                    "University of Stirling"
                ]
            },
            {
                "given": "Richard",
                "family": "Sinnott",
                "affiliation": [
                    "University of Glasgow"
                ]
            },
            {
                "given": "Ken",
                "family": "Prandy",
                "affiliation": [
                    "University of Cardiff "
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "2",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v2i1.14",
        "identifier": {
            "string_id": "10.2218/ijdc.v2i1.14",
            "id_scheme": "DOI"
        },
        "abstract": "The reference model for the Open Archival Information System (OAIS) is well established in the research community as a method of modelling the functions of a digital repository and as a basis in which to frame digital curation and preservation issues. In reference to the 5th anniversary review of the OAIS, it is timely to consider how it may be interpreted by an institutional repository. The paper examines methods of sharing essential functions and requirements of an OAIS between two or more institutions, outlining the practical considerations of outsourcing. It also details the approach taken by the SHERPA DP Project to introduce a disaggregated service model for institutional repositories that wish to implement preservation services.",
        "article_title": "Modelling OAIS Compliance for Disaggregated Preservation Services",
        "authors": [
            {
                "given": "Gareth",
                "family": "Knight",
                "affiliation": [
                    "SHERPA DP Project, AHDS Executive"
                ]
            },
            {
                "given": "Mark",
                "family": "Hedges",
                "affiliation": [
                    "SHERPA DP Project, AHDS Executive"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "2",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v2i1.13",
        "identifier": {
            "string_id": "10.2218/ijdc.v2i1.13",
            "id_scheme": "DOI"
        },
        "abstract": "This paper builds on the work presented at the ECDL 2006 in automated genre classification as a step toward automating metadata extraction from digital documents for ingest into digital repositories such as those run by archives, libraries and eprint services (Kim &amp; Ross, 2006b). We have previously proposed dividing features of a document into five types (features for visual layout, language model features, stylometric features, features for semantic structure, and contextual features as an object linked to previously classified objects and other external sources) and have examined visual and language model features. The current paper compares results from testing classifiers based on image and stylometric features in a binary classification to show that certain genres have strong image features which enable effective separation of documents belonging to the genre from a large pool of other documents.",
        "article_title": "“The Naming of Cats”: Automated Genre Classification",
        "authors": [
            {
                "given": "Yunhyong",
                "family": "Kim",
                "affiliation": [
                    "Digital Curation Centre (DCC)",
                    "Humanities Advanced Technology and Information Institute (HATII)"
                ]
            },
            {
                "given": "Seamus",
                "family": "Ross",
                "affiliation": [
                    "Digital Curation Centre (DCC)",
                    "Humanities Advanced Technology and Information Institute (HATII)"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "2",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v2i1.12",
        "identifier": {
            "string_id": "10.2218/ijdc.v2i1.12",
            "id_scheme": "DOI"
        },
        "abstract": "A successful research and innovation system depends on the open exchange of ideas, information and knowledge. But both research methods and the scholarly communications system are undergoing fundamental changes which present new opportunities and challenges in communicating the results of research. Funders are at different stages in responding to these changes, and this in turn presents challenges to researchers and research institutions. This paper reports on the findings of a study undertaken in 2006 into the policies, practices and views of a range of the major funders of research in the UK in relation to the management of the information outputs generated with the benefit of their support. It covers the full range of information outputs, including journal articles and monographs, but also other outputs, including data, that are not generally published in traditional form. The article also presents conclusions as to issues that need to be addressed in the development of a coherent and consistent policy framework for the future.",
        "article_title": "UK Research Funders’ Policies for the Management of Information Outputs",
        "authors": [
            {
                "given": "Michael",
                "family": "Jubb",
                "affiliation": [
                    "Research Information Network"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "2",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v2i1.11",
        "identifier": {
            "string_id": "10.2218/ijdc.v2i1.11",
            "id_scheme": "DOI"
        },
        "abstract": "Understanding and communicating the cost and value of digital curation activities has now been recognised by a number of projects and initiatives as a very important factor in ensuring the long-term survival of digital assets. A number of projects have developed costing models for digital preservation but there remains a major problem with information assets (digital or otherwise) in that their value is difficult to express in terms that are readily understood by all the stakeholders, especially those who might fund their preservation. This paper introduces a range of issues concerning information value and business models for sustained funding of digital preservation, with particular reference to the espida Project recently completed at the University of Glasgow. This project has developed a model of information value that builds on the Balanced Scorecard approach to business performance developed by Kaplan and Norton. This model casts information curation as an investment where current and ongoing expenditure is incurred in order to produce future returns, benefitting a range of stakeholders. In this formulation, value is seen as multi-facetted and, from the point of view of the individual or organisation funding the curation, explicitly related to the funder’s strategic goals. It also recognises that benefits may only accrue over the long term and that there is a risk that information that is preserved may fail to deliver any return. Examples discussed in the paper concern the establishment of an institutional repository and the establishment of an e-thesis service for an educational institution. It concludes that a deconstruction of benefits of this kind can be more quickly and fully understood even by stakeholders not necessarily expert in the curation field. This facilitates the production of a well-constructed case that clearly articulates information value and the benefit that accrues from its curation, which in turn allows senior management or other funders to make funding decisions based on understandable information: the basic premise of good practice in management. This is a commonly understood idea and one that the espida methodology helps fulfil.",
        "article_title": "The world is all grown digital.... How shall a man persuade management what to do in such times?",
        "authors": [
            {
                "given": "James",
                "family": "Currall",
                "affiliation": [
                    "University of Glasgow"
                ]
            },
            {
                "given": "Claire",
                "family": "Johnson",
                "affiliation": [
                    "University of Glasgow"
                ]
            },
            {
                "given": "Peter",
                "family": "McKinney",
                "affiliation": [
                    "University of Glasgow"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "2",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v2i1.10",
        "identifier": {
            "string_id": "10.2218/ijdc.v2i1.10",
            "id_scheme": "DOI"
        },
        "abstract": "The National Archives is developing a range of practical solutions to the active preservation of electronic records, using an extensible service-oriented architecture and a central technical registry (PRONOM). This paper describes TNA’s methodologies for characterisation, preservation planning, and preservation action, the technologies being adopted to implement them, and the role of PRONOM in supporting these services. It describes how this approach fits with international research programmes, and the types of preservation service which TNA may be able to provide externally in the future.",
        "article_title": "Developing Practical Approaches to Active Preservation",
        "authors": [
            {
                "given": "Adrian",
                "family": "Brown",
                "affiliation": [
                    "The National Archives, UK"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "2",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v2i2.28",
        "identifier": {
            "string_id": "10.2218/ijdc.v2i2.28",
            "id_scheme": "DOI"
        },
        "abstract": "The National Archives and Records Administration (NARA) and EU SHAMAN projects are working with multiple research institutions on tools and technologies that will supply a comprehensive, systematic, and dynamic means for preserving virtually any type of electronic record, free from dependence on any specific hardware or software. This paper describes the joint development work between the University of Liverpool and the San Diego Supercomputer Center (SDSC) at the University of California, San Diego on the NARA and SHAMAN prototypes. The aim is to provide technologies in support of the required generic data management infrastructure. We describe a Theory of Preservation that quantifies how communication can be accomplished when future technologies are different from those available at present. This includes not only different hardware and software, but also different standards for encoding information. We describe the concept of a “digital ontology” to characterize preservation processes; this is an advance on the current OAIS Reference Model of providing representation information about records. To realize a comprehensive Theory of Preservation, we describe the ongoing integration of distributed shared collection management technologies, digital library browsing, and presentation technologies for the NARA and SHAMAN Persistent Archive Testbeds.",
        "article_title": "Digital Preservation Theory and Application: Transcontinental Persistent Archives Testbed Activity",
        "authors": [
            {
                "given": "Paul",
                "family": "Watry",
                "affiliation": [
                    "University of Liverpool"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "2",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v2i2.27",
        "identifier": {
            "string_id": "10.2218/ijdc.v2i2.27",
            "id_scheme": "DOI"
        },
        "abstract": "Scientific data problems do not stand in isolation. They are part of a larger set of challenges associated with the escalation of scientific information and changes in scholarly communication in the digital environment. Biologists in particular are generating enormous sets of data at a high rate, and new discoveries in the biological sciences will increasingly depend on the integration of data across multiple scales. This work will require new kinds of information expertise in key areas. To build this professional capacity we have developed two complementary educational programs: a Biological Information Specialist (BIS) masters degree and a concentration in Data Curation (DC). We believe that BISs will be central in the development of cyberinfrastructure and information services needed to facilitate interdisciplinary and multi-scale science. Here we present three sample cases from our current research projects to illustrate areas in which we expect information specialists to make important contributions to biological research practice.",
        "article_title": "Graduate Curriculum for Biological Information Specialists: A Key to Integration of Scale in Biology",
        "authors": [
            {
                "given": "Carole L.",
                "family": "Palmer",
                "affiliation": [
                    "University of Illinois at Urbana-Champaign"
                ]
            },
            {
                "given": "Bryan P.",
                "family": "Heidorn",
                "affiliation": [
                    "University of Illinois at Urbana-Champaign"
                ]
            },
            {
                "given": "Dan",
                "family": "Wright",
                "affiliation": [
                    "University of Illinois at Urbana-Champaign"
                ]
            },
            {
                "given": "Melissa H.",
                "family": "Cragin",
                "affiliation": [
                    "University of Illinois at Urbana-Champaign"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "2",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v2i2.26",
        "identifier": {
            "string_id": "10.2218/ijdc.v2i2.26",
            "id_scheme": "DOI"
        },
        "abstract": "Astronomy is similar to other scientific disciplines in that scholarly publication relies on the presentation and interpretation of data. But although astronomy now has archives for its primary research telescopes and associated surveys, the highly processed data that is presented in the peer-reviewed journals and is the basis for final analysis and interpretation is generally not archived and has no permanent repository. We have initiated a project whose goal is to implement an end-to-end prototype system which, through a partnership of a professional society, that society’s scholarly publications/publishers, research libraries, and an information technology substrate provided by the Virtual Observatory, will capture high-level digital data as part of the publication process and establish a distributed network of curated, permanent data repositories. The data in this network will be accessible through the research journals, astronomy data centers, and Virtual Observatory data discovery portals.",
        "article_title": "Digital Data Preservation for Scholarly Publications in Astronomy",
        "authors": [
            {
                "given": "Sayeed",
                "family": "Choudhury",
                "affiliation": [
                    "The Johns Hopkins University"
                ]
            },
            {
                "given": "Tim",
                "family": "DiLauro",
                "affiliation": [
                    "The Johns Hopkins University"
                ]
            },
            {
                "given": "Alex",
                "family": "Szalay",
                "affiliation": [
                    "The Johns Hopkins University"
                ]
            },
            {
                "given": "Ethan",
                "family": "Vishniac",
                "affiliation": [
                    "The Johns Hopkins University"
                ]
            },
            {
                "given": "Robert",
                "family": "Hanisch",
                "affiliation": [
                    "Space Telescope Science Institute"
                ]
            },
            {
                "given": "Julie",
                "family": "Steffen",
                "affiliation": [
                    "The University of Chicago Press"
                ]
            },
            {
                "given": "Robert",
                "family": "Milkey",
                "affiliation": [
                    "American Astronomical Society"
                ]
            },
            {
                "given": "Teresa",
                "family": "Ehling",
                "affiliation": [
                    "Cornell University"
                ]
            },
            {
                "given": "Ray",
                "family": "Plante",
                "affiliation": [
                    "University of Illinois",
                    "National Center for Supercomputing Applications"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "2",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v2i2.25",
        "identifier": {
            "string_id": "10.2218/ijdc.v2i2.25",
            "id_scheme": "DOI"
        },
        "abstract": "To date many institutional repository (IR) software suppliers have pushed the IR as a digital preservation solution. We argue that the digital preservation of objects in IRs may better be achieved through the use of light-weight, add-on services. We present such a service – PRONOM-ROAR – that generates file format profiles for IRs. This demonstrates the potential of using third- party services to provide preservation expertise to IR managers by making use of existing machine interfaces to IRs.",
        "article_title": "PRONOM-ROAR: Adding Format Profiles to a Repository Registry to Inform Preservation Services",
        "authors": [
            {
                "given": "Tim",
                "family": "Brody",
                "affiliation": [
                    "University of Southampton"
                ]
            },
            {
                "given": "Leslie",
                "family": "Carr",
                "affiliation": [
                    "University of Southampton"
                ]
            },
            {
                "given": "Jessie M. N.",
                "family": "Hey",
                "affiliation": [
                    "University of Southampton"
                ]
            },
            {
                "given": "Adrian",
                "family": "Brown",
                "affiliation": [
                    "The National Archives (UK)"
                ]
            },
            {
                "given": "Steve",
                "family": "Hitchcock",
                "affiliation": [
                    "Preserv Project"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "2",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v3i1.46",
        "identifier": {
            "string_id": "10.2218/ijdc.v3i1.46",
            "id_scheme": "DOI"
        },
        "abstract": "The success of eScience research depends not only upon effective collaboration between scientists and technologists but also upon the active involvement of data archivists. Archivists rarely receive scientific data until findings are published, by which time important information about their origins, context, and provenance may be lost. Research reported here addresses the life cycle of data from collaborative ecological research with embedded networked sensing technologies. A better understanding of these processes will enable archivists to participate in earlier stages of the life cycle and to improve curation of these types of scientific data. Evidence from our interview study and field research yields a nine-stage life cycle. Among the findings are the cumulative effect of decisions made at each stage of the life cycle; the balance of decision-making between scientific and technology research partners; and the loss of certain types of data that may be essential to later interpretation.",
        "article_title": "Moving Archival Practices Upstream: An Exploration of the Life Cycle of Ecological Sensing Data in Collaborative Field Research",
        "authors": [
            {
                "given": "Jullian C.",
                "family": "Wallis",
                "affiliation": [
                    "Center for Embedded Networked Sensing, UCLA"
                ]
            },
            {
                "given": "Christine L.",
                "family": "Borgman",
                "affiliation": [
                    "Graduate School of Education & Information Studies, UCLA"
                ]
            },
            {
                "given": "Matthew S.",
                "family": "Mayernik",
                "affiliation": [
                    "Graduate School of Education & Information Studies, UCLA"
                ]
            },
            {
                "given": "Alberto",
                "family": "Pepe",
                "affiliation": [
                    "Graduate School of Education & Information Studies, UCLA"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "3",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v3i1.45",
        "identifier": {
            "string_id": "10.2218/ijdc.v3i1.45",
            "id_scheme": "DOI"
        },
        "abstract": "The Data Documentation Initiative (DDI) is an emerging metadata standard for the social sciences. The DDI is in active use by many data specialists and archivists, but researchers themselves have been slow to recognize the benefits of the standards approach to metadata. This paper outlines how the DDI has evolved since its inception in 1995 and discusses ways to broaden its impact in the social science research community.",
        "article_title": "Data Documentation Initiative: Toward a Standard for the Social Sciences",
        "authors": [
            {
                "given": "Mary",
                "family": "Vardigan",
                "affiliation": [
                    "University of Michigan"
                ]
            },
            {
                "given": "Pascal",
                "family": "Heus",
                "affiliation": [
                    "Open Data Foundation,Tucson, Arizona"
                ]
            },
            {
                "given": "Wendy",
                "family": "Thomas",
                "affiliation": [
                    "University of Minnesota"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "3",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v3i1.44",
        "identifier": {
            "string_id": "10.2218/ijdc.v3i1.44",
            "id_scheme": "DOI"
        },
        "abstract": "File format obsolescence is a major risk factor threatening the ongoing usefulness of digital information collections. While the preservation community has become increasingly interested in tools for assessing a wide range of risks, the National Library of Australia is developing mechanisms specifically focused on the risks of format obsolescence. The paper reports on the AONS II Project, undertaken in conjunction with the Australian Partnership for Sustainable Repositories (APSR). The project aimed to refine and develop a software tool that would automatically find and report indicators of obsolescence risks, to help repository managers decide if preservation action is needed. The paper discusses the current mismatch between this objective and the available sources of information on file formats, and emphasises the need to take account of both local and global factors in assessing risk. The paper calls for the preservation community to engage with the further development of thinking about file format obsolescence.",
        "article_title": "Defining File Format Obsolescence: A Risky Journey",
        "authors": [
            {
                "given": "David",
                "family": "Pearson",
                "affiliation": [
                    "National Library of Australia"
                ]
            },
            {
                "given": "Colin",
                "family": "Webb",
                "affiliation": [
                    "National Library of Australia"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "3",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v3i1.43",
        "identifier": {
            "string_id": "10.2218/ijdc.v3i1.43",
            "id_scheme": "DOI"
        },
        "abstract": "The OAIS concept of Representation Information (RI) is a potential strategy for the curation and preservation of all types of information. We share insights gained from our exploration of issues concerned with the capture of crystallography and engineering RI as well as its structuring, collection and curation. In addition, we discuss the supporting technical, IPR and globally collaborative infrastructures required to make such a strategy successful.",
        "article_title": "Challenges and Issues Relating to the Use of Representation Information for the Digital Curation of Crystallography and Engineering Data",
        "authors": [
            {
                "given": "Manjula",
                "family": "Patel",
                "affiliation": [
                    "UKOLN, University of Bath"
                ]
            },
            {
                "given": "Alexander",
                "family": "Ball",
                "affiliation": [
                    "UKOLN, University of Bath"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "3",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v3i1.42",
        "identifier": {
            "string_id": "10.2218/ijdc.v3i1.42",
            "id_scheme": "DOI"
        },
        "abstract": "A preservation environment manages communication from the past while communicating with the future. Information generated in the past is sent into the future by the current preservation environment. The proof that the preservation environment preserves authenticity and integrity while performing the communication constitutes a theory of digital preservation. We examine the representation information that is needed about the preservation environment for a theory of digital preservation. The representation information includes descriptions of the preservation management policies, the preservation processes, and the state information that is needed to verify the correct working behavior of the system. We demonstrate rule-based data grids that can verify that prior policies correctly enforced preservation properties, while sending into the future descriptions of the current preservation management policies.",
        "article_title": "Towards a Theory of Digital Preservation",
        "authors": [
            {
                "given": "Reagan",
                "family": "Moore",
                "affiliation": [
                    "San Diego Supercomputer Center"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "3",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v3i1.41",
        "identifier": {
            "string_id": "10.2218/ijdc.v3i1.41",
            "id_scheme": "DOI"
        },
        "abstract": "The explosion in the production of scientific data in recent years is placing strains upon conventional systems supporting integration, analysis, interpretation and dissemination of data and thus constraining the whole scientific process. Support for handling large quantities of diverse information can be provided by e-Science methodologies and the cyber-infrastructure that enables collaborative handling of such data. Regard needs to be taken of the whole process involved in scientific discovery. This includes the consideration of the requirements of the users and consumers further down the information chain and what they might ideally prefer to impose on the generators of those data. As the degree of digital capture in the laboratory increases, it is possible to improve the automatic acquisition of the ‘context of the data’ as well as the data themselves. This process provides an opportunity for the data creators to ensure that many of the problems they often encounter in later stages are avoided. We wish to elevate curation to an operation to be considered by the laboratory scientist as part of good laboratory practice, not a procedure of concern merely to the few specialising in archival processes. Designing curation into experiments is an effective solution to the provision of high-quality metadata that leads to better, more re-usable data and to better science.",
        "article_title": "Curation of Laboratory Experimental Data as Part of the Overall Data Lifecycle",
        "authors": [
            {
                "given": "Jeremy",
                "family": "Frey",
                "affiliation": [
                    "University of Southampton"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "3",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v3i1.40",
        "identifier": {
            "string_id": "10.2218/ijdc.v3i1.40",
            "id_scheme": "DOI"
        },
        "abstract": "The purpose of the DareLux (Data Archiving River Environment Luxembourg) Project was the preservation of unique and irreplaceable datasets, for which we chose hydrology data that will be required to be used in future climatic models. The results are: an operational archive built with XML containers, the OAI-PMH protocol and an architecture based upon web services. Major conclusions are: quality control on ingest is important; digital rights management demands attention; and cost aspects of ingest and retrieval cannot be underestimated. We propose a new paradigm for information retrieval of this type of dataset. We recommend research into visualisation tools for the search and retrieval of this type of dataset.",
        "article_title": "Dataset Preservation for the Long Term: Results of the DareLux Project",
        "authors": [
            {
                "given": "Eugène",
                "family": "Dürr",
                "affiliation": [
                    "Utrecht University and Euformatics b.v.,Netherlands"
                ]
            },
            {
                "given": "Kees",
                "family": "Van der Meer",
                "affiliation": [
                    "Delft University of Technology, Netherlands"
                ]
            },
            {
                "given": "Wim",
                "family": "Luxemburg",
                "affiliation": [
                    "Delft University of Technology, Netherlands"
                ]
            },
            {
                "given": "Ronald",
                "family": "Dekker",
                "affiliation": [
                    "Delft University of Technology Library, Netherlands"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "3",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v3i1.39",
        "identifier": {
            "string_id": "10.2218/ijdc.v3i1.39",
            "id_scheme": "DOI"
        },
        "abstract": "This paper first explores some of the reasons why collaboration is becoming increasingly important in supporting scientific data curation, digital preservation initiatives and institutional repository development. It then investigates the concepts of trust and control used in the organisation science literature and attempts to apply them to the work on trustworthy repositories being carried out by various international initiatives.",
        "article_title": "Toward Distributed Infrastructures for Digital Preservation: The Roles of Collaboration and Trust",
        "authors": [
            {
                "given": "Michael",
                "family": "Day",
                "affiliation": [
                    "UKOLN, University of Bath"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "3",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v3i1.38",
        "identifier": {
            "string_id": "10.2218/ijdc.v3i1.38",
            "id_scheme": "DOI"
        },
        "abstract": "The National Digital Information Infrastructure and Preservation Program (NDIIPP) was initiated in December 2000 when the U.S. Congress authorized the Library of Congress to work with a broad range of institutions to develop a national strategy for the preservation of at-risk digital content. Guided by a strategy of collaboration and iteration, the Library of Congress began the formation of a national network of partners dedicated to collecting and preserving important born-digital information. Over the last six years, the Library and its partners have been engaged in learning through action that has resulted in an evolving understanding of the most appropriate roles and functions for a national network of diverse stakeholders. The emerging network is complex and inclusive of a variety of stakeholders; content producers, content stewards and service providers from the public and private sectors. Lessons learned indicate that interoperability is a challenge in all aspects of collaborative work.",
        "article_title": "Evolving a Network of Networks: The Experience of Partnerships in the National Digital Information Infrastructure and Preservation Program",
        "authors": [
            {
                "given": "Martha",
                "family": "Anderson",
                "affiliation": [
                    "The Library of Congress"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "3",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v3i2.59",
        "identifier": {
            "string_id": "10.2218/ijdc.v3i2.59",
            "id_scheme": "DOI"
        },
        "abstract": "We present performance data relating to the use of migration in a system we are creating to provide web access to heterogeneous document collections in legacy formats. Our goal is to enable sustained access to collections such as these when faced with increasing obsolescence of the necessary supporting applications and operating systems. Our system allows searching and browsing of the original files within their original contexts utilizing binary images of the original media. The system uses static and dynamic file migration to enhance collection browsing, and emulation to support both the use of legacy programs to access data and long-term preservation of the migration software. While we provide an overview of the architectural issues in building such a system, the focus of this paper is an in-depth analysis of file migration using data gathered from testing our software on 1,885 CD-ROMs and DVDs. These media are among the thousands of collections of social and scientific data distributed by the United States Government Printing Office (GPO) on legacy media (CD-ROM, DVD, floppy disk) under the Federal Depository Library Program (FDLP) over the past 20 years.",
        "article_title": "Migration Performance for Legacy Data Access",
        "authors": [
            {
                "given": "Kam",
                "family": "Woods",
                "affiliation": [
                    "Indiana University"
                ]
            },
            {
                "given": "Geoffrey",
                "family": "Brown",
                "affiliation": [
                    "Indiana University"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "3",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v3i2.58",
        "identifier": {
            "string_id": "10.2218/ijdc.v3i2.58",
            "id_scheme": "DOI"
        },
        "abstract": "Ensuring the long-term usability of engineering informatics (EI) artifacts is a challenge, particularly for products with longer lifecycles than the computing hardware and software used for their design and manufacture. Addressing this challenge requires characterizing the nature of EI, defining metrics for EI sustainability, and developing methods for long-term EI curation. In this paper we highlight various issues related to long-term archival of EI and describe the work towards methods and metrics for sustaining EI. We propose an approach to enhance the Open Archival Information System (OAIS) functional model to incorporate EI sustainability criteria, Digital Object Prototypes (DOPs), and end user access requirements. We discuss the end user’s requirements from the point of view of reference, reuse and rationale – the “3Rs” – to better understand the level of granularity and abstractions required in the definition of engineering digital objects. Finally we present a proposed case study and experiment.",
        "article_title": "Sustaining Engineering Informatics: Toward Methods and Metrics for Digital Curation",
        "authors": [
            {
                "given": "Josh",
                "family": "Lubell",
                "affiliation": [
                    "National Institute of Standards and Technology, USA"
                ]
            },
            {
                "given": "Sudarsan",
                "family": "Rachuri",
                "affiliation": [
                    "National Institute of Standards and Technology, USA"
                ]
            },
            {
                "given": "Mahesh",
                "family": "Mani",
                "affiliation": [
                    "National Institute of Standards and Technology, USA"
                ]
            },
            {
                "given": "Eswaran",
                "family": "Subrahmanian",
                "affiliation": [
                    "Carnegie Mellon University"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "3",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v3i2.57",
        "identifier": {
            "string_id": "10.2218/ijdc.v3i2.57",
            "id_scheme": "DOI"
        },
        "abstract": "This paper explores data practices in a Long Term Ecological Research (LTER) setting. It describes a number of salient data characteristics that are specific to the LTER program and outlines some central features of the curation approach cultivated within the US LTER network. It goes on to identify recent developments within the international LTER program relating to data issues: increasing heterogeneities due to networking, integration of data from additional disciplines, and new technologies in a changing digital landscape. Information management experience within LTER provides one example of the recurrent balancing inherent to the work of data curation. It highlights (1) taking into account the extended temporal horizon of data care, (2) aligning support for data, science and information infrastructure, and (3) integrating site and network-level responsibilities. LTER contributes to the inquiry into how to manage the continuity of digital data and to our understanding of how to design a sustainable information infrastructure.",
        "article_title": "Digital Data Practices and the Long Term Ecological Research Program Growing Global",
        "authors": [
            {
                "given": "Helena",
                "family": "Karasti",
                "affiliation": [
                    "University of Oulu, Finland"
                ]
            },
            {
                "given": "Karen S.",
                "family": "Baker",
                "affiliation": [
                    "University of California, San Diego, USA"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "3",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v3i2.56",
        "identifier": {
            "string_id": "10.2218/ijdc.v3i2.56",
            "id_scheme": "DOI"
        },
        "abstract": "Computer games, like other digital media, are extremely vulnerable to long-term loss, yet little work has been done to preserve them. As a result we are experiencing large-scale loss of the early years of gaming history. Computer games are an important part of modern popular culture, and yet are afforded little of the respect bestowed upon established media such as books, film, television and music. We must understand the reasons for the current lack of computer game preservation in order to devise strategies for the future. Computer game history is a difficult area to work in, because it is impossible to know what has been lost already, and early records are often incomplete. This paper uses the information that is available to analyse the current status of computer game preservation, specifically in the UK. It makes a quantitative analysis of the preservation status of computer games, and finds that games are already in a vulnerable state. It proposes that work should be done to compile accurate metadata on computer games and to analyse more closely the exact scale of data loss, while suggesting strategies to overcome the barriers that currently exist.",
        "article_title": "‘Grand Theft Archive’: A Quantitative Analysis of the State of Computer Game Preservation",
        "authors": [
            {
                "given": "Paul",
                "family": "Gooding",
                "affiliation": [
                    "BBC Sport Library, London"
                ]
            },
            {
                "given": "Melissa",
                "family": "Terras",
                "affiliation": [
                    "University College London"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "3",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v3i2.55",
        "identifier": {
            "string_id": "10.2218/ijdc.v3i2.55",
            "id_scheme": "DOI"
        },
        "abstract": "This paper presents the SCOPE (Scientific Compound Object Publishing and Editing) system which is designed to enable scientists to easily author, publish and edit scientific compound objects. Scientific compound objects encapsulate the various datasets and resources generated or utilized during a scientific experiment or discovery process, within a single compound object, for publishing and exchange. The adoption of “named graphs” to represent these compound objects enables provenance information to be captured via the typed relationships between the components. This approach is also endorsed by the OAI-ORE initiative and hence ensures that we generate OAI-ORE-compliant Scientific Compound Objects. The SCOPE system is an extension of the Provenance Explorer tool – which supports access-controlled viewing of scientific provenance trails. Provenance Explorer provided dynamic rendering of RDF graphs of scientific discovery processes, showing the lineage from raw data to publication. Views of different granularity can be inferred automatically using SWRL (Semantic Web Rules Language) rules and an inferencing engine. SCOPE extends the Provenance Explorer tool and GUI by: 1) Adding an embedded web browser that can be used for incorporating objects discoverable via the Web; 2) Representing compound objects as Named Graphs, that can be saved in RDF, TriX, TriG or as an Atom syndication feed; 3) Enabling scientists to attach Creative Commons Licenses to the compound objects to specify how they may be re-used; 4) Enabling compound objects to be published as Fedora Object XML (FOXML) files within a Fedora digital library.",
        "article_title": "SCOPE: A Scientific Compound Object Publishing and Editing System",
        "authors": [
            {
                "given": "Kwok",
                "family": "Cheung",
                "affiliation": [
                    "AIBN, The University of Queensland"
                ]
            },
            {
                "given": "Jane",
                "family": "Hunter",
                "affiliation": [
                    "ITEE, The University of Queensland"
                ]
            },
            {
                "given": "Anna",
                "family": "Lashtabeg",
                "affiliation": [
                    "AIBN, The University of Queensland"
                ]
            },
            {
                "given": "John",
                "family": "Drennan",
                "affiliation": [
                    "AIBN, The University of Queensland"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2008-12-02",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "3",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i1.83",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i1.83",
            "id_scheme": "DOI"
        },
        "abstract": " This paper will describe the genesis and realisation of the Australian National Data Service (ANDS). It will commence by outlining the context within which ANDS was conceived, both in the international research and Australian research support domains. It will then describe the process that brought about the ANDS vision and the principles that informed the realisation of that vision. The paper will then outline each of the four ANDS programs (Developing Frameworks, Providing Utilities, Seeding the Commons, and Building Capabilities) while also discussing particular items of note about the approach ANDS is taking. The paper concludes by briefly examining related work in the UK and US.",
        "article_title": "Design and Implementation of the Australian National Data Service",
        "authors": [
            {
                "given": "Andrew",
                "family": "Treloar",
                "affiliation": [
                    "Monash University, Australia"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-06-29",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i1.82",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i1.82",
            "id_scheme": "DOI"
        },
        "abstract": " Government's use of the Web in the UK is prolific and a wide range of services are now available though this channel. The government set out to address the problem that links from Hansard (the transcripts of Parliamentary debates) were not maintained over time and that therefore there was need for some long-term storage and stewardship of information, including maintaining access. Further investigation revealed that linking was key, not only in maintaining access to information, but also to the discovery of information. This resulted in a project that affects the entire  government Web estate, with a solution leveraging the basic building blocks of the Internet (DNS) and the Web (HTTP and URIs) in a pragmatic way, to ensure that an infrastructure is in place to provide access to important information both now and in the future.   ",
        "article_title": "UK Government Web Continuity:  Persisting Access through Aligning Infrastructures",
        "authors": [
            {
                "given": "Amanda",
                "family": "Spencer",
                "affiliation": [
                    "The National Archives (UK)"
                ]
            },
            {
                "given": "John",
                "family": "Sheridan",
                "affiliation": [
                    "The National Archives (UK)"
                ]
            },
            {
                "given": "David",
                "family": "Thomas",
                "affiliation": [
                    "The National Archives (UK)"
                ]
            },
            {
                "given": "David",
                "family": "Pullinger",
                "affiliation": [
                    "Central Office of Information"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-06-29",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i1.81",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i1.81",
            "id_scheme": "DOI"
        },
        "abstract": " Increasing demand to manage and preserve 3-dimensional models for a variety of physical phenomena (e.g., building and engineering designs, computer games, or scientific visualizations) is creating new challenges for digital archives. Preserving 3D models requires identifying technical formats for the models that can be maintained over time, and the available formats offer different advantages and disadvantages depending on the intended future uses of the models. Additionally, the metadata required to manage 3D models is not yet standardized, and getting intellectual proposal rights for digital models is uncharted territory.  The FACADE Project at MIT is investigating these challenges in the architecture, engineering and construction (AEC) industry and has developed recommendations and systems to support digital archives in dealing with digital 3D models and related data. These results can also be generalized to other domains doing 3D modeling.",
        "article_title": "Curating Architectural 3D CAD Models",
        "authors": [
            {
                "given": "MacKenzie",
                "family": "Smith",
                "affiliation": [
                    "MIT Libraries"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-06-29",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i1.80",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i1.80",
            "id_scheme": "DOI"
        },
        "abstract": " Product Lifecycle Management (PLM) has become increasingly important in the engineering community over the last decade or so, due to the globalisation of markets and the rising popularity of products provided as services. It demands the efficient capture, representation, organisation, retrieval and reuse of product data over its entire life. Simultaneously, there is now a much greater reliance on CAD models for communicating designs to manufacturers, builders, maintenance crews and regulators, and for definitively expressing designs. Creating the engineering record digitally, however, presents problems not only for its long-term maintenance and accessibility - due in part to the rapid obsolescence of the hardware, software and file formats involved - but also for recording the evolution of designs, artefacts and products. We examine the curation and preservation requirements in PLM and suggest ways of alleviating the problems of sustaining CAD engineering models through the use of lightweight formats, layered annotation and the collection of Representation Information as defined in the Open Archival Information System (OAIS) Reference Model.  We describe two tools which have been specifically developed to aid in the curation of CAD engineering models in the context of PLM: Lightweight Models with Multilayered Annotation (LiMMA) and a Registry/Repository of Representation Information for Engineering (RRoRIfE).",
        "article_title": "Strategies for the Curation of CAD Engineering Models",
        "authors": [
            {
                "given": "Manjula",
                "family": "Patel",
                "affiliation": [
                    "UKOLN, University of Bath, UK"
                ]
            },
            {
                "given": "Alexander",
                "family": "Ball",
                "affiliation": [
                    "UKOLN, University of Bath, UK"
                ]
            },
            {
                "given": "Lian",
                "family": "Ding",
                "affiliation": [
                    "IdMRC, University of Bath, UK"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-06-29",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i1.79",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i1.79",
            "id_scheme": "DOI"
        },
        "abstract": " In the future, a scholar or researcher will want to know that a digital object is trusted - that it is authentic and reliable.  Digital objects can be surrogates, resulting from a digitization process, or they can be objects whose only form is digital.  Much has been accomplished in existing open source digital library platforms to provide capabilities for preserving digital objects including now ubiquitous features such as persistent identifiers, integrity checks, audit trails, and versioning.  However, achieving a level of digital object authenticity will require a multi-dimensional approach involving policies, processes, and continued technological innovation.  This paper proposes steps that the institution can take to insure the availability of authentic digital objects in the future.  In this proposal, authenticity is based on definitions from archival diplomatics and relies on methods from public key cryptography for digitally signing an object with a secure time stamp. Trustworthy processes, re-definition of traditional roles, and the implementation of technologies to support authenticity are all required to meet the needs of digital scholarship.  Implementation and policy issues are discussed with specific attention to transformations required of the archival institution and the professional archivist.",
        "article_title": "An Institutional Framework for Creating Authentic Digital Objects",
        "authors": [
            {
                "given": "Ronald",
                "family": "Jantz",
                "affiliation": [
                    "Rutgers University Libraries"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-06-29",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i1.78",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i1.78",
            "id_scheme": "DOI"
        },
        "abstract": " We characterize long-term preservation of digital content as an extended relay in time, in which repeated handoffs of information occur independently at every architectural layer: at the physical layer, where bits are handed off between storage systems; at the logical layer, where digital objects are handed off between repository systems; and at the administrative layer, where collections of objects and relationships are handed off between archives, curators, and institutions.  We examine the support of current preservation technologies for these handoffs, note shortcomings, and argue that some modest improvements would result in a \"relay-supporting\" preservation infrastructure, one that provides a baseline level of preservation by mitigating the risk of fundamental information loss.  Finally, we propose a series of tests to validate a relay-supporting infrastructure, including a second Archive Ingest and Handling Test (AIHT).",
        "article_title": "Relay-supporting Archives: Requirements and Progress",
        "authors": [
            {
                "given": "Greg",
                "family": "Janée",
                "affiliation": [
                    "University of California, Santa Barbara"
                ]
            },
            {
                "given": "James",
                "family": "Frew",
                "affiliation": [
                    "University of California, Santa Barbara"
                ]
            },
            {
                "given": "Terry",
                "family": "Moore",
                "affiliation": [
                    "University of Tennessee, Knoxville"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-06-29",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i1.77",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i1.77",
            "id_scheme": "DOI"
        },
        "abstract": " There is now widespread recognition that data are a valuable long-term resource and that making them publicly available is a way to realise their potential value - both as part of the scholarly record or for re-use by others. The Research Information Network (RIN) report, To share or not to share: Publication and quality assurance of research data outputs (June 2008), investigates whether or not researchers make their research data available to others and the issues they encounter when doing so. Importantly, it seeks to do this by seeking the perspectives of researchers themselves. This paper reflects on how this relates to the more top-down literature on the subject. The discussion of the significance of the RIN's main findings is correlated to the four themes of the RIN report. Firstly, it discusses some distinctions in the types of data that should be shared and preserved and what needs to done to do so effectively. Secondly, it reflects on the motivations for and constraints on researchers publishing their data, and how funders and publishers can address them. Thirdly, it reviews some issues around how data are discovered, accessed and re-used. Finally, it discusses the scholarly and technical quality of published data.",
        "article_title": "The Publication of Research Data:  Researcher Attitudes and Behaviour",
        "authors": [
            {
                "given": "Aaron",
                "family": "Griffiths",
                "affiliation": [
                    "Research Information Network"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-06-29",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i1.76",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i1.76",
            "id_scheme": "DOI"
        },
        "abstract": " The proliferation of Web, database and social networking technologies has enabled us to produce, publish and exchange digital assets at an enormous rate. This vast amount of information that is either digitized or born-digital needs to be collected, organized and preserved in a way that ensures that our digital assets and the information they carry remain available for future use. Digital curation has emerged as a new inter-disciplinary practice that seeks to set guidelines for disciplined management of information. In this paper we review two recent models for digital curation introduced by the Digital Curation Centre (DCC) and the Digital Curation Unit (DCU) of the Athena Research Centre. We then propose a fusion of the two models that highlights the need to extend the digital curation lifecycle by adding (a) provisions for the registration of usage experience, (b) a stage for knowledge enhancement and (c) controlled vocabularies used by convention to denote concepts, properties and relations. The objective of the proposed extensions is twofold: (i) to provide a more complete lifecycle model for the digital curation domain; and (ii) to provide a stimulus for a broader discussion on the research agenda.",
        "article_title": "DCC&U: An Extended Digital Curation Lifecycle Model",
        "authors": [
            {
                "given": "Panos",
                "family": "Constantopoulos",
                "affiliation": [
                    "Athena Research CentreAthens, Greece"
                ]
            },
            {
                "given": "Costis",
                "family": "Dallas",
                "affiliation": [
                    "Athena Research CentreAthens, Greece"
                ]
            },
            {
                "given": "Ion",
                "family": "Androutsopoulos",
                "affiliation": [
                    "Athena Research CentreAthens, Greece"
                ]
            },
            {
                "given": "Stavros",
                "family": "Angelis",
                "affiliation": [
                    "Athena Research CentreAthens, Greece"
                ]
            },
            {
                "given": "Antonios",
                "family": "Deligiannakis",
                "affiliation": [
                    "Athena Research CentreAthens, Greece"
                ]
            },
            {
                "given": "Dimitris",
                "family": "Gavrilis",
                "affiliation": [
                    "Athena Research CentreAthens, Greece"
                ]
            },
            {
                "given": "Yannis",
                "family": "Kotidis",
                "affiliation": [
                    "Athena Research CentreAthens, Greece"
                ]
            },
            {
                "given": "Christos",
                "family": "Papatheodorou",
                "affiliation": [
                    "Athena Research CentreAthens, Greece"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-06-29",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i1.75",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i1.75",
            "id_scheme": "DOI"
        },
        "abstract": " With new scientific instruments growing exponentially in their capability to generate research data, new infrastructure needs to be developed and deployed to allow researchers to effectively and securely manage their research data from collection, publication, and eventual dissemination to research communities.  In particular, researchers need to be able to easily acquire data from instruments, store and manage potentially large quantities of data, easily process the data, share research resources and work spaces with colleagues both inside and outside of their institution, search and discover across their accessible collections, and easily publish datasets and related research artefacts.  The ARCHER Project has developed production-ready generic e-Research infrastructure including: a Research Repository; Scientific Dataset Managers (both a web and desktop application); Distributed Integrated Multi-Sensor and Instrument Middleware; and a Collaborative Workspace Environment.  Institutions can selectively deploy these components to greatly assist their researchers in managing their research data.",
        "article_title": "ARCHER – e-Research Tools for Research Data Management",
        "authors": [
            {
                "given": "Steve",
                "family": "Androulakis",
                "affiliation": [
                    "Department of Biochemistry and Molecular Biology, Monash University"
                ]
            },
            {
                "given": "Ashley M.",
                "family": "Buckle",
                "affiliation": [
                    "Department of Biochemistry and Molecular Biology, Monash University"
                ]
            },
            {
                "given": "Ian",
                "family": "Atkinson",
                "affiliation": [
                    "ARCHER, James Cook University e-Research Centre"
                ]
            },
            {
                "given": "David",
                "family": "Groenewegen",
                "affiliation": [
                    "ANDS, ARCHER, ARROW"
                ]
            },
            {
                "given": "Nick",
                "family": "Nicholas",
                "affiliation": [
                    "ARCHER, Link Affiliates"
                ]
            },
            {
                "given": "Andrew",
                "family": "Treloar",
                "affiliation": [
                    "ANDS, ARCHER"
                ]
            },
            {
                "given": "Anthony",
                "family": "Beitz",
                "affiliation": [
                    "ARCHER, Monash e-Research Centre"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-06-29",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i1.72",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i1.72",
            "id_scheme": "DOI"
        },
        "abstract": " The Digital Preservation Program of the California Digital Library (CDL) is engaged in a process of reinvention involving significant transformations of its outlook, effort, and infrastructure. This includes a re-articulation of its mission in terms of digital curation, rather than preservation; encouraging a programmatic, rather than a project-oriented approach to curation activities; and a renewed emphasis on services, rather than systems. This last shift was motivated by a desire to deprecate the centrality of the repository as place. Having the repository as the locus for curation activity has resulted in the deployment of a somewhat cumbersome monolithic system that falls short of desired goals for responsiveness to rapidly changing user needs and operational and administrative sustainability. The Program is pursuing a path towards a new curation environment based on the principle of devolving curation function to a set of small, simple, loosely coupled services. In considering this new infrastructure, the Program is relying upon a highly deliberative process starting from first principles drawn from library and archival science. This is followed by a stagewise progression of identifying core preservable values, devising strategies promoting those values, defining abstract services embodying those strategies, and, finally, developing systems that instantiate those services. This paper presents a snapshot of the Program's transformative efforts in its early phase.",
        "article_title": "Preservation Is Not a Place",
        "authors": [
            {
                "given": "Stephen",
                "family": "Abrams",
                "affiliation": [
                    "California Digital Library, University of California"
                ]
            },
            {
                "given": "Patricia",
                "family": "Cruse",
                "affiliation": [
                    "California Digital Library, University of California"
                ]
            },
            {
                "given": "John",
                "family": "Kunze",
                "affiliation": [
                    "California Digital Library, University of California"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-06-29",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i2.97",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i2.97",
            "id_scheme": "DOI"
        },
        "abstract": "   Recent developments in the storage industry have resulted in the creation of an industry standard application programmer’s interface (API) known as XAM, the eXtensible Access Method. The XAM API focuses on the creation and management of reference information (otherwise known as fixed content). Storage vendors supporting the XAM API will provide new benefits to applications that are creating and managing large amounts of fixed content. The benefits described by this paper merit consideration and research by developers creating applications for Digital Curators.",
        "article_title": "The eXtensible Access Method (XAM) Standard",
        "authors": [
            {
                "given": "Steve",
                "family": "Todd",
                "affiliation": [
                    "EMC Corporation,Hopkinton, Massachusetts, USA"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-10-15",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i2.96",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i2.96",
            "id_scheme": "DOI"
        },
        "abstract": "This paper describes a technique for embedding document metadata, and potentially other semantic references inline in word processing documents, which the authors have implemented with the help of a software development team. Several assumptions underly the approach; It must be available across computing platforms and work with both Microsoft Word (because of its user base) and OpenOffice.org (because of its free availability). Further the application needs to be acceptable to and usable by users, so the initial implementation covers only small number of features, which will only be extended after user-testing. Within these constraints the system provides a mechanism for encoding not only simple metadata, but for inferring hierarchical relationships between metadata elements from a ‘flat’ word processing file.The paper includes links to open source code implementing the techniques as part of a broader suite of tools for academic writing. This addresses tools and software, semantic web and data curation, integrating curation into research workflows and will provide a platform for integrating work on ontologies, vocabularies and folksonomies into word processing tools.",
        "article_title": "Embedding Metadata and Other Semantics in Word Processing Documents",
        "authors": [
            {
                "given": "Peter",
                "family": "Sefton",
                "affiliation": [
                    "Australian Digital Futures Institute, University of Southern Queensland"
                ]
            },
            {
                "given": "Ian",
                "family": "Barnes",
                "affiliation": [
                    "The Australian National University"
                ]
            },
            {
                "given": "Ron",
                "family": "Ward",
                "affiliation": [
                    "Australian Digital Futures Institute, University of Southern Queensland"
                ]
            },
            {
                "given": "Jim",
                "family": "Downing",
                "affiliation": [
                    "The Unilever Centre for Molecular Science Informatics, University of Cambridge"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-10-15",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i2.95",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i2.95",
            "id_scheme": "DOI"
        },
        "abstract": "The Landesarchiv (State Archive) of Baden-Württemberg has designed and implemented a metadata concept for digital content covering a heterogenous range of digital-born and digitised material. Special attention was given to matters of authenticity and to economic ingest and dissemination methods under the requirements of a public archive. This paper describes the outcome of metadata discussions during the implementation period of the DIMAG repository. It treats integration of the repository’s architecture with the archival classification concept, measures for long-term accessibility, the creation of adapted metadata placement, and provisions for exchange with other applications for ingest and use. The deliberately short list of metadata elements is included in this paper. Some existing standards have been evaluated under a real use environment; this paper also introduces modifications applied to them in the project context.",
        "article_title": "One for Many: A Metadata Concept for Mixed Digital  Content at a State Archive",
        "authors": [
            {
                "given": "Kai",
                "family": "Naumann",
                "affiliation": [
                    "Landesarchiv Baden-Württemberg, Ludwigsburg, Germany"
                ]
            },
            {
                "given": "Christian",
                "family": "Keitel",
                "affiliation": [
                    "Landesarchiv Baden-Württemberg, Ludwigsburg, Germany"
                ]
            },
            {
                "given": "Rolf",
                "family": "Lang",
                "affiliation": [
                    "Landesarchiv Baden-Württemberg, Ludwigsburg, Germany"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-10-15",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i2.94",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i2.94",
            "id_scheme": "DOI"
        },
        "abstract": "Climate and Weather are of increasing interest to the scientific community and the general public.  Data curation and stewardship are essential building blocks in the science community’s quest to better understand how natural climate and weather systems behave and how activities of  human civilization are altering the natural system. Rudimentary observations of the atmosphere and ocean have been collected for over one hundred years and proxity measurements of the climate can trace our planet’s climatic history for  millions of years. These observations coupled with the rapid advances in technology, such as powerful computers, rapid access to massive amounts of data, and satellite observations, have allowed innovative techniques to be used to understand and predict the planet’s climate and weather.",
        "article_title": "Data Curation in Climate and Weather:  Transforming Our Ability to Improve Predictions through Global Knowledge Sharing",
        "authors": [
            {
                "given": "Clifford A.",
                "family": "Jacobs",
                "affiliation": [
                    "National Science Foundation, USA"
                ]
            },
            {
                "given": "Steven J.",
                "family": "Worley",
                "affiliation": [
                    "National Center for Atmospheric Research, USA"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-10-15",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i2.93",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i2.93",
            "id_scheme": "DOI"
        },
        "abstract": "   DCC DIFFUSE Standards Frameworks aims to offer domain specific advice on standards relevant to digital preservation and curation, to help curators identify which standards they should be using and where they can be appropriately implemented, to ensure authoritative digital material. The Project uses the DCC Curation Lifecycle Model and Web 2.0 technology, to visually present standards frameworks for a number of disciplines. The Digital Curation Centre (DCC) is actively working with a different relevant organisations to present searchable frameworks of standards, for a number of domains. These include digital repositories, records management, the geo-information sector, archives and the museum sector. Other domains, such as e-science, will shortly be investigated.",
        "article_title": "DCC DIFFUSE Standards Frameworks: A Standards Path through the Curation Lifecycle",
        "authors": [
            {
                "given": "Sarah",
                "family": "Higgins",
                "affiliation": [
                    "Digital Curation Centre"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-10-15",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i2.92",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i2.92",
            "id_scheme": "DOI"
        },
        "abstract": "This paper discusses the importance of a particular approach to building and sustaining digital content preservation infrastructures for cultural memory organizations (CMOs), namely distributed approaches that are cooperatively maintained by CMOs (rather than centralized approaches managed by agencies external to CMOs), and why this approach may fill a gap in capabilities for those CMOs actively digitizing historical and cultural content (rather than scientific data). Initial findings are presented from an early organizational effort (the MetaArchive Cooperative) that seeks to fill this gap for CMOs.  The paper situates these claims in the larger context of selected exemplars of DP efforts in both the United States and the United Kingdom that are seeking to develop effective DP models in an attempt to recognize those organizational aspects (such as the governmental frameworks, cultural backgrounds, and other differences in emphasis) that are UK and US-specific.",
        "article_title": "Comparison of Strategies and Policies for Building Distributed Digital Preservation Infrastructure: Initial Findings from the MetaArchive Cooperative",
        "authors": [
            {
                "given": "Martin",
                "family": "Halbert",
                "affiliation": [
                    "Emory University,Georgia, USA"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-10-15",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i2.91",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i2.91",
            "id_scheme": "DOI"
        },
        "abstract": "This paper presents LORE (Literature Object Re-use and Exchange), a light-weight tool which is designed to allow literature scholars and teachers to author, edit and publish compound information objects encapsulating related digital resources and bibliographic records. LORE enables users to easily create OAI-ORE-compliant compound objects, which build on the IFLA FRBR model, and also enables them to describe and publish them to an RDF repository as Named Graphs. Using the tool, literary scholars can create typed relationships between individual atomic objects using terms from a bibliographic ontology and can attach metadata to the compound object. This paper describes the implementation and user interface of the LORE tool, as developed within the context of an ongoing case study being conducted in collaboration with AustLit: The Australian Literature Resource, which focuses on compound objects for teaching and research within the Australian literature studies community.",
        "article_title": "A Compound Object Authoring and Publishing Tool  for Literary Scholars based on the IFLA-FRBR",
        "authors": [
            {
                "given": "Anna",
                "family": "Gerber",
                "affiliation": [
                    "University of Queensland,St Lucia, Queensland, Australia"
                ]
            },
            {
                "given": "Jane",
                "family": "Hunter",
                "affiliation": [
                    "University of Queensland,St Lucia, Queensland, Australia"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-10-15",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i2.90",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i2.90",
            "id_scheme": "DOI"
        },
        "abstract": "Scientific researchers today frequently package measurements and associated metadata as digital datasets in anticipation of storage in data repositories. Through the lens of environmental data stewardship, we consider the data repository as an organizational element central to data curation. One aspect of non-commercial repositories, their distance-from-origin of the data, is explored in terms of near and remote categories. Three idealized repository types are distinguished – local, center, and archive - paralleling research, resource, and reference collection categories respectively. Repository type characteristics such as scope, structure, and goals are discussed. Repository similarities in terms of roles, activities and responsibilities are also examined.  Data stewardship is related to care of research data and responsible scientific communication supported by an infrastructure that coordinates curation activities; data curation is defined as a set of repeated and repeatable activities focusing on tending data and creating data products within a particular arena. The concept of “sphere-of-context” is introduced as an aid to distinguishing repository types. Conceptualizing a “web-of-repositories” accommodates a variety of repository types and represents an ecologically inclusive approach to data curation.",
        "article_title": "Data Stewardship: Environmental Data Curation  and a Web-of-Repositories",
        "authors": [
            {
                "given": "Karen S.",
                "family": "Baker",
                "affiliation": [
                    "University of California,San Diego, USA"
                ]
            },
            {
                "given": "Lynn",
                "family": "Yarmey",
                "affiliation": [
                    "University of California,San Diego, USA"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-10-15",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i3.125",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i3.125",
            "id_scheme": "DOI"
        },
        "abstract": "   As storage costs drop, storage is becoming the lowest cost in a digital repository – and the biggest risk. We examine current modelling of costs and risks in digital preservation, concentrating on the Total Cost of Risk when using digital storage systems for preserving audiovisual material. We review the vital role of storage and show how planning for long-term preservation of data should consider the risks involved in using digital storage technology. Gaps in information necessary for accurate modelling – and planning – are presented. We call for new functionality to support recovery of files with errors, to eliminate the all-or-nothing approach of current IT systems, which in turn reduces the impact of failures of digital storage technology and mitigates against loss of digital data.",
        "article_title": "The Significance of Storage in the “Cost of Risk” of Digital Preservation",
        "authors": [
            {
                "given": "Richard",
                "family": "Wright",
                "affiliation": [
                    "BBC Research and Development, London"
                ]
            },
            {
                "given": "Ant",
                "family": "Miller",
                "affiliation": [
                    "BBC Research and Development, London"
                ]
            },
            {
                "given": "Matthew",
                "family": "Addis",
                "affiliation": [
                    "IT Innovation Centre, University of Southampton"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-12-07",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "3",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i3.117",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i3.117",
            "id_scheme": "DOI"
        },
        "abstract": "This paper presents a brief literature review and then introduces the methods, design, and construction of the Data Curation Profile, an instrument that can be used to provide detailed information on particular data forms that might be curated by an academic library. These data forms are presented in the context of the related sub-disciplinary research area, and they provide the flow of the research process from which these data are generated. The profiles also represent the needs for data curation from the perspective of the data producers, using their own language. As such, they support the exploration of data curation across different research domains in real and practical terms. With the sponsorship of the Institute of Museum and Library Services, investigators from Purdue University and the University of Illinois interviewed 19 faculty subjects to identify needs for discovery, access, preservation, and reuse of their research data. For each subject, a profile was constructed that includes information about his or her general research, data forms and stages, value of data, data ingest, intellectual property, organization and description of data, tools, interoperability, impact and prestige, data management, and preservation. Each profile also presents a specific dataset supplied by the subject to serve as a concrete example. The Data Curation Profiles are being published to a public wiki for questions and discussion, and a blank template will be disseminated with guidelines for others to create and share their own profiles. This study was conducted primarily from the viewpoint of librarians interacting with faculty researchers; however, it is expected that these findings will complement a wide variety of data curation research and practice outside of librarianship and the university environment.",
        "article_title": "Constructing Data Curation Profiles",
        "authors": [
            {
                "given": "Michael",
                "family": "Witt",
                "affiliation": [
                    "Distributed Data Curation Center, Purdue University"
                ]
            },
            {
                "given": "Jacob",
                "family": "Carlson",
                "affiliation": [
                    "Distributed Data Curation Center, Purdue University"
                ]
            },
            {
                "given": "D. Scott",
                "family": "Brandt",
                "affiliation": [
                    "Distributed Data Curation Center, Purdue University"
                ]
            },
            {
                "given": "Melissa H.",
                "family": "Cragin",
                "affiliation": [
                    "University of Illinois at Urbana-Champaign"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-12-07",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "3",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i3.116",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i3.116",
            "id_scheme": "DOI"
        },
        "abstract": "The curation of scientific research data at U.S. universities is a story of enterprising individuals and of incremental progress. A small number of libraries and data centers who see the possibilities of becoming “digital information management centers” are taking entrepreneurial steps to extend beyond their traditional information assets and include managing scientific and scholarly research data. The Georgia Institute of Technology (GT) has had a similar development path toward a data curation program based in its library. This paper will articulate GT’s program development, which the author offers as an experience common in U.S. universities. The main characteristic is a program devoid of top-level mandates and incentives, but rich with independent, “bottom-up” action. The paper will address program antecedents and context, inter-institutional partnerships that advance the library’s curation program, library organizational developments, partnerships with campus research communities, and a proposed model for curation program development. It concludes that despite the clear need for data curation put forth by researchers such as the groups of neuroscientists and bioscientists referenced in this paper, the university experience examined suggests that gathering resources for developing data curation programs at the institutional level is proving to be a quite onerous. However, and in spite of the challenges, some U.S. research universities are beginning to establish perceptible data curation programs.",
        "article_title": "Data Curation Program Development in U.S. Universities: The Georgia Institute of Technology Example",
        "authors": [
            {
                "given": "Tyler O.",
                "family": "Walters",
                "affiliation": [
                    "Library and Information Center, Georgia Institute of Technology"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-12-07",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "3",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i3.115",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i3.115",
            "id_scheme": "DOI"
        },
        "abstract": "Drawing on the final report on a recent series of case studies in the life sciences at the University of Edinburgh, this paper explores the attitudes and perceptions of researchers towards data sharing and contrasts these with the policies of the major research funders. Notwithstanding economic, technical and cultural inhibitors, the general ethos in the Life Sciences is one of support to the principle of data sharing. However, this position is subject to a complex range of qualifications, not least the crucial need for sharing through collaboration. The kind of generic vision for data sharing that is currently promoted by national agencies is judged to be neither productive nor effective.  Only close engagement with research practitioners in the identification of bottom-up strategies that preserve the exercise of informed choice - a fundamental and persistent element of scientific research - will produce change on a national scale.",
        "article_title": "Multi-scale Data Sharing in the Life Sciences: Some Lessons for Policy Makers",
        "authors": [
            {
                "given": "Graham",
                "family": "Pryor",
                "affiliation": [
                    "University of Edinburgh"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-12-07",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "3",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i3.120",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i3.120",
            "id_scheme": "DOI"
        },
        "abstract": " Developmental Gene Expression Map (DGEMap) is an EU-funded Design Study, which will accelerate an integrated European approach to gene expression in early human development. As part of this design study, we have had to address the challenges and issues raised by the long-term curation of such a resource. As this project is primarily one of data creators, learning about curation, we have been looking at some of the models and tools that are already available in the digital curation field in order to inform our thinking on how we should proceed with curating DGEMap. This has led us to uncover a wide range of resources for data creators and curators alike. Here we will discuss the future curation of DGEMap as a case study. We believe our experience could be instructive to other projects looking to improve the curation and management of their data.",
        "article_title": "Using the DCC Lifecycle Model to Curate a Gene Expression Database: A Case Study",
        "authors": [
            {
                "given": "Jean",
                "family": "O’Donoghue",
                "affiliation": [
                    "National e-Science Centre, School of Informatics, University of Edinburgh"
                ]
            },
            {
                "given": "Jano I.",
                "family": "Van Hemert",
                "affiliation": [
                    "National e-Science Centre, School of Informatics, University of Edinburgh"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-12-07",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "3",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i3.124",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i3.124",
            "id_scheme": "DOI"
        },
        "abstract": "   This paper describes how the Australian National Data Services (ANDS) is designing systems to support data sharing and Re-use. The paper commences with an overview of the setting for ANDS, before introducing ANDS itself. The paper then structures its discussion of ANDS services for Re-use in terms of the ANDS Data Sharing Verbs: Create, Store, Describe, Identify, Register, Discover, Access and Exploit. For each of the data verbs, a rationale for its importance is provided together with a description of how it is being implemented by ANDS. The paper concludes by arguing for the data verbs approach as a useful way to design and structure flexible services in a heterogenous environment.",
        "article_title": "Designing for Discovery and Re-Use: the ‘ANDS Data Sharing Verbs’ Approach to Service Decomposition",
        "authors": [
            {
                "given": "Adrian",
                "family": "Burton",
                "affiliation": [
                    "Australian National Data Service"
                ]
            },
            {
                "given": "Andrew",
                "family": "Treloar",
                "affiliation": [
                    "Australian National Data Service"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-12-07",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "3",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i3.126",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i3.126",
            "id_scheme": "DOI"
        },
        "abstract": "The CIA World Factbook is a prime example of a curated database – a database that is constructed and maintained with a great deal of human effort in collecting, verifying, and annotating data. Preservation of old versions of the Factbook is important for verification of citations; it is also essential for anyone interested in the history of the data such as demographic change. Although the Factbook has been published, both physically and electronically, only for the past 30 years, we appear in danger of losing this history. This paper investigates the issues involved in capturing the history of an evolving database and its application to the CIA World Factbook. In particular it shows that there is substantial added value to be gained by preserving databases in such a way that questions about the change in data, (longitudinal queries) can be readily answered. Within this paper, we describe techniques for recording change in a curated database and we describe novel techniques for querying the change. Using the example of this archived curated database, we discuss the extent to which the accepted practices and terminology of archiving, curation and digital preservation apply to this important class of digital artefacts.",
        "article_title": "Curating the CIA World Factbook",
        "authors": [
            {
                "given": "Peter",
                "family": "Buneman",
                "affiliation": [
                    "School of Informatics, University of Edinburgh"
                ]
            },
            {
                "given": "Heiko",
                "family": "Müller",
                "affiliation": [
                    "School of Informatics, University of Edinburgh"
                ]
            },
            {
                "given": "Chris",
                "family": "Rusbridge",
                "affiliation": [
                    "Digital Curation Centre, University of Edinburgh"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-12-07",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "3",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i3.114",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i3.114",
            "id_scheme": "DOI"
        },
        "abstract": "In the highly competitive engineering industry, product innovations are created with the help of a product lifecycle management (PLM) tool chain. In order to support fast-paced product development, a major company goal is the reuse of product designs and product descriptions. Due to the product’s complexity, the design of a product not only consists of geometry data but also of valuable engineering knowledge that is created during the various PLM phases. The need to preserve such intellectual capital leads engineering companies to introduce knowledge management and archiving their machine-readable formal representation. However, archived knowledge is in danger of becoming unusable since it is very likely that knowledge semantics and knowledge representation will evolve over long time periods, for example during the 50 operational years of some products. Knowledge evolution and knowledge representation technology changes are crucial issues since a reuse of the archived product information can only be ensured if its rationale and additional knowledge are interpretable with future software and technologies. Therefore, in order to reuse design data fully, knowledge about the design must also be migrated to be interoperable with future design systems and knowledge representation methods. This paper identifies problems, issues, requirements, challenges and solutions that arise while tackling the long-term preservation of engineering knowledge.",
        "article_title": "Enabling Product Design Reuse by Long-term Preservation of Engineering Knowledge",
        "authors": [
            {
                "given": "Jörg",
                "family": "Brunsmann",
                "affiliation": [
                    "Fernuniversität Hagen, Germany"
                ]
            },
            {
                "given": "Wolfgang",
                "family": "Wilkes",
                "affiliation": [
                    "Fernuniversität Hagen, Germany"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-12-07",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "3",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v4i3.127",
        "identifier": {
            "string_id": "10.2218/ijdc.v4i3.127",
            "id_scheme": "DOI"
        },
        "abstract": "ESA-ESRIN, the European Space Agency Centre for Earth Observation (EO), is the largest European EO data provider and operates as the reference European centre for EO payload data exploitation. EO Space Missions provide global coverage of the Earth across both space and time generating on a routine continuous basis huge amounts of data (from a variety of sensors) that need to be acquired, processed, elaborated, appraised and archived by dedicated systems. Long-term Preservation of these data and of the ability to discover, access and process them is a fundamental issue and a major challenge at programmatic, technological and operational levels.Moreover these data are essential for scientists needing broad series of data covering long time periods and from many sources. They are used for many types of investigations including ones of international importance such as the study of the Global Change and the Global Monitoring for Environment and Security (GMES) Program. Therefore it is of primary importance not only to guarantee easy accessibility of historical data but also to ensure users are able to understand and use them; in fact data interpretation can be even more complicated given the fact that scientists may not have (or may not have access to) the right knowledge to interpret these data correctly.To satisfy these requirements, the European Space Agency (ESA), in addition to other internal initiatives, is participating in several EU-funded projects such as CASPAR (Cultural, Artistic, and Scientific knowledge for Preservation, Access and Retrieval), which is building a framework to support the end-to-end preservation lifecycle for digital information, based on the OAIS reference model, with a strong focus on the preservation of the knowledge associated with data.In the CASPAR Project ESA plays the role of both user and infrastructure provider for one of the scientific testbeds, putting into effect dedicated scenarios with the aim of validating the CASPAR solutions in the Earth Science domain. The other testbeds are in the domains of Cultural Heritage and of Contemporary Performing Arts; together they provide a severe test of preservation tools and techniques.In the context of the current ESA overall strategies carried out in collaboration with European EO data owners/providers, entities and institutions which have the objective of guaranteeing long-term preservation of EO data and knowledge, this paper will focus on the ESA participation and contribution to the CASPAR Project, describing in detail the implementation of the ESA scientific testbed.",
        "article_title": "Long-term Preservation of Earth Observation Data and Knowledge in ESA through CASPAR",
        "authors": [
            {
                "given": "Sergio",
                "family": "Albani",
                "affiliation": [
                    "ACS c/o ESA-ESRIN, Italy"
                ]
            },
            {
                "given": "David",
                "family": "Giaretta",
                "affiliation": [
                    "STFC Rutherford Appleton Lab, UK"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2009-12-07",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "4",
        "issue": "3",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v5i1.150",
        "identifier": {
            "string_id": "10.2218/ijdc.v5i1.150",
            "id_scheme": "DOI"
        },
        "abstract": "Emulation is frequently discussed as a failsafe preservation strategy for born-digital documents that depend on contemporaneous software for access (Rothenberg, 2000). Yet little has been written about the contextual knowledge required to successfully use such software. The approach we advocate is to preserve necessary contextual information through scripts designed to control the legacy environment, and created during the preservation workflow. We describe software designed to minimize dependence on this knowledge by offering automated configuration and execution of emulated environments. We demonstrate that even simple scripts can reduce impediments to casual use of the digital objects being preserved. We describe tools to automate the remote use of preserved objects on local emulation environments.  This can help eliminate both a dependence on physical reference workstations at preservation institutions, and provide users accessing materials over the web with simplified, easy-to-use environments. Our implementation is applied to examples from an existing collection of over 4,000 virtual CD-ROM images containing thousands of custom binary executables.",
        "article_title": "Assisted Emulation for Legacy Executables",
        "authors": [
            {
                "given": "Kam",
                "family": "Woods",
                "affiliation": [
                    "School of Informatics and Computing,Indiana University"
                ]
            },
            {
                "given": "Geoffrey",
                "family": "Brown",
                "affiliation": [
                    "School of Informatics and Computing,Indiana University"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2010-06-22",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "5",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v5i1.149",
        "identifier": {
            "string_id": "10.2218/ijdc.v5i1.149",
            "id_scheme": "DOI"
        },
        "abstract": "Metadata extraction is a critical aspect of ingestion of collections into digital archives and libraries. A method for automatically recognizing document types and extracting metadata from digital records has been developed. The method is based on a method for automatically annotating semantic categories such as person’s names, job titles, dates, and postal addresses that may occur in a record. It extends this method by using the semantic annotations to identify the intellectual elements of a document’s form, parsing these elements using context-free grammars that define documentary forms, and interpreting the elements of the form of the document to identify metadata such as the chronological date, author(s), addressee(s), and topic. Context-free grammars were developed for fourteen of the documentary forms occurring in Presidential records. In an experiment, the document type recognizer successfully recognized the documentary form and extracted the metadata of two-thirds of the records in a series of Presidential e-records containing twenty-one document types.",
        "article_title": "Grammar-Based Recognition of Documentary Forms and Extraction of Metadata",
        "authors": [
            {
                "given": "William",
                "family": "Underwood",
                "affiliation": [
                    "Georgia Tech Research Institute"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2010-06-22",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "5",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v5i1.148",
        "identifier": {
            "string_id": "10.2218/ijdc.v5i1.148",
            "id_scheme": "DOI"
        },
        "abstract": "For years, discussions of digital preservation have routinely featured comments such as “bit preservation is a solved problem; the real issues are ...”. Indeed, current digital storage technologies are not just astoundingly cheap and capacious, they are astonishingly reliable. Unfortunately, these attributes drive a kind of “Parkinson’s Law” of storage, in which demands continually push beyond the capabilities of systems implementable at an affordable price. This paper is in four parts:Claims, reviewing a typical claim of storage system reliability, showing that it provides no useful information for bit preservation purposes.Theory, proposing “bit half-life” as an initial, if inadequate, measure of bit preservation performance, expressing bit preservation requirements in terms of it, and showing that the requirements being placed on bit preservation systems are so onerous that the experiments required to prove that a solution exists are not feasible.Practice, reviewing recent research into how well actual storage systems preserve bits, showing that they fail to meet the requirements by many orders of magnitude.Policy, suggesting ways of dealing with this unfortunate situation. ",
        "article_title": "Bit Preservation: A Solved Problem?",
        "authors": [
            {
                "given": "David S. H.",
                "family": "Rosenthal",
                "affiliation": [
                    "Stanford University Libraries, CA"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2010-06-22",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "5",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v5i1.147",
        "identifier": {
            "string_id": "10.2218/ijdc.v5i1.147",
            "id_scheme": "DOI"
        },
        "abstract": "The Chronopolis Digital Preservation Initiative, one of the Library of Congress’ latest efforts to collect and preserve at-risk digital information, has completed its first year of service as a multi-member partnership to meet the archival needs of a wide range of domains.Chronopolis is a digital preservation data grid framework developed by the San Diego Supercomputer Center (SDSC) at UC San Diego, the UC San Diego Libraries (UCSDL), and their partners at the National Center for Atmospheric Research (NCAR) in Colorado and the University of Maryland's Institute for Advanced Computer Studies (UMIACS).Chronopolis addresses a critical problem by providing a comprehensive model for the cyberinfrastructure of collection management, in which preserved intellectual capital is easily accessible, and research results, education material, and new knowledge can be incorporated smoothly over the long term. Integrating digital library, data grid, and persistent archive technologies, Chronopolis has created trusted environments that span academic institutions and research projects, with the goal of long-term digital preservation.A key goal of the Chronopolis project is to provide cross-domain collection sharing for long-term preservation. Using existing high-speed educational and research networks and mass-scale storage infrastructure investments, the partnership is leveraging the data storage capabilities at SDSC, NCAR, and UMIACS to provide a preservation data grid that emphasizes heterogeneous and highly redundant data storage systems.In this paper we will explore the major themes within Chronopolis, including:a) The philosophy and theory behind a nationally federated data grid for preservation. b) The core tools and technologies used in Chronopolis. c) The metadata schema that is being developed within Chronopolis for all of the data elements. d) Lessons learned from the first year of the project.e) Next steps in digital preservation using Chronopolis: how we plan to strengthen and broaden our network with enhanced services and new customers.",
        "article_title": "Chronopolis Digital Preservation Network",
        "authors": [
            {
                "given": "David",
                "family": "Minor",
                "affiliation": [
                    "UC San Diego, San Diego Supercomputer Center"
                ]
            },
            {
                "given": "Don",
                "family": "Sutton",
                "affiliation": [
                    "UC San Diego, San Diego Supercomputer Center"
                ]
            },
            {
                "given": "Ardys",
                "family": "Kozbial",
                "affiliation": [
                    "UC San Diego Libraries"
                ]
            },
            {
                "given": "Brad",
                "family": "Westbrook",
                "affiliation": [
                    "UC San Diego Libraries"
                ]
            },
            {
                "given": "Michael",
                "family": "Burek",
                "affiliation": [
                    "National Center for Atmospheric Research"
                ]
            },
            {
                "given": "Michael",
                "family": "Smorul",
                "affiliation": [
                    "University of Maryland Institute for Advanced Computer Studies"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2010-06-22",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "5",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v5i1.146",
        "identifier": {
            "string_id": "10.2218/ijdc.v5i1.146",
            "id_scheme": "DOI"
        },
        "abstract": "In this paper, we present the Core Scientific Metadata Model (CSMD), a model for the representation of scientific study metadata developed within the Science &amp; Technology Facilities Council (STFC) to represent the data generated from scientific facilities. The model has been developed to allow management of and access to the data resources of the facilities in a uniform way, although we believe that the model has wider application, especially in areas of “structural science” such as chemistry, materials science and earth sciences. We give some motivations behind the development of the model, and an overview of its major structural elements, centred on the notion of a scientific study formed by a collection of specific investigations. We give some details of the model, with the description of each investigation associated with a particular experiment on a sample generating data, and the associated data holdings are then mapped to the investigation with the appropriate parameters. We then go on to discuss the instantiation of the metadata model within a production quality data management infrastructure, the Information CATalogue (ICAT), which has been developed within STFC for use in large-scale photon and neutron sources. Finally, we give an overview of the relationship between CSMD, and other initiatives, and give some directions for future developments.     ",
        "article_title": "Using a Core Scientific Metadata Model in Large-Scale Facilities",
        "authors": [
            {
                "given": "Brian",
                "family": "Matthews",
                "affiliation": [
                    "STFC, e-Science Centre and ISIS Facility"
                ]
            },
            {
                "given": "Shoaib",
                "family": "Sufi",
                "affiliation": [
                    "STFC, e-Science Centre and ISIS Facility"
                ]
            },
            {
                "given": "Damian",
                "family": "Flannery",
                "affiliation": [
                    "STFC, e-Science Centre and ISIS Facility"
                ]
            },
            {
                "given": "Laurent",
                "family": "Lerusse",
                "affiliation": [
                    "STFC, e-Science Centre and ISIS Facility"
                ]
            },
            {
                "given": "Tom",
                "family": "Griffin",
                "affiliation": [
                    "STFC, e-Science Centre and ISIS Facility"
                ]
            },
            {
                "given": "Michael",
                "family": "Gleaves",
                "affiliation": [
                    "STFC, e-Science Centre and ISIS Facility"
                ]
            },
            {
                "given": "Kerstin",
                "family": "Kleese",
                "affiliation": [
                    "STFC, e-Science Centre and ISIS Facility"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2010-06-22",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "5",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v5i1.145",
        "identifier": {
            "string_id": "10.2218/ijdc.v5i1.145",
            "id_scheme": "DOI"
        },
        "abstract": "Software preservation has not had detailed consideration as a research topic or in practical application. In this paper, we present a conceptual framework to capture and organise the main notions of software preservation, which are required for a coherent and comprehensive approach.  This framework has three main aspects. Firstly a discussion of what it means to preserve software via a performance model which considers how a software artefact can be rebuilt from preserved components and can then be seen to be representative of the original software product. Secondly the development of a model of software artefacts, describing the basic components of all software, loosely based on the FRBR model for representing digital artefacts and their history within a library context. Finally, the definition and categorisation of the properties of software artefacts which are required to ensure that the software product has been adequately preserved. These are broken down into a number of categories and related to the concepts defined in the OAIS standard. We also discuss our experience of recording these preservation properties for a number of BADC software products, which arose from a series of case studies conducted to evaluate the software preservation framework, and also briefly describe the SPEQS toolkit, a tool to capture software preservation properties within a software development.",
        "article_title": "A Framework for Software Preservation",
        "authors": [
            {
                "given": "Brian",
                "family": "Matthews",
                "affiliation": [
                    "e-Science Centre, Science and Technology Facilities Council,Rutherford Appleton Laboratory, Oxon, UK"
                ]
            },
            {
                "given": "Arif",
                "family": "Shaon",
                "affiliation": [
                    "e-Science Centre, Science and Technology Facilities Council,Rutherford Appleton Laboratory, Oxon, UK"
                ]
            },
            {
                "given": "Juan",
                "family": "Bicarregui",
                "affiliation": [
                    "e-Science Centre, Science and Technology Facilities Council,Rutherford Appleton Laboratory, Oxon, UK"
                ]
            },
            {
                "given": "Catherine",
                "family": "Jones",
                "affiliation": [
                    "e-Science Centre, Science and Technology Facilities Council,Rutherford Appleton Laboratory, Oxon, UK"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2010-06-22",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "5",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v5i1.144",
        "identifier": {
            "string_id": "10.2218/ijdc.v5i1.144",
            "id_scheme": "DOI"
        },
        "abstract": "Interactive fiction and video games are part of our cultural heritage. As original systems cease to work because of hardware and media failures, methods to preserve obsolete video games for future generations have to be developed. The public interest in early video games is high, as exhibitions, regular magazines on the topic and newspaper articles demonstrate. Moreover, games considered to be classic are rereleased for new generations of gaming hardware. However, with the rapid development of new computer systems, the way games look and are played changes constantly. When trying to preserve console video games one faces problems of classified development documentation, legal aspects and extracting the contents from original media like cartridges with special hardware. Furthermore, special controllers and non-digital items are used to extend the gaming experience making it difficult to preserve the look and feel of console video games.This paper discusses strategies for the digital preservation of console video games. After a short overview of console video game systems, there follows an introduction to digital preservation and related work in common strategies for digital preservation and preserving interactive art. Then different preservation strategies are described with a specific focus on emulation. Finally a case study on console video game preservation is shown which uses the Planets preservation planning approach for evaluating preservation strategies in a documented decision-making process. Experiments are carried out to compare different emulators as well as other approaches, first for a single console video game system, then for different console systems of the same era and finally for systems of all eras. Comparison and discussion of results show that, while emulation works very well in principle for early console video games, various problems exist for the general use as a digital preservation alternative. We show what future work has to be done to tackle these problems.",
        "article_title": "Keeping the Game Alive: Evaluating Strategies for the Preservation of Console Video Games",
        "authors": [
            {
                "given": "Mark",
                "family": "Guttenbrunner",
                "affiliation": [
                    "Vienna University of Technology"
                ]
            },
            {
                "given": "Christoph",
                "family": "Becker",
                "affiliation": [
                    "Vienna University of Technology"
                ]
            },
            {
                "given": "Andreas",
                "family": "Rauber",
                "affiliation": [
                    "Vienna University of Technology"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2010-06-22",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "5",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v5i1.143",
        "identifier": {
            "string_id": "10.2218/ijdc.v5i1.143",
            "id_scheme": "DOI"
        },
        "abstract": "Quality management is an essential part in creating a trustworthy digital archive. The German network of expertise in Digital long-term preservation (nestor), in cooperation with the German Institute for Standards (DIN), has undertaken a small study to analyse systematically the relevance and usage of quality management standards for long-term preservation and to filter out the specific standardisation need for digital archives. This paper summarises the results of the study. It gives an overview on the differences in understanding the task “quality management” within different organisations and how they carry out appropriate measures, such as documentation, transparency, adequacy, and measureability in order to demonstrate the trustworthiness of their digital archive.",
        "article_title": "The Use of Quality Management Standards in Trustworthy Digital Archives",
        "authors": [
            {
                "given": "Susanne",
                "family": "Dobratz",
                "affiliation": [
                    "Humboldt-Universität zu Berlin"
                ]
            },
            {
                "given": "Peter",
                "family": "Rödig",
                "affiliation": [
                    "Universität der Bundeswehr München",
                    "University of the Federal Armed Forces Munich"
                ]
            },
            {
                "given": "Uwe M.",
                "family": "Borghoff",
                "affiliation": [
                    "University of the Federal Armed Forces Munich"
                ]
            },
            {
                "given": "Björn",
                "family": "Rätzke",
                "affiliation": [
                    "Rätzke IT-Service"
                ]
            },
            {
                "given": "Astrid",
                "family": "Schoger",
                "affiliation": [
                    "Bavarian State Library"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2010-06-22",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "5",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v5i1.142",
        "identifier": {
            "string_id": "10.2218/ijdc.v5i1.142",
            "id_scheme": "DOI"
        },
        "abstract": "Towards Interoperable Preservation Repositories (TIPR) is a project funded by the Institute of Museum and Library Services to create and test a Repository eXchange Package (RXP). The package will make it possible to transfer complex digital objects between dissimilar preservation repositories.  For reasons of redundancy, succession planning and software migration, repositories must be able to exchange copies of archival information packages with each other. Every different repository application, however, describes and structures its archival packages differently. Therefore each system produces dissemination packages that are rarely understandable or usable as submission packages by other repositories. The RXP is an answer to that mismatch. Other solutions for transferring packages between repositories focus either on transfers between repositories of the same type, such as DSpace-to-DSpace transfers, or on processes that rely on central translation services.  Rather than build translators between many dissimilar repository types, the TIPR project has defined a standards-based package of metadata files that can act as an intermediary information package, the RXP, a lingua franca all repositories can read and write.",
        "article_title": "Towards Interoperable Preservation Repositories: TIPR",
        "authors": [
            {
                "given": "Priscilla",
                "family": "Caplan",
                "affiliation": [
                    "Florida Center for Library Automation"
                ]
            },
            {
                "given": "William R.",
                "family": "Kehoe",
                "affiliation": [
                    "Cornell University Library"
                ]
            },
            {
                "given": "Joseph",
                "family": "Pawletko",
                "affiliation": [
                    "Bobst Library, New York University"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2010-06-22",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "5",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v5i1.141",
        "identifier": {
            "string_id": "10.2218/ijdc.v5i1.141",
            "id_scheme": "DOI"
        },
        "abstract": "This paper reports on research of scholarly research practices and requirements conducted in the context of the Preparing DARIAH European e-Infrastructures project, with a view to ensuring current and future fitness for purpose of the planned digital infrastructure, services and tools. It summarises the findings of earlier research, primarily from the field of human information behaviour as applied in scholarly work, it presents a conceptual perspective informed by cultural-historical activity theory, it introduces briefly a formal conceptual model for scholarly research activity compliant with CIDOC CRM, it describes the plan of work and methodology of an empirical research project based on open-questionnaire interviews with arts and humanities researchers, and presents illustrative examples of segmentation, tagging and initial conceptual analysis of the empirical evidence. Finally, it presents plans for future work, consisting, firstly, of a comprehensive re-analysis of interview segments within the framework of the scholarly research activity model, and, secondly, of the integration of this analysis with the extended digital curation process model we presented in earlier work.",
        "article_title": "Understanding the Information Requirements of Arts and Humanities Scholarship",
        "authors": [
            {
                "given": "Agiatis",
                "family": "Benardou",
                "affiliation": [
                    "Athena Research Centre"
                ]
            },
            {
                "given": "Panos",
                "family": "Constantopoulos",
                "affiliation": [
                    "Athena Research Centre",
                    "Athens University of Economics and Business"
                ]
            },
            {
                "given": "Costis",
                "family": "Dallas",
                "affiliation": [
                    "Athena Research Centre",
                    "Panteion University",
                    "University of Toronto"
                ]
            },
            {
                "given": "Dimitris",
                "family": "Gavrilis",
                "affiliation": [
                    "Athena Research Centre"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2010-06-22",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "5",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v5i1.140",
        "identifier": {
            "string_id": "10.2218/ijdc.v5i1.140",
            "id_scheme": "DOI"
        },
        "abstract": "Digital preservation aims to keep digital objects accessible over long periods of time, ensuring the authenticity and integrity of these digital objects. In such complex environments, Risk Management is a key factor in assuring the normal behaviour of systems over time. Currently, the digital preservation arena commonly uses Risk Management concepts to assess repositories. In this paper, we intend to go further and propose a perspective where Risk Management can be used not only to assess existing solutions, but also to conceive digital preservation environments. Thus, we propose a Risk Management-based approach to design and assess digital preservation environments, including:• the definition of context and identification of strategic objectives to determine specific requirements and characterize which consequences are acceptable within the identified context;• the identification, analysis and evaluation of threats and vulnerabilities that may affect the normal behaviour of a specific business or the achievement of the goals and conformance to the requirements identified in the context characterization; and, • definition of actions to deal with the risks associated with the identified threats and vulnerabilities.We generalize and survey the main requirements, threats, vulnerabilities and techniques that can be applied in the scope of digital preservation. ",
        "article_title": "Designing Digital Preservation Solutions: A Risk Management-Based Approach",
        "authors": [
            {
                "given": "José",
                "family": "Barateiro",
                "affiliation": [
                    "Instituto de Engenharia de Sistemas e Computadores Investigação eDesenvolvimento em Lisboa (INESC-ID)",
                    "Laboratório Nacional de Engenharia Civil (LNEC)"
                ]
            },
            {
                "given": "Gonçalo",
                "family": "Antunes",
                "affiliation": [
                    "Instituto de Engenharia de Sistemas e Computadores Investigação eDesenvolvimento em Lisboa (INESC-ID)"
                ]
            },
            {
                "given": "Filipe",
                "family": "Freitas",
                "affiliation": [
                    "Instituto de Engenharia de Sistemas e Computadores Investigação eDesenvolvimento em Lisboa (INESC-ID)"
                ]
            },
            {
                "given": "José",
                "family": "Borbinha",
                "affiliation": [
                    "Instituto de Engenharia de Sistemas e Computadores Investigação eDesenvolvimento em Lisboa (INESC-ID)"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2010-06-22",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "5",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i1.183",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i1.183",
            "id_scheme": "DOI"
        },
        "abstract": "Within information systems, a significant aspect of search and retrieval across information objects, such as datasets, journal articles, or images, relies on the identity construction of the objects. This paper uses identity to refer to the qualities or characteristics of an information object that make it definable and recognizable, and can be used to distinguish it from other objects. Identity, in this context, can be seen as the foundation from which citations, metadata and identifiers are constructed.In recent years the idea of including datasets within the scientific record has been gaining significant momentum, with publishers, granting agencies and libraries engaging with the challenge. However, the task has been fraught with questions of best practice for establishing this infrastructure, especially in regards to how citations, metadata and identifiers should be constructed. These questions suggests a problem with how dataset identities are formed, such that an engagement with the definition of datasets as conceptual objects is warranted.This paper explores some of the ways in which scientific data is an unruly and poorly bounded object, and goes on to propose that in order for datasets to fulfill the roles expected for them, the following identity functions are essential for scholarly publications: (i) the dataset is constructed as a semantically and logically concrete object, (ii) the identity of the dataset is embedded, inherent and/or inseparable, (iii) the identity embodies a framework of authorship, rights and limitations, and (iv) the identity translates into an actionable mechanism for retrieval or reference.",
        "article_title": "Linking to Scientific Data: Identity Problems of Unruly and Poorly Bounded Digital Objects",
        "authors": [
            {
                "given": "Laura",
                "family": "Wynholds",
                "affiliation": [
                    "University of California, Los Angeles"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-03-08",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i1.182",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i1.182",
            "id_scheme": "DOI"
        },
        "abstract": "We report on an exploratory study consisting of brief case studies in selected disciplines, examining what motivates researchers to work (or want to work) in an open manner with regard to their data, results and protocols, and whether advantages are delivered by working in this way. We review the policy background to open science, and literature on the benefits attributed to open data, considering how these relate to curation and to questions of who participates in science. The case studies investigate the perceived benefits to researchers, research institutions and funding bodies of utilising open scientific methods, the disincentives and barriers, and the degree to which there is evidence to support these perceptions. Six case study groups were selected in astronomy, bioinformatics, chemistry, epidemiology, language technology and neuroimaging. The studies identify relevant examples and issues through qualitative analysis of interview transcripts. We provide a typology of degrees of open working across the research lifecycle, and conclude that better support for open working, through guidelines to assist research groups in identifying the value and costs of working more openly, and further research to assess the risks, incentives and shifts in responsibility entailed by opening up the research process are needed.",
        "article_title": "Open Science in Practice: Researcher Perspectives and Participation",
        "authors": [
            {
                "given": "Angus",
                "family": "Whyte",
                "affiliation": [
                    "Digital Curation Centre"
                ]
            },
            {
                "given": "Graham",
                "family": "Pryor",
                "affiliation": [
                    "Digital Curation Centre"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-03-08",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i1.181",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i1.181",
            "id_scheme": "DOI"
        },
        "abstract": "Many digital preservation scenarios are based on the migration strategy, which itself is heavily tool-dependent. For popular, well-defined and often open file formats – e.g., digital images, such as PNG, GIF, JPEG – a wide range of tools exist. Migration workflows become more difficult with proprietary formats, as used by the several text processing applications becoming available in the last two decades. If a certain file format can not be rendered with actual software, emulation of the original environment remains a valid option. For instance, with the original Lotus AmiPro or Word Perfect, it is not a problem to save an object of this type in ASCII text or Rich Text Format. In specific environments, it is even possible to send the file to a virtual printer, thereby producing a PDF as a migration output. Such manual migration tasks typically involve human interaction, which may be feasible for a small number of objects, but not for larger batches of files.We propose a novel approach using a software-operated VNC abstraction layer in order to replace humans with machine interaction. Emulators or virtualization tools equipped with a VNC interface are very well suited for this approach. But screen, keyboard and mouse interaction is just part of the setup. Furthermore, digital objects need to be transferred into the original environment in order to be extracted after processing. Nevertheless, the complexity of the new generation of migration services is quickly rising; a preservation workflow is now comprised not only of the migration tool itself, but of a complete software and virtual hardware stack with recorded workflows linked to every supported migration scenario. Thus the requirements of OAIS management must include proper software archiving, emulator selection, system image and recording handling. The concept of view-paths could help either to automatically determine the proper pre-configured virtual environment or to set up system images for certain migration workflows. View-paths may rise in demand, as the generation of PDF output files from Word Perfect input could be cached as pre-fabricated emulator system images. The current groundwork provides several possible optimizations, such as using the automation features of the original environments.",
        "article_title": "Automation of Flexible Migration Workflows",
        "authors": [
            {
                "given": "Dirk",
                "family": "Von Suchodoletz",
                "affiliation": [
                    "University of Freiburg"
                ]
            },
            {
                "given": "Klaus",
                "family": "Rechert",
                "affiliation": [
                    "University of Freiburg"
                ]
            },
            {
                "given": "Randolph",
                "family": "Welte",
                "affiliation": [
                    "University of Freiburg"
                ]
            },
            {
                "given": "Maurice",
                "family": "Van den Dobbelsteen",
                "affiliation": [
                    "National Archives of the Netherlands"
                ]
            },
            {
                "given": "Bill",
                "family": "Roberts",
                "affiliation": [
                    "National Archives of the Netherlands"
                ]
            },
            {
                "given": "Jeffrey",
                "family": "Van der Hoeven",
                "affiliation": [
                    "Koninklijke Bibliotheek"
                ]
            },
            {
                "given": "Jasper",
                "family": "Schroder",
                "affiliation": [
                    "IBM Netherlands B.V."
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-03-08",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i1.180",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i1.180",
            "id_scheme": "DOI"
        },
        "abstract": "The Web is increasingly becoming a platform for linked data. This means making connections and adding value to data on the Web. As more data becomes openly available and more people are able to use the data, it becomes more powerful. An example is file format registries and the evaluation of format risks. Here the requirement for information is now greater than the effort that any single institution can put into gathering and collating this information. Recognising that more is better, the creators of PRONOM, JHOVE, GDFR and others are joining to lead a new initiative: the Unified Digital Format Registry. Ahead of this effort, a new RDF-based framework for structuring and facilitating file format data from multiple sources, including PRONOM, has demonstrated it is able to produce more links, and thus provide more answers to digital preservation questions - about format risks, applications, viewers and transformations - than the native data alone. This paper will describe this registry, P2, and its services, show how it can be used, and provide examples where it delivers more answers than the contributing resources. The P2 Registry is a reference platform to allow and encourage publication of preservation data, and also an examplar of what can be achieved if more data is published openly online as simple machine-readable documents. This approach calls for the active participation of the digital preservation community to contribute data by simply publishing it openly on the Web as linked data.",
        "article_title": "Where the Semantic Web and Web 2.0 Meet Format Risk Management: P2 Registry",
        "authors": [
            {
                "given": "David",
                "family": "Tarrant",
                "affiliation": [
                    "University of Southampton"
                ]
            },
            {
                "given": "Steve",
                "family": "Hitchcock",
                "affiliation": [
                    "University of Southampton"
                ]
            },
            {
                "given": "Leslie",
                "family": "Carr",
                "affiliation": [
                    "University of Southampton"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-03-08",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i1.179",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i1.179",
            "id_scheme": "DOI"
        },
        "abstract": "Recent work in the semantics of markup languages may offer a way to achieve more reliable results for format conversion, or at least a way to state the goal more explicitly. In the work discussed, the meaning of markup in a document is taken as the set of things accepted as true because of the markup's presence, or equivalently, as the set of inferences licensed by the markup in the document. It is possible, in principle, to apply a general semantic description of a markup vocabulary to documents encoded using that vocabulary and to generate a set of inferences (typically rather large, but finite) as a result. An ideal format conversion translating a digital object from one vocabulary to another, then, can be characterized as one which neither adds nor drops any licensed inferences; it is possible to check this equivalence explicitly for a given conversion of a digital object, and possible in principle (although probably beyond current capabilities in practice) to prove that a given transformation will, if given valid and semantically correct input, always produce output that is semantically equivalent to its input. This approach is directly applicable to the XML formats frequently used for scientific and other data, but it is also easily generalized from SGML/XML-based markup languages to digital formats in general; at a high level, it is equally applicable to document markup, to database exchanges, and to ad hoc formats for high-volume scientific data.Some obvious complications and technical difficulties arising from this approach are discussed, as are some important implications. In most real-world format conversions, the source and target formats differ at least somewhat in their ontology, either in the level of detail they cover or in the way they carve reality into classes; it is thus desirable not only to define what a perfect format conversion looks like, but to quantify the loss or distortion of information resulting from the conversion.",
        "article_title": "What Constitutes Successful Format Conversion? Towards a Formalization of 'Intellectual Content'",
        "authors": [
            {
                "given": "C. M.",
                "family": "Sperberg-McQueen",
                "affiliation": [
                    "Black Mesa Technologies LLC"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-03-08",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i1.178",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i1.178",
            "id_scheme": "DOI"
        },
        "abstract": "Over the past decade, a rich body of research and practice has emerged under the rubrics of electronic records, digital preservation and digital curation. Most of this work has taken place as research activity (often financed by government agencies) within libraries and information/computer science departments. Many projects focus on one format of information, such as research publications or data, potentially de-contextualizing individual records. Meanwhile, most institutional archives and manuscript repositories, which possess a rich theoretical and practical framework for preserving context among mixed analog materials, have failed to extend their capabilities to digital records. As a result, relatively few institutions have implemented systematic methods to capture, preserve and provide access to the complete range of documentation that end users need to understand and interpret past human activity.The Practical E-Records Method attempts to address this problem by providing easy-to-implement software reviews, guidance/policy templates, and program recommendations that blend digital curation research findings with traditional archival processes and workflows. Using the method discussed in this paper, archives and manuscript repositories can use existing resources to incrementally develop digital curation skills, building a collaborative, expanding program in the process. Archival programs that make digital curation a systematic institutional function will systematically gather, preserve, and provide access to genres of documentation that are contextually-rich and highly susceptible to loss, complementing efforts undertaken by librarians, information scientists and external service providers. Over the next year, the suggested techniques will be tested and refined at the University of Illinois Archives and possibly elsewhere.",
        "article_title": "Making Digital Curation a Systematic Institutional Function",
        "authors": [
            {
                "given": "Christopher",
                "family": "Prom",
                "affiliation": [
                    "University of Illinois at Urbana-Champaign"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-03-08",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i1.177",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i1.177",
            "id_scheme": "DOI"
        },
        "abstract": "Large, collaboratively managed datasets have become essential to many scientific and engineering endeavors, and their management has increased the need for \"eScience professionals\" who solve large scale information management problems for researchers and engineers. This paper considers the dimensions of work, worker, and workplace, including the knowledge, skills, and abilities needed for eScience professionals. We used focus groups and interviews to explore the needs of scientific researchers and how these needs may translate into curricular and program development choices. A cohort of five masters students also worked in targeted internship settings and completed internship logs. We organized this evidence into a job analysis that can be used for curriculum and program development at schools of library and information science.",
        "article_title": "Education for eScience Professionals: Integrating Data Curation and Cyberinfrastructure",
        "authors": [
            {
                "given": "Youngseek",
                "family": "Kim",
                "affiliation": [
                    "School of Information Studies, Syracuse University"
                ]
            },
            {
                "given": "Benjamin K.",
                "family": "Addom",
                "affiliation": [
                    "School of Information Studies, Syracuse University"
                ]
            },
            {
                "given": "Jeffrey M.",
                "family": "Stanton",
                "affiliation": [
                    "School of Information Studies, Syracuse University"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-03-08",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i1.176",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i1.176",
            "id_scheme": "DOI"
        },
        "abstract": "Underpinning every digital library and digital repository there is a policy framework, which makes the digital library viable - without a policy framework a digital library is little more than a container for content. Policy governs how a digital library is instantiated and run. It is therefore a meta-domain which is situated both outside the digital library and any technologies used to deliver it, and within the digital library itself. Policy is also a key aspect of digital library and digital repository interoperability in a common and integrated information space. Policy interoperability - that is the exchange and reuse of policies - is a step beyond policy standardisation. Furthermore, effective and efficient policy frameworks are also one of the Digital Curation Center (DCC), DigitalPreservationEurope (DPE), nestor and Center for Research Libraries (CRL) core criteria for digital repositories. In this article, we share our research on policy interoperability levels and the experimental survey on policy interoperability conducted with real-life digital libraries, as a contribution towards the definition of a Policy Interoperability Framework.",
        "article_title": "Towards a Holistic Approach to Policy Interoperability in Digital Libraries and Digital Repositories",
        "authors": [
            {
                "given": "Perla",
                "family": "Innocenti",
                "affiliation": [
                    "HATII, University of Glasgow"
                ]
            },
            {
                "given": "MacKenzie",
                "family": "Smith",
                "affiliation": [
                    "MIT Libraries"
                ]
            },
            {
                "given": "Kevin",
                "family": "Ashley",
                "affiliation": [
                    "Digital Curation Centre"
                ]
            },
            {
                "given": "Seamus",
                "family": "Ross",
                "affiliation": [
                    "University of Toronto"
                ]
            },
            {
                "given": "Antonella",
                "family": "De Robbio",
                "affiliation": [
                    "University of Padua"
                ]
            },
            {
                "given": "Hans",
                "family": "Pfeiffenberger",
                "affiliation": [
                    "Alfred Wagner Institute"
                ]
            },
            {
                "given": "John",
                "family": "Faundeen",
                "affiliation": [
                    "US Geological Survey"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-03-08",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i1.175",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i1.175",
            "id_scheme": "DOI"
        },
        "abstract": "Emulation has been widely discussed as a preservation strategy for digital documents that depend upon proprietary executables, as well as for legacy programs. The fundamental assumption of this strategy is that an artifact (document or program) will be bundled with any required contemporaneous software in an archival information package (AIP) which can be loaded and executed in an emulation environment by patrons wishing to access the preserved artifact, yet little has been written about how to identify the required components for such an AIP. Even where a digital document was distributed with a binary viewer, there may be dependencies on other software libraries. In this paper we discuss a pilot study that performed dependency analysis for digital materials originally distributed on CD-ROM. In particular, we show how to utilize a small number of existing off-the-shelf libraries to build a tool that can analyze executables within ISO (CD-ROM) images, and then examine the results of applying this tool to a body of archived images.",
        "article_title": "Dependency Analysis of Legacy Digital Materials to Support Emulation Based Preservation",
        "authors": [
            {
                "given": "Aaron",
                "family": "Hsu",
                "affiliation": [
                    "Indiana University School of Informatics and Computing"
                ]
            },
            {
                "given": "Geoffrey",
                "family": "Brown",
                "affiliation": [
                    "Indiana University School of Informatics and Computing"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-03-08",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i1.174",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i1.174",
            "id_scheme": "DOI"
        },
        "abstract": "Rescuing data from inaccessible or damaged storage media for the purpose of preserving the digital data for the long term is one of the dimensions of digital archaeology. With the current pace of technological development, any system can become obsolete in a matter of years and hence the data stored in a specific storage media might not be accessible anymore due to the unavailability of the system to access the media. In order to preserve digital records residing in such storage media, it is necessary to extract the data stored in those media by some means.One early storage medium for home computers in the 1980s was audio tape. The first home computer systems allowed the use of standard cassette players to record and replay data. Audio cassettes are more durable than old home computers when properly stored. Devices playing this medium (i.e. tape recorders) can be found in working condition or can be repaired, as they are usually made out of standard components. By re-engineering the format of the waveform and the file formats, the data on such media can then be extracted from a digitised audio stream and migrated to a non-obsolete format.In this paper we present a case study on extracting the data stored on an audio tape by an early home computer system, namely the Philips Videopac+ G7400. The original data formats were re-engineered and an application was written to support the migration of the data stored on tapes without using the original system. This eliminates the necessity of keeping an obsolete system alive for enabling access to the data on the storage media meant for this system. Two different methods to interpret the data and eliminate possible errors in the tape were implemented and evaluated on original tapes, which were recorded 20 years ago. Results show that with some error correction methods, parts of the tapes are still readable even without the original system. It also implies that it is easier to build solutions while original systems are still available in a working condition.",
        "article_title": "Migrating Home Computer Audio Waveforms to Digital Objects: A Case Study on Digital Archaeology",
        "authors": [
            {
                "given": "Mark",
                "family": "Guttenbrunner",
                "affiliation": [
                    "Vienna University of Technology,Vienna, Austria"
                ]
            },
            {
                "given": "Mihai",
                "family": "Ghete",
                "affiliation": [
                    "Vienna University of Technology,Vienna, Austria"
                ]
            },
            {
                "given": "Annu",
                "family": "John",
                "affiliation": [
                    "Vienna University of Technology,Vienna, Austria"
                ]
            },
            {
                "given": "Chrisanth",
                "family": "Lederer",
                "affiliation": [
                    "Vienna University of Technology,Vienna, Austria"
                ]
            },
            {
                "given": "Andreas",
                "family": "Rauber",
                "affiliation": [
                    "Vienna University of Technology,Vienna, Austria"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-03-08",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i1.173",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i1.173",
            "id_scheme": "DOI"
        },
        "abstract": "Data curation includes the goal of facilitating the re-use and combination of datasets, which is often impeded by incompatible data schema. Can we use ontologies to help with data integration? We suggest a semi-automatic process that involves the use of automatic text searching to help identify overlaps in metadata that accompany data schemas, plus human validation of suggested data matches.Problems include different text used to describe the same concept, different forms of data recording and different organizations of data. Ontologies can help by focussing attention on important words, providing synonyms to assist matching, and indicating in what context words are used. Beyond ontologies, data on the statistical behavior of data can be used to decide which data elements appear to be compatible with which other data elements. When curating data which may have hundreds or even thousands of data labels, semi-automatic assistance with data fusion should be of great help.",
        "article_title": "Use of Ontologies for Data Integration and Curation",
        "authors": [
            {
                "given": "Judith",
                "family": "Gelernter",
                "affiliation": [
                    "Carnegie-Mellon University"
                ]
            },
            {
                "given": "Michael",
                "family": "Lesk",
                "affiliation": [
                    "Rutgers University"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-03-08",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i1.172",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i1.172",
            "id_scheme": "DOI"
        },
        "abstract": "There is almost universal agreement that scientific data should be shared for use beyond the purposes for which they were initially collected. Access to data enables system-level science, expands the instruments and products of research to new communities, and advances solutions to complex human problems. While demands for data are not new, the vision of open access to data is increasingly ambitious. The aim is to make data accessible and usable to anyone, anytime, anywhere, and for any purpose. Until recently, scholarly investigations related to data sharing and reuse were sparse. They have become more common as technology and instrumentation have advanced, policies that mandate sharing have been implemented, and research has become more interdisciplinary. Each of these factors has contributed to what is commonly referred to as the \"data deluge\". Most discussions about increases in the scale of sharing and reuse have focused on growing amounts of data. There are other issues related to open access to data that also concern scale which have not been as widely discussed: broader participation in data sharing and reuse, increases in the number and types of intermediaries, and more digital data products. The purpose of this paper is to develop a research agenda for scientific data sharing and reuse that considers these three areas.",
        "article_title": "Beyond the Data Deluge: A Research Agenda for Large-Scale Data Sharing and Reuse",
        "authors": [
            {
                "given": "Ixchel M.",
                "family": "Faniel",
                "affiliation": [
                    "University of Michigan"
                ]
            },
            {
                "given": "Ann",
                "family": "Zimmerman",
                "affiliation": [
                    "University of Michigan"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-03-08",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i1.171",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i1.171",
            "id_scheme": "DOI"
        },
        "abstract": "As collections become larger in size, more complex in structure and increasingly diverse in composition, new approaches are needed to help curators assess digital files and make decisions about their long-term preservation. We present research on the use of interactive visualization to analyze file characterization information for the purpose of assessing the preservation condition of a vast collection of complex electronic records. The case study collection contains over 1,000,000 files of diverse formats arranged in varied record structures and record groups. The visualization application uses tree maps and a relational database management system (RDBMS) to represent the collection's arrangement and to show available characterization information at different levels of aggregation, classification and abstraction. Through this visualization interface curators can interact dynamically with the collections' characterization information to discover trends, as well as compare and contrast various file characteristics across the collection. Curators may select and weight the variables that they want to analyze. They can pursue analysis workflows that go from a high-level overview of the collection's preservation condition based on file format risks, to obtaining more detailed results about the condition of record groups and individual records. While there are various digital preservation planning tools available, to our knowledge none have been designed specifically to visually present assessment information across vast and complex collections. We present research to address the need for such a tool.",
        "article_title": "Assessing the Preservation Condition of Large and Heterogeneous Electronic Records Collections with Visualization",
        "authors": [
            {
                "given": "Maria",
                "family": "Esteva",
                "affiliation": [
                    "University of Texas, Austin"
                ]
            },
            {
                "given": "Weijia",
                "family": "Xu",
                "affiliation": [
                    "University of Texas, Austin"
                ]
            },
            {
                "given": "Suyog Dutt",
                "family": "Jain",
                "affiliation": [
                    "University of Texas, Austin"
                ]
            },
            {
                "given": "Jennifer L.",
                "family": "Lee",
                "affiliation": [
                    "University of Texas, Austin"
                ]
            },
            {
                "given": "Wendy K.",
                "family": "Martin",
                "affiliation": [
                    "University of Texas, Austin"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-03-08",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i1.170",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i1.170",
            "id_scheme": "DOI"
        },
        "abstract": "MESSAGE (Mobile Environmental Sensing System Across Grid Environments) was an ambitious, multi-partner, interdisciplinary e-Science research project, jointly funded by the Engineering and Physical Sciences Research Council (EPSRC) and the UK Department for Transport (DfT) between 2006 and 2009. It aimed to develop and demonstrate the potential of diverse, low cost sensors to provide heterogeneous data for the planning, management and control of the environmental impacts of transport activity at urban, regional and national level. During the last year of the project, the Digital Curation Centre (DCC) interviewed and observed members of the project team in order to identify and analyse key aspects of their data-related activities, recording attitudes towards the data that they create and/or re-use. This paper describes the major issues identified over the course of the case study, which are presented in parallel with the perspectives of the project team in order to demonstrate the multiplicity of views that may be projected onto a single dataset. It concludes with a contextualisation of the case study's themes with those of a number of contemporary reports.",
        "article_title": "The Milieu and the MESSAGE: Talking to Researchers about Data Curation Issues in a Large and Diverse e-Science Project",
        "authors": [
            {
                "given": "Martin",
                "family": "Donnelly",
                "affiliation": [
                    "University of Edinburgh"
                ]
            },
            {
                "given": "Robin",
                "family": "North",
                "affiliation": [
                    "Imperial College London"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-03-08",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i1.169",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i1.169",
            "id_scheme": "DOI"
        },
        "abstract": "UK data centres are an important part of efforts to gain maximum value from research data. However, if they are to operate effectively, the services that they provide must be based upon an understanding of researchers' practices and needs. Furthermore, in order to build a case for ongoing funding, data centres must be able to demonstrate their value to researchers work and, increasingly, their contribution to wider political \"impact\" agendas. This paper presents the findings of a survey of users of five UK data centres. It suggests that research data centres are highly valued by their users. Benefits appear to be particularly strong around improving research efficiency, especially access to data. Data centres are less important in terms of stimulating novel research questions. Despite a few interesting cases of observable impact, in the main it remains difficult to understand the wider reach of research which draws upon data centre resources.",
        "article_title": "Use and Impact of UK Research Data Centres",
        "authors": [
            {
                "given": "Ellen",
                "family": "Collins",
                "affiliation": [
                    "Research Information Network"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-03-08",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i1.168",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i1.168",
            "id_scheme": "DOI"
        },
        "abstract": "For millions of legacy documents, correct rendering depends upon resources such as fonts that are not generally embedded within the document structure. Yet there is a significant risk of information loss due to missing or incorrectly substituted fonts. Large document collections depend on thousands of unique fonts not available on a common desktop workstation, which typically has between 100 and 200 fonts. Silent substitution of fonts, performed by applications such as Microsoft Office, can yield poorly rendered documents. In this paper we use a collection of 230,000 Word documents to assess the difficulty of matching font requirements with a database of fonts. We describe the identifying information contained in common font formats, font requirements stored in Word documents, the API provided by Windows to support font requests by applications, the documented substitution algorithms used by Windows when requested fonts are not available, and the ways in which support software might be used to control font substitution in a preservation environment.",
        "article_title": "Born Broken: Fonts and Information Loss in Legacy Digital Documents",
        "authors": [
            {
                "given": "Geoffrey",
                "family": "Brown",
                "affiliation": [
                    "Indiana University Bloomington"
                ]
            },
            {
                "given": "Kam",
                "family": "Woods",
                "affiliation": [
                    "Indiana University Bloomington"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-03-08",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i2.207",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i2.207",
            "id_scheme": "DOI"
        },
        "abstract": "Telehealth monitoring data is now being collected across large populations of patients with chronic diseases such as stroke, hypertension, COPD and dementia. These large, complex and heterogeneous datasets, including distributed sensor and mobile datasets, present real opportunities for knowledge discovery and re-use, however they also generate new challenges for curation. This paper uses qualitative research with stakeholders in two nationally-funded telehealth projects to outline the perceptions, practices and preferences of different stakeholders with regard to data curation. Telehealth provides a living laboratory for the very different challenges implicit in designing and managing data infrastructure for embedded and ubiquitous computing. Here, technical and human agents are distributed, and interaction and state change is a central component of design, rather than an inconvenient challenge to it. The authors argue that there are lessons to be learned from other domains where data infrastructure has been radically rethought to address these challenges.",
        "article_title": "Curating Complex, Dynamic and Distributed Data: Telehealth as a Laboratory for Strategy",
        "authors": [
            {
                "given": "Jenny",
                "family": "Ure",
                "affiliation": [
                    "Edinburgh Napier University"
                ]
            },
            {
                "given": "Tasneem",
                "family": "Irshad",
                "affiliation": [
                    "Edinburgh University"
                ]
            },
            {
                "given": "Janet",
                "family": "Hanley",
                "affiliation": [
                    "Edinburgh Napier University"
                ]
            },
            {
                "given": "Angus",
                "family": "Whyte",
                "affiliation": [
                    "Edinburgh University"
                ]
            },
            {
                "given": "Claudia",
                "family": "Pagliari",
                "affiliation": [
                    "Edinburgh University"
                ]
            },
            {
                "given": "Hilary",
                "family": "Pinnock",
                "affiliation": [
                    "Edinburgh University"
                ]
            },
            {
                "given": "Brian",
                "family": "McKinstry",
                "affiliation": [
                    "Edinburgh University"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-08-19",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i2.206",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i2.206",
            "id_scheme": "DOI"
        },
        "abstract": "The subject of digital game preservation is one that has moved up the research agenda in recent years with a number of international projects, such as KEEP and Preserving Virtual Worlds, highlighting and seeking to address the impact of media decay, hardware and software obsolescence through different strategies including code emulation, for instance. Similarly, and reflecting a popular interest in the histories of digital games, exhibitions such as Game On (Barbican, UK) and GameCity (Nottingham, UK) experiment with ways of presenting games to a general audience. This article focuses on the UK’s National Videogame Archive (NVA) which, since its foundation in 2008, has developed approaches that both dovetail with and critique existing strategies to game preservation, exhibition and display.The article begins by noting the NVA’s interest in preserving not only the code or text of the game, but also the experience of using it – that is, the preservation of gameplay as well as games. This approach is born of a conceptualisation of digital games as what Moulthrop (2004) has called “configurative performances” that are made through the interaction of code, systems, rules and, essentially, the actions of players at play. The analysis develops by problematising technical solutions to game preservation by exploring the way seemingly minute differences in code execution greatly impact on this user experience.Given these issues, the article demonstrates how the NVA returns to first principles and questions the taken-for-granted assumption that the playable game is the most effective tool for interpretation. It also encourages a consideration of the uses of non-interactive audiovisual and (para)textual materials in game preservation activity. In particular, the focus falls upon player-produced walkthrough texts, which are presented as archetypical archival documents of gameplay. The article concludes by provocatively positing that these non-playable, non-interactive texts might be more useful to future game scholars than the playable game itself.",
        "article_title": "(Not) Playing Games: Player-Produced Walkthroughs as Archival Documents of Digital Gameplay",
        "authors": [
            {
                "given": "James",
                "family": "Newman",
                "affiliation": [
                    "Bath Spa University"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-08-19",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i2.192",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i2.192",
            "id_scheme": "DOI"
        },
        "abstract": "Virtual environments, such as Second Life, have assumed an increasingly important role in popular culture, education and research. Unfortunately, we have almost no practical experience in how to preserve these highly dynamic, interactive information resources. This article reports on research by the National Digital Information Infrastructure for Preservation Program (NDIIPP)-funded Preserving Virtual Worlds project, which examines the issues that arise when attempting to archive regions from Second Life. Intellectual property and contractual issues can raise significant impediments to the creation of an archival information package for these environments, as can the technical design of the worlds themselves. We discuss the implication of these impediments for distributed models of preservation, such as NDIIPP.",
        "article_title": "Saving Second Life: Issues in Archiving a Complex, Multi-User Virtual World",
        "authors": [
            {
                "given": "Jerome",
                "family": "McDonough",
                "affiliation": [
                    "University of Illinois at Urbana-Champaign"
                ]
            },
            {
                "given": "Robert",
                "family": "Olendorf",
                "affiliation": [
                    "University of Illinois at Urbana-Champaign"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-07-25",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i2.205",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i2.205",
            "id_scheme": "DOI"
        },
        "abstract": "This paper discusses many of the issues associated with formally publishing data in academia, focusing primarily on the structures that need to be put in place for peer review and formal citation of datasets. Data publication is becoming increasingly important to the scientific community, as it will provide a mechanism for those who create data to receive academic credit for their work and  will allow the conclusions arising from an analysis to be more readily verifiable, thus promoting transparency in the scientific process. Peer review of data will also provide a mechanism for ensuring the quality of datasets, and we provide suggestions on the types of activities one expects to see in the peer review of data. A simple taxonomy of data publication methodologies is presented and evaluated, and the paper concludes with a discussion of dataset granularity, transience and semantics, along with a recommended human-readable citation syntax.",
        "article_title": "Citation and Peer Review of Data: Moving Towards Formal Data Publication",
        "authors": [
            {
                "given": "Bryan",
                "family": "Lawrence",
                "affiliation": [
                    "STFC Rutherford Appleton Laboratory"
                ]
            },
            {
                "given": "Catherine",
                "family": "Jones",
                "affiliation": [
                    "STFC Rutherford Appleton Laboratory"
                ]
            },
            {
                "given": "Brian",
                "family": "Matthews",
                "affiliation": [
                    "STFC Rutherford Appleton Laboratory"
                ]
            },
            {
                "given": "Sam",
                "family": "Pepler",
                "affiliation": [
                    "STFC Rutherford Appleton Laboratory"
                ]
            },
            {
                "given": "Sarah",
                "family": "Callaghan",
                "affiliation": [
                    "STFC Rutherford Appleton Laboratory"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-07-26",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i2.191",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i2.191",
            "id_scheme": "DOI"
        },
        "abstract": "In the mid 1990s UK digital preservation activity concentrated on ensuring the survival of digital material – spurred on by the US report Preserving Digital Information (The Task Force on Archiving of Digital Information, 1996) and developed through JISC-funded activities. Technical developments and a maturing understanding of organisational activity and workflow saw the emphasis move to ensuring the access, use and reuse of digital materials throughout their lifecycle. Digital Curation emerged as a new discipline supported through the activities of the UK’s Digital Curation Centre and a number of EU 6th Framework Projects. Digital Curation is now embedded in both practice and research; with the development of tools, and the foundation of a number of support units and academic educators offering training and furthering research.",
        "article_title": "Digital Curation: The Emergence of a New Discipline",
        "authors": [
            {
                "given": "Sarah",
                "family": "Higgins",
                "affiliation": [
                    "Aberystwyth University"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-07-25",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i2.190",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i2.190",
            "id_scheme": "DOI"
        },
        "abstract": "This study explores how researchers at a major Midwestern university are managing their data, as well as the factors that have shaped their practices and those that motivate or inhibit changes to that practice. A combination of survey (n=363) and interview data (n=15) yielded both qualitative and quantitative results bearing on my central research question: In what types of data management activities do researchers at this institution engage? Corollary to that, I also explored the following questions: What do researchers feel could be improved about their data management practices? Which services might be of interest to them? How do they feel those services could most effectively be implemented?In this paper, I situate researchers’ data management practices within a theory of personal information management. I present a view of data management and preservation needs from researchers’ perspectives across a range of domains. Additionally, I discuss the implications that understanding research data management as personal information management has for introducing services to support and improve data management practice.",
        "article_title": "“You made it, you take care of it”: Data Management as Personal Information Management",
        "authors": [
            {
                "given": "Kathleen",
                "family": "Fear",
                "affiliation": [
                    "School of Information, University of Michigan"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-07-25",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v6i2.204",
        "identifier": {
            "string_id": "10.2218/ijdc.v6i2.204",
            "id_scheme": "DOI"
        },
        "abstract": "The challenge of digital preservation of scientific data lies in the need to preserve not only the dataset itself but also the ability it has to deliver knowledge to a future user community. A true scientific research asset allows future users to reanalyze the data within new contexts. Thus, in order to carry out meaningful preservation we need to ensure that future users are equipped with the necessary information to re-use the data. This paper presents an overview of a preservation analysis methodology which was developed in response to that need on the CASPAR and Digital Curation Centre SCARP projects. We intend to place it in relation to other digital preservation practices, discussing how they can interact to provide archives caring for scientific data sets with the full arsenal of tools and techniques necessary to rise to this challenge.",
        "article_title": "Curating Scientific Research Data for the Long Term: A Preservation Analysis Method in Context",
        "authors": [
            {
                "given": "Esther",
                "family": "Conway",
                "affiliation": [
                    "Science and Technology Facilities Council"
                ]
            },
            {
                "given": "David",
                "family": "Giaretta",
                "affiliation": [
                    "Science and Technology Facilities Council"
                ]
            },
            {
                "given": "Simon",
                "family": "Lambert",
                "affiliation": [
                    "Science and Technology Facilities Council"
                ]
            },
            {
                "given": "Brian",
                "family": "Matthews",
                "affiliation": [
                    "Science and Technology Facilities Council"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2011-07-26",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "6",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v7i1.217",
        "identifier": {
            "string_id": "10.2218/ijdc.v7i1.217",
            "id_scheme": "DOI"
        },
        "abstract": "The capability to validate and view or play binary file formats, as well as to convert binary file formats to standard or current file formats, is critically important to the preservation of digital data and records. This paper describes the extension of context-free grammars from strings to binary files. Binary files are arrays of data types, such as long and short integers, floating-point numbers and pointers, as well as characters. The concept of an attribute grammar is extended to these context-free array grammars. This attribute grammar has been used to define a number of chunk-based and directory-based binary file formats. A parser generator has been used with some of these grammars to generate syntax checkers (recognizers) for validating binary file formats. Among the potential benefits of an attribute grammar-based approach to specification and parsing of binary file formats is that attribute grammars not only support format validation, but support generation of error messages during validation of format, validation of semantic constraints, attribute value extraction (characterization), generation of viewers or players for file formats, and conversion to current or standard file formats. The significance of these results is that with these extensions to core computer science concepts, traditional parser/compiler technologies can potentially be used as a part of a general, cost effective curation strategy for binary file formats.",
        "article_title": "Grammar-Based Specification and Parsing of Binary File Formats",
        "authors": [
            {
                "given": "William",
                "family": "Underwood",
                "affiliation": [
                    "Georgia Tech Research Institute"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2012-03-09",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "7",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v7i1.216",
        "identifier": {
            "string_id": "10.2218/ijdc.v7i1.216",
            "id_scheme": "DOI"
        },
        "abstract": "Genomic and environmental sciences represent two poles of scientific data. In the first, highly parallel sequencing facilities generate large quantities of sequence data. In the latter, loosely networked remote and field sensors produce intermittent streams of different data types. Yet both genomic and environmental sciences are said to be moving to data intensive research. This paper explores and contrasts data flow in these two domains in order to better understand how data intensive research is being done. Our case studies are next generation sequencing for genomics and environmental networked sensors.Our objective was to enrich understanding of the ‘intensive’ processes and properties of data intensive research through a ‘sociology’ of data using methods that capture the relational properties of data flows. Our key methodological innovation was the staging of events for practitioners with different kinds of expertise in data intensive research to participate in the collective annotation of visual forms. Through such events we built a substantial digital data archive of our own that we then analysed in terms of three traits of data flow: durability, replicability and metrology.Our findings are that analysing data flow with respect to these three traits provides better insight into how doing data intensive research involves people, infrastructures, practices, things, knowledge and institutions. Collectively, these elements shape the topography of data and condition how it flows. We argue that although much attention is given to phenomena such as the scale, volume and speed of data in data intensive research, these are measures of what we call ‘extensive’ properties rather than intensive ones. Our thesis is that extensive changes, that is to say those that result in non-linear changes in metrics, can be seen to result from intensive changes that bring multiple, disparate flows into confluence.If extensive shifts in the modalities of data flow do indeed come from the alignment of disparate things, as we suggest, then we advocate the staging of workshops and other events with the purpose of developing the ‘missing’ metrics of data flow.",
        "article_title": "Understanding the ‘Intensive’ in ‘Data Intensive Research’: Data Flows in Next Generation Sequencing and Environmental Networked Sensors",
        "authors": [
            {
                "given": "Ruth",
                "family": "McNally",
                "affiliation": [
                    "ESRC Cesagen, Lancaster University"
                ]
            },
            {
                "given": "Adrian",
                "family": "Mackenzie",
                "affiliation": [
                    "ESRC Cesagen, Lancaster University"
                ]
            },
            {
                "given": "Allison",
                "family": "Hui",
                "affiliation": [
                    "Hong Kong Baptist University"
                ]
            },
            {
                "given": "Jennifer",
                "family": "Tomomitsu",
                "affiliation": [
                    "University of the Arts, London"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2012-03-09",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "7",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v7i1.215",
        "identifier": {
            "string_id": "10.2218/ijdc.v7i1.215",
            "id_scheme": "DOI"
        },
        "abstract": "One morning we came in to work to find that one of our servers had made 1.5 million attempts to contact an external server in the preceding hour. It turned out that the calls were being generated by the Library’s digital preservation system (Rosetta) while attempting to validate XML Schema Definition (XSD) declarations included in the XML files of the Library’s online newspaper application Papers Past, which we were in the process of loading into Rosetta. This paper describes our response to this situation and outlines some of the issues that needed to be canvassed before we were able to arrive at a suitable solution, including the digital preservation status of these XSDs; their impact on validation tools, such as JHOVE; and where these objects should reside if they are considered material to the digital preservation process.",
        "article_title": "A Short Story about XML Schemas, Digital Preservation and Format Libraries",
        "authors": [
            {
                "given": "Steve",
                "family": "Knight",
                "affiliation": [
                    "National Library of New Zealand, Te Puna Mātauranga o Aotearoa"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2012-03-09",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "7",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v7i1.214",
        "identifier": {
            "string_id": "10.2218/ijdc.v7i1.214",
            "id_scheme": "DOI"
        },
        "abstract": "Freedom of information legislation came into effect in the UK in 2005. All universities that receive block grants from the Higher Education Funding Councils in England, Wales, Scotland and Northern Ireland are subject to the legislation. Recent cases where universities have received requests for data and other information generated by researchers, working in areas such as climate, have given rise to controversy and widespread concern in the research community. This paper examines some of those concerns, relating to responsibilities for the ownership and holding of information, for data and records management, and for the handling of requests under the legislation. It also considers the implications relating to personal data, and to information that may affect the commercial interests of universities operating in a competitive environment, or the interests of the many other organisations which may be involved in research partnerships with universities; and it outlines concerns about the possible impact on quality assurance, peer review, and scholarly discourse. Finally, the paper emphasises the need for support and training for researchers so that they become more aware of the legislation and its implications, and how to deal with requests when they arise.",
        "article_title": "Freedom of Information in the UK and its Implications for Research in the Higher Education Sector",
        "authors": [
            {
                "given": "Michael",
                "family": "Jubb",
                "affiliation": [
                    "Research Information Network"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2012-03-09",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "7",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v7i1.213",
        "identifier": {
            "string_id": "10.2218/ijdc.v7i1.213",
            "id_scheme": "DOI"
        },
        "abstract": "From where did this tweet originate? Was this quote from the New York Times modified? Daily, we rely on data from the Web, but often it is difficult or impossible to determine where it came from or how it was produced. This lack of provenance is particularly evident when people and systems deal with Web information or with any environment where information comes from sources of varying quality. Provenance is not captured pervasively in information systems. There are major technical, social, and economic impediments that stand in the way of using provenance effectively. This paper synthesizes requirements for provenance on the Web for a number of dimensions, focusing on three key aspects of provenance: the content of provenance, the management of provenance records, and the uses of provenance information. To illustrate these requirements, we use three synthesized scenarios that encompass provenance problems faced by Web users today.",
        "article_title": "Requirements for Provenance on the Web",
        "authors": [
            {
                "given": "Paul",
                "family": "Groth",
                "affiliation": [
                    "VU University, Amsterdam"
                ]
            },
            {
                "given": "Yolanda",
                "family": "Gil",
                "affiliation": [
                    "University of Southern California"
                ]
            },
            {
                "given": "James",
                "family": "Cheney",
                "affiliation": [
                    "University of Edinburgh"
                ]
            },
            {
                "given": "Simon",
                "family": "Miles",
                "affiliation": [
                    "Kings College London"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2012-03-09",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "7",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v7i1.212",
        "identifier": {
            "string_id": "10.2218/ijdc.v7i1.212",
            "id_scheme": "DOI"
        },
        "abstract": "The majority of information about science, culture, society, economy and the environment is born digital, yet the underlying technology is subject to rapid obsolescence. One solution to this obsolescence, format migration, is widely practiced and supported by many software packages, yet migration has well known risks. For example, newer formats – even where similar in function – do not generally support all of the features of their predecessors, and, where similar features exist, there  may be significant differences of interpretation.There appears to be a conflict between the wide use of migration and its known risks. In this paper  we explore a simple hypothesis – that, where migration paths exist, the majority of data files can be safely migrated leaving only a few that must be handled more carefully – in the context of several scientific data formats that are or were widely used. Our approach is to gather information about  potential migration mismatches and, using custom tools, evaluate a large collection of data files for the incidence of these risks. Our results support our  initial hypothesis, though with some caveats.  Further, we found that writing a tool to identify “risky” format features is considerably easier than  writing a migration tool.",
        "article_title": "Assessing Migration Risk for Scientific Data Formats",
        "authors": [
            {
                "given": "Chris",
                "family": "Frisz",
                "affiliation": [
                    "Indiana University"
                ]
            },
            {
                "given": "Geoffrey",
                "family": "Brown",
                "affiliation": [
                    "Indiana University"
                ]
            },
            {
                "given": "Samuel",
                "family": "Waggoner",
                "affiliation": [
                    "Indiana University"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2012-03-09",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "7",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v7i1.211",
        "identifier": {
            "string_id": "10.2218/ijdc.v7i1.211",
            "id_scheme": "DOI"
        },
        "abstract": "The digital preservation community currently utilises a number of tools and automated processes to identify and validate digital objects. The identification of digital objects is a vital first step in their long-term preservation, but the results returned by tools used for this purpose are lacking in transparency, and are not easily tested or verified. This paper suggests that a test corpus of digital objects is one way of providing this verification and validation, ultimately improving trust in the tools, and providing further stimulus to their development. Issues to be considered are outlined, and attention is drawn to particular examples of existing digital corpora which could conceivably provide a useable framework or starting point for our own communities needs. This paper does not seek to answer all questions in this area, but merely attempts to set out areas for consideration in any next step that is taken.",
        "article_title": "Towards the Development of a Test Corpus of Digital Objects for the Evaluation of File Format Identification Tools and Signatures",
        "authors": [
            {
                "given": "Andrew",
                "family": "Fetherston",
                "affiliation": [
                    "The National Archives"
                ]
            },
            {
                "given": "Tim",
                "family": "Gollins",
                "affiliation": [
                    "The National Archives"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2012-03-09",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "7",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v7i1.210",
        "identifier": {
            "string_id": "10.2218/ijdc.v7i1.210",
            "id_scheme": "DOI"
        },
        "abstract": "Network modelling provides a framework for the systematic analysis of needs and options for preservation.  A number of general strategies can be identified, characterised and applied to many situations; these strategies may be combined to produce robust preservation solutions tailored to the needs of the community and responsive to their environment. This paper provides an overview of this approach. We describe the components of a Preservation Network Model and go on to show how it may be used to plan preservation actions according to the requirements of the particular situation using illustrative examples from scientific archives.",
        "article_title": "Managing Risks in the Preservation of Research Data with Preservation Networks",
        "authors": [
            {
                "given": "Esther",
                "family": "Conway",
                "affiliation": [
                    "Science and Technology Facilities Council"
                ]
            },
            {
                "given": "Brian",
                "family": "Matthews",
                "affiliation": [
                    "Science and Technology Facilities Council"
                ]
            },
            {
                "given": "David",
                "family": "Giaretta",
                "affiliation": [
                    "Science and Technology Facilities Council"
                ]
            },
            {
                "given": "Simon",
                "family": "Lambert",
                "affiliation": [
                    "Science and Technology Facilities Council"
                ]
            },
            {
                "given": "Michael",
                "family": "Wilson",
                "affiliation": [
                    "Science and Technology Facilities Council"
                ]
            },
            {
                "given": "Nick",
                "family": "Draper",
                "affiliation": [
                    "Tessella"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2012-03-09",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "7",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v7i2.228",
        "identifier": {
            "string_id": "10.2218/ijdc.v7i2.228",
            "id_scheme": "DOI"
        },
        "abstract": "The growth of computing technology during the previous three decades has resulted in a large amount of content being created in digital form. As their creators retire or pass away, an increasing number of personal data collections, in the form of digital media and complete computer systems, are being offered to the academic institutional archive. For the digital curator or archivist, the handling and processing of such digital material represents a considerable challenge, requiring development of new processes and procedures. This paper outlines how digital forensic methods, developed by the law enforcement and legal community, may be applied by academic digital archives. It goes on to describe the strategic and practical decisions that should be made to introduce forensic methods within an existing curatorial infrastructure and how different techniques, such as forensic hashing, timeline analysis and data carving, may be used to collect information of a greater breadth and scope than may be gathered through manual activities.",
        "article_title": "The Forensic Curator: Digital Forensics as a Solution to Addressing the Curatorial Challenges Posed by Personal Digital Archives",
        "authors": [
            {
                "given": "Gareth",
                "family": "Knight",
                "affiliation": [
                    "London School of Hygiene and Tropical Medicine"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2012-10-23",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "7",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v7i2.227",
        "identifier": {
            "string_id": "10.2218/ijdc.v7i2.227",
            "id_scheme": "DOI"
        },
        "abstract": "In this paper we discuss archival storage container formats from the point of view of digital curation and preservation, an aspect of preservation overlooked by most other studies. Considering established approaches to data management as our jumping off point, we selected seven container format attributes that are core to the long term accessibility of digital materials. We have labeled these core preservation attributes. These attributes are then used as evaluation criteria to compare storage container formats belonging to five common categories: formats for archiving selected content (e.g. tar, WARC), disk image formats that capture data for recovery or installation (partimage, dd raw image), these two types combined with a selected compression algorithm (e.g. tar+gzip),  formats that combine packing and compression (e.g. 7-zip), and forensic file formats for data analysis in criminal investigations (e.g. aff – Advanced Forensic File format). We present a general discussion of the storage container format landscape in terms of the attributes we discuss, and make a direct comparison between the three most promising archival formats: tar, WARC, and aff. We conclude by suggesting the next steps to take the research forward and to validate the observations we have made.",
        "article_title": "Digital Forensics Formats: Seeking a Digital Preservation Storage Container Format for Web Archiving",
        "authors": [
            {
                "given": "Yunhyong",
                "family": "Kim",
                "affiliation": [
                    "University of Glasgow"
                ]
            },
            {
                "given": "Seamus",
                "family": "Ross",
                "affiliation": [
                    "University of Toronto, Canada",
                    "Humanities Advanced Technology and Information Institute,University of Glasgow"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2012-10-23",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "7",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v7i2.226",
        "identifier": {
            "string_id": "10.2218/ijdc.v7i2.226",
            "id_scheme": "DOI"
        },
        "abstract": "Over the past 20 years, many thousands of CD-ROM titles were published; many of these have lasting cultural significance, yet present a difficult challenge for libraries due to obsolescence of the supporting software and hardware, and the consequent decline in the technical knowledge required to support them. The current trend appears to be one of abandonment – for example, the Indiana University Libraries no longer maintain machines capable of accessing early CD-ROM titles.In previous work, we proposed an access model based upon networked ‘virtual collections’ of CD-ROMs which can enable consortia of libraries to pool the technical expertise necessary to provide continued access to such materials for a geographically sparse base of patrons, who may have limited technical knowledge.In this paper, we extend this idea to CD-ROMs designed to operate on ‘classic’ Macintosh systems with an extensive case study – the catalog of the Voyager Company publications, which was the first major innovator in interactive CD-ROMs. The work described includes emulator extensions to support obsolete CD formats and to enable networked access to the virtual collection.",
        "article_title": "Developing Virtual CD-ROM Collections: The Voyager Company Publications",
        "authors": [
            {
                "given": "Geoffrey",
                "family": "Brown",
                "affiliation": [
                    "Indiana University School of Informatics and Computing"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2012-10-23",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "7",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v8i1.240",
        "identifier": {
            "string_id": "10.2218/ijdc.v8i1.240",
            "id_scheme": "DOI"
        },
        "abstract": "User-generated content (UGC) has become a part of personal digital collections on the Web, as such collections often contain personal memories, activities, thoughts and even profiles. With the increase in the creation of personal materials on the Web, the needs for archiving and preserving these materials are increasing, not only for the purpose of developing personal archives but also for the purpose of capturing social memory and tracking human traces in this era. Using both survey and interview methods, this study investigated blogs, one popular type of UGC, and analyzed travel bloggers’ perceptions of the value of blogs and the elements of blogs that are important for preservation. The study respondents found personal and sentimental value (e.g., a way to express themselves, a way to keep personal memories and thoughts, and a way to maintain a record for their family) to be the most important reason for preserving blogs, followed by informational value and cultural/historical value. Sharing also appeared as one of the values that respondents found in their blogs. The respondents reported that self-created blog posts (content) and information related to the blog posts (context) are more important to preserve than some other elements (behavior and appearance). Integrating what bloggers consider as most valuable and what archivists think are worth preserving may be an important step when collecting personal blogs.",
        "article_title": "Defining What Matters When Preserving Web-Based Personal Digital Collections: Listening to Bloggers",
        "authors": [
            {
                "given": "Ayoung",
                "family": "Yoon",
                "affiliation": [
                    "University of North Carolina at Chapel Hill"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2013-06-14",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "8",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v8i1.252",
        "identifier": {
            "string_id": "10.2218/ijdc.v8i1.252",
            "id_scheme": "DOI"
        },
        "abstract": "In contemporary scientific research, standard-making and standardization are key processes for the sharing and reuse of data. The goals of this paper are twofold: 1) to stress that collaboration is crucial to standard-making, and 2) to urge recognition of metadata standardization as part of the scientific process. To achieve these goals, a participatory framework for developing and implementing scientific metadata standards is presented. We highlight the need for ongoing, open dialogue within and among research communities at multiple levels. Using the Long Term Ecological Research network adoption of the Ecological Metadata Language as a case example in the natural sciences, we illustrate how a participatory framework addresses the need for active coordination of the evolution of scientific metadata standards. The participatory framework is contrasted with a hierarchical framework to underscore how the development of scientific standards is a dynamic and continuing process. The roles played by ‘best practices’ and ‘working standards’ are identified in relation to the process of standardization.",
        "article_title": "Towards Standardization: A Participatory Framework for Scientific Standard-Making",
        "authors": [
            {
                "given": "Lynn",
                "family": "Yarmey",
                "affiliation": [
                    "University of Colorado at Boulder"
                ]
            },
            {
                "given": "Karen S.",
                "family": "Baker",
                "affiliation": [
                    "University of Illinois at Urbana-Champaign"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2013-06-14",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "8",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v8i1.251",
        "identifier": {
            "string_id": "10.2218/ijdc.v8i1.251",
            "id_scheme": "DOI"
        },
        "abstract": "ISO 16363:2012, Space Data and Information Transfer Systems - Audit and Certification of Trustworthy Digital Repositories (ISO TRAC), outlines actions a repository can take to be considered trustworthy, but research examining whether the repository’s designated community of users associates such actions with trustworthiness has been limited. Drawing from this ISO document and the management and information systems literatures, this paper discusses findings from interviews with 66 archaeologists and quantitative social scientists. We found similarities and differences across the disciplines and among the social scientists. Both disciplinary communities associated trust with a repository’s transparency. However, archaeologists mentioned guarantees of preservation and sustainability more frequently than the social scientists, who talked about institutional reputation. Repository processes were also linked to trust, with archaeologists more frequently citing metadata issues and social scientists discussing data selection and cleaning processes. Among the social scientists, novices mentioned the influence of colleagues on their trust in repositories almost twice as much as the experts. We discuss the implications our findings have for identifying trustworthy repositories and how they extend the models presented in the management and information systems literatures.",
        "article_title": "Trust in Digital Repositories",
        "authors": [
            {
                "given": "Elizabeth",
                "family": "Yakel",
                "affiliation": [
                    "University of Michigan"
                ]
            },
            {
                "given": "Ixchel M.",
                "family": "Faniel",
                "affiliation": [
                    "OCLC Research"
                ]
            },
            {
                "given": "Adam",
                "family": "Kriesberg",
                "affiliation": [
                    "University of Michigan"
                ]
            },
            {
                "given": "Ayoung",
                "family": "Yoon",
                "affiliation": [
                    "University of North Carolina"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2013-06-14",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "8",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v8i1.250",
        "identifier": {
            "string_id": "10.2218/ijdc.v8i1.250",
            "id_scheme": "DOI"
        },
        "abstract": "The changing world of IT services opens the chance to more tightly integrate digital long-term preservation into systems, both for commercial and end users. The emergence of cloud offerings re-centralizes services, and end users interact with them remotely through standardized (web-)client applications on their various devices. This offers the chance to use partially the same concepts and methods to access obsolete computer environments and allows for more sustainable business processes. In order to provide a large variety of user-friendly remote emulation services, especially in combination with authentic performance and user experience, a distributed system model and architecture is required, suitable to run as a cloud service, allowing for the specialization both of memory institutions and third party service providers. The shift of the usually non-trivial task of the emulation of obsolete software environments from the end user to specialized providers can help to simplify digital preservation and access strategies. Besides offering their users better access to their holdings, libraries and archives may gain new business opportunities to offer services to a third party, such as businesses requiring authentic reproduction of digital objects and processes for legal reasons. This paper discusses cloud concepts as the next logical step for accessing original digital material. Emulation-as-a-Service (EaaS) fills the gap between the successful demonstration of emulation strategies as a long term access strategy and it’s perceived availability and usability. EaaS can build upon the ground of research and prototypical implementations of previous projects, and reuse well established remote access technology. In this article we develop requirements and a system model, suitable for a distributed environment. We will discuss the building blocks of the core services as well as requirements regarding access management. Finally, we will try to present a business model and estimate costs to implement and run such a service. The implementations of EaaS will influence future preservation planning in memory institutions, as it shifts the focus on object access workflows. ",
        "article_title": "Towards Emulation-as-a-Service: Cloud Services for Versatile Digital Object Access",
        "authors": [
            {
                "given": "Dirk",
                "family": "Von Suchodoletz",
                "affiliation": [
                    "University of Freiburg"
                ]
            },
            {
                "given": "Klaus",
                "family": "Rechert",
                "affiliation": [
                    "University of Freiburg"
                ]
            },
            {
                "given": "Isgandar",
                "family": "Valizada",
                "affiliation": [
                    ""
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2013-06-14",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "8",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v8i1.249",
        "identifier": {
            "string_id": "10.2218/ijdc.v8i1.249",
            "id_scheme": "DOI"
        },
        "abstract": "To preserve digital information it is vital that the format of that information can be identified, in-perpetuity. This is the major focus of research within the field of Digital Preservation. The National Archives of the UK called for the Digital Preservation and Digital Curation communities to develop a test corpus of digital objects to help further develop tools to aid this purpose. Following that call, an attempt has been made to develop the suite. This paper initially outlines a methodology to generate a skeleton corpus using simple user-generated digital objects. It then explores the lessons learnt in the generation of a corpus using scripting language techniques from the file format signatures described in The National Archives PRONOM technical registry. It will also discuss the use of the digital signature for this purpose, the benefits of developing a test corpus using this technique. Finally, this paper will outline a methodology for future research before exploring how the community can best make use of the output of this project and how this project needs to be taken forward to completion. ",
        "article_title": "Generation of a Skeleton Corpus of Digital Objects for the Validation and Evaluation of Format Identification Tools and Signatures",
        "authors": [
            {
                "given": "Ross",
                "family": "Spencer",
                "affiliation": [
                    "Independent Digital Preservation Researcher"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2013-06-14",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "8",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v8i1.248",
        "identifier": {
            "string_id": "10.2218/ijdc.v8i1.248",
            "id_scheme": "DOI"
        },
        "abstract": "The LOCKSS system is a leading technology in the field of Distributed Digital Preservation. Libraries run LOCKSS boxes to collect and preserve content published on the Web in PC servers with local disk storage. They form nodes in a network that continually audits their content and repairs any damage. Libraries wondered whether they could use cloud storage for their LOCKSS boxes instead of local disks. We review the possible configurations, evaluate their technical feasibility, assess their economic feasibility, report on an experiment in which we ran a production LOCKSS box in Amazon’s cloud service, and describe some simulations of future costs of cloud and local storage. We conclude that current cloud storage services are not cost-competitive with local hardware for long term storage, including for LOCKSS boxes.",
        "article_title": "Distributed Digital Preservation in the Cloud",
        "authors": [
            {
                "given": "David S. H.",
                "family": "Rosenthal",
                "affiliation": [
                    "Stanford University Libraries"
                ]
            },
            {
                "given": "Daniel L.",
                "family": "Vargas",
                "affiliation": [
                    "Stanford University Libraries"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2013-06-14",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "8",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v8i1.238",
        "identifier": {
            "string_id": "10.2218/ijdc.v8i1.238",
            "id_scheme": "DOI"
        },
        "abstract": "This paper examines the development of the Open Access movement in scholarly communication, with particular attention to some of the rhetorical strategies and policy mechanisms used to promote it to scholars and scientists. Despite the majority of journal publishers’ acceptance of author self-archiving practices, and the minimal time commitment required by authors to successfully self-archive their work in disciplinary or institutional repositories, the majority of authors still by and large avoid participation. The paper reviews the strategies and arguments used for increasing author participation in open access, including the role of open access mandates. We recommend a service-oriented approach towards increasing participation in open access, rather than rhetoric that speculates on the benefits that open access will have on text/data mining innovation. In advocating for open access participation, we recommend focusing on its most universal and tangible purpose: increasing public open (gratis) access to the published results of publicly funded research.  Researchers require strong institutional support to understand the copyright climate of open access self-archiving, user-friendly interfaces and useful metrics, such as repository usage statistics. We recommend that mandates and well-crafted and responsive author support services at universities will ultimately be required to ensure the growth of open access. We describe the mediated deposit service that was developed to support author self-archiving in Spectrum: Concordia University Research Repository. By comparing the number of deposits of non-thesis materials (e.g. articles and conference presentations) that were accomplished through the staff-mediated deposit service to the number of deposits that were author-initiated, we demonstrate the relative significance of this service to the growth of the repository.",
        "article_title": "The Critical Role of Institutional Services in Open Access Advocacy",
        "authors": [
            {
                "given": "Tomasz",
                "family": "Neugebauer",
                "affiliation": [
                    "Concordia University"
                ]
            },
            {
                "given": "Annie",
                "family": "Murray",
                "affiliation": [
                    "Concordia University"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2013-06-14",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "8",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v8i1.242",
        "identifier": {
            "string_id": "10.2218/ijdc.v8i1.242",
            "id_scheme": "DOI"
        },
        "abstract": "With digital curation’s increasingly important role in the fast-paced and data-intensive information environment, there is a need to identify a set of competencies for professionals in this growing field. As part of a curriculum development project funded by the U.S. Institute of Museum and Library Services, a total of 173 job advertisements posted between October 2011 and April 2012 were collected from various sources to take into account varying types of professionals in the field of digital curation across North America. Position title, institution types and location, educational background, experience, knowledge and skills, and duties were examined and analyzed. The results of the analysis show that digital curation jobs are characterized by a complex interplay of various skills and knowledge. The findings of this study present emerging requirements for a qualified workforce in the field of digital curation.",
        "article_title": "Competencies Required for Digital Curation: An Analysis of Job Advertisements",
        "authors": [
            {
                "given": "Jeonghyun",
                "family": "Kim",
                "affiliation": [
                    "University of North Texas"
                ]
            },
            {
                "given": "Edward",
                "family": "Warga",
                "affiliation": [
                    "University of North Texas"
                ]
            },
            {
                "given": "William",
                "family": "Moen",
                "affiliation": [
                    "University of North Texas"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2013-06-14",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "8",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v8i1.237",
        "identifier": {
            "string_id": "10.2218/ijdc.v8i1.237",
            "id_scheme": "DOI"
        },
        "abstract": "The preservation of artistic works with technological components, such as musical works, is recognised as an issue by both the artistic community and the archival community. Preserving such works involves tackling the difficulties associated with digital information in general, but also raises its own specific problems, such as constantly evolving digital instruments embodied within software and idiosyncratic human-computer interactions. Because of these issues, standards in place for archiving digital information are not always suitable for the preservation of these works. The impact on the organisation and the descriptions of such archives need to be conceptualised in order to provide these technological components with readability, authenticity and intelligibility. While previous projects emphasized readability and authenticity, less effort has been dedicated to addressing intelligibility issues. The research into the specification of significant properties and its extension, namely significant knowledge, offers some grounds for reflecting on this question. Furthermore, the relevance of taking into account the creative process involved in the production of technological components offers an opportunity to redefine the status of technological agents in the performative aspect of digital records. Altogether, the research on significant knowledge and creative processes provide us with a conceptual framework that we propose to bring together with digital archives models to form a coherent framework. ",
        "article_title": "A Digital Archives Framework for the Preservation of Cultural Artifacts with Technological Components",
        "authors": [
            {
                "given": "Guillaume",
                "family": "Boutard",
                "affiliation": [
                    "McGill University"
                ]
            },
            {
                "given": "Catherine",
                "family": "Guastavino",
                "affiliation": [
                    "McGill University"
                ]
            },
            {
                "given": "James",
                "family": "Turner",
                "affiliation": [
                    "Université de Montréal"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2013-06-14",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "8",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v8i1.247",
        "identifier": {
            "string_id": "10.2218/ijdc.v8i1.247",
            "id_scheme": "DOI"
        },
        "abstract": "‘Big Science’ - that is, science which involves large collaborations with dedicated facilities, and involving large data volumes and multinational investments – is often seen as different when it comes to data management and preservation planning. Big Science handles its data differently from other disciplines and has data management problems that are qualitatively different from other disciplines. In part, these differences arise from the quantities of data involved, but possibly more importantly from the cultural, organisational and technical distinctiveness of these academic cultures. Consequently, the data management systems are typically and rationally bespoke, but this means that the planning for data management and preservation (DMP) must also be bespoke. These differences are such that ‘just read and implement the OAIS specification’ is reasonable Data Management and Preservation (DMP) advice, but this bald prescription can and should be usefully supported by a methodological ‘toolkit’, including overviews, case-studies and costing models to provide guidance on developing best practice in DMP policy and infrastructure for these projects, as well as considering OAIS validation, audit and cost modelling. In this paper, we build on previous work with the LIGO collaboration to consider the role of DMP planning within these big science scenarios, and discuss how to apply current best practice. We discuss the result of the MaRDI-Gross project (Managing Research Data Infrastructures – Big Science), which has been developing a toolkit to provide guidelines on the application of best practice in DMP planning within big science projects. This is targeted primarily at projects’ engineering managers, but intending also to help funders collaborate on DMP plans which satisfy the requirements imposed on them. ",
        "article_title": "Data Management and Preservation Planning for Big Science",
        "authors": [
            {
                "given": "Juan",
                "family": "Bicarregui",
                "affiliation": [
                    "Scientific Computing Department, STFC"
                ]
            },
            {
                "given": "Norman",
                "family": "Gray",
                "affiliation": [
                    "University of Glasgow"
                ]
            },
            {
                "given": "Rob",
                "family": "Henderson",
                "affiliation": [
                    "University of Lancaster"
                ]
            },
            {
                "given": "Roger",
                "family": "Jones",
                "affiliation": [
                    "University of Lancaster"
                ]
            },
            {
                "given": "Simon",
                "family": "Lambert",
                "affiliation": [
                    "Scientific Computing Department, STFC"
                ]
            },
            {
                "given": "Brian",
                "family": "Matthews",
                "affiliation": [
                    "Scientific Computing Department, STFC"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2013-06-14",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "8",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v8i1.246",
        "identifier": {
            "string_id": "10.2218/ijdc.v8i1.246",
            "id_scheme": "DOI"
        },
        "abstract": "The fast growth of scientific and non-scientific digital data, as well as the proliferation of new types of digital content, has led – among many other things – to a lot of innovative work on the concept of the identifier. Digital identifiers have become the key to preserving and accessing content, just as physical identifier tags have been the key to accessing paper-based content and other physical entities for millennia. Two main schools of thought have emerged: on the one hand, librarians and public repositories have pushed the concept of the Persistent Identifier (PI) as a way to guarantee long term identification and (sometimes) access; on the other hand, the extraordinary success of the web has led several researchers and web experts to push the concept of the Cool URI as the universal mechanism for identifying and accessing digital content. Both views have their pros and cons, but so far (with only a few exceptions) the two visions have developed in parallel, sometimes with a subtle underlying hostility. In this paper, we present the evolution of the Entity Name System (ENS), an open service-based platform developed as part of the OKKAM EU co-funded project, which can reconcile these two approaches. The new system, called ENS2.0, is currently under development and will enable data creators and curators to combine the technical strengths and opportunities of the (Semantic) Web vision with the organizational, economical and social requirements legitimately raised by the PI community and stakeholders. ",
        "article_title": "Can Persistent Identifiers Be Cool?",
        "authors": [
            {
                "given": "Barbara",
                "family": "Bazzanella",
                "affiliation": [
                    "DISI, University of Trento"
                ]
            },
            {
                "given": "Stefano",
                "family": "Bortoli",
                "affiliation": [
                    "DISI, University of Trento"
                ]
            },
            {
                "given": "Paolo",
                "family": "Bouquet",
                "affiliation": [
                    "DISI, University of Trento"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2013-06-14",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "8",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v8i1.245",
        "identifier": {
            "string_id": "10.2218/ijdc.v8i1.245",
            "id_scheme": "DOI"
        },
        "abstract": "To qualify materials for specific applications comprehensive testing is necessary, and consequently the engineering materials community has developed an extensive collection of documentary testing standards to define test conditions, specimen configurations, and post processing and reporting procedures. Unfortunately, in the absence of corresponding data formats, test results are rarely conserved and their value diminishes as the material pedigree, test conditions, and results become disassociated. In an effort to address this issue, prenormative research has demonstrated the viability of deriving data formats from documentary testing standards and thus the possibility to realize a standards-based data infrastructure for the engineering materials community.",
        "article_title": "Prenormative Research into Standard Messaging Formats for Engineering Materials Data",
        "authors": [
            {
                "given": "Tim",
                "family": "Austin",
                "affiliation": [
                    "European Commission Joint Research Centre Institute for Energy and Transport"
                ]
            },
            {
                "given": "Chris",
                "family": "Bullough",
                "affiliation": [
                    "Alstom Power"
                ]
            },
            {
                "given": "Dimitri",
                "family": "Gagliardi",
                "affiliation": [
                    "University of Manchester"
                ]
            },
            {
                "given": "David",
                "family": "Leal",
                "affiliation": [
                    "CAESAR Systems"
                ]
            },
            {
                "given": "Malcolm",
                "family": "Loveday",
                "affiliation": [
                    "Beta Technology"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2013-06-14",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "8",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v8i2.268",
        "identifier": {
            "string_id": "10.2218/ijdc.v8i2.268",
            "id_scheme": "DOI"
        },
        "abstract": "This paper describes work undertaken by Data Intensive Cyber Environments Center (DICE) at the University of North Carolina at Chapel Hill and the University of Liverpool on the development of an integrated preservation environment, which has been presented at the National Coordination Office for Networking and Information Technology Research and Development (NITRD), at the National Science Foundation, and at the European Commission. The underlying technology is based on the integrated Rule-Oriented Data System (iRODS), which implements a policy-based approach to distributed data management. By differentiating between different phases of the data life cycle based upon the evolution of data management policies, the infrastructure can be tuned to support data publication, data sharing, data analysis and data preservation. It is possible to build generic data management infrastructure that can evolve to meet the management requirements of each user community, federal agency and academic research project. In order to manage the properties of the data collections, we have developed and integrated scalable digital library services that support the discovery of, and access to, material organized as a collection.The integrated preservation environment prototype implements specific technologies that are capable of managing a wide range of preservation requirements, from parsing of legacy document formats, to enforcement of preservation policies, to validation of trustworthiness assessment criteria. Each capability has been demonstrated and is instantiated in multiple instances, both in the United States as part of the DataNet Federation Consortium (DFC) and through multiple European projects, primarily the FP7 SHAMAN project. ",
        "article_title": "Evolving Persistent Archives and Digital Library Systems: Integrating iRods, Cheshire3 and Multivalent",
        "authors": [
            {
                "given": "Reagan",
                "family": "Moore",
                "affiliation": [
                    "University of North Carolina"
                ]
            },
            {
                "given": "Arcot",
                "family": "Rajasekar",
                "affiliation": [
                    "University of North Carolina"
                ]
            },
            {
                "given": "Paul",
                "family": "Watry",
                "affiliation": [
                    "University of Liverpool"
                ]
            },
            {
                "given": "Fabio",
                "family": "Corubolo",
                "affiliation": [
                    "University of Liverpool"
                ]
            },
            {
                "given": "John",
                "family": "Harrison",
                "affiliation": [
                    "University of Liverpool"
                ]
            },
            {
                "given": "Jerome",
                "family": "Fuselier",
                "affiliation": [
                    "University of Liverpool"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2013-11-19",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "8",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v8i2.262",
        "identifier": {
            "string_id": "10.2218/ijdc.v8i2.262",
            "id_scheme": "DOI"
        },
        "abstract": "The task repurposing of heterogeneous, distributed data for originally unintended research objectives is a non-trivial problem because the mappings required may not be precise. A particular case is clinical data collected for patient care being used for medical research. The fact that research repositories will record data differently means that assumptions must be made as how to transform of this data. Records of provenance that document how this process has taken place will enable users of the data warehouse to utilise the data appropriately and ensure that future data added from another source is transformed using comparable assumptions. For a provenance-based approach to be reusable and supportable with software tools, the provenance records must use a well-defined model of the transformation process. In this paper, we propose such a model, including a classification of the individual ‘sub-functions’ that make up the overall transformation. This model enables meaningful provenance data to be generated automatically. A case study is used to illustrate this approach and an initial classification of transformations that alter the information is created.",
        "article_title": "Informative Provenance for Repurposed Data: A Case Study using Clinical Research Data",
        "authors": [
            {
                "given": "Richard",
                "family": "Bache",
                "affiliation": [
                    "King’s College London"
                ]
            },
            {
                "given": "Simon",
                "family": "Miles",
                "affiliation": [
                    "King’s College London"
                ]
            },
            {
                "given": "Bolaji",
                "family": "Coker",
                "affiliation": [
                    "King’s College London",
                    "Biomedical Research Centre,Guy’s and St Thomas’ NHS Foundation Trust"
                ]
            },
            {
                "given": "Adel",
                "family": "Taweel",
                "affiliation": [
                    "King’s College London"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2013-11-19",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "8",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v8i2.263",
        "identifier": {
            "string_id": "10.2218/ijdc.v8i2.263",
            "id_scheme": "DOI"
        },
        "abstract": "Academic librarians are increasingly engaging in data curation by providing infrastructure (e.g., institutional repositories) and offering services (e.g., data management plan consultations) to support the management of research data on their campuses. Efforts to develop these resources may benefit from a greater understanding of disciplinary differences in research data management needs. After conducting a survey of data management practices and perspectives at our research university, we categorized faculty members into four research domains—arts and humanities, social sciences, medical sciences, and basic sciences—and analyzed variations in their patterns of survey responses. We found statistically significant differences among the four research domains for nearly every survey item, revealing important disciplinary distinctions in data management actions, attitudes, and interest in support services. Serious consideration of both the similarities and dissimilarities among disciplines will help guide academic librarians and other data curation professionals in developing a range of data-management services that can be tailored to the unique needs of different scholarly researchers.",
        "article_title": "Disciplinary differences in faculty research data management practices and perspectives",
        "authors": [
            {
                "given": "Katherine G.",
                "family": "Akers",
                "affiliation": [
                    "Emory University Libraries"
                ]
            },
            {
                "given": "Jennifer",
                "family": "Doty",
                "affiliation": [
                    "Emory University Libraries"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2013-11-19",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "8",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v9i1.304",
        "identifier": {
            "string_id": "10.2218/ijdc.v9i1.304",
            "id_scheme": "DOI"
        },
        "abstract": " Data sharing is a difficult process for both the data producer and the data reuser. Both parties are faced with more disincentives than incentives. Data producers need to sink time and resources into adding metadata for data to be findable and usable, and there is no promise of receiving credit for this effort. Making data available also leaves data producers vulnerable to being scooped or data misuse. Data reusers also need to sink time and resources into evaluating data and trying to understand them, making collecting their own data a more attractive option. In spite of these difficulties, some data producers are looking for new ways to make data sharing and reuse a more viable option. This paper presents two cases from the surface and climate modeling communities, where researchers who produce data are reaching out to other researchers who would be interested in reusing the data. These cases are evaluated as a strategy to identify ways to overcome the challenges typically experienced by both data producers and data reusers. By working together with reusers, data producers are able to mitigate the disincentives and create incentives for sharing data. By working with data producers, data reusers are able to circumvent the hurdles that make data reuse so challenging. ",
        "article_title": "Data Producers Courting Data Reusers: Two Cases from Modeling Communities",
        "authors": [
            {
                "given": "Jillian",
                "family": "Wallis",
                "affiliation": [
                    "University of California"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2014-06-12",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "9",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v9i1.303",
        "identifier": {
            "string_id": "10.2218/ijdc.v9i1.303",
            "id_scheme": "DOI"
        },
        "abstract": " In the era of research infrastructures and big data, sophisticated data management practices are becoming essential building blocks of successful science. Most practices follow a data-centric approach, which does not take into account the processes that created, analysed and presented the data. This fact limits the possibilities for reliable verification of results. Furthermore, it does not guarantee the reuse of research, which is one of the key aspects of credible data-driven science. For that reason, we propose the introduction of the new concept of Process Management Plans, which focus on the identification, description, sharing and preservation of the entire scientific processes. They enable verification and later reuse of result data and processes of scientific experiments. In this paper we describe the structure and explain the novelty of Process Management Plans by showing in what way they complement existing Data Management Plans. We also highlight key differences, major advantages, as well as references to tools and solutions that can facilitate the introduction of Process Management Plans. ",
        "article_title": "Process Management Plans",
        "authors": [
            {
                "given": "Tomasz",
                "family": "Miksa",
                "affiliation": [
                    "SBA Research"
                ]
            },
            {
                "given": "Stephan",
                "family": "Strodl",
                "affiliation": [
                    "SBA Research"
                ]
            },
            {
                "given": "Andreas",
                "family": "Rauber",
                "affiliation": [
                    "SBA Research",
                    " Vienna University of Technology"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2014-05-30",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "9",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v9i1.302",
        "identifier": {
            "string_id": "10.2218/ijdc.v9i1.302",
            "id_scheme": "DOI"
        },
        "abstract": " In this paper we describe eBird, a highly successful citizen science project. With over 150,000 participants worldwide and an accumulation of over 140,000,000 bird observations globally in the last decade, eBird has evolved into a major tool for scientific investigations in diverse fields such as ornithology, computer science, statistics, ecology and climate change. eBird’s impact in scientific research is grounded in careful data curation practices that pay attention to all stages of the data lifecycle, and attend to the needs of stakeholders engaged in that data lifecycle. We describe the important aspects of eBird, paying particular attention to the mechanisms to improve data quality; describe the data products that are available to the global community; investigate some aspects of the downloading community; and demonstrate significant results that derive from the use of openly-available eBird data. ",
        "article_title": "eBird: Curating Citizen Science Data for Use by Diverse Communities",
        "authors": [
            {
                "given": "Carl",
                "family": "Lagoze",
                "affiliation": [
                    "University of Michigan"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2014-05-30",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "9",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v9i1.301",
        "identifier": {
            "string_id": "10.2218/ijdc.v9i1.301",
            "id_scheme": "DOI"
        },
        "abstract": " We present a case study of data integration and reuse involving 12 researchers who published datasets in Open Context, an online data publishing platform, as part of collaborative archaeological research on early domesticated animals in Anatolia. Our discussion reports on how different editorial and collaborative review processes improved data documentation and quality, and created ontology annotations needed for comparative analyses by domain specialists. To prepare data for shared analysis, this project adapted editor-supervised review and revision processes familiar to conventional publishing, as well as more novel models of revision adapted from open source software development of public version control. Preparing the datasets for publication and analysis required significant investment of effort and expertise, including archaeological domain knowledge and familiarity with key ontologies. To organize this work effectively, we emphasized these different models of collaboration at various stages of this data publication and analysis project. Collaboration first centered on data editors working with data contributors, then widened to include other researchers who provided additional peer-review feedback, and finally the widest research community, whose collaboration is facilitated by GitHub’s version control system. We demonstrate that the “publish” and “push” models of data dissemination need not be mutually exclusive; on the contrary, they can play complementary roles in sharing high quality data in support of research. This work highlights the value of combining multiple models in different stages of data dissemination. ",
        "article_title": "Publishing and Pushing: Mixing Models for Communicating Research Data in Archaeology",
        "authors": [
            {
                "given": "Eric C.",
                "family": "Kansa",
                "affiliation": [
                    "Open Context",
                    "University ofCalifornia, Berkeley"
                ]
            },
            {
                "given": "Sarah Whitcher",
                "family": "Kansa",
                "affiliation": [
                    "Open Context"
                ]
            },
            {
                "given": "Benjamin",
                "family": "Arbuckle",
                "affiliation": [
                    "The University of North Carolina,Chapel Hill"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2014-05-30",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "9",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v9i1.299",
        "identifier": {
            "string_id": "10.2218/ijdc.v9i1.299",
            "id_scheme": "DOI"
        },
        "abstract": " In eScience, where vast data collections are processed in scientific workflows, new risks and challenges are emerging. Those challenges are changing the eScience paradigm, mainly regarding digital preservation and scientific workflows. To address specific concerns with data management in these scenarios, the concept of the Data Management Plan was established, serving as a tool for enabling digital preservation in eScience research projects. We claim risk management can be jointly used with a Data Management Plan, so new risks and challenges can be easily tackled. Therefore, we propose an analysis process for eScience projects using a Data Management Plan and ISO 31000 in order to create a Risk Management Plan that can complement the Data Management Plan. The motivation, requirements and validation of this proposal are explored in the MetaGen-FRAME project, focused in Metagenomics. ",
        "article_title": "Data Management in Metagenomics: A Risk Management Approach",
        "authors": [
            {
                "given": "Filipe",
                "family": "Ferreira",
                "affiliation": [
                    "Universidade de Lisboa, Portugal"
                ]
            },
            {
                "given": "Miguel E.",
                "family": "Coimbra",
                "affiliation": [
                    "Universidade de Lisboa, Portugal"
                ]
            },
            {
                "given": "Raquel",
                "family": "Bairrão",
                "affiliation": [
                    "Universidade de Lisboa, Portugal"
                ]
            },
            {
                "given": "Ricardo",
                "family": "Viera",
                "affiliation": [
                    "Universidade de Lisboa, Portugal"
                ]
            },
            {
                "given": "Ana T.",
                "family": "Freitas",
                "affiliation": [
                    "Universidade de Lisboa, Portugal"
                ]
            },
            {
                "given": "Luís M. S.",
                "family": "Russo",
                "affiliation": [
                    "Universidade de Lisboa, Portugal"
                ]
            },
            {
                "given": "José",
                "family": "Borbinha",
                "affiliation": [
                    "Universidade de Lisboa, Portugal"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2014-05-29",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "9",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v9i1.298",
        "identifier": {
            "string_id": "10.2218/ijdc.v9i1.298",
            "id_scheme": "DOI"
        },
        "abstract": " Citizen Cyberscience Projects (CCPs) that recruit members of the public as volunteers to process and produce large datasets promise a great deal of benefits to scientists and science. However, if this promise is to be realised, and citizen science-produced datasets are to be widely used by scientists, it is essential that these datasets win the trust of the scientific community. This task of securing credibility involves, in part, applying standard scientific procedures to clean up datasets formed by volunteer contributions. However, the management of volunteers’ behaviour in terms of how they contribute also plays a significant role in improving both the quality of individual contributions and the overall robustness of the resultant datasets. This can assist CCPs in securing a reputation for producing trustworthy datasets.  Through a case study of Galaxy Zoo, a CCP set up to generate datasets based on volunteer classifications of galaxy morphologies, this paper explores how those involved in running the project manage volunteers. In particular, it focuses on how methods for crediting volunteer contributions motivate volunteers to provide higher quality contributions and to behave in a way that better corresponds to statistical assumptions made when combining volunteer contributions into datasets. These methods have made a significant contribution to the success of the project in securing trust in these datasets, which have been well used by other scientists.  Implications for practice are then presented for CCPs, providing a list of considerations to guide choices regarding how to credit volunteer contributions to improve the quality and trustworthiness of citizen science-produced datasets. ",
        "article_title": "Managing the Public to Manage Data: Citizen Science and Astronomy",
        "authors": [
            {
                "given": "Peter",
                "family": "Darch",
                "affiliation": [
                    "University of California Los Angeles"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2014-05-29",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "9",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v9i1.297",
        "identifier": {
            "string_id": "10.2218/ijdc.v9i1.297",
            "id_scheme": "DOI"
        },
        "abstract": " The plethora of new data sources, combined with a growing interest in increased access to previously unpublished data, poses a set of ethical challenges regarding individual privacy. This paper sets out one aspect of those challenges: the need to anonymise data in such a form that protects the privacy of individuals while providing sufficient data utility for data users. This issue is discussed using a case study of Scottish Government’s administrative data, in which disclosure risk is examined and data utility is assessed using a potential ‘real-world’ analysis. ",
        "article_title": "Examining Disclosure Risk and Data Utility: An Administrative Data Case Study",
        "authors": [
            {
                "given": "Michael",
                "family": "Comerford",
                "affiliation": [
                    "University of Glasgow"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2014-05-29",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "9",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v9i1.288",
        "identifier": {
            "string_id": "10.2218/ijdc.v9i1.288",
            "id_scheme": "DOI"
        },
        "abstract": " The growth of television, and in particular television news, has created a challenge in preserving and providing access to the resulting material. At the same time, technology has opened many opportunities to capture this information and make it more widely available. In some ways, it is a race of technology against the speed of content creation. In this paper, we describe a very successful archival project that records, indexes, archives and makes available the totality of the programming of the U.S. based C-SPAN television network, a nonprofit network that telecasts the entirety of the U.S. congressional proceedings, hearings, presidential speeches and other public policy events. As such, it is an archive of unedited primary source events. The use of evolving technology over 25 years has made this archive possible and it exists free on the Internet for world-wide access. ",
        "article_title": "Creating an Online Television Archive, 1987–2013",
        "authors": [
            {
                "given": "Robert",
                "family": "Browning",
                "affiliation": [
                    "Purdue University"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2014-05-28",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "9",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v9i2.272",
        "identifier": {
            "string_id": "10.2218/ijdc.v9i2.272",
            "id_scheme": "DOI"
        },
        "abstract": "Based on existing appraisal/selection policies in libraries, archives, museum, social science and science data centers, this paper presents a generic appraisal/selection framework for digital curation. In presenting this framework, the author discusses how archival appraisal theories, methods, and criteria adapt to the general digital curation context.",
        "article_title": "Appraisal and Selection for Digital Curation",
        "authors": [
            {
                "given": "Jinfang",
                "family": "Niu",
                "affiliation": [
                    "University of South Florida"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2014-10-23",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "9",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v9i2.267",
        "identifier": {
            "string_id": "10.2218/ijdc.v9i2.267",
            "id_scheme": "DOI"
        },
        "abstract": " In recent years the Portable Document Format (PDF) has become a ubiquitous format in the exchange of documents; in 2005 the PDF/A profile was defined in order to meet long term accessibility needs, and has accordingly come to be regarded as a long-term archiving strategy for PDF files. In the field of archaeology, a growing number of PDF files – containing the detailed results of fieldwork and research – are beginning to be deposited with digital archives such as the Archaeology Data Service (ADS). In the ADS’ experience, the use of PDF/A has had benefits as well as drawbacks: the majority of PDF reports are now in a standard format better suited to longer-term access, however migrating to PDF/A and managing and ensuring reuse of these files is intensive, and fraught with potential pitfalls. Of these, perhaps the most serious has been an unreliability in PDF/A conformance by the wide range of tools and software now available. There are also practical and more theoretical implications for reuse which, as our discipline of archaeology alongside so many others rapidly becomes digitized, presents us with a large corpus of ‘data’ that is human readable, but may not be amenable to machine-based technologies such as NLP. It may be argued that these factors effectively undermine some of the perceived cost benefit of moving from paper to digital, as well as the longer-term sustainability of PDF/A within digital archives. ",
        "article_title": "The Use of PDF/A in Digital Archives: A Case Study from Archaeology",
        "authors": [
            {
                "given": "Tim N. L.",
                "family": "Evans",
                "affiliation": [
                    "Archaeology Data Service"
                ]
            },
            {
                "given": "Ray H.",
                "family": "Moore",
                "affiliation": [
                    "Archaeology Data Service"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2014-10-29",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "9",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v9i2.294",
        "identifier": {
            "string_id": "10.2218/ijdc.v9i2.294",
            "id_scheme": "DOI"
        },
        "abstract": " Video games are a cultural phenomenon; a medium like no other that has become one of the largest entertainment sectors in the world. While the UK boasts an enviable games development heritage, it risks losing a major part of its cultural output through an inability to preserve the games that are created by the country’s independent games developers. The issues go deeper than bit rot and other problems that affect all digital media; loss of context, copyright and legal issues, and the throwaway culture of the ‘next’ game all hinder the ability of fans and academics to preserve video games and make them accessible in the future.  This study looked at the current attitudes towards preservation in the UK’s independent (‘indie’) video games industry by examining current record-keeping practices and analysing the views of games developers. The results show that there is an interest in preserving games, and possibly a desire to do so, but issues of piracy and cost prevent the industry from undertaking preservation work internally, and from allowing others to assume such responsibility. The recommendation made by this paper is not simply for preservation professionals and enthusiasts to collaborate with the industry, but to do so by advocating the commercial benefits that preservation may offer to the industry. ",
        "article_title": "Video Game Preservation in the UK: A Survey of Records Management Practices",
        "authors": [
            {
                "given": "Alasdair",
                "family": "Bachell",
                "affiliation": [
                    "Perth and Kinross Council Archives"
                ]
            },
            {
                "given": "Matthew",
                "family": "Barr",
                "affiliation": [
                    "HATII, University of Glasgow"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2014-10-29",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "9",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v10i1.344",
        "identifier": {
            "string_id": "10.2218/ijdc.v10i1.344",
            "id_scheme": "DOI"
        },
        "abstract": "The Data Curation Profiles Toolkit (DCPT) emerged out of a Purdue University Libraries’ 2004 initiative to engage in multidisciplinary research. It is a tool developed to assist librarians and other information professionals to conduct data interviews and identify the needs of researchers when managing, sharing, or curating their data. The DCPT has been widely adopted and applied in various contexts but its usability as a tool has not been formally assessed. To address this need, we have conducted a survey of users of the DCPT. The survey included quantitative measures of potential influencing factors of using the DCPT and its perceived usability (its usefulness as a tool and its ease of use). Open-ended questions about users’ experiences with the DCPT were also included to better understand the strengths and weaknesses of the tool, as well as areas that could be improved. Factor analysis of the quantitative results and subsequent regression models revealed several underlying factors that affect the perceived usability of the DCPT. Responses to the open-ended questions revealed several themes of users’ concerns: the amount of time required to use the DCPT, the structure and format of the DCPT, alignment of the DCPT with particular contexts, and the use of the DCPT to engage faculty and the library community. By correlating themes identified from the open-ended questions with the analysis of quantitative data, this paper provides the first empirical assessment of the DCPT that could help further improve the toolkit’s usability based on user needs and expectations. The methodology used in the study could readily be applied to assess and improve the utility of other tools used by data and information professional. ",
        "article_title": "Assessing Perceived Usability of the Data Curation Profile Toolkit Using the Technology Acceptance Model",
        "authors": [
            {
                "given": "Tao",
                "family": "Zhang",
                "affiliation": [
                    "Purdue University"
                ]
            },
            {
                "given": "Lisa",
                "family": "Zilinski",
                "affiliation": [
                    "Carnegie Mellon University"
                ]
            },
            {
                "given": "D. Scott",
                "family": "Brandt",
                "affiliation": [
                    "Purdue University"
                ]
            },
            {
                "given": "Jake",
                "family": "Carlson",
                "affiliation": [
                    "University of Michigan"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2015-01-30",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "10",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v10i1.343",
        "identifier": {
            "string_id": "10.2218/ijdc.v10i1.343",
            "id_scheme": "DOI"
        },
        "abstract": "User-defined metadata is useful for curating and helping to provide context for experiment records, but our previous investigations have demonstrated that simply providing the facility to add metadata is not enough to ensure that metadata is added, let alone to ensure that the metadata is of high quality. For metadata to be useful it first has to be present, but enforcing metadata generation is of no benefit if it is low quality, inconsistent, or irrelevant. Researchers need support. One strategy to encourage more effective metadata creation is to design user interfaces that invite users to add metadata by asking them questions. If we ask users specific questions about their experiments and other activities then we could capture more relevant or useful metadata, although there is a risk that asking the wrong questions may lead to loss of valuable metadata terms or the creation of irrelevant material. In this paper we report on a study to investigate how different questions could be used to generate metadata by eliciting information in three different conditions: free recall, changing perspective by thinking about search terms to help someone else, and providing cues by using a set of topic-based questions. We also investigate how responses varied with different information types. The results of the study show that different terms are created under the different conditions, as expected. The use of cues generates the highest numbers of terms and the most diverse range, including elements that are not captured in other conditions. However, important themes generated in other conditions are not produced because the cues to create them are missing. The study also generated a number of unexpected findings, including responses describing information that is not in the original material: personal opinions and experiences, and comments about the information text itself. These unexpected responses have both positive and negative consequences for the generation of metadata and the curation of scientific records. The results of studies using these techniques to capture metadata for chemistry experiments are also discussed. ",
        "article_title": "User-Defined Metadata: Using Cues and Changing Perspectives",
        "authors": [
            {
                "given": "Cerys",
                "family": "Willoughby",
                "affiliation": [
                    "University of Southampton"
                ]
            },
            {
                "given": "Colin",
                "family": "Bird",
                "affiliation": [
                    "University of Southampton"
                ]
            },
            {
                "given": "Jeremy",
                "family": "Frey",
                "affiliation": [
                    "University of Southampton"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2015-01-30",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "10",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v10i1.289",
        "identifier": {
            "string_id": "10.2218/ijdc.v10i1.289",
            "id_scheme": "DOI"
        },
        "abstract": "In order to better understand the factors that most influence where researchers deposit their data when they have a choice, we collected survey data from researchers who deposited phylogenetic data in either the TreeBASE or Dryad data repositories. Respondents were asked to rank the relative importance of eight possible factors. We found that factors differed in importance for both TreeBASE and Dryad, and that the rankings differed subtly but significantly between TreeBASE and Dryad users. On average, TreeBASE users ranked the domain specialization of the repository highest, while Dryad users ranked as equal highest their trust in the persistence of the repository and the ease of its data submission process. Interestingly, respondents (particularly Dryad users) were strongly divided as to whether being directed to choose a particular repository by a journal policy or funding agency was among the most or least important factors. Some users reported depositing their data in multiple repositories and archiving their data voluntarily.",
        "article_title": "What Factors Influence Where Researchers Deposit their Data? A Survey of Researchers Submitting to Data Repositories",
        "authors": [
            {
                "given": "Shea",
                "family": "Swauger",
                "affiliation": [
                    "Colorado State University"
                ]
            },
            {
                "given": "Todd J.",
                "family": "Vision",
                "affiliation": [
                    "University of North Carolina at Chapel Hill"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2015-01-30",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "10",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v10i1.361",
        "identifier": {
            "string_id": "10.2218/ijdc.v10i1.361",
            "id_scheme": "DOI"
        },
        "abstract": "In this paper we consider the requirements for preserving the memory of science.  This is becoming more challenging as data volumes and rates continue to increase.  Further, to capture a full picture of the scientific memory we need to move beyond the bit preservation challenge to consider how to capture research in context, represent the meaning of the data, and how to interpret data in relation to other scientific artefacts distributed in multiple information spaces. We review the progress of scientific research into the digital preservation of science over the last decade, emphasising in particular the research and development programme of STFC. We conclude with a number of observations into the future directions of research and also the practical deployment of policy and infrastructure to effectively preserve the scientific memory.",
        "article_title": "Towards the Preservation of the Scientific Memory",
        "authors": [
            {
                "given": "Brian",
                "family": "Matthews",
                "affiliation": [
                    "STFC Scientific Computing DepartmentRutherford Appleton Laboratory"
                ]
            },
            {
                "given": "Shirley",
                "family": "Crompton",
                "affiliation": [
                    "STFC Scientific Computing DepartmentDaresbury Laboratory"
                ]
            },
            {
                "given": "Catherine",
                "family": "Jones",
                "affiliation": [
                    "STFC Scientific Computing DepartmentRutherford Appleton Laboratory"
                ]
            },
            {
                "given": "Simon",
                "family": "Lambert",
                "affiliation": [
                    "STFC Scientific Computing DepartmentRutherford Appleton Laboratory"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2015-04-30",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "10",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v10i1.360",
        "identifier": {
            "string_id": "10.2218/ijdc.v10i1.360",
            "id_scheme": "DOI"
        },
        "abstract": "The notion of a “designated community” has always been a rather elusive concept across the digital curation landscape. This paper is an effort to revisit the concept to stir up new discussions in the area. More specifically, this study offers a perspective on designated communities through the lens of the web, powered by developments in the last ten years in social media. The research presents a multi-faceted analysis of communities based on HTML content from online web pages to propose heuristics for defining designated communities based on the technology they adopt, properties of knowledge organisation, and how they link to each other. This impacts the building of quantifiable models of designated communities, estimating curation risks associated to the community and further, refining approaches to preservation strategies that meet the needs of the community.",
        "article_title": "“Designated Communities”: Through the Lens of the Web",
        "authors": [
            {
                "given": "Yunhyong",
                "family": "Kim",
                "affiliation": [
                    "University of Glasgow"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2015-04-30",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "10",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v10i1.324",
        "identifier": {
            "string_id": "10.2218/ijdc.v10i1.324",
            "id_scheme": "DOI"
        },
        "abstract": "This paper aims to give state-of-the-art information about digital preservation activities in the Czech Republic during the last decade to an English-speaking audience. We briefly describe major phases of the “digital” projects. These were mainly in libraries, with some references to museums, galleries and archives. We focus on aspects related to the preservation of collected born-digital and digitised content. Even now, digital preservation activities in heritage institutions are often on the periphery of the interest of all stakeholders and the infrastructure supporting digital preservation of data in heritage institutions is not well financed or coordinated. Even though the “long decade”, which lasted from the dramatic events of 2002 until approximately 2014, saw a number of successful projects creating digital data in Czech libraries, the handful of projects which were in part focused on digital preservation were not flexible enough to accommodate user requirements and were failing to meet expectations. There is still much room for further development in the area of long-term preservation of digital data in the Czech Republic.  This article is a shortened version of one of the analyses written under the “Strategy of the research, development and innovation for the years 2010–2015” program of the Moravian Library in Brno, Czech Republic. ",
        "article_title": "The long decade of digital preservation in heritage institutions in the Czech Republic: 2002–2014",
        "authors": [
            {
                "given": "Jan",
                "family": "Hutař",
                "affiliation": [
                    "Archives New Zealand"
                ]
            },
            {
                "given": "Marek",
                "family": "Melichar",
                "affiliation": [
                    "Charles University, Prague"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2015-03-25",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "10",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v10i1.347",
        "identifier": {
            "string_id": "10.2218/ijdc.v10i1.347",
            "id_scheme": "DOI"
        },
        "abstract": "Understanding the methods and processes implemented by data producers to generate research data is essential for fostering data reuse. Yet, producing the metadata that describes these methods remains a time-intensive activity that data producers do not readily undertake. In particular, researchers in the long tail of science often lack the financial support or tools for metadata generation, thereby limiting future access and reuse of data produced. The present study investigates research journal publications as a potential source for identifying descriptive metadata about methods for research data. Initial results indicate that journal articles provide rich descriptive content that can be sufficiently mapped to existing metadata standards with methods-related elements, resulting in a mapping of the data production process for a study. This research has implications for enhancing the generation of robust metadata to support the curation of research data for new inquiry and innovation. ",
        "article_title": "Mapping Methods Metadata for Research Data",
        "authors": [
            {
                "given": "Tiffany",
                "family": "Chao",
                "affiliation": [
                    "University of Illinois Urbana-Champaign"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2015-02-26",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "10",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v10i1.328",
        "identifier": {
            "string_id": "10.2218/ijdc.v10i1.328",
            "id_scheme": "DOI"
        },
        "abstract": " This article considers digital curation in doctoral study and the role of the doctoral supervisor and institution in facilitating students’ acquisition of digital curation skills, including some of the potentially problematic expectations of the supervisory relationship with regards to digital curation. Research took the form of an analysis of the current digital curation training landscape, focussing on doctoral study and supervision. This was followed by a survey (n=116) investigating attitudes towards importance, expertise, and responsibilities regarding digital curation. This research confirms that digital curation is considered to be very important within doctoral study but that doctoral supervisors and particularly students consider themselves to be largely unskilled at curation tasks. It provides a detailed picture of curation activity within doctoral study and identifies the areas of most concern. A detailed analysis demonstrates that most of the responsibility for curation is thought to lie with students and that institutions are perceived to have very low responsibility and that individuals tend to over-assign responsibility to themselves. Finally, the research identifies which types of support system for curation are most used and makes suggestions for ways in which students, supervisors, institutions, and others can effectively and efficiently address problematic areas and improve digital curation within doctoral study. ",
        "article_title": "Digital Curation and Doctoral Research",
        "authors": [
            {
                "given": "Daisy",
                "family": "Abbott",
                "affiliation": [
                    "Glasgow School of Art"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2015-01-30",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "10",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v10i2.359",
        "identifier": {
            "string_id": "10.2218/ijdc.v10i2.359",
            "id_scheme": "DOI"
        },
        "abstract": "This paper presents the results of a research data assessment and landscape study in the institutional context of Virginia Tech to determine the data sharing and reuse practices of academic faculty researchers. Through mapping the level of user engagement in “openness of data,” “openness of methodologies and workflows,” and “reuse of existing data,” this study contributes to the current knowledge in data sharing and open access, and supports the strategic development of institutional data stewardship. Asking faculty researchers to self-reflect sharing and reuse from both data producers’ and data users’ perspectives, the study reveals a significant gap between the rather limited sharing activities and the highly perceived reuse or repurpose values regarding data, indicating that potential values of data for future research are lost right after the original work is done. The localized and sporadic data management and documentation practices of researchers also contribute to the obstacles they themselves often encounter when reusing existing data.   ",
        "article_title": "Research Data Sharing and Reuse Practices of Academic Faculty Researchers: A Study of the Virginia Tech Data Landscape",
        "authors": [
            {
                "given": "Yi",
                "family": "Shen",
                "affiliation": [
                    "Virginia Polytechnic Institute and State University"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2016-05-14",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "10",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v10i2.321",
        "identifier": {
            "string_id": "10.2218/ijdc.v10i2.321",
            "id_scheme": "DOI"
        },
        "abstract": "A study of 56 professors at five American universities found that a majority had little understanding of principles, well-known in the field of data curation, informing the ongoing administration of digital materials and chose to manage and store work-related data by relying on the use of their own storage devices and cloud accounts. It also found that a majority of them had experienced the loss of at least one work-related digital object that they considered to be important in the course of their professional career. Despite such a rate of loss, a majority of respondents expressed at least a moderate level of confidence that they would be able to make use of their digital objects in 25 years. The data suggest that many faculty members are unaware that their data is at risk. They also indicate a strong correlation between faculty members’ digital object loss and their data management practices. University professors producing digital objects can help themselves by becoming aware that these materials are subject to loss. They can also benefit from awareness and use of better personal data management practices, as well as participation in university-level programmatic digital curation efforts and the availability of more readily accessible, robust infrastructure for the storage of digital materials. ",
        "article_title": "Intellectual Capital at Risk: Data Management Practices and Data Loss by Faculty Members at Five American Universities",
        "authors": [
            {
                "given": "Jaime",
                "family": "Schumacher",
                "affiliation": [
                    "Northern Illinois University"
                ]
            },
            {
                "given": "Drew",
                "family": "VandeCreek",
                "affiliation": [
                    "Northern Illinois University"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2015-07-31",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "10",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v10i2.342",
        "identifier": {
            "string_id": "10.2218/ijdc.v10i2.342",
            "id_scheme": "DOI"
        },
        "abstract": "As science becomes more data-intensive and collaborative, researchers increasingly use larger and more complex data to answer research questions. The capacity of storage infrastructure, the increased sophistication and deployment of sensors, the ubiquitous availability of computer clusters, the development of new analysis techniques, and larger collaborations allow researchers to address grand societal challenges in a way that is unprecedented. In parallel, research data repositories have been built to host research data in response to the requirements of sponsors that research data be publicly available. Libraries are re-inventing themselves to respond to a growing demand to manage, store, curate and preserve the data produced in the course of publicly funded research. As librarians and data managers are developing the tools and knowledge they need to meet these new expectations, they inevitably encounter conversations around Big Data. This paper explores definitions of Big Data that have coalesced in the last decade around four commonly mentioned characteristics: volume, variety, velocity, and veracity. We highlight the issues associated with each characteristic, particularly their impact on data management and curation. We use the methodological framework of the data life cycle model, assessing two models developed in the context of Big Data projects and find them lacking. We propose a Big Data life cycle model that includes activities focused on Big Data and more closely integrates curation with the research life cycle. These activities include planning, acquiring, preparing, analyzing, preserving, and discovering, with describing the data and assuring quality being an integral part of each activity. We discuss the relationship between institutional data curation repositories and new long-term data resources associated with high performance computing centers, and reproducibility in computational science. We apply this model by mapping the four characteristics of Big Data outlined above to each of the activities in the model. This mapping produces a set of questions that practitioners should be asking in a Big Data project ",
        "article_title": "Revisiting the Data Lifecycle with Big Data Curation",
        "authors": [
            {
                "given": "Line",
                "family": "Pouchard",
                "affiliation": [
                    "Purdue University Libraries"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2016-05-27",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "10",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v10i2.329",
        "identifier": {
            "string_id": "10.2218/ijdc.v10i2.329",
            "id_scheme": "DOI"
        },
        "abstract": "There is increasing pressure from funders, publishers, the public, universities and other research organisations for researchers to improve their data management and sharing practices. However, little is known about researchers’ data management and sharing practices and concerns. The research reported in this paper seeks to address this by providing insight into the research data management and sharing practices of academics at ten universities in New South Wales, Australia. Empirical data was taken from a survey to which 760 academics responded, with 634 completing at least one section. Results showed that at the time of the survey there were a wide variety of research data in use, including analogue data, and that the challenges researchers faced in managing their data included finding safe and secure storage, particularly after project completion, but also during projects when data are used (and thus stored) on a wide variety of less-than-optimal temporary devices. Data sharing was not widely practiced and only a relatively small proportion of researchers had a research data management plan. Since the survey was completed much has changed: capacities and communities are being built around data management and sharing and policies, and guidelines are being constructed. Data storage and curation services are now more freely available. It will be interesting to observe how the findings of future studies compare with those reported here.",
        "article_title": "Research Data Management Practices: A Snapshot in Time",
        "authors": [
            {
                "given": "Mary Anne",
                "family": "Kennan",
                "affiliation": [
                    "Charles Sturt University – Sydney"
                ]
            },
            {
                "given": "Lina",
                "family": "Markauskaite",
                "affiliation": [
                    "University of Sydney"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2015-07-29",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "10",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v10i2.375",
        "identifier": {
            "string_id": "10.2218/ijdc.v10i2.375",
            "id_scheme": "DOI"
        },
        "abstract": "This article reports the results of a study examining the state of data guidance provided to authors by 50 oncology journals. The purpose of the study was the identification of data practices addressed in the journals’ policies. While a number of studies have examined data sharing practices among researchers, little is known about how journals address data sharing. Thus, what was discovered through this study has practical implications for journal publishers, editors, and researchers. The findings indicate that journal publishers should provide more meaningful and comprehensive data guidance to prospective authors. More specifically, journal policies requiring data sharing, should direct researchers to relevant data repositories, and offer better metadata consultation to strengthen existing journal policies. By providing adequate guidance for authors, and helping investigators to meet data sharing mandates, scholarly journal publishers can play a vital role in advancing access to research data. ",
        "article_title": "State of Data Guidance in Journal Policies: A Case Study in Oncology",
        "authors": [
            {
                "given": "Deborah H.",
                "family": "Charbonneau",
                "affiliation": [
                    "School of Library and Information Science Wayne State University, Detroit, MI, USA"
                ]
            },
            {
                "given": "Joan E.",
                "family": "Beaudoin",
                "affiliation": [
                    "School of Library and Information Science Wayne State University, Detroit, MI, USA"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2016-05-13",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "10",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v10i2.346",
        "identifier": {
            "string_id": "10.2218/ijdc.v10i2.346",
            "id_scheme": "DOI"
        },
        "abstract": " Digital data are accumulating rapidly, yet issues relating to data production remain unexamined. Data sharing efforts in particular are nascent, disunited and incomplete. We investigate the development of data products tailored for diverse communities with differing knowledge bases. We explore not the technical aspects of how, why, or where data are made available, but rather the socio-scientific aspects influencing what data products are created and made available for use. These products differ from compact data summaries often published in journals. We report on development by a national data center of two data collections describing the changing polar environment. One collection characterizes sea ice products derived from satellite remote sensing data and development unfolds over three decades. The second collection characterizes the Greenland Ice Sheet melt where development of an initial collection of data products over a period of several months was informed by insights gained from earlier experience. In documenting the generation of these two collections, a data product development cycle supported by a data product team is identified as key to mobilizing scientific knowledge. The collections reveal a co-evolution of data products and designated communities where community interest may be triggered by events such as environmental disturbance and new modes of communication. These examples of data product development in practice illustrate knowledge mobilization in the earth sciences; the collections create a bridge between data producers and a growing number of audiences interested in making evidence-based decisions.    ",
        "article_title": "Scientific Knowledge Mobilization: Co-evolution of Data Products and Designated Communities",
        "authors": [
            {
                "given": "Karen S.",
                "family": "Baker",
                "affiliation": [
                    "Center for Informatics Research in Science and Scholarship Graduate School of Library and Information Science University of Illinois at Urbana-Champaign, IL"
                ]
            },
            {
                "given": "Ruth E.",
                "family": "Duerr",
                "affiliation": [
                    "National Snow and Ice Data Center University of Colorado at Boulder, CO"
                ]
            },
            {
                "given": "Mark A.",
                "family": "Parsons",
                "affiliation": [
                    "Research Data Alliance Rensselaer Polytechnic Institute, NY"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2016-05-12",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "10",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v11i1.389",
        "identifier": {
            "string_id": "10.2218/ijdc.v11i1.389",
            "id_scheme": "DOI"
        },
        "abstract": "In order to better understand the current state of data management education in multiple fields of science, this study surveyed scientists, including information scientists, about their data management education practices, including at what levels they are teaching data management, which topics they covering, and what barriers they experience in teaching these topics. We found that a handful of scientists are teaching data management in undergraduate, graduate, and other types of courses, as well as outside of classroom settings. Commonly taught data management topics included quality control, protecting data, and management planning. However, few instructors felt they were covering data management topics thoroughly, and respondents cited barriers such as lack of time, lack of necessary expertise, and lack of information for teaching data management. We offer some potential explanations for the existing state of data management education and suggest areas for further research. ",
        "article_title": "Data Management Education from the Perspective of Science Educators",
        "authors": [
            {
                "given": "Carol",
                "family": "Tenopir",
                "affiliation": [
                    "University of Tennessee"
                ]
            },
            {
                "given": "Suzie",
                "family": "Allard",
                "affiliation": [
                    "University of Tennessee"
                ]
            },
            {
                "given": "Priyanki",
                "family": "Sinha",
                "affiliation": [
                    "University of Tennessee"
                ]
            },
            {
                "given": "Danielle",
                "family": "Pollock",
                "affiliation": [
                    "University of Tennessee"
                ]
            },
            {
                "given": "Jess",
                "family": "Newman",
                "affiliation": [
                    "University of Tennessee"
                ]
            },
            {
                "given": "Elizabeth",
                "family": "Dalton",
                "affiliation": [
                    "University of Tennessee"
                ]
            },
            {
                "given": "Mike",
                "family": "Frame",
                "affiliation": [
                    "U.S. Geological Survey"
                ]
            },
            {
                "given": "Lynn",
                "family": "Baird",
                "affiliation": [
                    "University of Idaho"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2016-11-28",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "11",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v11i1.425",
        "identifier": {
            "string_id": "10.2218/ijdc.v11i1.425",
            "id_scheme": "DOI"
        },
        "abstract": "The  ability  to  measure  the  use  and  impact  of  published  data  sets  is  key  to  the  success  of the  open  data/open  science  paradigm.  A  direct  measure  of  impact  would  require  tracking data  (re)use  in  the  wild,  which  is  difficult  to  achieve.  This  is  therefore  commonly  replaced by  simpler  metrics  based  on  data  download  and  citation  counts.  In  this  paper  we  describe a  scenario  where  it  is  possible  to  track  the trajectory  of  a  dataset after  its  publication, and  show  how  this  enables  the  design  of  accurate  models  for  ascribing  credit  to  data originators.  A  Data  Trajectory  (DT)  is  a  graph  that  encodes  knowledge  of  how,  by  whom, and  in  which  context  data  has  been  re-used,  possibly  after  several  generations.  We  provide a  theoretical  model  of  DTs  that  is  grounded  in  the  W3C  PROV  data  model  for  provenance, and  we  show  how  DTs  can  be  used  to  automatically  propagate  a  fraction  of  the  credit associated  with  transitively  derived  datasets,  back  to  original  data  contributors.  We  also show  this  model  of transitive credit  in  action  by  means  of  a  Data  Reuse  Simulator.  In  the longer  term,  our  ultimate  hope  is  that  credit  models  based  on  direct  measures  of  data  reuse will  provide  further  incentives  to  data  publication.  We  conclude  by  outlining  a  research agenda  to  address  the  hard  questions  of  creating,  collecting,  and  using  DTs  systematically across  a  large  number  of  data  reuse  instances  in  the  wild. ",
        "article_title": "Data trajectories: tracking reuse of published data for transitive credit attribution",
        "authors": [
            {
                "given": "Paolo",
                "family": "Missier",
                "affiliation": [
                    "NewcastleUniversity,UK"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2016-09-29",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "11",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v11i1.357",
        "identifier": {
            "string_id": "10.2218/ijdc.v11i1.357",
            "id_scheme": "DOI"
        },
        "abstract": "As scientific data volumes, format types, and sources increase rapidly with the invention and improvement of scientific capabilities, the resulting datasets are becoming more complex to manage as well. One of the significant management challenges is pulling apart the individual contributions of specific people and organizations within large, complex projects. This is important for two aspects: 1) assigning responsibility and accountability for scientific work, and 2) giving professional credit to individuals (e.g. hiring, promotion, and tenure) who work within such large projects. This paper aims to review the extant practice of data attribution and how it may be improved. Through a case study of creating a detailed attribution record for a climate model dataset, the paper evaluates the strengths and weaknesses of the current data attribution method and proposes an alternative attribution framework accordingly. The paper concludes by demonstrating that, analogous to acknowledging the different roles and responsibilities shown in movie credits, the methodology developed in the study could be used in general to identify and map out the relationships among the organizations and individuals who had contributed to a dataset.  As a result, the framework could be applied to create data attribution for other dataset types beyond climate model datasets.     ",
        "article_title": "Recognizing the Diversity of Contributions: A Case Study for Framing Attribution and Acknowledgement for Scientific Data",
        "authors": [
            {
                "given": "Chung-Yi",
                "family": "Hou",
                "affiliation": [
                    "Graduate School of Library and Information Science University of Illinois at Urbana-Champaign"
                ]
            },
            {
                "given": "Matthew",
                "family": "Mayernik",
                "affiliation": [
                    "NCAR Library National Center for Atmospheric Research (NCAR)"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2016-10-05",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "11",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v11i1.387",
        "identifier": {
            "string_id": "10.2218/ijdc.v11i1.387",
            "id_scheme": "DOI"
        },
        "abstract": "Designated communities are central to validation of preservation. If a designated community is able to understand and use information found within a digital repository, the assumption is that the information has been properly preserved. As judging the trustworthiness of information requires at least some level of understanding of that information, this paper presents results of a study aimed at developing a tool for measuring designated community members’ perceptions of trustworthiness for preserved information found within a digital repository. The study focuses on genealogists at the Washington State Digital Archives who routinely interact with digitized genealogical records, including digitized marriage, death, and birth records. Results of the study include construction of an original Digitized Archival Document Trustworthiness Scale (DADTS). DADTS is a ready-made tool for digital curators to use to measure the trustworthiness perceptions of their designated community members. Implications of this study include the feasibility of engaging members of a designated community in the construction of a scale for measuring trustworthiness perception, thereby providing deeper insight into the understandability and usability of preserved information by that designated community.   ",
        "article_title": "The Digitized Archival Document Trustworthiness Scale",
        "authors": [
            {
                "given": "Devan Ray",
                "family": "Donaldson",
                "affiliation": [
                    "Indiana University"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2016-11-28",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "11",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v11i1.401",
        "identifier": {
            "string_id": "10.2218/ijdc.v11i1.401",
            "id_scheme": "DOI"
        },
        "abstract": "The development of e-Research infrastructure has enabled data to be shared and accessed more openly. Policy mandates for data sharing have contributed to the increasing availability of research data through data repositories, which create favourable conditions for the re-use of data for purposes not always anticipated by original collectors. Despite the current efforts to promote transparency and reproducibility in science, data re-use cannot be assumed, nor merely considered a ‘thrifting’ activity where scientists shop around in data repositories considering only the ease of access to data. The lack of an integrated view of individual, social and technological influential factors to intentional and actual data re-use behaviour was the key motivator for this study. Interviews with 13 social scientists produced 25 factors that were found to influence their perceptions and experiences, including both their unsuccessful and successful attempts to re-use data. These factors were grouped into six theoretical variables: perceived benefits, perceived risks, perceived effort, social influence, facilitating conditions, and perceived re-usability. These research findings provide an in-depth understanding about the re-use of research data in the context of open science, which can be valuable in terms of theory and practice to help leverage data re-use and make publicly available data more actionable.   ",
        "article_title": "Factors Influencing Research Data Reuse in the Social Sciences: An Exploratory Study",
        "authors": [
            {
                "given": "Renata Gonçalves",
                "family": "Curty",
                "affiliation": [
                    "Universidade Estadual de Londrina, Brazil"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2016-10-05",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "11",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v11i1.428",
        "identifier": {
            "string_id": "10.2218/ijdc.v11i1.428",
            "id_scheme": "DOI"
        },
        "abstract": "Scientists in all fields face challenges in managing and sustaining access to their research data. The larger and longer term the research project, the more likely that scientists are to have resources and dedicated staff to manage their technology and data, leaving those scientists whose work is based on smaller and shorter term projects at a disadvantage. The volume and variety of data to be managed varies by many factors, only two of which are the number of collaborators and length of the project. As part of an NSF project to conceptualize the Institute for Empowering Long Tail Research, we explored opportunities offered by Software as a Service (SaaS). These cloud-based services are popular in business because they reduce costs and labor for technology management, and are gaining ground in scientific environments for similar reasons. We studied three settings where scientists conduct research in small and medium-sized laboratories. Two were NSF Science and Technology Centers (CENS and C-DEBI) and the third was a workshop of natural reserve scientists and managers. These laboratories have highly diverse data and practices, make minimal use of standards for data or metadata, and lack resources for data management or sustaining access to their data, despite recognizing the need. We found that SaaS could address technical needs for basic document creation, analysis, and storage, but did not support the diverse and rapidly changing needs for sophisticated domain-specific tools and services. These are much more challenging knowledge infrastructure requirements that require long-term investments by multiple stakeholders.   ",
        "article_title": "Data Management in the Long Tail: Science, Software, and Service",
        "authors": [
            {
                "given": "Christine L.",
                "family": "Borgman",
                "affiliation": [
                    "University of California, Los Angeles"
                ]
            },
            {
                "given": "Milena S.",
                "family": "Golshan",
                "affiliation": [
                    "University of California, Los Angeles"
                ]
            },
            {
                "given": "Ashley E.",
                "family": "Sands",
                "affiliation": [
                    "University of California, Los Angeles"
                ]
            },
            {
                "given": "Jillian C.",
                "family": "Wallis",
                "affiliation": [
                    "University of California, Los Angeles"
                ]
            },
            {
                "given": "Rebekah L.",
                "family": "Cummings",
                "affiliation": [
                    "University of California, Los Angeles"
                ]
            },
            {
                "given": "Peter T.",
                "family": "Darch",
                "affiliation": [
                    "University of California, Los Angeles"
                ]
            },
            {
                "given": "Bernadette M.",
                "family": "Randles",
                "affiliation": [
                    "University of California, Los Angeles"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2016-10-12",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "11",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v11i1.339",
        "identifier": {
            "string_id": "10.2218/ijdc.v11i1.339",
            "id_scheme": "DOI"
        },
        "abstract": " This article extends previous work known as Preserving Virtual Worlds II (PVWII), funded through a grant from the Institute of Museum and Library Services. The author draws on interview data collected from video game developers, content analysis of several long-running video game series, as well as the project’s advisory board and researcher reports. This paper exposes two fundamental challenges in creating metrics and specifications for the preservation of virtual worlds; namely, that there is no one type of user or designated video game stakeholder community, and that significant properties of games cannot always be located in code or platform. The PVWII data serve to explain why existing ideas about preservation of video games are inadequate when games are treated as digital cultural heritage. Preservation specialists need to bind nebulous and dynamic digital objects, a process that is necessary while inherently artificial.     ",
        "article_title": "Enrolling Heterogeneous Partners in Video Game Preservation",
        "authors": [
            {
                "given": "Rhiannon",
                "family": "Bettivia",
                "affiliation": [
                    "University of Illinois, Urbana-Champaign"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2016-10-05",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "11",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v11i2.390",
        "identifier": {
            "string_id": "10.2218/ijdc.v11i2.390",
            "id_scheme": "DOI"
        },
        "abstract": "Software plays a significant role in modern academic research, yet lacks a similarly significant presence in the scholarly record. With increasing interest in promoting reproducible research, curating software as a scholarly resource not only promotes access to these tools, but also provides recognition for the intellectual efforts that go into their development. This work reviews existing standards for identifying, promoting discovery of, and providing credit for software development work. In addition, it shows how these guidelines have been integrated into existing tools and community cultures, and provides recommendations for future software curation efforts.    ",
        "article_title": "Citations for Software: Providing Identification, Access and Recognition for Research Software",
        "authors": [
            {
                "given": "Laura",
                "family": "Soito",
                "affiliation": [
                    "University of New Mexico"
                ]
            },
            {
                "given": "Lorraine J",
                "family": "Hwang",
                "affiliation": [
                    "University of California, Davis"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2017-07-04",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "11",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v12i1.532",
        "identifier": {
            "string_id": "10.2218/ijdc.v12i1.532",
            "id_scheme": "DOI"
        },
        "abstract": "Workflows processing data from research activities and driving in silico experiments are becoming an increasingly important method for conducting scientific research. Workflows have the advantage that not only can they be automated and used to process data repeatedly, but they can also be reused – in part or whole – enabling them to be evolved for use in new experiments. A number of studies have investigated strategies for storing and sharing workflows for the benefit of reuse. These have revealed that simply storing workflows in repositories without additional context does not enable workflows to be successfully reused. These studies have investigated what additional resources are needed to facilitate users of workflows and in particular to add provenance traces and to make workflows and their resources machine-readable. These additions also include adding metadata for curation, annotations for comprehension, and including data sets to provide additional context to the workflow. Ultimately though, these mechanisms still rely on researchers having access to the software to view and run the workflows. We argue that there are situations where researchers may want to understand a workflow that goes beyond what provenance traces provide and without having to run the workflow directly; there are many situations in which it can be difficult or impossible to run the original workflow. To that end, we have investigated the creation of an interactive workflow visualization that captures the flow chart element of the workflow with additional context including annotations, descriptions, parameters, metadata and input, intermediate, and results data that can be added to the record of a workflow experiment to enhance both curation and add value to enable reuse. We have created interactive workflow visualisations for the popular workflow creation tool KNIME, which does not provide users with an in-built function to extract provenance information that can otherwise only be viewed through the tool itself. Making use of the strengths of KNIME for adding documentation and user-defined metadata we can extract and create a visualisation and curation package that encourages and enhances curation@source, facilitating effective communication, collaboration, and reuse of workflows. ",
        "article_title": "Documentation and Visualisation of Workflows for Effective Communication, Collaboration and Publication @ Source",
        "authors": [
            {
                "given": "Cerys",
                "family": "Willoughby",
                "affiliation": [
                    "University of Southampton"
                ]
            },
            {
                "given": "Jeremy G.",
                "family": "Frey",
                "affiliation": [
                    "University of Southampton"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2017-09-16",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "12",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v12i1.530",
        "identifier": {
            "string_id": "10.2218/ijdc.v12i1.530",
            "id_scheme": "DOI"
        },
        "abstract": "This paper describes a preliminary study of research transparency, which draws on the findings from four focus group sessions with faculty in chemistry, law, urban and social studies, and civil and environmental engineering. The multi-faceted nature of transparency is highlighted by the broad ways in which the faculty conceptualised the concept (data sharing, ethics, replicability) and the vocabulary they used with common core terms identified (data, methods, full disclosure). The associated concepts of reproducibility and trust are noted. The research lifecycle stages are used as a foundation to identify the action verbs and software tools associated with transparency. A range of transparency drivers and motivations are listed. The role of libraries and data scientists is discussed in the context of the provision of transparency services for researchers. ",
        "article_title": "Research Transparency: A Preliminary Study of Disciplinary Conceptualisation, Drivers, Tools and Support Services",
        "authors": [
            {
                "given": "Liz",
                "family": "Lyon",
                "affiliation": [
                    "University of Pittsburgh"
                ]
            },
            {
                "given": "Wei",
                "family": "Jeng",
                "affiliation": [
                    "University of Pittsburgh"
                ]
            },
            {
                "given": "Eleanor",
                "family": "Mattern",
                "affiliation": [
                    "University of Pittsburgh"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2017-09-16",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "12",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v12i1.481",
        "identifier": {
            "string_id": "10.2218/ijdc.v12i1.481",
            "id_scheme": "DOI"
        },
        "abstract": "The Data Seal of Approval (DSA) is one of the most widely used standards for Trusted Digital Repositories to date. Those who developed this standard have articulated seven main benefits of acquiring DSAs: 1) stakeholder confidence, 2) improvements in communication, 3) improvement in processes, 4) transparency, 5) differentiation from others, 6) awareness raising about digital preservation, and 7) less labor- and time-intensive. Little research has focused on if and how those who have acquired DSAs actually perceive these benefits. Consequently, this study examines the benefits of acquiring DSAs from the point of view of those who have them. In a series of 15 semi-structured interviews with representatives from 16 different organizations, participants described the benefits of having DSAs in their own words. Our findings suggest that participants experience all of the seven benefits that those who developed the standard promised. Additionally, our findings reflect the greater importance of some of those benefits compared to others. For example, participants mentioned the benefits of stakeholder confidence, transparency, improvement in processes and awareness raising about digital preservation more frequently than they discussed less labor- and time-intensive (e.g. it being less labor- and time-intensive to acquire DSAs than becoming certified by other standards), improvements in communication, and differentiation from others. Participants also mentioned two additional benefits of acquiring DSAs that are not explicitly listed on the DSA website that were very important to them: 1) the impact of acquiring the DSA on documentation of their workflows, and 2) assurance that they were following best practice. Implications and future directions for research are discussed. ",
        "article_title": "The Perceived Value of Acquiring Data Seals of Approval",
        "authors": [
            {
                "given": "Devan Ray",
                "family": "Donaldson",
                "affiliation": [
                    "School of Informatics, Computing, and Engineering Indiana University Bloomington"
                ]
            },
            {
                "given": "Ingrid",
                "family": "Dillo",
                "affiliation": [
                    "Data Archiving and Networked Services (DANS)"
                ]
            },
            {
                "given": "Robert",
                "family": "Downs",
                "affiliation": [
                    "Center for International Earth Science Information Network (CIESIN), Columbia University"
                ]
            },
            {
                "given": "Sarah",
                "family": "Ramdeen",
                "affiliation": [
                    "School of Information and Library Science, University of North Carolina at Chapel Hill"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2017-12-29",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "12",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v12i1.495",
        "identifier": {
            "string_id": "10.2218/ijdc.v12i1.495",
            "id_scheme": "DOI"
        },
        "abstract": "In the era of data science, datasets are shared widely and used for many purposes unforeseen by the original creators of the data.  In   this context, defects in datasets can have far reaching consequences,  spreading from dataset to dataset, and affecting the consumers of  data in ways that are hard to predict or quantify.  Some form of waste   is often the result.   For example,  scientists using defective data to propose hypotheses for experimentation may waste their limited wet lab resources chasing the wrong experimental targets.  Scarce drug trial resources may be used to test drugs that actually have little chance of giving a cure.   Because of the potential real world costs, database owners care about providing high quality data. Automated curation tools can be used to an extent to discover and correct some forms of defect. However, in some areas human curation, performed by highly-trained domain experts, is needed to ensure that the data represents our current interpretation of reality accurately. Human curators are expensive, and there is far more curation work to be done than there are curators available to perform it. Tools and techniques are needed to enable the full value to be obtained from the curation effort currently available.  In this paper,we explore one possible approach to maximising the  value obtained from human curators, by automatically extracting information about data defects and corrections from the work that the curators do. This information is packaged in a source independent form, to allow it to be used by the owners of other databases (for which human curation effort is not available or is insufficient).  This amplifies the efforts of the human curators, allowing their work to be applied to other sources, without requiring any additional effort or  change in their processes or tool sets. We show that this approach can discover significant numbers of defects, which can also be found in other sources. ",
        "article_title": "Amplifying  Data  Curation  Efforts  to  Improve  the  Quality  of  Life  Science  Data",
        "authors": [
            {
                "given": "Mariam",
                "family": "Alqasab",
                "affiliation": [
                    "University of Manchester"
                ]
            },
            {
                "given": "Suzanne M.",
                "family": "Embury",
                "affiliation": [
                    "University of Manchester"
                ]
            },
            {
                "given": "Sandra",
                "family": "De  F.  Mendes  Sampaio",
                "affiliation": [
                    "University of Manchester"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2017-09-16",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "12",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v12i2.500",
        "identifier": {
            "string_id": "10.2218/ijdc.v12i2.500",
            "id_scheme": "DOI"
        },
        "abstract": "Social scientists are producing an ever-expanding volume of data, leading to questions about appraisal and selection of content given finite resources to process data for reuse. We analyze users’ search activity in an established social science data repository to better understand demand for data and more effectively guide collection development. By applying a data-driven approach, we aim to ensure curation resources are applied to make the most valuable data findable, understandable, accessible, and usable. We analyze data from a domain repository for the social sciences that includes over 500,000 annual searches in 2014 and 2015 to better understand trends in user search behavior. Using a newly created search-to-study ratio technique, we identified gaps in the domain data repository’s holdings and leveraged this analysis to inform our collection and curation practices and policies. The evaluative technique we propose in this paper will serve as a baseline for future studies looking at trends in user demand over time at the domain data repository being studied with broader implications for other data repositories. ",
        "article_title": "A Data-Driven Approach to Appraisal and Selection at a Domain Data Repository",
        "authors": [
            {
                "given": "Amy M",
                "family": "Pienta",
                "affiliation": [
                    "ICPSR, University of Michigan"
                ]
            },
            {
                "given": "Dharma",
                "family": "Akmon",
                "affiliation": [
                    "ICPSR, University of Michigan"
                ]
            },
            {
                "given": "Justin",
                "family": "Noble",
                "affiliation": [
                    "ICPSR, University of Michigan"
                ]
            },
            {
                "given": "Lynette",
                "family": "Hoelter",
                "affiliation": [
                    "ICPSR, University of Michigan"
                ]
            },
            {
                "given": "Susan",
                "family": "Jekielek",
                "affiliation": [
                    "ICPSR, University of Michigan"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2018-06-01",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "12",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v12i2.429",
        "identifier": {
            "string_id": "10.2218/ijdc.v12i2.429",
            "id_scheme": "DOI"
        },
        "abstract": "This paper develops and tests a lifecycle model for the preservation of research data by investigating the research practices of scientists.  This research is based on a mixed-method approach.  An initial study was conducted using case study analytical techniques; insights from these case studies were combined with grounded theory in order to develop a novel model of the Digital Research Data Lifecycle.  A broad-based quantitative survey was then constructed to test and extend the components of the model.  The major contribution of these research initiatives are the creation of the Digital Research Data Lifecycle, a data lifecycle that provides a generalized model of the research process to better describe and explain both the antecedents and barriers to preservation.  The antecedents and barriers to preservation are data management, contextual metadata, file formats, and preservation technologies.  The availability of data management support and preservation technologies, the ability to create and manage contextual metadata, and the choices of file formats all significantly effect the preservability of research data. ",
        "article_title": "Modelling the Research Data Lifecycle",
        "authors": [
            {
                "given": "Stacy T",
                "family": "Kowalczyk",
                "affiliation": [
                    "Dominican University"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2018-06-01",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "12",
        "issue": "2",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v13i1.631",
        "identifier": {
            "string_id": "10.2218/ijdc.v13i1.631",
            "id_scheme": "DOI"
        },
        "abstract": "The complexity of preserving virtual reality environments combines the challenges of preserving singular digital objects, the relationships among those objects, and the processes involved in creating those relationships. A case study involving the preservation of the Virtual Bethel environment is presented. This case is active and ongoing. The paper provides a brief history of the Bethel AME Church of Indianapolis and its importance, then describes the unique preservation challenges of the Virtual Bethel project, and finally provides guidance and preservation recommendations for Virtual Bethel, using the National Digital Stewardship Alliance Levels of Preservation. Discussion of limitations of the guidance and recommendations follow. ",
        "article_title": "Complexities of Digital Preservation in a Virtual Reality Environment, the Case of Virtual Bethel",
        "authors": [
            {
                "given": "Angela P.",
                "family": "Murillo",
                "affiliation": [
                    "Indiana University - Purdue University"
                ]
            },
            {
                "given": "Lydia",
                "family": "Spotts",
                "affiliation": [
                    "Indiana University - Purdue University"
                ]
            },
            {
                "given": "Andrea",
                "family": "Copeland",
                "affiliation": [
                    "Indiana University - Purdue University"
                ]
            },
            {
                "given": "Ayoung",
                "family": "Yoon",
                "affiliation": [
                    "Indiana University - Purdue University"
                ]
            },
            {
                "given": "Zebulun M",
                "family": "Wood",
                "affiliation": [
                    "Indiana University - Purdue University"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2018-12-21",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "13",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v13i1.632",
        "identifier": {
            "string_id": "10.2218/ijdc.v13i1.632",
            "id_scheme": "DOI"
        },
        "abstract": "This research study compared four academic libraries’ approaches to curating the metadata of dataset submissions in their institutional repositories and classified them in one of four categories: no curation, pre-ingest curation, selective curation, and post-ingest curation. The goal is to understand the impact that curation may have on the quality of user-submitted metadata. The findings were 1) the metadata elements varied greatly between institutions, 2) repositories with more options for authors to contribute metadata did not result in more metadata contributed, 3) pre- or post-ingest curation process could have a measurable impact on the metadata but are difficult to separate from other factors, and 4) datasets submitted to a repository with pre- or post-ingest curation more often included documentation. ",
        "article_title": "Giving datasets context: a comparison study of institutional repositories that apply varying degrees of curation",
        "authors": [
            {
                "given": "Amy",
                "family": "Koshoffer",
                "affiliation": [
                    "University of Cincinnati"
                ]
            },
            {
                "given": "Amy E.",
                "family": "Neeser",
                "affiliation": [
                    "University of California Berkeley"
                ]
            },
            {
                "given": "Linda",
                "family": "Newman",
                "affiliation": [
                    "University of Cincinnati"
                ]
            },
            {
                "given": "Lisa R",
                "family": "Johnston",
                "affiliation": [
                    "University of Minnesota"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2018-12-21",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "13",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v13i1.534",
        "identifier": {
            "string_id": "10.2218/ijdc.v13i1.534",
            "id_scheme": "DOI"
        },
        "abstract": "This paper describes the findings from a participatory prototype design project, where the authors worked with maternal and child health (MCH) researchers and stakeholders to develop a MCH metadata profile and sustainable curation workflow. This work led to the development of three prototypes: 1) a study catalogue hosted in Dataverse, 2) a metadata and research records repository hosted in REDCap and 3) a metadata harvesting tool/dashboard hosted within the Shiny RStudio environment. We present a brief overview of the methods used to develop the metadata profile, curation workflow and prototypes. Researchers and other stakeholders were participant-collaborators throughout the project. The participatory process involved a number of steps, including but not limited to: initial project design and grant writing; scoping and mapping existing practices, workflows and relevant metadata standards; creating the metadata profile; developing semi-automated and manual techniques to harvest and transform metadata; and end project sustainability/future planning. In this paper, we discuss the design process and project outcomes, limitations and benefits of the approach, and implications for researcher-oriented metadata and data curation initiatives. ",
        "article_title": "Participatory Prototype Design: Developing a Sustainable Metadata Curation Workflow for Maternal Child Health Research",
        "authors": [
            {
                "given": "Amanda",
                "family": "Harrigan",
                "affiliation": [
                    "University of Alberta"
                ]
            },
            {
                "given": "Saurabh",
                "family": "Vashishtha",
                "affiliation": [
                    "University of Alberta"
                ]
            },
            {
                "given": "Sharon",
                "family": "Farnel",
                "affiliation": [
                    "University of Alberta"
                ]
            },
            {
                "given": "Kendall",
                "family": "Roark",
                "affiliation": [
                    "Purdue University"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2018-12-28",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "13",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v13i1.554",
        "identifier": {
            "string_id": "10.2218/ijdc.v13i1.554",
            "id_scheme": "DOI"
        },
        "abstract": "Libraries and archives are increasingly producing subject-based digital collections alongside, but separate from, their main digital collections. These smaller projects are often treated as digital one-offs; they are created, launched, promoted, and then largely forgotten. The authors of this study argue that small-scale digital collections instead be treated as test cases for their institutions’ main digitization programs. Because they are lightweight and have relatively low stakes, these collections get pushed through the system quickly and can illuminate its workings and shortcomings in a snapshot form. The authors treat their own experience in developing the Animal Welfare Act History Digital Collection at the National Agricultural Library as a case study in using a digital collection to test and revise an institution’s digitization program. In so doing, this study suggests how agile projects like the AWAHDC can be core components in digital curation policies and their implementation.  ",
        "article_title": "Getting to Beta",
        "authors": [
            {
                "given": "Kathryn",
                "family": "Gucer",
                "affiliation": [
                    "University of Maryland"
                ]
            },
            {
                "given": "Kristina",
                "family": "Adams",
                "affiliation": [
                    "National Agriculture Library"
                ]
            },
            {
                "given": "Chuck",
                "family": "Schoppet",
                "affiliation": [
                    "National Agriculture Library"
                ]
            },
            {
                "given": "Ricardo",
                "family": "Punzalan",
                "affiliation": [
                    "University of Maryland"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2019-04-13",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "13",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v13i1.492",
        "identifier": {
            "string_id": "10.2218/ijdc.v13i1.492",
            "id_scheme": "DOI"
        },
        "abstract": "In this article, we examine how data producers’ and reusers’ privacy concerns shape their views about data sharing and reuse in the field of education, with an emphasis on video records of practice. We find that data producers and reusers were concerned about the risks that qualitative data, and video records of practice in particular, present to themselves, their colleagues, and the subjects represented in the data. Specifically, they emphasized risks relating to the privacy the subjects – teachers and students who appear in the videos. In response to these risks, data producers have engaged in a number of strategies to minimize risk and/or mitigate potential harm including: (1) education and training; (2) using informed consent to facilitate and/or restrict data sharing; and (3) limiting data capture/production. We discuss the implications that our findings have for digital repositories, and for efforts to facilitate the sharing and reuse of qualitative video data in education. ",
        "article_title": "Issues of Privacy in Qualitative Video Data Reuse",
        "authors": [
            {
                "given": "Rebecca D.",
                "family": "Frank",
                "affiliation": [
                    "University of Michigan"
                ]
            },
            {
                "given": "Allison R. B.",
                "family": "Tyler",
                "affiliation": [
                    "University of Michigan"
                ]
            },
            {
                "given": "Anna",
                "family": "Gault",
                "affiliation": [
                    "Supreme Court of Ohio Law Library"
                ]
            },
            {
                "given": "Kara",
                "family": "Suzuka",
                "affiliation": [
                    "University of Hawaiʻi at Mānoa"
                ]
            },
            {
                "given": "Elizabeth",
                "family": "Yakel",
                "affiliation": [
                    "University of Michigan"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "1970-01-01",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "13",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v13i1.502",
        "identifier": {
            "string_id": "10.2218/ijdc.v13i1.502",
            "id_scheme": "DOI"
        },
        "abstract": "Since its creation nearly a decade ago, the Digital Curation Centre (DCC) Curation Lifecycle Model has become the quintessential framework for understanding digital curation. Organizations and consortia around the world have used the DCC Curation Lifecycle Model as a tool to ensure that all the necessary stages of digital curation are undertaken, to define roles and responsibilities, and to build a framework of standards and technologies for digital curation. Yet, research on the application of the model to large-scale digitization projects as a way of understanding their efforts at digital curation is scant. This paper reports on findings of a qualitative case study analysis of Indiana University Bloomington’s multi-million-dollar Media Digitization and Preservation Initiative (MDPI), employing the DCC Curation Lifecycle Model as a lens for examining the scope and effectiveness of its digital curation efforts. Findings underscore the success of MDPI in performing digital curation by illustrating the ways it implements each of the model’s components. Implications for the application of the DCC Curation Lifecycle Model in understanding digital curation for mass digitization projects are discussed as well as directions for future research. ",
        "article_title": "Media Digitization and Preservation Initiative: A Case Study",
        "authors": [
            {
                "given": "Devan Ray",
                "family": "Donaldson",
                "affiliation": [
                    "Indiana University, Bloomington"
                ]
            },
            {
                "given": "Allison",
                "family": "McClanahan",
                "affiliation": [
                    "Indiana University, Bloomington"
                ]
            },
            {
                "given": "Leif",
                "family": "Christiansen",
                "affiliation": [
                    "Indiana University, Bloomington"
                ]
            },
            {
                "given": "Laura",
                "family": "Bell",
                "affiliation": [
                    "Indiana University, Bloomington"
                ]
            },
            {
                "given": "Mikala",
                "family": "Narlock",
                "affiliation": [
                    "Indiana University, Bloomington"
                ]
            },
            {
                "given": "Shannon",
                "family": "Martin",
                "affiliation": [
                    "Indiana University, Bloomington"
                ]
            },
            {
                "given": "Haley",
                "family": "Suby",
                "affiliation": [
                    "Indiana University, Bloomington"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2018-12-23",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "13",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v13i1.630",
        "identifier": {
            "string_id": "10.2218/ijdc.v13i1.630",
            "id_scheme": "DOI"
        },
        "abstract": "For open science to flourish, data and any related digital outputs should be discoverable and re-usable by a variety of potential consumers. The recent FAIR Data Principles produced by the Future of Research Communication and e-Scholarship (FORCE11) collective provide a compilation of considerations for making data findable, accessible, interoperable, and re-usable. The principles serve as guideposts to ‘good’ data management and stewardship for data and/or metadata. On a conceptual level, the principles codify best practices that managers and stewards would find agreement with, exist in other data quality metrics, and already implement. This paper reports on a secondary purpose of the principles: to inform assessment of data’s FAIR-ness or, put another way, data’s fitness for use. Assessment of FAIR-ness likely requires more stratification across data types and among various consumer communities, as how data are found, accessed, interoperated, and re-used differs depending on types and purposes. This paper’s purpose is to present a method for qualitatively measuring the FAIR Data Principles through operationalizing findability, accessibility, interoperability, and re- usability from a re-user’s perspective. The findings may inform assessments that could also be used to develop situationally-relevant fitness for use frameworks. ",
        "article_title": "Measuring FAIR Principles to Inform Fitness for Use",
        "authors": [
            {
                "given": "Carolyn",
                "family": "Hank",
                "affiliation": [
                    "University of Tennessee"
                ]
            },
            {
                "given": "Bradley Wade",
                "family": "Bishop",
                "affiliation": [
                    "University of Tennessee"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2018-12-22",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "13",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v14i1.588",
        "identifier": {
            "string_id": "10.2218/ijdc.v14i1.588",
            "id_scheme": "DOI"
        },
        "abstract": "This study identifies challenges and promising directions in the curation of 3D data. 3D visualization shows great promise for a range of scholarly fields through interactive engagement with and analysis of spatially complex artifacts, spaces, and data. While the new affordability of emerging 3D capture technologies presents greater academic possibilities, academic libraries need more effective workflows, policies, standards, and practices to ensure that they can support the creation, discovery, access, preservation, and reproducibility of 3D data sets. This study uses nominal group technique with invited experts across several disciplines and sectors to identify common challenges in the creation and re-use of 3D data for the purpose of developing library strategy for supporting curation of 3D data. This article identifies staffing needs for 3D imaging; alignment with IT resources; the roll of archivists in addressing unique challenges posed by these datasets; the importance of data annotation, metadata, and transparency for research integrity and reproducibility; and features for storage, access, and management to facilitate re-use by researchers and educators. Participants identified three main challenges for supporting 3D data that align with the strengths of libraries: 1) development of crosswalks and aggregation tools for discipline-specific metadata models, data dictionaries for 3D research, and aggregation tools for expanding discovery; 2) development of an open source viewer that supports streaming and annotation on archival formats of 3D models and makes archival master files accessible, while also serving derivative files based on user requirements; and 3) widespread of adoption of better documentation and technical metadata for image capture and modeling processes in order to support replicability of research, reproducibility of models, and transparency of scientific process. ",
        "article_title": "Challenges and Directions in 3D and VR Data Curation",
        "authors": [
            {
                "ORCID": "http://orcid.org/0000-0002-0676-9916",
                "authenticated-orcid": false,
                "given": "Nathan Frank",
                "family": "Hall",
                "affiliation": [
                    "Virginia Tech"
                ]
            },
            {
                "given": "Juliet",
                "family": "Hardesty",
                "affiliation": [
                    "Indiana University"
                ]
            },
            {
                "given": "Zack",
                "family": "Lischer-Katz",
                "affiliation": [
                    "University of Oklahoma"
                ]
            },
            {
                "given": "Jennifer",
                "family": "Johnson",
                "affiliation": [
                    "Indiana University - Purdue University Indianapolis"
                ]
            },
            {
                "given": "Matt",
                "family": "Cook",
                "affiliation": [
                    "University of Oklahoma"
                ]
            },
            {
                "given": "Julie",
                "family": "Griffin",
                "affiliation": [
                    "Virginia Tech"
                ]
            },
            {
                "given": "Andrea",
                "family": "Ogier",
                "affiliation": [
                    "Virginia Tech"
                ]
            },
            {
                "given": "Tara",
                "family": "Carlisle",
                "affiliation": [
                    "University of Oklahoma"
                ]
            },
            {
                "given": "Zhiwu",
                "family": "Xie",
                "affiliation": [
                    "Virginia Tech"
                ]
            },
            {
                "given": "Robert",
                "family": "McDonald",
                "affiliation": [
                    "University of Colorado"
                ]
            },
            {
                "given": "Jamie",
                "family": "Wittenberg",
                "affiliation": [
                    "Indiana University"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "1970-01-01",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "14",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v14i1.586",
        "identifier": {
            "string_id": "10.2218/ijdc.v14i1.586",
            "id_scheme": "DOI"
        },
        "abstract": "Digital/data curation curricula have been around for a couple of decades. Currently, several ALA-accredited LIS programs offer digital/data curation courses and certificate programs to address the high demand for professionals with the knowledge and skills to handle digital content and research data in an ever-changing information environment.  In this study, we aimed to examine the topical scopes of digital/data curation curricula in the context of the LIS field.  We collected 16 syllabi from the digital/data curation courses, as well as textual descriptions of the 11 programs and their core courses offered in the U.S., Canada, and the U.K. The collected data were analyzed using a probabilistic topic modeling technique, Latent Dirichlet Allocation, to identify both common and unique topics. The results are the identification of 20 topics both at the program- and course-levels. Comparison between the program- and course-level topics uncovered a set of unique topics, and a number of common topics.  Furthermore, we provide interactive visualizations for digital/data curation programs and courses for further analysis of topical distributions. We believe that our combined approach of a topic modeling and visualizations may provide insight for identifying emerging trends and co-occurrences of topics among digital/data curation curricula in the LIS field. ",
        "article_title": "Identifying Topical Coverages of Curricula using Topic Modeling and Visualization Techniques: A Case of Digital and Data Curation",
        "authors": [
            {
                "given": "Seungwon",
                "family": "Yang",
                "affiliation": [
                    "Louisiana State University"
                ]
            },
            {
                "given": "Boryung",
                "family": "Ju",
                "affiliation": [
                    "Louisiana State University"
                ]
            },
            {
                "given": "Haeyong",
                "family": "Chung",
                "affiliation": [
                    "The University of Alabama in Huntsville"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2019-09-11",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "14",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v14i1.643",
        "identifier": {
            "string_id": "10.2218/ijdc.v14i1.643",
            "id_scheme": "DOI"
        },
        "abstract": "The Data Curation Continuum was developed as a way of thinking about data repository infrastructure. Since its original development over a decade ago, a number of things have changed in the data infrastructure domain. This paper revisits the thinking behind the original data curation continuum and updates it to respond to changes in research objects, storage models, and the repository landscape in general.    ",
        "article_title": "Updating the Data Curation Continuum",
        "authors": [
            {
                "given": "Andrew",
                "family": "Treloar",
                "affiliation": [
                    "Monash University"
                ]
            },
            {
                "given": "Jens",
                "family": "Klump",
                "affiliation": [
                    "CSIRO"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2019-09-11",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "14",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v14i1.594",
        "identifier": {
            "string_id": "10.2218/ijdc.v14i1.594",
            "id_scheme": "DOI"
        },
        "abstract": "The National Imaging Facility (NIF) provides Australian researchers with state-of-the-art instrumentation—including magnetic resonance imaging (MRI), positron emission tomography (PET), X-ray computed tomography (CT) and multispectral imaging – and expertise for the characterisation of animals, plants and materials.  To maximise research outcomes, as well as to facilitate collaboration and sharing, it is essential not only that the data acquired using these instruments be managed, curated and archived in a trusted data repository service, but also that the data itself be of verifiable quality. In 2017, several NIF nodes collaborated on a national project to define the requirements and best practices necessary to achieve this, and to establish exemplar services for both preclinical MRI data and clinical ataxia MRI data. In this paper we describe the project, its key outcomes, challenges and lessons learned, and future developments, including extension to other characterisation facilities and instruments/modalities. ",
        "article_title": "Putting the Trust into Trusted Data Repositories: A Federated Solution for the Australian National Imaging Facility",
        "authors": [
            {
                "given": "Andrew James",
                "family": "Mehnert",
                "affiliation": [
                    "CMCA, The University of Western Australia"
                ]
            },
            {
                "given": "Andrew",
                "family": "Janke",
                "affiliation": [
                    "Research Technology, The University of Sydney"
                ]
            },
            {
                "given": "Marco",
                "family": "Gruwel",
                "affiliation": [
                    "MWAC, The University of New South Wales"
                ]
            },
            {
                "given": "Wojtek James",
                "family": "Goscinski",
                "affiliation": [
                    "MeRC, Monash University"
                ]
            },
            {
                "given": "Thomas",
                "family": "Close",
                "affiliation": [
                    "MBI, Monash University"
                ]
            },
            {
                "given": "Dean",
                "family": "Taylor",
                "affiliation": [
                    "CMCA, The University of Western Australia"
                ]
            },
            {
                "given": "Aswin",
                "family": "Narayanan",
                "affiliation": [
                    "CAI, University of Queensland"
                ]
            },
            {
                "given": "George",
                "family": "Vidalis",
                "affiliation": [
                    "MeRC, Monash University"
                ]
            },
            {
                "given": "Graham",
                "family": "Galloway",
                "affiliation": [
                    "National Imaging Facility"
                ]
            },
            {
                "given": "Andrew",
                "family": "Treloar",
                "affiliation": [
                    "Australian Research Data Commons"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2019-09-11",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "14",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v14i1.598",
        "identifier": {
            "string_id": "10.2218/ijdc.v14i1.598",
            "id_scheme": "DOI"
        },
        "abstract": "PARADISEC’s PNG collections represent the great diversity in the regions and languages of PNG. In 2016 and 2017, in recognition of the value of PARADISEC’s collections, ANDS (the Australian National Data Service) provided funding for us to concentrate efforts on enhancing the metadata that describes our Papua New Guinea (PNG) collections, an effort designed to maximise the findability and useability of the language and music recordings preserved in the archive for both source communities and researchers. PARADISEC's subsequent engagement with PNG language experts has led to collaborations with members of speaker communities who are part of the PNG diaspora in Australia. In this paper, we show that making historical recordings more findable, accessible and better described can result in meaningful interactions with and responses to the data in source communities. The effects of empowering speaker communities in their relationships to archives can be far reaching – even inverting, or disrupting the power relationships that have resulted from the colonial histories in which archives are embedded. ",
        "article_title": "Making Meaning of Historical Papua New Guinea Recordings",
        "authors": [
            {
                "given": "Amanda",
                "family": "Harris",
                "affiliation": [
                    "University of Sydney, Conservatorium of Music"
                ]
            },
            {
                "given": "Steven",
                "family": "Gagau",
                "affiliation": [
                    "University of Sydney, Conservatorium of Music"
                ]
            },
            {
                "given": "Jodie",
                "family": "Kell",
                "affiliation": [
                    "University of Sydney, Conservatorium of Music"
                ]
            },
            {
                "given": "Nick",
                "family": "Thieberger",
                "affiliation": [
                    "University of Melbourne"
                ]
            },
            {
                "given": "Nick",
                "family": "Ward",
                "affiliation": [
                    "University of Sydney, Conservatorium of Music"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "1970-01-01",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "14",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v14i1.595",
        "identifier": {
            "string_id": "10.2218/ijdc.v14i1.595",
            "id_scheme": "DOI"
        },
        "abstract": "University libraries have played an important role in constructing an infrastructure of support for Research Data Management at an institutional level. This paper presents a comparative analysis of two international surveys of libraries about their involvement in Research Data Services conducted in 2014 and 2018. The aim was to explore how services had developed over this time period, and to explore the drivers and barriers to change. In particular, there was an interest in how far the FAIR data principles had been adopted. Services in nearly every area were more developed in 2018 than before, but technical services remained less developed than advisory. Progress on institutional policy was also evident. However, priorities did not seem to have shifted significantly. Open ended answers suggested that funder policy, rather than researcher demand, remained the main driver of service development and that resources and skills gaps remained issues. While widely understood as an important reference point and standard, because of their relatively recent publication date, FAIR principles had not been widely adopted explicitly in policy. ",
        "article_title": "Progress in Research Data Services",
        "authors": [
            {
                "given": "Andrew M",
                "family": "Cox",
                "affiliation": [
                    "Information School, University of Sheffield"
                ]
            },
            {
                "given": "Mary Anne",
                "family": "Kennan",
                "affiliation": [
                    "Charles Sturt University"
                ]
            },
            {
                "given": "Elizabeth Josephine",
                "family": "Lyon",
                "affiliation": [
                    "iSchool, University of Pittsburgh"
                ]
            },
            {
                "given": "Stephen",
                "family": "Pinfield",
                "affiliation": [
                    "Information School, University of Sheffield"
                ]
            },
            {
                "given": "Laura",
                "family": "Sbaffi",
                "affiliation": [
                    "University of Sheffield"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2019-09-11",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "14",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v14i1.556",
        "identifier": {
            "string_id": "10.2218/ijdc.v14i1.556",
            "id_scheme": "DOI"
        },
        "abstract": "This article presents the findings of the Ibadan/Liverpool Digital Curation Curriculum Review Project, a research project conducted to formally benchmark the teaching of digital curation in the archival education programmes at the University of Liverpool, United Kingdom and the University of Ibadan, Nigeria. It provides background to the history and establishment of both universities and the development of their archives curricula. A matrix was developed using the DigCurV Curriculum Framework to assess whether digital curation skills and knowledge outlined in the framework are being taught, practised and tested in the Master’s programmes. These skills and knowledge were assessed according to the four domains outlined in DigCurV: Knowledge and Intellectual Abilities (KIA), Personal Qualities (PQ), Professional Conduct (PC), and Management and Quality Assurance (MQA), to levels appropriate to practitioners and managers. The exercise identified skill and knowledge areas where teaching materials could be shared between the universities, and areas where new materials are needed. ",
        "article_title": "Digital Curation Education at the Universities of Ibadan and Liverpool",
        "authors": [
            {
                "given": "Abiola",
                "family": "Abioye",
                "affiliation": [
                    "University of  Ibadan"
                ]
            },
            {
                "given": "James",
                "family": "Lowry",
                "affiliation": [
                    "University of Liverpool"
                ]
            },
            {
                "given": "Rosemary",
                "family": "Lynch",
                "affiliation": [
                    "University of Liverpool"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2019-09-11",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "14",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v15i1.602",
        "identifier": {
            "string_id": "10.2218/ijdc.v15i1.602",
            "id_scheme": "DOI"
        },
        "abstract": "The decision to allow users access to restricted and protected data is based on the development of trust in the user by data repositories. In this article, I propose a model of the process of trust development at restricted data repositories, a model which emphasizes the increasing levels of trust dependent on prior interactions between repositories and users. I find that repositories develop trust in their users through the interactions of four dimensions – promissory, experience, competence, and goodwill – that consider distinct types of researcher expertise and the role of a researcher’s reputation in the trust process. However, the processes used by repositories to determine a level of trust corresponding to data access are inconsistent and do not support the sharing of trusted users between repositories to maximize efficient yet secure access to restricted research data. I highlight the role of a researcher’s reputation as an important factor in trust development and trust transference, and discuss the implications of modelling the restricted data access process as a process of trust development. ",
        "article_title": "Facilitating Access to Restricted Data",
        "authors": [
            {
                "given": "Allison Rae Bobyak",
                "family": "Tyler",
                "affiliation": [
                    "University of  Michigan"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2020-07-22",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "15",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v15i1.646",
        "identifier": {
            "string_id": "10.2218/ijdc.v15i1.646",
            "id_scheme": "DOI"
        },
        "abstract": "One of the grand curation challenges is to secure metadata quality in the ever-changing environment of metadata standards and file formats. As the Red Queen tells Alice in Through the Looking-Glass: “Now, here, you see, it takes all the running you can do, to keep in the same place.” That is, there is some “running” needed to keep metadata records in a research data repository fit for long-term use and put in place. One of the main tools of adaptation and keeping pace with the evolution of new standards, formats – and versions of standards in this ever-changing environment are validation schemas. Validation schemas are mainly seen as methods of checking data quality and fitness for use, but are also important for long-term preservation. We might like to think that our present (meta)data standards and formats are made for eternity, but in reality we know that standards evolve, formats change (some even become obsolete with time), and so do our needs for storage, searching and future dissemination for re-use. Eventually, we come to a point where transformation of our archival records and migration to other formats will be necessary. This could also mean that even if the AIPs, the Archival Information Packages stay the same in storage, the DIPs, the Dissemination Information Packages that we want to extract from the archive are subject to change of format. Further, in order for archival information packages to be self-sustainable, as required in the OAIS model, it is important to take interdependencies between individual files in the information packages into account. This should be done already by the time of ingest and validation of the SIPs, the Submission Information Packages, and along the line at different points of necessary transformation/migration (from SIP to AIP, from AIP to DIP etc.), in order to counter obsolescence. This paper investigates possible validation errors and missing elements in metadata records from three general purpose, multidisciplinary research data repositories – Figshare, Harvard’s Dataverse and Zenodo, and explores the potential effects of these errors on future transformation to AIPs and migration to other formats within a digital archive.   ",
        "article_title": "The Red Queen in the Repository",
        "authors": [
            {
                "given": "Joakim",
                "family": "Philipson",
                "affiliation": [
                    "Stockholm University"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2020-07-22",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "15",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v15i1.710",
        "identifier": {
            "string_id": "10.2218/ijdc.v15i1.710",
            "id_scheme": "DOI"
        },
        "abstract": "This paper explores the tension between the tools that data reusers in the field of education prefer to use when working with qualitative video data and the tools that repositories make available to data reusers. Findings from this mixed-methods study show that data reusers utilizing qualitative video data did not use repository-based tools. Rather, they valued common, widely available tools that were collaborative and easy to use.   ",
        "article_title": "Tool Selection Among Qualitative Data Reusers",
        "authors": [
            {
                "given": "Rebecca D.",
                "family": "Frank",
                "affiliation": [
                    "Humboldt University of Berlin"
                ]
            },
            {
                "given": "Kara",
                "family": "Suzuka",
                "affiliation": [
                    "University of Hawaiʻi at Mānoa"
                ]
            },
            {
                "given": "Eric",
                "family": "Johnson",
                "affiliation": [
                    "University of Michigan"
                ]
            },
            {
                "given": "Elizabeth",
                "family": "Yakel",
                "affiliation": [
                    "University of Michigan"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2020-08-05",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "15",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v15i1.601",
        "identifier": {
            "string_id": "10.2218/ijdc.v15i1.601",
            "id_scheme": "DOI"
        },
        "abstract": "This paper describes the development of a systematic approach to the creation, management and curation of linguistic resources, particularly spoken language corpora. It also presents first steps towards a framework for continuous quality control to be used within external research projects by non-technical users, and discuss various domain and discipline specific problems and individual solutions. The creation of spoken language corpora is not only a time-consuming and costly process, but the created resources often represent intangible cultural heritage, containing recordings of, for example, extinct languages or historical events. Since high quality resources are needed to enable re-use in as many future contexts as possible, researchers need to be provided with the necessary means for quality control. We believe that this includes methods and tools adapted to Humanities researchers as non-technical users, and that these methods and tools need to be developed to support existing tasks and goals of research projects. ",
        "article_title": "Towards Continuous Quality Control for Spoken Language Corpora",
        "authors": [
            {
                "given": "Anne",
                "family": "Ferger",
                "affiliation": [
                    "University of Hamburg"
                ]
            },
            {
                "given": "Hanna",
                "family": "Hedeland",
                "affiliation": [
                    "University of Hamburg"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2020-07-22",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "15",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    },
    {
        "url": "http://dx.doi.org/10.2218/ijdc.v15i1.671",
        "identifier": {
            "string_id": "10.2218/ijdc.v15i1.671",
            "id_scheme": "DOI"
        },
        "abstract": "Effective data management and data sharing are crucial components of the research lifecycle, yet evidence suggests that many social science graduate programs are not providing training in these areas. The current exploratory study assesses how U.S. masters and doctoral programs in the social sciences include formal, non-formal, and informal training in data management and sharing. We conducted a survey of 150 graduate programs across six social science disciplines, and used a mix of closed and open-ended questions focused on the extent to which programs provide such training and exposure. Results from our survey suggested a deficit of formal training in both data management and data sharing, limited non-formal training, and cursory informal exposure to these topics. Utilizing the results of our survey, we conducted a syllabus analysis to further explore the formal and non-formal content of graduate programs beyond self-report. Our syllabus analysis drew from an expanded seven social science disciplines for a total of 140 programs. The syllabus analysis supported our prior findings that formal and non-formal inclusion of data management and data sharing training is not common practice. Overall, in both the survey and syllabi study we found a lack of both formal and non-formal training on data management and data sharing. Our findings have implications for data repository staff and data service professionals as they consider their methods for encouraging data sharing and prepare for the needs of data depositors. These results can also inform the development and structuring of graduate education in the social sciences, so that researchers are trained early in data management and sharing skills and are able to benefit from making their data available as early in their careers as possible. ",
        "article_title": "An Exploratory Analysis of Social Science Graduate Education in Data Management and Data Sharing",
        "authors": [
            {
                "given": "Ashley",
                "family": "Doonan",
                "affiliation": [
                    "ICPSR, University of Michigan"
                ]
            },
            {
                "given": "Dharma",
                "family": "Akmon",
                "affiliation": [
                    "ICPSR, University of Michigan"
                ]
            },
            {
                "given": "Evan",
                "family": "Cosby",
                "affiliation": [
                    "ICPSR, University of Michigan"
                ]
            }
        ],
        "publisher": "Edinburgh University",
        "date": "2020-07-22",
        "keywords": null,
        "journal_title": "International Journal of Digital Curation",
        "volume": "15",
        "issue": "1",
        "ISSN": [
            {
                "value": "1746-8256",
                "type": "electronic"
            }
        ]
    }
]