<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
	"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head><meta http-equiv="content-type" content="text/html; charset=UTF-8"/><meta name="generator" content="ABBYY FineReader 14"/><title>Microsoft Word - 183. Jean-Caurant-Limiter LImpact Des Erreurs OCR Sur Les ReprÇsentations DistribuÇes De Mots-183.docx</title><link rel="stylesheet" href="183_files/183.css" type="text/css"/>
</head>
<body><h1><a name="caption1"></a><a name="bookmark0"></a><span class="font2" style="font-weight:bold;">Limiter l'impact des erreurs OCR sur les représentations&nbsp;distribuées de mots</span></h1>
<p><span class="font4" style="font-weight:bold;">Axel Jean-Caurant</span></p>
<p><span class="font4"><a href="mailto:axel.jean-caurant@univ-lr.fr">axel.jean-caurant@univ-lr.fr</a></span></p>
<p><span class="font4">Laboratoire Informatique, Image et Interaction (L3i) Uni-</span></p>
<p><span class="font4">versite de La Rochelle, France</span></p>
<p><span class="font4" style="font-weight:bold;">Cyrille Suire</span></p>
<p><span class="font4"><a href="mailto:cyrille.suire@univ-lr.fr">cyrille.suire@univ-lr.fr</a></span></p>
<p><span class="font4">Laboratoire Informatique, Image et Interaction (L3i) Uni-versite de La Rochelle, France</span></p>
<p><span class="font4" style="font-weight:bold;">Vincent Courboulay</span></p>
<p><span class="font4"><a href="mailto:vincent.courboulay@univ-lr.fr">vincent.courboulay@univ-lr.fr</a></span></p>
<p><span class="font4">Laboratoire Informatique, Image et Interaction (L3i) Uni-versite de La Rochelle, France</span></p>
<p><span class="font4" style="font-weight:bold;">Jean-Christophe Burie</span></p>
<p><span class="font4"><a href="mailto:jean-christophe.burie@univ-lr.fr">jean-christophe.burie@univ-lr.fr</a></span></p>
<p><span class="font4">Laboratoire Informatique, Image et Interaction (L3i) Universite de La Rochelle, France</span></p>
<p><span class="font4">Les chercheurs en Humanites numeriques intéresses par l'analyse de grands corpus textuels utilisent de nombreuses méthodes et outils issus de domaines informatiques comme le traitement du langage naturel&nbsp;(Piotrowski, 2012) ou l'analyse de réseaux (Lemercier,&nbsp;2005). Des methodes récentes fondées sur les réseaux&nbsp;de neurones présentent egalement un interêt majeur.&nbsp;Word2Vec est une méthode qui a grandement facilité&nbsp;l'utilisation de tels modules (Mikolov, 2013). Les différentes optimisations apportees permettent, très simplement, d'entraîner un module sur de grandes quantités de donnees en utilisant un simple ordinateur de&nbsp;bureau. Le code source a ete largement diffuse et a&nbsp;rendu cette methode très populaire, notamment parmi&nbsp;les chercheurs en Humanites numériques. Hamilton a&nbsp;par exemple montré l'interêt de ces modules pour analyser l'évolution de certains mots du langage au cours&nbsp;du temps (Hamilton, 2016). Ces méthodes peuvent&nbsp;également être utilisées à d'autres fins. En effet, de&nbsp;nombreux corpus utiles aux Humanités numériques&nbsp;sont issus de processus de reconnaissance de carac-téres (OCR). Malheureusement, ces processus gé-nérent trés souvent des erreurs, en particulier quand&nbsp;les documents analysés sont de mauvaise qualité (documents anciens ou mal numérisés par exemple). Ces&nbsp;erreurs touchent notamment les entités nommées&nbsp;comme les noms de lieux ou de personnes, particuliérement intéressants pour les chercheurs (Gefen,&nbsp;2015). Ces erreurs ont un impact majeur sur l'accés a&nbsp;l'information car elles peuvent empécher d'accéder a&nbsp;toutes les occurrences d'un mot d'intérêt.</span></p>
<p><span class="font4">Dans ce poster, nous présentons la méthode que nous avons développée pour étendre l'usage de&nbsp;Word2Vec a l'identification des erreurs OCR dérivées&nbsp;d'entités nommées. Aprés avoir entraîné un modéle&nbsp;sur un corpus donné, chaque mot est associé a un vecteur représentatif. Il devient alors possible de comparer les vecteurs pour extraire des relations morphologiques ou sémantiques entre les mots. On peut&nbsp;par exemple calculer la distance cosinus qui sépare&nbsp;deux mots dans l'espace vectoriel du modéle. Si, au&nbsp;sein du corpus, ces mots apparaissent dans des contextes similaires, la distance qui les sépare sera faible.&nbsp;Or, une entité nommée, bien que mal reconnue par le&nbsp;processus OCR, apparaît souvent dans le méme contexte que l'entité originale. En combinant cette distance, qui agit sur les vecteurs, avec une distance d'édition sur les mots, nous pouvons identifier des mots&nbsp;proches sémantiquement et qui possèdent beaucoup&nbsp;de caractères en commun. Cette analyse produit ainsi&nbsp;une liste de termes qui ont toutes les chances d'étre&nbsp;des entités mal reconnues par le processus de reconnaissance de caractères.</span></p><img src="183_files/183-1.jpg" style="width:240pt;height:115pt;"/>
<p><span class="font0">Figure 1: Expérience menée par Bjerva et. al., qui présente les similarités entre différents personnages et quelques&nbsp;grands concepts. Plus une cellule est rouge, plus la similarité est importante.</span></p>
<p><span class="font4">Une fois les erreurs identifiées, il est possible de s'intéresser a une entité nommée particulière. Sur la base des résultats précédents, nous proposons la construction d'un nouveau vecteur associant le vecteur de l'entité originale et les vecteurs représentatifs des erreurs.&nbsp;Ce nouveau vecteur est le résultat de la combinaison&nbsp;linéaire des vecteurs du mot original et des erreurs&nbsp;OCR. Pour modérer l'importance des vecteurs dans la&nbsp;combinaison, ces derniers sont pondères selon le nombre d'occurrences du terme correspondant dans le&nbsp;corpus.</span></p><img src="183_files/183-2.jpg" style="width:235pt;height:95pt;"/>
<p><span class="font5">gothness greekness</span></p>
<p><span class="font5">liberty</span></p>
<p><span class="font5">antiquity romanness</span></p>
<p><span class="font0">Figure 2: Reproduction de l'expérience menée par Bjerva et. al., avec notre modèle modifié.</span></p><img src="183_files/183-3.jpg" style="width:230pt;height:72pt;"/>
<p><span class="font0">Figure 3: Comparaison des similarités Personne/Concept entre le modèle de Bjerva et. al. et notre modèle modifié.&nbsp;Chaque cellule représente la valeur absolue de la différence&nbsp;de similarité entre les deux modèles. Les cellules rouges&nbsp;présentent le plus de différences.</span></p>
<p><span class="font4">Nous avons expérimenté notre méthode en reproduisant l'expérience men^e par Bjerva et. al. (Bjerva, 2015). Ces derniers se sont interesses aux relations&nbsp;qu'entretiennent différentes personnalités du VI<sup>ème&nbsp;</sup>siecle avec de grands concepts (Modernite, Liberte,&nbsp;Gothique, ...). Ils ont utilisé Word2Vec pour entraîner&nbsp;un modele sur environ 11 000 textes latins, pour ensuite comparer les distances qui separent les personnes des concepts dans l'espace vectoriel du modele&nbsp;(voir figure 1). Nous avons utilise notre méthode pour&nbsp;calculer, pour chaque personne d'intérét, un nouveau&nbsp;vecteur représentatif prenant en compte les différentes erreurs OCR identifiées. Les distances entre&nbsp;personnes et concepts au sein de notre modéle modifié&nbsp;sont présentées dans la figure 2. Pour plus de clarté,&nbsp;les deux modéles sont comparés dans la figure 3. On&nbsp;peut par exemple observer qu'Odovacer, la personne&nbsp;pour qui les différences sont les plus grandes, est assez&nbsp;peu citée dans le corpus. Notre méthode a cependant&nbsp;identifié de nombreuses erreurs OCR qui ont révélé&nbsp;des informations inconnues au seul vecteur de l'entité&nbsp;originale.</span></p>
<p><span class="font4">La méthode présentée ici permet d'identifier de potentielles erreurs OCR sur les entités nommées au sein d'un corpus. La prise en compte de ces erreurs peut&nbsp;avoir un impact non négligeable sur le modèle et donc&nbsp;sur les analyses qui en decoulent. Cela semble en particulier vrai pour les entites nommées peu présentes&nbsp;dans un corpus.</span></p><h2><a name="bookmark1"></a><span class="font1" style="font-weight:bold;">Bibliographie</span></h2>
<p><span class="font3" style="font-weight:bold;">Bjerva, J. and Praet, R. </span><span class="font3">(2015). &quot;Word Embeddings Pointing the Way for Late Antiquity.&quot; LaTeCH 2015: 53.</span></p>
<p><span class="font3" style="font-weight:bold;">Gefen, A. </span><span class="font3">(2015). Les enjeux épistémologiques des humanités numériques. Socio. La nouvelle revue des sciences sociales, 4: 61-74.</span></p>
<p><span class="font3" style="font-weight:bold;">Hamilton, W. </span><span class="font3">(2016). ‘‘Diachronic Word Embeddings Reveal Statistical Laws of Semantic Change.'' Proceedings of the&nbsp;54th Annual Meeting of the Association for Computational Linguistics, 1.</span></p>
<p><span class="font3" style="font-weight:bold;">Lemercier, C. </span><span class="font3">(2005). Analyse de reseaux et histoire. Revue D'histoire Moderne et Contemporaine(2): 88-112.</span></p>
<p><span class="font3" style="font-weight:bold;">Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S. and Dean, J. </span><span class="font3">(2013). ‘‘Distributed representations of words&nbsp;and phrases and their compositionality.'' Advances in&nbsp;Neural Information Processing Systems. pp. 3111-3119</span></p>
<p><span class="font3" style="font-weight:bold;">Piotrowski, M. </span><span class="font3">(2012). Natural Language Processing for Historical Texts. (Synthesis Lectures on Human Language Technologies 17). San Rafael, CA: Morgan &amp; Claypool.</span></p>
</body>
</html>