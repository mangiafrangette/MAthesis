<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
	"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head><meta http-equiv="content-type" content="text/html; charset=UTF-8"/><meta name="generator" content="ABBYY FineReader 14"/><title>Microsoft Word - 215. Van Der Zwaan-Flexible NLP Pipelines for Digital Humanities Research-215.docx</title><link rel="stylesheet" href="215_files/215.css" type="text/css"/>
</head>
<body><h1><a name="caption1"></a><a name="bookmark0"></a><span class="font4" style="font-weight:bold;">Flexible NLP Pipelines for Digital Humanities Research</span></h1><h4><a name="bookmark1"></a><span class="font3" style="font-weight:bold;">Janneke M. van der Zwaan</span></h4>
<p><span class="font3"><a href="mailto:j.vanderzwaan@esciencecenter.nl">j.vanderzwaan@esciencecenter.nl</a></span></p>
<p><span class="font3">Netherlands eScience Center, The Netherlands</span></p><h4><a name="bookmark2"></a><span class="font3" style="font-weight:bold;">Wouter Smink</span></h4>
<p><span class="font3"><a href="mailto:w.a.c.smink@utwente.nl">w.a.c.smink@utwente.nl</a></span></p>
<p><span class="font3">University of Twente, The Netherlands</span></p><h4><a name="bookmark3"></a><span class="font3" style="font-weight:bold;">Anneke Sools</span></h4>
<p><span class="font3">a. &nbsp;&nbsp;&nbsp;<a href="mailto:m.sools@utwente.nl">m.sools@utwente.nl</a></span></p>
<p><span class="font3">University of Twente, The Netherlands</span></p><h4><a name="bookmark4"></a><span class="font3" style="font-weight:bold;">Gerben Westerhof</span></h4>
<p><span class="font3"><a href="mailto:g.j.westerhof@utwente.nl">g.j.westerhof@utwente.nl</a></span></p>
<p><span class="font3">University of Twente, The Netherlands</span></p><h4><a name="bookmark5"></a><span class="font3" style="font-weight:bold;">Bernard Veldkamp</span></h4>
<p><span class="font3">b. &nbsp;&nbsp;&nbsp;<a href="mailto:p.veldkamp@utwente.nl">p.veldkamp@utwente.nl</a></span></p>
<p><span class="font3">University of Twente, The Netherlands</span></p><h4><a name="bookmark6"></a><span class="font3" style="font-weight:bold;">Sytske Wiegersma</span></h4>
<p><span class="font3"><a href="mailto:s.wiegersma@utwente.nl">s.wiegersma@utwente.nl</a></span></p>
<p><span class="font3">University of Twente, The Netherlands</span></p><h2><a name="bookmark7"></a><span class="font1" style="font-weight:bold;">Introduction</span></h2>
<p><span class="font3">A lot of Digital Humanities (DH) research involves applying Natural Language Processing (NLP) tasks,&nbsp;such as, sentiment analysis, named entity recognition,&nbsp;or topic modeling. A large amount of NLP software is&nbsp;already available. On the one hand, there are&nbsp;frameworks that bundle software for different tasks&nbsp;and languages (e.g., NLTK [Bird et al, 2009], or xtasl),&nbsp;and on the other hand there are tools that target&nbsp;specific tasks (e.g., gensim, Rehurek and Sojka, 2010).&nbsp;As long as researchers do not need to combine tools&nbsp;from different packages, it is usually relatively easy to&nbsp;write scripts that perform the task. However, for&nbsp;innovative research, combining tools often is required,&nbsp;especially when working with non-English text. This&nbsp;abstract presents work in progress on NLP Pipeline&nbsp;(</span><span class="font3" style="font-weight:bold;">nlppln</span><span class="font3">), an open source tool that improves access to</span></p>
<p><span class="font3">NLP software by facilitating combining NLP functionality from different software packages2.</span></p>
<p><span class="font3" style="font-weight:bold;">nlppln </span><span class="font3">is based on Common Workflow Language (CWL), a standard for describing data analysis&nbsp;workflows and tools (Amstutz et al, 2016). The main&nbsp;advantage of using a standard is that any existing NLP&nbsp;tool can be integrated into a workflow, as long as it can&nbsp;be run as a command line tool. This flexibility is&nbsp;missing from existing frameworks for creating NLP&nbsp;pipelines, such as DKPro (Eckart de Castilho, and&nbsp;Gurevych, 2015) using the UIMA framework (Ferrucci,&nbsp;and Lally, 2004). In addition to improved reuse of&nbsp;existing software, CWL increases research&nbsp;reproducibility, as it provides a standardized, formal&nbsp;record of all steps taken in a processing pipeline.&nbsp;Finally, CWL workflows are modular. This means that&nbsp;individual processing steps can easily be swapped in&nbsp;and out.</span></p>
<p><span class="font3">To demonstrate how NLP tools can be combined using nlppln, we show what need to be done to create&nbsp;a pipeline that removes named entities from a&nbsp;directory of text files. This is a common NLP task, that&nbsp;can be used as part of a data anonymization procedure.&nbsp;</span><span class="font1" style="font-weight:bold;">The Software</span></p>
<p><span class="font3">An NLP pipeline or workflow is a sequence of natural language processing steps. A ‘step’ represents&nbsp;a specific NLP task, that is executed by a single tool.&nbsp;Tools require input and produce output. The basic&nbsp;units in CWL are command line tools (i.e., tools that&nbsp;can be run from the command line). In order to be able&nbsp;to run a command line tool, CWL needs a specification.&nbsp;The </span><span class="font3" style="font-weight:bold;">nlppln </span><span class="font3">software helps creating those&nbsp;specifications. In addition, </span><span class="font3" style="font-weight:bold;">nlppln </span><span class="font3">provides&nbsp;functionality to convert existing NLP tools written in&nbsp;Python to command line tools. Finally, the software&nbsp;helps users to combine (existing and new) processing&nbsp;steps to pipelines.</span></p>
<p><span class="font3">In the next section, we explain how </span><span class="font3" style="font-weight:bold;">nlppln </span><span class="font3">facilitates creating NLP steps, and in “Constructing&nbsp;Pipelines” we demonstrate the creation of an NLP&nbsp;pipeline for data anonymization.</span></p><h3><a name="bookmark8"></a><span class="font1">Generating Steps</span></h3>
<p><span class="font3" style="font-weight:bold;">nlppln </span><span class="font3">allows users to generate CWL specifications for existing NLP tools. To simplify the generation of&nbsp;CWL specifications, we use a convention for NLP tasks.&nbsp;The convention assumes that there can be two types of&nbsp;input parameters: a list of files for which the command&nbsp;should be executed, and/or a file containing metadata&nbsp;about the texts in the corpus. Output parameters&nbsp;consist of a directory where output files are stored&nbsp;(usually there is one output file for every input file)&nbsp;and/or a file in which metadata is stored. So far, almost&nbsp;all steps that are currently available in </span><span class="font3" style="font-weight:bold;">nlppln </span><span class="font3">follow&nbsp;this convention. Be that as it may, we would like to&nbsp;emphasize that it is possible to deviate from this&nbsp;convention; for example, when existing NLP&nbsp;functionality requires different parameters (e.g., the&nbsp;name of a directory containing the input files instead&nbsp;of a list of input files). This does however mean that&nbsp;the user has to adapt the CWL specification by hand.</span></p>
<p><span class="font3">In addition to CWL specifications, </span><span class="font3" style="font-weight:bold;">nlppln </span><span class="font3">allows users to generate boilerplate Python command line&nbsp;tools. A boilerplate command line tool contains&nbsp;generic functionality, such as opening input files and&nbsp;saving output files, but lacks implementation of the&nbsp;specific NLP task. The generated Python command can&nbsp;be used to turn existing NLP functionality into&nbsp;command line tools, and to create Python command&nbsp;line tools for new NLP tasks.</span></p>
<p><span class="font3">Python commands and associated CWL steps are generated using a command line tool that requires the&nbsp;user to answer a sequence of yes / no questions. Listing&nbsp;1 shows what that looks like for a (hypothetical)&nbsp;command ‘command’, that takes as input a metadata&nbsp;file and multiple input files, and produces as output&nbsp;multiple text files and metadata.</span></p>
<p><span class="font5">Generatepythoncommand?[y]:</span></p>
<p><span class="font5">Generate </span><span class="font5" style="text-decoration:underline;">cwl</span><span class="font5"> step? [y]:</span></p>
<p><span class="font5">Commandname[command]:</span></p>
<p><span class="font5">Multiple input files? [y]T Multipleoutput files?[y]:</span></p>
<p><span class="font5">Extension of output files ? [ json ]: txt Metadata output file? [n] : y&nbsp;Savepythoncommandto[nl</span><span class="font5" style="text-decoration:underline;">ppln/</span><span class="font5">c</span><span class="font5" style="text-decoration:underline;">ommand.py</span><span class="font5">]:&nbsp;Savemetadatato?[m</span><span class="font5" style="text-decoration:underline;">etadataout.csv</span><span class="font5">]:</span></p>
<p><span class="font5">Save </span><span class="font5" style="text-decoration:underline;">cwl</span><span class="font5"> step to [ c</span><span class="font5" style="text-decoration:underline;">wl /command. cwl</span><span class="font5"> ] :</span></p>
<p><span class="font0">Listing 1: Generating a CWL specification and associated boilerplate Python command using </span><span class="font0" style="font-weight:bold;">nlppln.</span></p><h3><a name="bookmark9"></a><span class="font1">Constructing Pipelines</span></h3>
<p><span class="font3">To combine text processing steps into a CWL pipeline, </span><span class="font3" style="font-weight:bold;">nlppln </span><span class="font3">provides an interface that allows&nbsp;users to write a simple Python script. We demonstrate&nbsp;this functionality by creating a pipeline that replaces&nbsp;named entities in a collection of text documents.&nbsp;Named entities are objects in text referred to by&nbsp;proper names, such as persons, organizations, and&nbsp;locations. In the example pipeline, named entities will&nbsp;be replaced with their named entity type (i.e., PER&nbsp;(person), ORG (organization), LOC (location), or UNSP&nbsp;(unspecified)). The pipeline can be used as part of a&nbsp;data anonymization procedure.</span></p>
<p><span class="font3">The pipeline consists of the following steps:</span></p>
<p><span class="font3">1. &nbsp;&nbsp;&nbsp;Extract named entities from text documents&nbsp;using frog (van den Bosch et al, 2007), an&nbsp;existing parser/tagger for Dutch</span></p>
<p><span class="font3">2. &nbsp;&nbsp;&nbsp;Convert frog output to SAF, a generic&nbsp;representation for text data3</span></p>
<p><span class="font3">3. &nbsp;&nbsp;&nbsp;Aggregate data about named entities that&nbsp;occur in the text files</span></p>
<p><span class="font3">4. &nbsp;&nbsp;&nbsp;Replace named entities with their named&nbsp;entity type in the SAF documents</span></p>
<p><span class="font3">5. &nbsp;&nbsp;&nbsp;Convert SAF documents to text</span></p>
<p><span class="font3">All steps required for this pipeline are available through </span><span class="font3" style="font-weight:bold;">nlppln</span><span class="font3">. Listing 2 shows the script that creates&nbsp;a CWL workflow for this pipeline. After importing&nbsp;</span><span class="font3" style="font-weight:bold;">nlppln </span><span class="font3">(line 1), a new WorkflowGenerator object is&nbsp;created (line 3), and the available NLP steps are listed&nbsp;(line 4). Next, the script specifies the workflow inputs&nbsp;(line 6). In this case, there is a single input, which is a&nbsp;directory containing text files. This directory is the&nbsp;input of the first step, which is frog_dir (line 8). The&nbsp;output argument txts contains the internal CWL name&nbsp;of the input parameter (line 6). By assigning its value&nbsp;to the input argument dir_in of frog_dir (line 8), the&nbsp;output is connected to the input. Steps 1 to 5 from the&nbsp;pipeline description correspond to lines 8 to 12 in&nbsp;listing 2. After the remaining steps steps of the&nbsp;workflow are added (lines 9-12), the workflow&nbsp;outputs are specified (line 14). Finally, the workflow is&nbsp;saved to a CWL file (line 16).</span></p>
<p><span class="font5">1. &nbsp;&nbsp;&nbsp;impo r tnl</span><span class="font5" style="text-decoration:underline;">ppln</span></p>
<p><span class="font5">2.</span></p>
<p><span class="font5">3. &nbsp;&nbsp;&nbsp;wf=nl</span><span class="font5" style="text-decoration:underline;">ppln.Workf lowGenerator</span><span class="font5"> ( )</span></p>
<p><span class="font5">4. &nbsp;&nbsp;&nbsp;printof ,list_steps()</span></p>
<p><span class="font5">5.</span></p>
<p><span class="font5">6. &nbsp;&nbsp;&nbsp;txtawf. add_inputs (txt_dir=' Directory' )</span></p>
<p><span class="font5">7.</span></p>
<p><span class="font5">8. &nbsp;&nbsp;&nbsp;</span><span class="font5" style="text-decoration:underline;">frogout</span><span class="font5">wf. frog_dir (dir in=txts)</span></p>
<p><span class="font5">9. &nbsp;&nbsp;&nbsp;</span><span class="font5" style="text-decoration:underline;">saf</span><span class="font5">wf. f rog_to_s</span><span class="font5" style="text-decoration:underline;">af (i</span><span class="font5">n_f lies=</span><span class="font5" style="text-decoration:underline;">frogout</span><span class="font5">)</span></p>
<p><span class="font5">10. &nbsp;&nbsp;&nbsp;</span><span class="font5" style="text-decoration:underline;">ner</span><span class="font5">_stata?f. save_ner_data(in_files=sa£)</span></p>
<p><span class="font5">11. &nbsp;&nbsp;&nbsp;new</span><span class="font5" style="text-decoration:underline;">_sa^</span><span class="font5">/f. replace_<sub>r</sub>ner_Unetadata=ner_stats ¿n_f iles=sa±)</span></p>
<p><span class="font5">12. &nbsp;&nbsp;&nbsp;txtwf</span><span class="font5" style="text-decoration:underline;">. saf_t</span><span class="font5">o_txt (Tn_f iles=new_</span><span class="font5" style="text-decoration:underline;">saf</span><span class="font5">)</span></p>
<p><span class="font5">13.</span></p>
<p><span class="font5">14. &nbsp;&nbsp;&nbsp;wf. add_outputXner_stats=ner_statt3{,t=txt)</span></p>
<p><span class="font5">15.</span></p>
<p><span class="font5">16. &nbsp;&nbsp;&nbsp;wf. save (<sup>1</sup> anonymize ..cwl<sup>1</sup>)</span></p>
<p><span class="font0">Listing 2: Python script for constructing the pipeline to replace named entities in text files.</span></p><h2><a name="bookmark10"></a><span class="font1" style="font-weight:bold;">Conclusion</span></h2>
<p><span class="font3">To help DH researchers to (re)use and combine existing NLP software, we presented </span><span class="font3" style="font-weight:bold;">nlppln</span><span class="font3">, an open&nbsp;source Python package for creating flexible and&nbsp;reusable NLP pipelines in CWL. nlppln comes with&nbsp;ready-to-use NLP steps, facilitates creating new steps,&nbsp;and helps combining steps into standardized&nbsp;workflows that are portable across different software&nbsp;and hardware environments. Compared to existing&nbsp;frameworks for creating NLP pipelines, CWL and</span></p>
<p><span class="font3" style="font-weight:bold;">nlppln </span><span class="font3">add flexibility and improved research reproducibility.</span></p>
<p><span class="font3" style="font-weight:bold;">nlppln </span><span class="font3">is a work in progress. An important challenge that needs to be addressed is the fact that&nbsp;there is no standard data format for representing text&nbsp;and/or information extracted from text. This means&nbsp;that we will have to add NLP steps that convert&nbsp;different data formats (cf. Eckart de Castilho, 2016)).&nbsp;For future work, we plan to implement additional NLP&nbsp;steps and pipelines, including functionality that&nbsp;targets more languages. We would also like to add&nbsp;visualizations of pipelines and allow users to run&nbsp;pipelines directly from </span><span class="font3" style="font-weight:bold;">nlppln</span><span class="font3">.</span></p><h2><a name="bookmark11"></a><span class="font1" style="font-weight:bold;">Bibliography</span></h2>
<p><span class="font2" style="font-weight:bold;">Amstutz, P., Crusoe, M. R., Tijanic, N., Chapman, B., Chilton, J., Heuer, M., Kartashov, A., Leehr, D., Ménager, H., Nedeljkovich, M., Scales, M., Soiland-</span></p>
<p><span class="font2" style="font-weight:bold;">Reyes, S., and Stojanovic, L. </span><span class="font2">(2016). </span><span class="font2" style="font-style:italic;">Common Workflow Language, v1.0</span><span class="font2">,.</span></p>
<p><span class="font2" style="font-weight:bold;">Bird, S., Loper, E., and Klein, E. </span><span class="font2">(2009) </span><span class="font2" style="font-style:italic;">Natural Language Processing with Python</span><span class="font2">. O'Reilly Media Inc.</span></p>
<p><span class="font2" style="font-weight:bold;">van den Bosch, A., B Busser, B., Dealemans, G. J., and Canisius, S. </span><span class="font2">(2007) An efficient memory-based mor-</span></p>
<p><span class="font2">phosyntactic tagger and parser for Dutch. In </span><span class="font2" style="font-style:italic;">Proceedings of the 17th Meeting of Computational Linguistics in</span></p>
<p><span class="font2" style="font-style:italic;">the Netherlands,</span><span class="font2"> pages 191-206, 2007.</span></p>
<p><span class="font2" style="font-weight:bold;">Eckart de Castilho, R. </span><span class="font2">(2016). Interoperability = f(commu-nity, division of labour). In </span><span class="font2" style="font-style:italic;">Proceedings of the Workshop</span></p>
<p><span class="font2" style="font-style:italic;">on Cross-Platform Text Mining and Natural Language</span></p>
<p><span class="font2" style="font-style:italic;">Processing Interoperability (INTEROP 2016) at LREC</span></p>
<p><span class="font2" style="font-style:italic;">2016</span><span class="font2">, pages 24-28, 2016.</span></p>
<p><span class="font2" style="font-weight:bold;">Eckart de Castilho, R., and Gurevych, I. (</span><span class="font2">2014). A broad-</span></p>
<p><span class="font2">coverage collection of portable NLP components for building shareable analysis pipelines. In </span><span class="font2" style="font-style:italic;">Proceedings of</span></p>
<p><span class="font2" style="font-style:italic;">the Workshop on Open Infrastructures and Analysis Frameworks for HLT (OIAF4HLT) at COLING 2014,</span><span class="font2"> pages&nbsp;1-11.</span></p>
<p><span class="font2" style="font-weight:bold;">Ferrucci, D., and Lally., A. </span><span class="font2">(2004) UIMA: an architectural approach to unstructured information processing in the</span></p>
<p><span class="font2">corporate research environment. </span><span class="font2" style="font-style:italic;">Natural Language Engineering</span><span class="font2"> 10.3-4, pages 327-348.</span></p>
<p><span class="font2" style="font-weight:bold;">Rehurek, R., and Sojka, P. </span><span class="font2">(2010). Software Framework for Topic Modelling with Large Corpora. In </span><span class="font2" style="font-style:italic;">Proceedings&nbsp;of the LREC 2010 Workshop on New Challenges for NLP</span></p>
<p><span class="font2" style="font-style:italic;">Frameworks</span><span class="font2">, pages 45-50.</span></p>
</body>
</html>