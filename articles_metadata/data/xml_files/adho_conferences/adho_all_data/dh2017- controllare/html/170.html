<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
	"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head><meta http-equiv="content-type" content="text/html; charset=UTF-8"/><meta name="generator" content="ABBYY FineReader 14"/><title>Microsoft Word - 170. Kitamoto-MemoryGraph-170.docx</title><link rel="stylesheet" href="170_files/170.css" type="text/css"/>
</head>
<body>
<p><span class="font2" style="font-weight:bold;">MemoryGraph: Digital</span></p>
<p><span class="font2" style="font-weight:bold;">Critique of Old</span></p>
<p><span class="font2" style="font-weight:bold;">Photographs Using a</span></p>
<p><span class="font2" style="font-weight:bold;">Mobile App that Enhances the Interpretation of&nbsp;Landscape</span></p>
<p><span class="font4" style="font-weight:bold;">Asanobou Kitamoto</span></p>
<p><span class="font4"><a href="mailto:kitamoto@nii.ac.jp">kitamoto@nii.ac.jp</a></span></p>
<p><span class="font4">National Institute of Informatics, Japan</span></p>
<p><span class="font1" style="font-weight:bold;">Introduction</span></p>
<p><span class="font4">MemoryGraph is a medium to record memories as the augmentation of a photograph, which is a medium to record photons. MemoryGraph is&nbsp;a new photographic technique that creates a&nbsp;layer of “memories” (or more precisely, time-series photographs) which are taken by the same&nbsp;composition at different times. Photographs of&nbsp;the same composition can be taken by traditional&nbsp;cameras, but this requires substantial effort, because matching a printed photograph with the&nbsp;current landscape requires mental rotation&nbsp;(Shepard et al., 1971), a psychologically demanding task. MemoryGraph simplifies this task&nbsp;through direct overlay of a photograph and the&nbsp;current landscape on a camera viewfinder with&nbsp;adjustable transparency. We demonstrate that&nbsp;this simple idea opens up new possibilities for&nbsp;the critical interpretation of photographs in the&nbsp;context of digital critique.</span></p>
<p><span class="font1" style="font-weight:bold;">Related Methods</span></p>
<p><span class="font4">MemoryGraph focuses on the spatio-temporal relationship between photographs and the real world. This field of interest has given rise to&nbsp;many methods similar to MemoryGraph. For this&nbsp;reason, we begin with a comparison between&nbsp;MemoryGraph and these related methods in order to characterize MemoryGraph's unique properties.</span></p>
<p><span class="font4">First, it is necessary to compare MemoryGraph with time-lapse animation, which&nbsp;is also a time-series image of the same composition. The fundamental difference between time-lapse animation and MemoryGraph is in time&nbsp;scale and device dependence. Time lapse animation deals with high frequency observations of&nbsp;seconds to minutes using the same location-fized&nbsp;camera, while MemoryGraph deals with low frequency observations over a period of days to&nbsp;years. These observations may potentially use&nbsp;different cameras that are not fixed at the location. In short, MemoryGraph is a tool to realize&nbsp;fixed point observation at any place for any time&nbsp;interval.</span></p>
<p><span class="font4">Secondly, we contrast MemoryGraph with augmented reality (AR), which focuses on the&nbsp;alignment of the real space and the virtual space&nbsp;so that a photograph can be seen as an overlay on&nbsp;the real space through a camera viewfinder. On&nbsp;the contrary, MemoryGraph focuses on the overlay of a photograph on a camera viewfinder as a&nbsp;graphic reference to illustrate the composition of&nbsp;a further action (namely, taking a photograph).&nbsp;This key contrast suggests fundamentally different roles between augmented reality and&nbsp;MemoryGraph. Augmented reality is a tool for exhibition, in the sense that alignment is controlled&nbsp;by a tool, while the user is allowed to be a passive&nbsp;visitor who experiences an environment prepared by someone else. Quite the opposite,&nbsp;MemoryGraph is a tool for participation: the “visitor” controls the alignment, and the user should&nbsp;be an active explorer who searches for the best&nbsp;match between photograph and real-life landscape. In short, MemoryGraph is a tool for actions, such as participatory annotation.</span></p>
<p><span class="font4">Our final comparison discusses photo-sharing services dedicated to old photographs. For example, Historypin (Shift, 2010) is designed to&nbsp;share photographs of the past using a map interface, while an advanced system might use a&nbsp;street-view interface to place photographs in 3D.&nbsp;Both tools aim to link photographs to the real&nbsp;world, however, their methods of achieving this&nbsp;goal do not rely on ventures into the “real world”&nbsp;to “place” the photographs. Photo sharing services depend on “arm-chair” annotators, but&nbsp;MemoryGraph depends on “field” annotators&nbsp;who visit a real place to take another photograph. In short, MemoryGraph is a tool to motivate people to move in the real world.</span></p>
<p><span class="font1" style="font-weight:bold;">Proposed Method</span></p>
<p><span class="font4">MemoryGraph is designed as a mobile app for two reasons. First, the idea of “graphic reference”&nbsp;overlay on a camera viewfinder cannot be implemented on traditional cameras that do not expose API (application programming interface).&nbsp;By re-purposing the viewfinder of a smart phone,&nbsp;MemoryGraph can extend the grid-based reference of a traditional camera viewfinder to a&nbsp;graphic reference such as an old photograph.&nbsp;Secondly, in order employ MemoryGraph as a&nbsp;field work tool, the use of a mobile phone is the&nbsp;best choice for mobility and also for real-time information sharing with the server.</span></p>
<p><span class="font4">The task of the user is to find the best match between a graphic reference and the real world&nbsp;using an opaque viewfinder with adjustable&nbsp;transparency. Direct comparison between two&nbsp;scenes not only reduces the burden of mental rotation for the user, but also makes the search enjoyable: the movement of the user gives real-time&nbsp;visual feedback that suggests how “good” the&nbsp;move is. This gamification effect motivates users&nbsp;to search for better matching, and promotes photographic crowd-sourcing for participatory annotation.</span></p>
<p><span class="font4">The outcome of this task is two types of data. One is a photograph that records the current&nbsp;landscape, and another is the metadata of the&nbsp;photograph such as latitude, longitude, and direction observed by sensors in a mobile phone.&nbsp;Metadata may be enhanced later to add a title,&nbsp;and description (among other things), and users&nbsp;can upload metadata and photographs to the&nbsp;server for sharing. The uploaded data can then&nbsp;be used for scholarly research, because the GPS&nbsp;coordinates and the temporally different views&nbsp;of the landscape are valuable resources for understanding the landscape changes.</span></p>
<p><span class="font1" style="font-weight:bold;">Results</span></p>
<p><span class="font4">The MemoryGraph (CODH, 2016) app is available for free on Google Play, but an iOS version has not yet been released. The predecessor app,&nbsp;MemoryHunt (Kitamoto, 2015), has been used&nbsp;for both the study of cultural landscapes and the&nbsp;monitoring of disaster recovery (DSR, 2014).</span></p>
<p><span class="font4">To study cultural landscapes, we held several workshops with both scholars and laypersons&nbsp;who tried the app in the field. An example is&nbsp;shown in Figure 1, where the reference image&nbsp;was a photograph of Imperial Palace Moat in Tokyo. The photograph was easy to interpret, but&nbsp;the actual place was difficult to find. Figure 2&nbsp;shows how participants walked along the moat</span></p>
<p><span class="font4">to find the best match. At each place, participants took the photograph that they believed to be the&nbsp;best match, but the best solution of Figure 1 was&nbsp;found after many trials of all the participants.</span></p><img src="170_files/170-1.jpg" style="width:217pt;height:60pt;"/>
<p><span class="font0">Figure 1. Comparison of two photographs of the same composition. “A view from Miyakezaka to the ministry&nbsp;of justice” taken around 1911 and the current landscape. Courtesy of National Diet Library.</span></p><img src="170_files/170-2.jpg" style="width:188pt;height:180pt;"/>
<p><span class="font0">Figure 2. Participants walked along the moat to find the best match, and their trials are marked by icons.&nbsp;The final solution of Figure 1 was obtained at the&nbsp;north end of the moat.</span></p>
<p><span class="font4">For the second purpose, we held workshops at Kobe in Japan, which was severely damaged by&nbsp;the earthquake in 1995, and Aceh in Indonesia,&nbsp;which was severely damaged by the tsunami in&nbsp;2004, to understand how the city recovered from&nbsp;the disaster. The app was enjoyed by local people&nbsp;in two countries, and some children were involved more actively than adults due to the gamification effect.</span></p>
<p><span class="font4">MemoryGraph can be generalized in several ways. First, it can be generalized from landscape&nbsp;to object: for example, time-series photographs&nbsp;of the same person at different places. Second, it&nbsp;can be generalized to cross-media reference: for&nbsp;example, taking the same composition at a “sacred place” of pop-culture work inspired by the&nbsp;real landscape.</span></p>
<p><span class="font1" style="font-weight:bold;">Discussion on Digital Critique</span></p>
<p><span class="font4">Digital critique, or what has been referred to in other words as digital criticism (Kitamoto,&nbsp;2016) or data criticism (Kitamoto, 2014), was&nbsp;proposed by the author as a framework for digital scholarship in the humanities. It has been applied to the criticism of non-textural sources&nbsp;such as maps and photographs with the intent of&nbsp;using them as evidence for historical studies. Although the digital humanities are often considered quantitative or metric humanities, digital&nbsp;critique focuses on the digital creation and management of humanities knowledge. Several types&nbsp;of digital tools have been designed for the critical&nbsp;interpretation of textual and non-textural&nbsp;sources, including success stories such as the&nbsp;identification of Silk Road ruins, or the characterization of mistakes in the renovation of old Beijing maps (Kitamoto et al., 2014) (Kitamoto et al.,&nbsp;2016). We claim that MemoryGraph is another&nbsp;digital critique tool that asks the following research questions in order to use a photographic&nbsp;source as historical evidence.</span></p>
<p><span class="font4">The first research question asks what the variance and invariance is in the target landscape over time. Invariance is often found as artificial&nbsp;features such as roads and monuments, or natural features such as a mountain ridge, but in&nbsp;other cases, the identification of invariance requires training of the user in terms of interpretive performance on the historical landscape.</span></p>
<p><span class="font4">Secondly, we ask how historical evidences can be best integrated across different sources, such&nbsp;as old maps, old photographs and historical databases. Invariance found through the app is a&nbsp;hint to links different sources over time, and this&nbsp;contributes to expanding our understanding by&nbsp;integrating knowledge from different sources.</span></p>
<p><span class="font4">Our final research question asks why the photograph was taken in this setting. This is because the best match is theoretically achieved by the&nbsp;same physical posture between the original photographer and the user (Kitamoto, 2015). This&nbsp;means that as a user tries to find the best match&nbsp;using the app, a user can re-experience the original photographer who took the photograph in&nbsp;the same posture. The physical overlay of the&nbsp;user and the photographer may lead to research&nbsp;questions investigating the emotion or the way&nbsp;of thinking of the original photographer at the&nbsp;time. This has potential to give birth to new interpretation of photographs from the physical or&nbsp;emotional perspective.</span></p>
<p><span class="font1" style="font-weight:bold;">Acknowledgments</span></p>
<p><span class="font4">The project was partially supported by JSPS</span></p>
<p><span class="font4">Kakenhi Center Grant Number 16H02920 and by Center for Integrated Area Studies (CIAS), Kyoto&nbsp;University. The core contributor to the app is Mr.&nbsp;Tomohiro Ikezaki.</span></p>
<p><span class="font1" style="font-weight:bold;">Bibliography</span></p>
<p><span class="font3" style="font-weight:bold;">Center for Open Data in the Humanities (CODH)</span></p>
<p><span class="font3">(2016). “MemoryGraph.” <a href="https://mp.ex.nii.ac.jp/mg/">https://mp.ex.nii.ac.jp/mg/</a>, (accessed on April 6,&nbsp;2017).</span></p>
<p><span class="font3" style="font-weight:bold;">Digital Silk Road Project (DSR) </span><span class="font3">(2014). “MemoryHunt.”&nbsp;&nbsp;&nbsp;&nbsp;<a href="http://dsr.nii.ac.jp/memory-">http://dsr.nii.ac.jp/memory-</a></span></p>
<p><span class="font3">hunting/, (accessed on April 6, 2017).</span></p>
<p><span class="font3" style="font-weight:bold;">Kitamoto, A., and Nishimura, Y. </span><span class="font3">(2016). &quot;Digital criticism platform for evidence-based digital humanities with applications to historical studies of Silk Road.&quot; Digital Humanities 2016:Conference Abstracts.</span></p>
<p><span class="font3" style="font-weight:bold;">Kitamoto, A., and Nishimura, Y. </span><span class="font3">(2014). &quot;Data criticism: general framework for the quantitative interpretation of non-textual sources.&quot; Digital Humanities 2014:Conference Abstracts.</span></p>
<p><span class="font3" style="font-weight:bold;">Kitamoto, A. </span><span class="font3">(2015). &quot;MemoryHunt: a mobile app with an active viewfinder for crowdsourced annotation through the re-experience of the photographer&quot;, Fifth Annual Conference of the Japanese Association for Digital Humanities: Conference Abstracts.</span></p>
<p><span class="font3" style="font-weight:bold;">Shepard, R.N., Metzler, J. </span><span class="font3">(1971). &quot;Mental rotation of three-dimensional objects.&quot; Science, 171(3972):&nbsp;701-703.</span></p>
<p><span class="font3" style="font-weight:bold;">Shift </span><span class="font3">(2010). “Historypin.” <a href="http://www.history-pin.org/">http://www.history-pin.org/</a>, (accessed on April 6, 2017).</span></p>
</body>
</html>