<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
	"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head><meta http-equiv="content-type" content="text/html; charset=UTF-8"/><meta name="generator" content="ABBYY FineReader 14"/><title>Microsoft Word - 509. Bassett-Critical Digital Humanities and Machine-Learning-509.docx</title><link rel="stylesheet" href="509_files/509.css" type="text/css"/>
</head>
<body><h1><a name="caption1"></a><a name="bookmark0"></a><span class="font2" style="font-weight:bold;">Critical Digital Humanities and Machine Learning</span></h1><h3><a name="bookmark1"></a><span class="font4" style="font-weight:bold;">Caroline Bassett</span></h3>
<p><span class="font4">c. &nbsp;&nbsp;&nbsp;<a href="mailto:bassett@sussex.ac.uk">bassett@sussex.ac.uk</a></span></p>
<p><span class="font4">University of Sussex, United Kingdom</span></p><h3><a name="bookmark2"></a><span class="font4" style="font-weight:bold;">David M. Berry</span></h3>
<p><span class="font4">d. &nbsp;&nbsp;&nbsp;<a href="mailto:m.berry@sussex.ac.uk">m.berry@sussex.ac.uk</a></span></p>
<p><span class="font4">University of Sussex, United Kingdom</span></p><h3><a name="bookmark3"></a><span class="font4" style="font-weight:bold;">M. Beatrice Fazi</span></h3>
<p><span class="font4"><a href="mailto:b.fazi@sussex.ac.uk">b.fazi@sussex.ac.uk</a></span></p>
<p><span class="font4">University of Sussex, United Kingdom</span></p><h3><a name="bookmark4"></a><span class="font4" style="font-weight:bold;">Jack Pay</span></h3>
<p><span class="font4"><a href="mailto:jp242@sussex.ac.uk">jp242@sussex.ac.uk</a></span></p>
<p><span class="font4">University of Sussex, United Kingdom</span></p><h3><a name="bookmark5"></a><span class="font4" style="font-weight:bold;">Ben Roberts</span></h3>
<p><span class="font4"><a href="mailto:b.l.roberts@sussex.ac.uk">b.l.roberts@sussex.ac.uk</a></span></p>
<p><span class="font4">University of Sussex, United Kingdom</span></p><h2><a name="bookmark6"></a><span class="font1" style="font-weight:bold;">Panel Statement</span></h2>
<p><span class="font4">This panel undertakes a speculative and theoretical discussion of possible future directions for digital humanities work driven by what we call informating,&nbsp;augmenting and automating technologies in the digital&nbsp;humanities. The panel particularly examines the emergence of a new paradigm of artificial intelligence&nbsp;around machine learning, statistical techniques and&nbsp;textual interfaces; a paradigm that challenges the way&nbsp;in which we understand the provision of digital humanities technologies and infrastructures. We explore&nbsp;the debates over informating, augmenting and automating processes that are now starting to emerge in&nbsp;digital humanities, and the historical trajectory that&nbsp;led to the current rapid changes from computational&nbsp;techniques. By looking at how machine-learning infrastructures effect knowledge formations, we engage&nbsp;with these new knowledges and practices, and argue&nbsp;that digital humanities must seek to contest and transform particular institutional structures that are problematic for humanities scholarship.</span></p>
<p><span class="font4">Although differences have emerged within the digital humanities between “those who use new digital tools to aid relatively traditional scholarly projects&nbsp;and those who believe that DH is most powerful as a&nbsp;disruptive political force that has the potential to reshape fundamental aspects of academic practice”&nbsp;(Gold, 2012: x), it is still the case that, as a growing and&nbsp;developing disciplinary area, digital humanities has&nbsp;much opportunity for these disparate elements to&nbsp;work together. Not unlike differences between empirical and critical sociology in a previous iteration of a&nbsp;contestation over knowledge, epistemology, disciplinary identity and research, digital humanities as a discipline will be richer and more vibrant with alternative voices contributing to projects, publications and&nbsp;practices. Indeed, the debates within digital humanities “bear the mark of a field in the midst of growing&nbsp;pains as its adherents expand from a small circle of&nbsp;like-minded scholars to a more heterogeneous set of&nbsp;practitioners who sometimes ask more disruptive&nbsp;questions” (Gold, 2012: x-xi).</span></p>
<p><span class="font4">Developing a critical approach to machine learning, for example, calls for computation itself to be histori-cised, and its developing relationship with humanities&nbsp;to be carefully uncovered. Similarly, by focusing on the&nbsp;materiality of machine learning, our attention is&nbsp;drawn to the microanalysis required at the level of&nbsp;computational conditions of possibility, combined&nbsp;with a macroanalysis of deployment of machine-learning systems in humanities work. This calls for us to&nbsp;think critically about how machine learning is being&nbsp;designed and deployed in the specific problem domains represented by the informating, augmenting&nbsp;and automating of digital humanities. The panel critically engages with these three modes of thought and&nbsp;practice, in order to connect and explore the present&nbsp;and possible future of digital humanities. We develop&nbsp;this approach in the context of these new techniques&nbsp;of knowledge-presentation, new infrastructures for&nbsp;knowledge work, and new formations around human&nbsp;capacities to work with complex and large data sets.&nbsp;Strong claims are often made about the potential for&nbsp;replacing aspects of traditionally humanities work undertaken by human labour alone through machinelearning techniques. Here, through a critical examination of new epistemologies and machine-generated&nbsp;data ontologies, for example, we examine the possibility of methods for a </span><span class="font4" style="font-style:italic;">critical digital humanities</span><span class="font4"> in relation to new machine-learning techniques, together</span></p>
<p><span class="font4">with how machine learning might be repurposed </span><span class="font4" style="font-style:italic;">for</span><span class="font4"> a critical project within DH scholarship.</span></p><h2><a name="bookmark7"></a><span class="font1" style="font-weight:bold;">Towards a critique of machine learning: critical digital humanities and AI</span></h2>
<p><span class="font0" style="font-style:italic;">David M. Berry</span></p>
<p><span class="font4">In this paper I investigate the claims of computational models and practices drawn from the field of artificial intelligence and more particularly machine learning. I do this to explore the extent to which machine learning raises important questions for our notions of being human, but also, relatedly the concept of&nbsp;civil society and democracy as distilled through notions of hermeneutic practice. That is, that in the 21st&nbsp;century we are seeing the creation of specific formations which threaten historical notions of humanities research and thinking. They represent new modes&nbsp;of knowing and thinking driven by these new forms of&nbsp;computation such as machine learning and Big Data,&nbsp;and which will have implications for the capacity to&nbsp;develop and use social and human faculties.</span></p>
<p><span class="font4">It is certainly the case that through the innovative assembling and organisation of scale technologies together with human actors new cognitive forms are under construction and experimentation. This paper develops a speculative and theoretical discussion of possible future directions driven by what we call In-formating or Augmenting technologies in the digital&nbsp;humanities. In this paper, the notion of a digital humanities is linked to the social, cultural, economic and&nbsp;political questions of a recontextualisation and social&nbsp;re-embedding of digital technologies within a social&nbsp;field. Indeed, exploring the digital humanities through&nbsp;a critical lens I seek to understand how different disciplinary specialisms are newly refracted not just by&nbsp;their interaction, but also by the common denominator and limitations of computation. That is, how the&nbsp;constellation of concepts that are used within a disciplinary context are challenged and transformed within&nbsp;a computational frame.</span></p>
<p><span class="font4">Indeed, this raises theoretical and methodological questions, for example, digital humanities is keen develop tools to explore the new techniques such as machine learning for the field. This calls for a critical response, and there has already been some valuable&nbsp;work undertaken in this area, such as Alan Liu's work&nbsp;on critical infrastructure studies, but here I explore&nbsp;how a critical digital humanities can offer a way of&nbsp;thinking about the theoretical and empirical approach&nbsp;to massive-scale technologies. In this paper I argue&nbsp;that digital humanities should not only map these challenges but also propose new ways of reconfiguring research and teaching to safeguard critical and rational&nbsp;thought in a digital age. First, I turn my attention to research infrastructure and how critical approaches can&nbsp;contribute to and offer methods for contesting ML. I&nbsp;argue that research infrastructures provide the technical a priori for the support of and conditions of possibility for digital humanities projects, but in a machine-learning paradigm different techniques and critical methods will be required to make sense of their&nbsp;use. Secondly, in relation to data, we might consider&nbsp;the more general implications of datafication not just&nbsp;within the general problem of big-data, but in terms of&nbsp;the specific issues raised by machine learning in the</span></p>
<p><span class="font4">generation, processing and automated classification of</span></p>
<p><span class="font4">data-especially where the metadata becomes nonhuman-readable.</span></p>
<p><span class="font4">This links to my final question about how visibility is made problematic when mediated through computational systems. The question is also linked to </span><span class="font4" style="font-style:italic;">who&nbsp;</span><span class="font4">and </span><span class="font4" style="font-style:italic;">what</span><span class="font4"> is made visible in these kinds of machinelearning systems, especially where as Feminist theorists have shown, visibility itself can be a gendered&nbsp;concept and practice, as demonstrated in the historical&nbsp;invisibility of women in the public sphere, for example&nbsp;(see Benhabib, 1992). Finally, this paper will explore&nbsp;how to embed the capacity for reflection and thought&nbsp;into a critically-oriented digital humanities and thus to&nbsp;move to a new mode of experience, a two dimensional&nbsp;experience responsive to the potentialities of people&nbsp;and things intensified by the advances in machinelearning capacities. In other words, the reconfiguring&nbsp;of quantification practices and instrumental processes&nbsp;away from domination (Adorno, Horkheimer, Marcuse) and control (Habermas), instead towards reflex-ivity, critique and democratic practices. As Galloway&nbsp;argues, “as humanist scholars in the liberal arts, are we&nbsp;outgunned and outclassed by capital? Indeed we are-now more than ever. Yet as humanists we have access&nbsp;to something more important.... continue to pursue&nbsp;the very questions that technoscience has always bungled, beholden as it is to specific ideological and industrial mandates” (Galloway, 2014: 128). I argue that&nbsp;specific intervention points within the materialisation&nbsp;of this ML a priori, such as in design processes, can be&nbsp;explored to contest machine-learning techniques that&nbsp;serve to instrumentalise humanities approaches.</span></p>
<p><span class="font4">Digital humanities has the technical skills and cultural capital to make a real difference in how these machine-learning projects are developed, the ways in which instrumental logics are embedded within them&nbsp;and interventions made possible. For example, digital&nbsp;humanities through its already strong advocacy of&nbsp;open access, could push for and defend open source,&nbsp;open standards and copyleft licenses for technical&nbsp;components and software, opening up and documenting new techniques for machine-learning by humanists for humanists-but this could also be the opening&nbsp;up of the complexity of the black box of ML systems.&nbsp;The ways in which these aspects interrelate in terms&nbsp;of the ML “space of work” is hugely important, that is,&nbsp;the functional capacity of a machine-learning system&nbsp;is crucial, in as much as the range of humanities work&nbsp;may be adversely effected or inhibited by the shape of&nbsp;a machine-learning infrastructural system. I argue that&nbsp;these are urgent questions, with the recent turn towards what has come to be called “platformisation”,&nbsp;that is the construction of a single digital system that&nbsp;acts as a technical monopoly within a particular sector,&nbsp;and it is certainly the case that the implications of machine-learning infrastructures and their black-boxed&nbsp;techniques for sorting, classification and ordering&nbsp;large amounts of data needs constant vigilance from&nbsp;digital humanists.</span></p><h2><a name="bookmark8"></a><span class="font1" style="font-weight:bold;">Augmenting and automating human and machine attention in the (digital) humanities</span></h2>
<p><span class="font0" style="font-style:italic;">M. Beatrice Fazi</span></p>
<p><span class="font4">Attention denotes the cognitive process of selecting and focusing upon certain aspects of information&nbsp;whilst ignoring others. In recent years, it has been argued that this special state of percipient awareness is&nbsp;undergoing a profound transformation, due to the increasing intertwining of digital devices and everyday&nbsp;cognitive tasks (see Carr, 2010; Gazzaley and Rosen,&nbsp;2016). Social media, phone apps, design interfaces,&nbsp;smart devices: the industry markets these technologies as helpful assistants that will free us from the&nbsp;chore of identifying, selecting and retaining relevant&nbsp;information, thus allowing us to dedicate our time, and&nbsp;our mental efforts, to other things. In addition, digital&nbsp;software and hardware are equally used to tune&nbsp;senses and to maintain motivation. Whilst cognitive&nbsp;cognates such as memory and intelligence are of&nbsp;course also targeted, it is the capacity to pay attention&nbsp;that seems primarily to be called into question here. In&nbsp;an attention economy, attention is believed to be a&nbsp;scarce commodity. The assumption is that, with the&nbsp;current information overload, digital machines are instruments able to outsource decisions regarding what&nbsp;to prioritise, what to select and what to discard in the&nbsp;data-deluge. Whilst much concern in the 20th century&nbsp;focused on the question “Can a machine think?”, and&nbsp;Artificial Intelligence labs were devoted to answering&nbsp;this question, in the 21st century the central question&nbsp;seems to be “How do we think with machines, and how&nbsp;do we get machines to do much of our thinking for us?”</span></p>
<p><span class="font4">The exteriorisation of cognitive faculties such as the capacity for attention does, however, come at a&nbsp;price. Studies in neuroscience and neuropsychology,&nbsp;drawing from theories of neuronal plasticity, show&nbsp;that our brain is being rewired in favour of new cognitive skills, and to the detriment of older but cherished&nbsp;abilities, such as the capacity to read a novel from&nbsp;cover to cover. Evidence of this deterioration of human&nbsp;attention comes from science, yet everyday anecdotal&nbsp;confirmations also come from educators and parents,&nbsp;who report of children who cannot focus, and of students who are distracted and cannot complete their&nbsp;assignments. Relevantly, N. Katherine Hayles (2007)&nbsp;has described this situation in terms of a generational&nbsp;cognitive shift.</span></p>
<p><span class="font4">The humanities, due to the fact that they are largely based around texts, have often elaborated and developed concerns about human attention under the rubric of debates as to what counts as reading. Within&nbsp;the digital humanities, more specifically, it has been&nbsp;stressed that, whilst humans are very good at “close&nbsp;reading” (i.e. the careful, attentive and sustained inspection of a text), computing machines allow us to&nbsp;consider a broader picture. Franco Moretti (2013),&nbsp;amongst others, has called this condition “distant&nbsp;reading”. These debates have opened up considerations about the possibility of an “algorithmic criticism”&nbsp;(Ramsay, 2011), as well as reflections on the importance of the hermeneutic faculties of human beings&nbsp;(Berry, 2012; Stiegler, 2010 and 2016). In this paper, I&nbsp;depart from these discussions within the digital humanities and then move to argue how new understandings of human attention might emerge in conjunction with possible conceptions of what I call “machine attention”. I will map these possible conceptions&nbsp;of machine attention in relation to increasingly popular Artificial Intelligence techniques known as machine learning. More specifically, I will consider how&nbsp;machine-learning programs might be said or seen to&nbsp;pay attention to data-stimuli: they detect some information and discard some others, forming and dissolving patterns, in order to shape and sharpen their cognitive outcomes based on these selections. I will then&nbsp;emphasise the relevance of these modes of machine attention for the way in which we can understand what&nbsp;human attention might become after the computational turn in the humanities.</span></p>
<p><span class="font4">The question of what is happening to human attention is an important and pressing one for the humanities. It is always difficult to define what the humanities are, or where they begin and end. However, surely few&nbsp;would object that the humanities are the locus of&nbsp;“deep” attention: humanities disciplines prioritise textual analysis, where the process of knowing is intimately connected to those of making sense, interpreting, and of giving meaning. These are epistemic processes that start and end with the cognitive exercise of&nbsp;attention. The pedagogical issue of what happens to&nbsp;students if they have lost (or never gained) the capacity to focus is also a question upon which the future of&nbsp;humanities disciplines, and humanities departments,&nbsp;seems to be predicated. In this paper I will address&nbsp;these issues, by considering the intermeshing of human and machine modes of attention, whilst also arguing that our engagement with automated forms of attention (as well as of other automated and augmented&nbsp;cognitive processes) should involve a commitment to&nbsp;re-defining and enlarging the prospect of what computational mechanisms are, and what rule-based, computational cognitive processes might amount to.</span></p><h2><a name="bookmark9"></a><span class="font1" style="font-weight:bold;">‘The new spirit of automation': the changing discourse of automation anxiety</span></h2>
<p><span class="font0" style="font-style:italic;">Caroline Bassett, Ben Roberts and Jack Pay</span></p>
<p><span class="font4">From self-driving cars, through high-frequency trading to military drones and organised swarms of&nbsp;shelf-stacking robots, our era is marked by rising automation and a new fascination with the likely social,&nbsp;cultural, and economic impacts of this computationally driven transformation. This paper will explore innovative methods by which the humanities might address contemporary </span><span class="font4" style="font-style:italic;">automation anxiety</span><span class="font4">. The wider&nbsp;topic of automation is a pressing subject with various&nbsp;existing academic responses such as Frey and Osborne's work on automation and the future of employment (2013). The focus of this paper is to address, as a&nbsp;topic in its own right, the cultural and social anxiety&nbsp;generated by these new forms of computational automation. What new research methods can the humanities use to map and understand automation anxiety&nbsp;around opaque computational decision making? What&nbsp;digital tools can be brought to bear on the diverse&nbsp;types of online public culture in which this anxiety is&nbsp;expressed?</span></p>
<p><span class="font4">Automation anxiety is evident in a plethora of popular contemporary accounts, public debates and political interventions. Tyler Cowen's </span><span class="font4" style="font-style:italic;">Average is Over</span><span class="font4"> depicts a dystopian future in which the job market is divided between a highly educated and skilled elite capable of harnessing automation for personal wealth creation and a wider mass who are consigned to low&nbsp;paid work. Other accounts see in this new wave of&nbsp;computerisation the potential for a productive redefinition of the relationship with work. Futurists</span></p>
<p><span class="font4">Martin Ford in </span><span class="font4" style="font-style:italic;">Rise of the Robots</span><span class="font4"> (2015) and Jerry Kaplan in </span><span class="font4" style="font-style:italic;">Humans Need Not Apply</span><span class="font4"> (2015) propose to&nbsp;respond to the automation of work through the creation of a universal income. In a more radical version of&nbsp;this thesis, postcapitalism, as charted by Paul Mason,&nbsp;posits automation as the basis of a technologically-driven, non-market successor to capitalism. Another&nbsp;type of anxiety arises out of the increasing use of computerisation in law enforcement and military action.&nbsp;Here there is an automation anxiety that the current&nbsp;wave of military drones will evolve into fully autonomous killing machines, with software systems governing decisions about life and death. In July 2015 over&nbsp;3000 robotics and artificial intelligence researchers&nbsp;and over 17000 other academics and interested parties (including Stephen Hawking, Elon Musk and Noam&nbsp;Chomsky) signed an open letter, published on the Future of Life website and widely disseminated in the&nbsp;global media, calling for a global ban on “offensive autonomous weapons beyond meaningful human control.” There is also a more general anxiety which asks&nbsp;what happens to human life when so many tasks are&nbsp;automated away. Nicholas Carr's </span><span class="font4" style="font-style:italic;">The Glass Cage:&nbsp;Where Automation is Taking Us</span><span class="font4"> (2014) suggests that&nbsp;automation is a threat to humanity itself—as we delegate tasks to computational tools, human cognitive capacities atrophy, understanding weakens, and the&nbsp;power of human reasoning is undermined.</span></p>
<p><span class="font4">This paper places contemporary automation anxiety in the context of historical debates about automation. It examines methods that might be used to analyse changing social attitudes to automation and computation between the 1960s and the present. Automation was a controversial topic in both Britain and the United States in the 1960s. In 1964 defence automation specialist Sir Leon Bagrit gave the public BBC&nbsp;Reith lectures on the topic. In the same year, President&nbsp;Lyndon B. Johnson set up the National Commission on&nbsp;Technology, Automation, and Economic Progress.&nbsp;Then, as now, there were concerns about automation&nbsp;and the future of employment. Then, as now, there&nbsp;were utopian imaginings of the future social benefits&nbsp;of automation. Nevertheless the hypothesis here&nbsp;would be that there are important differences between the two eras and that we can learn from changing attitudes to automation and computation. Among&nbsp;other things, analysis of changing attitudes to automation might illuminate different historical perspectives&nbsp;on: the end(s) of work; the relationship between labour and the domestic sphere; the role of computation&nbsp;in society.</span></p>
<p><span class="font4">The paper takes inspiration, but not theoretical orientation, from Boltanski and Chiapello's </span><span class="font4" style="font-style:italic;">The New Spirit of Capitalism</span><span class="font4"> which used textual analysis of management literature from the 1960s and 1990s to argue&nbsp;for a fundamental shift in what they call the ‘spirit of&nbsp;capitalism', i.e. the way in which capitalism justifies itself. In a similar vein we analysed key grey literatures&nbsp;(policy, commercial reports, academic and government papers) on automation from the 1960s and present in order to understand the changing discourse&nbsp;around automation. A key concern was to use digital&nbsp;humanities tools which provide different scales of&nbsp;analysis and new perspectives. We did this both to&nbsp;generate new understandings of automation anxiety&nbsp;across time and to investigate ways in which digital&nbsp;humanities and media archaeological approaches intersect.</span></p>
<p><span class="font4">The “new spirit” of capitalism which has emerged between the 1960s and the present day consists in a&nbsp;highly decentralised networked form of capitalism,&nbsp;characterised by “flatter” organisational hierarchy,&nbsp;much greater autonomy within firms for both individuals and teams, lower job security and the proliferation of temporary contracts and outsourcing. Boltan-ski and Chiapello use their sociological analysis of&nbsp;management literature to support a more speculative,&nbsp;philosophical account of capitalism and its critique,&nbsp;notably seeing the contemporary spirit of capitalism&nbsp;as incorporating the critiques that were made of capitalism in the 1960s and particularly around May 1968.</span></p>
<p><span class="font4">Similarly this paper argues that automation controversies could be a springboard to more general debates about the changing relationship between computation and society. The central premise here is that there is a much to be discovered from </span><span class="font4" style="font-style:italic;">attitudes to</span><span class="font4"> automation and the justification of computation tools as&nbsp;there is from the specific technological forms and implementations of automation.</span></p><h2><a name="bookmark10"></a><span class="font1" style="font-weight:bold;">Bibliography</span></h2>
<p><span class="font3" style="font-weight:bold;">Bagrit, L. </span><span class="font3">(1965). </span><span class="font3" style="font-style:italic;">The Age of Automation</span><span class="font3">. The BBC Reith Lectures 1964. London: Weidenfeld and Nicholson.</span></p>
<p><span class="font3" style="font-weight:bold;">Benhabib, S. </span><span class="font3">(1992). </span><span class="font3" style="font-style:italic;">Situating the Self: Gender, Community and Postmodernism in Contemporary Ethics</span><span class="font3">. London:&nbsp;Routledge.</span></p>
<p><span class="font3" style="font-weight:bold;">Berry, D. M. </span><span class="font3">(2011). </span><span class="font3" style="font-style:italic;">The Philosophy of Software: Code and Mediation in the Digital Age</span><span class="font3">. London: Palgrave Macmillan.</span></p>
<p><span class="font3" style="font-weight:bold;">Berry, D. M. </span><span class="font3">(2012). </span><span class="font3" style="font-style:italic;">Understanding Digital Humanities</span><span class="font3">. Basingstoke: Palgrave.</span></p>
<p><span class="font3" style="font-weight:bold;">Berry, D. M. </span><span class="font3">(2014). </span><span class="font3" style="font-style:italic;">Critical Theory and the Digital</span><span class="font3">. New York: Bloomsbury</span></p>
<p><span class="font3" style="font-weight:bold;">Berry, D. M. and Fagerjord, A. </span><span class="font3">(2017). </span><span class="font3" style="font-style:italic;">Digital Humanities: Knowledge and Critique in a Digital Age</span><span class="font3">. Cambridge: Polity.</span></p>
<p><span class="font3" style="font-weight:bold;">Boltanski, L. and Chiapello, E. </span><span class="font3">(2007). </span><span class="font3" style="font-style:italic;">The New Spirit of Capitalism</span><span class="font3">. London: Verso.</span></p>
<p><span class="font3" style="font-weight:bold;">Carr, N. </span><span class="font3">(2010). </span><span class="font3" style="font-style:italic;">The Shallows: What the Internet is Doing to Our Brains</span><span class="font3">. New York: W. W. Norton.</span></p>
<p><span class="font3" style="font-weight:bold;">Carr, N. G. </span><span class="font3">(2014). </span><span class="font3" style="font-style:italic;">The Glass Cage: Automation and Us</span><span class="font3">. New York: Norton.</span></p>
<p><span class="font3" style="font-weight:bold;">Cowen, T. </span><span class="font3">(2013). </span><span class="font3" style="font-style:italic;">Average Is Over: Powering America Beyond the Age of the Great Stagnation</span><span class="font3">. New York: Dutton.</span></p>
<p><span class="font3" style="font-weight:bold;">Ford, M. </span><span class="font3">(2015). </span><span class="font3" style="font-style:italic;">The Rise of the Robots: Technology and the Threat of Mass Unemployment</span><span class="font3">. London: Oneworld Publications.</span></p>
<p><span class="font3" style="font-weight:bold;">Frey, C. B. and Osborne, M. A. </span><span class="font3">(2013). </span><span class="font3" style="font-style:italic;">The Future of Employment: How Susceptible Are Jobs to Computerisation</span><span class="font3">. Oxford Martin Working Papers.</span></p>
<p><span class="font3" style="font-weight:bold;">Kaplan, J. </span><span class="font3">(2015). </span><span class="font3" style="font-style:italic;">Humans Need Not Apply: A Guide to Wealth and Work in the Age of Artificial Intelligence</span><span class="font3">. New&nbsp;Haven, CT: Yale University Press.</span></p>
<p><span class="font3" style="font-weight:bold;">Galloway, A. </span><span class="font3">(2014). “The cybernetic hypothesis.” </span><span class="font3" style="font-style:italic;">differences</span><span class="font3">, 25(1): 107-31.</span></p>
<p><span class="font3" style="font-weight:bold;">Gazzaley, A. and Rosen, L. D. </span><span class="font3">(2016). </span><span class="font3" style="font-style:italic;">The Distracted Mind: Ancient Brains in a High-Tech World</span><span class="font3">. Cambridge, MA: The&nbsp;MIT Press.</span></p>
<p><span class="font3" style="font-weight:bold;">Gold, M. K. </span><span class="font3">(2012). “The digital humanities moment.” In M. K. Gold (ed) </span><span class="font3" style="font-style:italic;">Debates in the Digital Humanities</span><span class="font3">. Minneapolis, MI: University of Minnesota Press, pp. ix-xvi.</span></p>
<p><span class="font3" style="font-weight:bold;">Hayles, N. K. </span><span class="font3">(2007). &quot;Hyper and deep attention: the generational divide in cognitive modes.&quot; </span><span class="font3" style="font-style:italic;">Profession 2007</span><span class="font3">, pp. 187-99.</span></p>
<p><span class="font3" style="font-weight:bold;">Mason, P. </span><span class="font3">(2015). </span><span class="font3" style="font-style:italic;">Postcapitalism: A Guide to Our Future</span><span class="font3">. London: Allen Lane.</span></p>
<p><span class="font3" style="font-weight:bold;">Moretti, F. </span><span class="font3">(2013). </span><span class="font3" style="font-style:italic;">Distant Reading</span><span class="font3">. London: Verso.</span></p>
<p><span class="font3" style="font-weight:bold;">Ramsay, S. </span><span class="font3">(2011). </span><span class="font3" style="font-style:italic;">Reading Machines</span><span class="font3">: </span><span class="font3" style="font-style:italic;">Toward an Algorithmic Criticism</span><span class="font3">. Champaign, IL: University of Illinois Press.</span></p>
<p><span class="font3" style="font-weight:bold;">Stiegler, B. </span><span class="font3">(2010). </span><span class="font3" style="font-style:italic;">Taking Care of Youth and the Generations</span><span class="font3">. Translated by S. Barker. Stanford, CA: Stanford University Press.</span></p>
<p><span class="font3" style="font-weight:bold;">Stiegler, B. </span><span class="font3">(2016). </span><span class="font3" style="font-style:italic;">Automatic Society. Volume 1: The Future of Work</span><span class="font3">. Cambridge: Polity.</span></p>
</body>
</html>