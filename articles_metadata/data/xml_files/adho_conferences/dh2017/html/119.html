<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
	"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head><meta http-equiv="content-type" content="text/html; charset=UTF-8"/><meta name="generator" content="ABBYY FineReader 14"/><title>Microsoft Word - 119. Mauro-Chatbot Based Content Discovery-119.docx</title><link rel="stylesheet" href="119_files/119.css" type="text/css"/>
</head>
<body><h1><a name="caption1"></a><a name="bookmark0"></a><span class="font2" style="font-weight:bold;">Chatbot Based Content</span></h1><h1><a name="bookmark1"></a><span class="font2" style="font-weight:bold;">Discovery: Faulknerbot in the Archive</span></h1>
<p><span class="font4" style="font-weight:bold;">Aaron Mauro</span></p>
<p><span class="font4"><a href="mailto:mauro@psu.edu">mauro@psu.edu</a></span></p>
<p><span class="font4" style="text-decoration:underline;">Pennsylvania State Digital Humanities Lab, United States</span></p>
<p><span class="font1" style="font-weight:bold;">Introduction</span></p>
<p><span class="font4">In March of 2016, the failure of Microsoft's prototype chatbot, Tay, was not just a technological failure. It was a disciplinary failure. It was a failure of an industry leader to adopt a critical perspective when building systems in a complex cultural and social environment. Tay, which stands for “thinking about you,” was&nbsp;the name given to an artificial intelligence chatbot for&nbsp;Twitter that was quickly corrupted by users and began&nbsp;spewing racist, sexist, and homophobic slurs. Pundits&nbsp;quickly leapt to conclusions about the political beliefs&nbsp;of internet users, but these same pundits failed to understand that this hacking of Tay was in fact a critique&nbsp;of chatbots in the real world. Users of Twitter were exposing a fundamental error made by the Microsoft development team. Because the system learned direct-ly&nbsp;from user input without editorial control or content&nbsp;awareness, Tay was quickly trained to repeat slurs by&nbsp;users eager to embarrass Microsoft.</span></p>
<p><span class="font4">This moment in technological development makes for an interesting anecdote, but it also represents the&nbsp;moment that chatbots entered the public consciousness and became nothing less than the future direction of a unified interface for the whole of the web. Of&nbsp;course, chatbots captured imaginations in the 90s as&nbsp;well. Systems like Cleverbot, Jabberwacky, and&nbsp;Splotchy were fascinating to play with, but they had no&nbsp;real application. Today, text based AI has been identified as the the successor to keyword search. No longer will we plug in keywords into Google, comb through&nbsp;lists of text, and depend on search engine optimization (SEO) to deliver the best content. Search will be&nbsp;around for a long time, but in the near future much&nbsp;more content will be delivered through text based&nbsp;messenger services and voice controlled systems.&nbsp;We've seen the early stages of this change in products&nbsp;like Amazon's Alexa, Apple's Siri, Google Now, and Microsoft's Cortana. There are now bots embedded within common platforms like Slack, Skype, and Facebook</span></p>
<p><span class="font4">Messager. We are now approaching a world that Apple envisioned in 1987 with a mockup system called the&nbsp;“Knowledge Navigator” that sought to give users an interactive and intelligent tool to access, synthesize, present, and share information seamlessly.</span></p>
<p><span class="font4">Humanities in the Loop</span></p>
<p><span class="font4">We are likely decades away from a true “knowledge navigator,” but the second generation of these chatbots&nbsp;are now in development. The company that developed&nbsp;Siri for Apple is now in the final stages of development&nbsp;on a system called Viv (Matney). Viv is the first viable&nbsp;company to produce a unified interface for text and&nbsp;speech based AI assistants. Facebook is testing project&nbsp;M within its messenger app to allow users to issue&nbsp;commands, access services, and make purchases&nbsp;through text input (Hempel). The remarka-ble thing&nbsp;about M is that Facebook has built a system with “humans in the loop.” This means that when a service is&nbsp;accessed, perhaps by purchasing movie tick-ets, a human will fine tune the AI generated results for each&nbsp;transaction. There is currently an understanding&nbsp;within the machine learning community that human&nbsp;assisted training of these systems produces more accurate results but will also train more robust systems going forward (Biewald, Bridgwater). The current need&nbsp;for human in the loop systems means that we are at a&nbsp;crucial moment for humanists to lend their experience&nbsp;and critical abilities to the development and training of&nbsp;AI systems. In the field of machine learning, training a&nbsp;system to answer humanities based problems will&nbsp;show how these systems succeed or fail, but they will&nbsp;also demonstrate the value of the humanities in a digital world. If the purpose of the humanities is to better&nbsp;understand what it is to be human, training AI to answer philosophical, historical, or cultural questions&nbsp;will help us understand our experiences as we become more accustomed to intelligent systems in our&nbsp;lives. Grappling with AI, whether it is in a mundane&nbsp;consumer exchange or in matters of grave ethical importance, is rapidly becoming a practical problem in&nbsp;our lives.</span></p>
<p><span class="font4">With humanists in the loop, we will better understand the social and cultural contexts in which these systems appear and avoid the regrettable failure of&nbsp;systems like Tay in the future. We are currently on the&nbsp;cusp of a revolution in the applicability of natural language understanding, artificial intelligence, and conversation based interfaces design. These technologies&nbsp;will have ranging consequences socially, culturally, and&nbsp;economically in the coming decade, but these technologies are also deeply connected to the social and cultural contexts in which they appear. My goal is to train&nbsp;machines to be humanists. It is the literary crit-ic's&nbsp;ability to close read complex philosophical, histori-cal,&nbsp;and artistic meaning that these systems lack. It is the&nbsp;ability of the historian to contextualize political and&nbsp;technological change within the breadth of human&nbsp;progress. It is the dramatists ability to understand performance and dialogue that will animate our conversations with computers. The digital humanities are well&nbsp;situated to make the most of NLP techniques and find&nbsp;culturally significant training sets.</span></p><img src="119_files/119-1.jpg" style="width:160pt;height:256pt;"/>
<p><span class="font0">Figure 1: Faulknerbot interface with basic query and response</span></p>
<p><span class="font1" style="font-weight:bold;">Method: Conversational Data Retrieval</span></p>
<p><span class="font4">Biographical and archival material has been used to train a system to allow a conversation with the famed&nbsp;American author William Faulkner. I will pre-sent a&nbsp;system trained with nearly all the interviews that&nbsp;Faulkner has given. Author interviews are an ex-cellent&nbsp;training set because the questions asked by the interview anticipate user interests and model a con-versa-tional style of response. The interviews collected during Faulkner's visit to the University of Virginia were&nbsp;instrumental in building this tool. The applica-tions for&nbsp;such a system are numerous. A conversation with&nbsp;Faulkner might benefit a creative writing student in&nbsp;the midst of writer's block. A chatbot offers a more inviting interface for a general public. Most important-ly,&nbsp;Faulknerbot will represent a novel form of content discovery for student researchers. Once a user has developed a chat history worth exploring, Faulknerbot's&nbsp;responses link to original archival materials for research purposes.</span></p>
<p><span class="font4">Current systems have come a long way from the toy-like chatbots that populated the web in the late&nbsp;90s. After a pre-processing stage using word2vec,&nbsp;which vectorizes the bag of words, this model uses&nbsp;Tensor Flow to generate two complementary neural&nbsp;networks that encodes and decodes inputs and responses. This model has only recently been made accessible to non-computer science researchers recently&nbsp;by Google open sourcing Tensor Flow. is not based on&nbsp;the retrieval based model using a rule based expressions, with a heuristic to determine intent and draw&nbsp;from a predefined response. This is not a simplistic&nbsp;tree model based on nested “if/then” statements. Instead this uses a generative model. This generative&nbsp;model uses sequence to sequence learning with neural networks (<a href="https://arxiv.org/abs/1409.3215">https://arxiv.org/abs/1409.3215</a>). This&nbsp;model links words statistically to determine “flows” of&nbsp;meaning through a word vector. Geoff Hinton calls this&nbsp;a “thought vector.” In other words, this is an end-to-end&nbsp;model that remains open. Rather than a retrieval&nbsp;method, which limits the scope of the conversation,&nbsp;this system dynamically learns and allows for a retention of what has been said. The generative model allows for this context based discussion without resorting to an enormous conversation log. In Tensor Flow,&nbsp;this operates on a Long Short Term Memory (LSTM)&nbsp;network. As I've said, the sequence to sequence model&nbsp;is based on two neural nets. One is an encoder, which&nbsp;encodes input data from the user. The decoder model&nbsp;determines the reply by generating the output, which&nbsp;need not echo the size of the vector. This thought vector generalizes input and links to a target response.&nbsp;This is not a “feed forward” neural net. It is a recurrent&nbsp;neural net that continually retrains on the training&nbsp;data, which is often the marker of a true “deep learning” system. This model makes no assumption about&nbsp;purpose or predetermined output. It simply reinforces&nbsp;relationships between thought vectors over time.&nbsp;There is a deeply emotional resonance that is carried&nbsp;through conversation. The blurring of lines between&nbsp;social media, search, and messaging will result in a&nbsp;seamless and unified interface for digital technology.&nbsp;Driven by the mobile space's demand for streamlined&nbsp;UI design, we will become more reliant on assistive&nbsp;technologies that can anticipate, learn, and adapt to&nbsp;user input.</span></p>
<p><span class="font1" style="font-weight:bold;">Conclusion</span></p>
<p><span class="font4">It is important for the humanities to anticipate this new cultural space. When the Google autocomplete&nbsp;system was introduced to search, there were many cultural commentators decrying the loss of independ-ent&nbsp;thought and the potential for entrenching damag-ing&nbsp;stereotypes (Postcolonial). The loss of critical awareness and even just the ability to spell. Technolo-gy that&nbsp;offends our sense of what it is to be essentially human&nbsp;is usually the next important media type. Chat-ting&nbsp;with machines tends to cross such lines. There are&nbsp;practical uses for remedial education and composition&nbsp;studies. A functioning Teaching Assistant Bot capable&nbsp;of answering questions about deadlines, assignments,&nbsp;and course policy would be welcome by most educators. Indeed, an AI TA has been developed recently, but&nbsp;it is unclear if this system can be trained on any course&nbsp;material or was custom built for this class (Maderer).&nbsp;Generalizing these systems is a difficult task, to be&nbsp;sure. The newly open sourced Tensor Flow machine&nbsp;learning library can answer questions derived from a&nbsp;training set of just over a million words. When we consider the limits of machine learning in intelligent assistants, scholarly communication through chat interfaces is certainly the next logical step. However these&nbsp;systems require humans in the loop. They require-thoughtful and critical reflection. They require an attention to depth and nuanced meaning. They require a&nbsp;humanist in the loop.</span></p>
<p><span class="font1" style="font-weight:bold;">Bibliography</span></p>
<p><span class="font3" style="font-weight:bold;">Alphabet. </span><span class="font3">(2011) Google Code Archive. Web. &lt;<a href="https://code.google.com/archive/p/word2vec/">https://code.google.com/archive/p/word2vec/</a>&gt;.</span></p>
<p><span class="font3" style="font-weight:bold;">Apple </span><span class="font3">(2016) “Knowledge Navigator.” 28 October. &lt;<a href="https://www.youtube.com/watch?v=HGYFEI6uLy0">https://www.youtube.com/watch?v=HGYFEI6uLy0</a>&gt;.</span></p>
<p><span class="font3" style="font-weight:bold;">Bridgwater, A. </span><span class="font3">(2016) “Machine Learning Needs A Human-In-The-Loop.” &nbsp;&nbsp;&nbsp;7 March.</span></p>
<p><span class="font3">&lt;<a href="http://www.forbes.com/sites/adrianbridgwa-">http://www.forbes.com/sites/adrianbridgwa-</a></span></p>
<p><span class="font3">ter/2016/03/07/machine-learning-needs-a-human-in-</span></p>
<p><span class="font3">the-loop/#2175c4ba6590&gt;.</span></p>
<p><span class="font3" style="font-weight:bold;">Biewald, L. </span><span class="font3">“Why human-in-the-loop computing is the future of machine learning.” 13 Nov. 2015.&lt;<a href="http://www.computerworld.com/arti-">http://www.computerworld.com/arti-</a></span></p>
<p><span class="font3">cle/3004013/robotics/why-human-in-the-loop-compu-</span></p>
<p><span class="font3">ting-is-the-future-of-machine-learning.html&gt;.</span></p>
<p><span class="font3" style="font-weight:bold;">Carpenter, R. </span><span class="font3">Cleverbot. 28 Oct. 2016. &lt;<a href="http://www.clever-bot.com/">http://www.clever-bot.com/</a>&gt;.</span></p>
<p><span class="font3" style="font-weight:bold;">Carpenter, R. </span><span class="font3">Jabberwacky. 28 Oct. 2016. &lt;<a href="http://www.jab-berwacky.com/">http://www.jab-berwacky.com/</a>&gt;.</span></p>
<p><span class="font3" style="font-weight:bold;">Railton, S. et al. </span><span class="font3">(n.d.)Faulkner at Virginia. &lt;<a href="http://faulk-ner.lib.virginia.edu/">http://faulk-ner.lib.virginia.edu/</a>&gt;.</span></p>
<p><span class="font3" style="font-weight:bold;">Hempel, J. </span><span class="font3">“Facebook Launches M, Its Bold Answer to Siri and Cortana.” 26 Aug. 2015.&nbsp;&lt;<a href="https://www.wired.com/2015/08/facebook-launches-m-new-kind-virtual-assistant/">https://www.wired.com/2015/08/facebook-launches-m-new-kind-virtual-assistant/</a>&gt;.</span></p>
<p><span class="font3" style="font-weight:bold;">Hunt, E. </span><span class="font3">(2016). “Tay, Microsoft's AI chatbot, gets a crash course in racism from Twitter.” 24 March .Web.&nbsp;&lt;<a href="https://www.theguardian.com/technol-">https://www.theguardian.com/technol-</a></span></p>
<p><span class="font3">ogy/2016/mar/24/tay-microsofts-ai-chatbot-gets-a-</span></p>
<p><span class="font3">crash-course-in-racism-from-twitter&gt;.</span></p>
<p><span class="font3" style="font-weight:bold;">Maderer, J. </span><span class="font3">(2016) “Artificial Intelligence Course Creates AI Teaching Assistant.” 9 May 2016.&nbsp;&lt;<a href="http://www.news.gatech.edu/2016/05/09/artificial-intelligence-course-creates-ai-">http://www.news.gatech.edu/2016/05/09/artificial-intelligence-course-creates-ai-</a></span></p>
<p><span class="font3">teaching-assistant&gt;.</span></p>
<p><span class="font3" style="font-weight:bold;">Matney, L. </span><span class="font3">(2016). “Siri-creator shows off first public demo of Viv, ‘the intelligent interface for everything'”&nbsp;TechCrunch. 9&nbsp;May.&lt;<a href="https://techcrunch.com/2016/05/09/siri-crea-">https://techcrunch.com/2016/05/09/siri-crea-</a></span></p>
<p><span class="font3">tor-shows-off-first-public-demo-of-viv-the-intelligent-</span></p>
<p><span class="font3">interface-for-everything/&gt;.</span></p>
<p><span class="font3" style="font-weight:bold;">Microsoft. </span><span class="font3">(2016) “TayTweets.” Twitter. 28 October. &lt;<a href="https://twitter.com/tayandyou">https://twitter.com/tayandyou</a>&gt;.</span></p>
<p><span class="font3" style="font-weight:bold;">Postcolonial Digital Humanities. </span><span class="font3">(2013) “Google's Auto-com-pletion: Algorithms, Stereotypes and Accountability.” 19 November. &lt;<a href="http://dhpoco.org/blog/2013/11/19/googles-auto-">http://dhpoco.org/blog/2013/11/19/googles-auto-</a></span></p>
<p><span class="font3">completion-algorithms-stereotypes-and-accountabil-</span></p>
<p><span class="font3">ity/&gt;.</span></p>
<p><span class="font3" style="font-weight:bold;">Splotchy (2016). </span><span class="font3">Algebra.com 28 Oct. &lt;<a href="https://www.alge-bra.com/cgi-bin/chat.mpl">https://www.alge-bra.com/cgi-bin/chat.mpl</a>&gt;.</span></p>
</body>
</html>