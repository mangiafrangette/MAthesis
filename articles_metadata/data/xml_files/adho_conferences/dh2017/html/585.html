<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
	"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head><meta http-equiv="content-type" content="text/html; charset=UTF-8"/><meta name="generator" content="ABBYY FineReader 14"/><title>Microsoft Word - 585. Page-Contextual Interpretation of Digital Music Notation-585.docx</title><link rel="stylesheet" href="585_files/585.css" type="text/css"/>
</head>
<body><h1><a name="caption1"></a><a name="bookmark0"></a><span class="font1" style="font-weight:bold;">Contextual interpretation of digital music notation</span></h1>
<p><span class="font3" style="font-weight:bold;">Kevin Page</span></p>
<p><span class="font3"><a href="mailto:kevin.page@oerc.ox.ac.uk">kevin.page@oerc.ox.ac.uk</a></span></p>
<p><span class="font3">University of Oxford, United Kingdom</span></p>
<p><span class="font3" style="font-weight:bold;">David Lewis</span></p>
<p><span class="font3"><a href="mailto:david.lewis@oerc.ox.ac.uk">david.lewis@oerc.ox.ac.uk</a></span></p>
<p><span class="font3">University of Oxford, United Kingdom</span></p>
<p><span class="font3" style="font-weight:bold;">David Weigl</span></p>
<p><span class="font3"><a href="mailto:david.weigl@oerc.ox.ac.uk">david.weigl@oerc.ox.ac.uk</a></span></p>
<p><span class="font3">University of Oxford, United Kingdom</span></p>
<p><span class="font4" style="font-weight:bold;">Research Objects and scholarship in the digital age</span></p>
<p><span class="font3">As scientific research practice has grown to include ever greater quantities of data, larger collaborations,&nbsp;and distributed methods, Research Objects (Bechhofer&nbsp;et al, 2013) have been introduced as a means to gather&nbsp;together the context surrounding an investigation and&nbsp;to support its future validation, understanding, and reuse. In many cases these Research Objects build upon&nbsp;the methods, output, and provenance already captured and encoded by workflow systems -- the digital&nbsp;environments in which the science is conducted.</span></p>
<p><span class="font3">More recently there have been proposals for the use of Research Objects within the digital humanities&nbsp;and musicology (Dreyfus and Rindfleisch 2014; De&nbsp;Roure et al. 2016). Digital editions and annotations of&nbsp;digitally encoded works can be viewed as manifestations of workflows deployed in musicological scholarship, raising the question of how e.g. editorial annotations in a digital score should reference other digital&nbsp;items within the Research Object and vice versa.</span></p>
<p><span class="font3">For example, a study of the Mariinsky Opera's rendition of Wagner's </span><span class="font3" style="font-style:italic;">Ring</span><span class="font3"> cycle in November 2014 produced a multimedia dataset including audio, annotations made by a musicologist on a short score before the performance (annotations which could be identified a priori from the score such as dynamics, appearances of a leitmotif, etc.), further annotations captured&nbsp;digitally by the musicologist during the live performance (typically staging and interpretive commentary), and free-form text from a digital pen (Page et al.</span></p>
<p><span class="font3">2016). If the score in use had been a digital edition encoded in MEI (the XML-based </span><span class="font3" style="text-decoration:underline;">Music Encoding Initiative</span><span class="font3">. as reviewed by Crawford and Lewis 2016) how might we reference the musicologist's annotations? Or&nbsp;the other media objects captured and the metadata describing them; existing Linked Data references to Wagner and leitmotifs; and to earlier surveys and studies&nbsp;made by the musicologist on leitmotif interpretation?&nbsp;</span><span class="font4" style="font-weight:bold;">Linked notation in support of musicology</span></p>
<p><span class="font3">Notation examples are a vital part of analytical essays in musicology, helping to illustrate analytical observations and justify hypotheses, arguments and conclusions. They can be excerpts from a score, or custom-made notations which add annotations or comments to the original notation.</span></p>
<p><span class="font3">Furthermore, the presentation of multiple analogous musical extracts for comparison is often required to support a musicological narrative. </span><span class="font3" style="font-style:italic;">Paradigmatic&nbsp;analysis</span><span class="font3">, for example, involves passages of music&nbsp;placed one above another such that analogous elements are directly juxtaposed, with gaps left as necessary to ensure that vertical alignment is preserved.&nbsp;Stacked presentation of different scores or different&nbsp;parts of the same score have been used for well over a&nbsp;century, but they quickly become unwieldy and hard&nbsp;to interpret, especially as the number of extracts increases. What is not available in such paper-based approaches is the interactivity that can make complex&nbsp;comparisons between many extracts practical by turning a static presentation into an iterative exploration&nbsp;of digital materials.</span></p>
<p><span class="font3">In this paper we consider the example of a digital companion presenting the contents of a Research Object studying the interpretation of leitmotif examples&nbsp;from Wagner's compositions, specifically the </span><span class="font3" style="font-style:italic;">Ring</span><span class="font3"> cycle, as they are presented in numerous historical introductions, opera guides, leitmotivic threads and leitmotif lists included in libretto editions and piano scores.&nbsp;The study of the incidences of these particular leitmotif identifications consists of both the gathering of&nbsp;source material and its digitisation and cataloguing,&nbsp;and a musicological study of the potential relationships, influence and evolution between leitmotif interpretations. To enable the extension and repurposing of&nbsp;the identified leitmotif relationships they are structured using an ontology.</span></p>
<p><span class="font3">Notation examples in leitmotif guides are usually abstractions drawn from a piano score. When reporting findings from this research it is desirable to present and relate the scholarly arguments back to the&nbsp;musicological context within which they are made:&nbsp;from the score excerpts in the source material; and to&nbsp;MEI encodings that illustrate and encode both the examples from which they are drawn and to complete&nbsp;(piano) scores of the overall operas.</span></p>
<p><span class="font3">This enables matching and linking of the examples as they are described in the scholarly text, via semantic&nbsp;hyperlinks, to and from the score, including exact&nbsp;matches and variants, illustrating interpretations, and&nbsp;situating the examples back in context. Encoding interpretations in the form of notation examples as variant&nbsp;readings of a certain passage could thereby chart the&nbsp;‘understanding' of the work as a history of its variants.</span></p>
<p><span class="font3">(For example comparing: Richard Wagner, Die Walküre, piano score by Felix Mottl, Leipzig,</span></p>
<p><span class="font3">Peters, 1914, p.165; Hans von Wolzogen, Thematischer Leitfaden durch die Musik zu Richard Wagners Festspiel Der Ring des Nibelungen, 2<sup>nd</sup> ed., Leipzig, Schloemp, 1876, p.58, ‘Schicksalsmotiv'; Gustav Kobbe, Wagner's Music Dramas Analyzed With the&nbsp;Leading Motives, New York: Schirmer, 1923, p. 57,&nbsp;‘Motive of Fate'; George Dunning Gribble, The Master&nbsp;Works of Richard Wagner, London, Everett, 1913, p.&nbsp;289, ‘Fate Motif'.)</span></p>
<p><span class="font4" style="font-weight:bold;">Introducing MELD: Music Encoding and Linked Data</span></p>
<p><span class="font3">To realise the digital notation companion we have developed the MELD framework (</span><span class="font3" style="text-decoration:underline;">Music Encoding and&nbsp;Linked Data</span><span class="font3">). MELD enables the interactive presentation of multimedia contents of the Research Object,&nbsp;such as the images, text, audio, and MEI encoded music&nbsp;notation described in the previous section. These can&nbsp;be explored contextually alongside each other through&nbsp;the use of semantic links, encoded using RDF, which&nbsp;describe the musicological relationships between the&nbsp;resources (and elements within them). In contrast to&nbsp;earlier technologies which have typically aligned resources against a timeline (e.g. in milliseconds, or using MIDI), MELD expresses relationships anchored to&nbsp;musically meaningful items scoped using MEI. Figure&nbsp;1 shows a screenshot of MELD displaying text and notation, highlighting leitmotifs as identified in different&nbsp;historical guides.</span></p><img src="585_files/585-1.jpg" style="width:241pt;height:140pt;"/>
<p><span class="font0">Figure 1. MELD displaying contextualised text and music notation.</span></p>
<p><span class="font3">To render our music notation (encoded using MEI) we use Verovio (Pugin et al. 2013), an open-source&nbsp;MEI renderer that produces beautiful SVG renditions&nbsp;of the score. In addition, Verovio provides an architecture in which identifiers (in other words, anchors for&nbsp;our relational Linked Data expressions in the MEI&nbsp;XML) are persisted through to the rendering (in SVG)&nbsp;which can be connected to identifiers in our contextual&nbsp;information (in RDF). When rendered (and re-rendered) for the user in our web based application interface, the browser uses these identifiers to generate interface elements and undertake actions that combine&nbsp;information from the MEI and the Linked Data.</span></p><img src="585_files/585-2.jpg" style="width:239pt;height:137pt;"/>
<p><span class="font0">Figure 2. Musicological relationships, encoded using Open Annotations, within the Research Object (simplified).</span></p>
<p><span class="font3">Within the Research Object, we treat the XML IDs of elements within the MEI resource as fragment identifiers, so URIs can be straightforwardly generated for&nbsp;each notation element of interest. We employ the Web&nbsp;Annotation Data Model (Sanderson et al. 2017), using&nbsp;these URIs as targets of annotations representing each&nbsp;musicological marking. Corresponding annotation&nbsp;bodies are associated with semantic tags defined to&nbsp;encode the different musicological interpretations,&nbsp;which are in turn the annotation bodies of a top-level&nbsp;annotation targeting the URI of the files currently being viewed, including the music encoding (MEI) and&nbsp;scholarly interpretation (HTML). A simplified example&nbsp;of such relationships is shown in Figure 2.</span></p><img src="585_files/585-3.jpg" style="width:242pt;height:93pt;"/>
<p><span class="font0">Figure 3. The MELD framework (shading corresponds to that in Figure 2).</span></p>
<p><span class="font3">The MELD client then uses HTML/CSS and JavaScript, served by a simple web service implemented with Python Flask, and illustrated in Figure 3. The procedure driving the rendering and user interaction is illustrated in Figure 1. The client processes a framed&nbsp;(see the </span><span class="font3" style="text-decoration:underline;">explanation of framing) JSON-LD</span><span class="font3"> representation of the </span><span class="font3" style="text-decoration:underline;">RDF</span><span class="font3"> graph instantiating the data model. It&nbsp;then performs an HTTP GET call to acquire the MEI resource targeted by the top-level annotation, and renders the corresponding musical score to SVG using&nbsp;Verovio. User interactions are captured using HTML&nbsp;divs drawn as bounding boxes over portions of the&nbsp;SVG corresponding to MEI elements of interest; this is&nbsp;simplified by Verovio's retention of MEI identifiers in&nbsp;the produced SVG output.</span></p>
<p><span class="font4" style="font-weight:bold;">Acknowledgements</span></p>
<p><span class="font3">This work has been supported by the UK Arts and Humanities Research Council grant AH/L006820/1&nbsp;‘Transforming Musicology', and EPSRC grant&nbsp;EP/L019981/1 ‘Fusing Audio and Semantic Technologies for Intelligent Music Production and Consumption'. We thank all our colleagues on these projects&nbsp;who have supported and encouraged this work, particularly Carolin Rindfleisch for her complementary&nbsp;work on musicological ontologies, and Laurence Dreyfus for wider inspiration and motivation in developing&nbsp;these technologies.</span></p>
<p><span class="font2" style="font-weight:bold;">Crawford, T., &amp; Lewis, R. </span><span class="font2">(2016). Review: Music Encoding Initiative. </span><span class="font2" style="font-style:italic;">Journal of the American Musicological Society</span><span class="font2">,&nbsp;</span><span class="font2" style="font-style:italic;">69</span><span class="font2">(1), 273-285.</span></p>
<p><span class="font2" style="font-weight:bold;">De Roure, D., Klyne, G., Page, K.R., Pybus, J., Weigl, D.M., Wilcoxson, M., Willcox, P. </span><span class="font2">(2016). Plans and Performances: Parallels in the Production of Science and Music.&nbsp;</span><span class="font2" style="font-style:italic;">Proceedings of the 2016 IEEE 12th International Conference on e-Science</span><span class="font2">. IEEE, pp. 185-192.</span></p>
<p><span class="font2" style="font-weight:bold;">Dreyfus, L., &amp; Rindfleisch, C. </span><span class="font2">(2014). Using Digital Libraries in the Research of the Reception and Interpretation of Richard Wagner's Leitmotifs. </span><span class="font2" style="font-style:italic;">Proceedings of the 1st International Workshop on Digital Libraries for Musicology.&nbsp;</span><span class="font2">ACM, pp. 1-3</span></p>
<p><span class="font2" style="font-weight:bold;">Page, K., Nurmikko-Fuller, T., Rindfleisch, C., Weigl, D.</span></p>
<p><span class="font2">(2016). Digital Annotation Tooling for Opera Performance Studies. </span><span class="font2" style="font-style:italic;">Digital Humanities 2016: Conference Abstracts</span><span class="font2">. Jagiellonian University &amp; Pedagogical University,</span></p>
<p><span class="font2">Krakow, pp. 306-309.</span></p>
<p><span class="font2" style="font-weight:bold;">Pugin, L., Zitellini, R., &amp; Roland, P. </span><span class="font2">(2014). Verovio: A Library for Engraving MEI Music Notation into SVG. </span><span class="font2" style="font-style:italic;">Proceedings of the 15th International Society for Music Information Retrieval Conference</span><span class="font2">, pp. 107-112.</span></p>
<p><span class="font2" style="font-weight:bold;">Sanderson, R., Ciccarese, P., Young, B</span><span class="font2">. (2017). Web Annotation Data Model. W3C recommendation.</span></p>
<p><span class="font4" style="font-weight:bold;">Bibliography</span></p>
<p><span class="font2" style="font-weight:bold;">Bechhofer, S., Buchan, I., De Roure, D., Missier, P., Ainsworth, J., Bhagat, J., Couch, P., Cruickshank, D., Delderfield, M., Dunlop, I. and Gamble, M. </span><span class="font2">(2013).&nbsp;Why linked data is not enough for scientists. </span><span class="font2" style="font-style:italic;">Future Generation Computer Systems</span><span class="font2">, </span><span class="font2" style="font-style:italic;">29</span><span class="font2">(2), pp.599-611.</span></p>
</body>
</html>