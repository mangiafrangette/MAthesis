<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
	"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head><meta http-equiv="content-type" content="text/html; charset=UTF-8"/><meta name="generator" content="ABBYY FineReader 14"/><title>Microsoft Word - 582. Heuser-Word Vectors in the Eighteenth Century-582.docx</title><link rel="stylesheet" href="582_files/582.css" type="text/css"/>
</head>
<body><h1><a name="caption1"></a><a name="bookmark0"></a><span class="font7" style="font-weight:bold;">Word Vectors in the Eighteenth Century</span></h1>
<p><span class="font4" style="font-weight:bold;">Ryan James Heuser</span></p>
<p><span class="font4"><a href="mailto:heuser@stanford.edu">heuser@stanford.edu</a></span></p>
<p><span class="font4">Stanford University, United States of America</span></p><h2><a name="bookmark1"></a><span class="font1" style="font-weight:bold;">Introduction</span></h2>
<p><span class="font4">This talk explores how new vector-based approaches to computational semantics both afford new methods to digital humanities research, and raise interesting questions for eighteenth-century literary&nbsp;studies in particular. New semantic models known as&nbsp;“word embedding models” have generated excitement&nbsp;recently in the natural language processing and machine learning communities, due to their ability to represent and predict semantic relationships as complex&nbsp;as analogy. “Man” is to “woman” as “king” is to what?,&nbsp;one can ask of the model; “queen,” it will most likely&nbsp;reply. These models formulate analogical and other semantic relationships by computing mathematical vectors for words, such that, if </span><span class="font4" style="font-style:italic;">V(x)</span><span class="font4"> denotes the vector for</span></p>
<p><span class="font4">the word </span><span class="font4" style="font-style:italic;">x</span><span class="font4">, then the above analogy can be expressed</span></p>
<p><span class="font4">as </span><span class="font4" style="font-style:italic;">V(woman) - V(man) + V(king) ~ V(queen).</span><span class="font4"> Although these models have a longer history- vector space semantics dates from the ‘70s, having been first developed for the SMART information retrieval system (Sal-ton, 1971) by Gerard Salton and his colleagues (Salton&nbsp;et al, 1975)” (Turney and Pantel, 2010)- new innovations in their speed and accuracy (see Note [1]) have&nbsp;renewed researchers' interests—a development begun, in part, by Google, when researchers there unveiled newly efficient algorithms in 2013, packaged in&nbsp;software they released called word2vec. (The&nbsp;word2vec algorithm was originally described by</span></p>
<p><span class="font4">Mikolov et al, 2013. It introduced the neural network to vector space semantics, providing an efficient means by&nbsp;which to compute word vectors. The GloVe algorithm&nbsp;from the Stanford NLP Group eschews the neural network approach, instead performing a novel method of dimensionality reduction on word collocation counts).</span></p>
<p><span class="font4">“Word vectors,” as these new methods are sometimes informally called, have already enabled published research into questions relevant to humanistic research, such as a recent landmark paper from researchers in the Stanford NLP Group into patterns of&nbsp;semantic change across centuries of discourse (Hamilton et al). However, unfortunately, word vectors have&nbsp;so far rarely appeared in research from the digital humanities community itself. Moreover, what work that&nbsp;does exist has so far been primarily circulated through&nbsp;blogs, rather than through published proceedings or</span></p>
<p><span class="font4">articles. Ben Schmidt, for instance, has written an influential introduction to word vectors in his blog post “Vector Space Models for the Digital Humanities” (2015a), which also includes a documented R package for computing them. Also notable is his post, “Rejecting the gender&nbsp;binary” (Schmidt, 2015b), which uses word vectors to&nbsp;dissect the polysemy of words; as well as Michael Gavin's&nbsp;post, “The Arithmetic of Concepts” (2015), which explores the conceptual implications of adding and subtracting word vectors.</span></p>
<p><span class="font4">On the whole, the current research landscape of word vectors in the digital humanities resembles the&nbsp;landscape of topic modeling years ago, when the original LDA algorithm (published in 2003 [Blei et al]), before appearing in landmark published DH studies such&nbsp;as Matt Jockers' </span><span class="font4" style="font-style:italic;">Macroanalysis</span><span class="font4"> (2013), was employed&nbsp;for humanistic research as early as 2006 by researchers working outside or tangentially to the digital humanities (Newman and Block).</span></p>
<p><span class="font4">Given this scarcity of digital-humanities research on word vectors, work that seeks equally to explain,&nbsp;interpret, and demonstrate their potential seems particularly useful. With these goals in mind, this paper&nbsp;attempts first to unpack for a digital-humanities audience how word vectors work, with reference to the canonical analogy cited above: “man is to woman as king&nbsp;is to queen.” Second, in order to interpret word vectors' conceptual implications for eighteenth-century&nbsp;literature, I move away from this canonical analogy to&nbsp;one central to a particularly influential argument in&nbsp;the period: “Learning is to Genius as Riches are to Virtue.” Lastly, I turn from this close reading of word vectors to methods of distant-reading analogies that lie&nbsp;implicit in eighteenth-century literature.</span></p><h2><a name="bookmark2"></a><span class="font1" style="font-weight:bold;">Explaining Word Vectors</span></h2>
<p><span class="font4">How do word vectors work? In the interests of space, I have omitted this section of my talk from the&nbsp;abstract. Readers curious about the mechanics of word&nbsp;vectors can read more on my blog, which also links to&nbsp;a number of other explanatory resources (Heuser,&nbsp;“Methods”).</span></p><h2><a name="bookmark3"></a><span class="font1" style="font-weight:bold;">Close-reading Word Vectors</span></h2>
<p><span class="font4">Word vectors provide a persuasive computational means for the semantic representation and analysis of&nbsp;analogies. They combine a mathematical elegance&nbsp;with an intuitive interpretability to yield what is, potentially, a method useful not only for large-scale semantic analysis, but also for smaller-scale explorations of particular analogies in literature, and their&nbsp;specific forms of analogical argumentation. For instance, analogy lies at the heart of Edward Young's essay </span><span class="font4" style="font-style:italic;">Conjectures on Original Composition (1759),</span><span class="font4"> which&nbsp;argued for the superior aesthetic interest of modern,&nbsp;“original” composition over the neoclassical imitation&nbsp;of the ancients. Crucially, Young makes his argument&nbsp;through analogy, identifying several other conceptual</span></p>
<p><span class="font4">contrasts as analogues to his central one between original and imitative composition:</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-style:italic;">Type of opposition</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-style:italic;">Associated with original composition</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-style:italic;">Associated with imitative composition</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-style:italic;">Attributes of a Poet/Author</span></p></td><td style="vertical-align:middle;">
<p><span class="font8">Genius</span></p></td><td style="vertical-align:middle;">
<p><span class="font8">Learning</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-style:italic;">Forms of social organization</span></p></td><td style="vertical-align:middle;">
<p><span class="font8">Organic growth</span></p></td><td style="vertical-align:middle;">
<p><span class="font8">Mechanistic commerce</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-style:italic;">Forms of social value</span></p></td><td style="vertical-align:middle;">
<p><span class="font8">Virtue</span></p></td><td style="vertical-align:middle;">
<p><span class="font8">Riches</span></p></td></tr>
</table>
<p><span class="font0">Table 1. Table of conceptual analogies leveraged by Edward Young to argue for original over imitative</span></p>
<p><span class="font0">composition (Conjectures on Original Composition, 1759).</span></p>
<p><span class="font4">“I would compare Genius to Virtue, and Learning to Riches,” Young writes; “[a]s Riches are most wanted&nbsp;where there is least Virtue; so Learning where there is&nbsp;least Genius.” In this way, Young's valuation of “Genius” over “Learning,” and of original over imitative&nbsp;composition, become </span><span class="font4" style="font-style:italic;">ethically justified</span><span class="font4"> through their&nbsp;analogy with another, more obviously moral contrast&nbsp;between “Virtue” and “Riches.”</span></p>
<p><span class="font4">But what is the logic behind this analogy? Here, word vectors provide the close reader with a framework, language, and method of exploring the semantic&nbsp;implications at work in an analogy. In terms of vectors,&nbsp;we can ask, what does </span><span class="font4" style="font-style:italic;">V(Virtue)-V(Riches) (</span><span class="font4">Also sometimes expressed here, in a shorthand, as V(Virtue-Riches) mean, and is it in fact correlated with </span><span class="font4" style="font-style:italic;">V(Ge-nius)-V(Learning)</span><span class="font4"> in the broader discourse of the period? Asking this question of a word2vec model&nbsp;trained on the 80 million words of eighteenth-century&nbsp;literature in the ECCO-TCP corpus, we find that&nbsp;“Riches” are to “Virtue” as “Learning” is to...</span></p>
<table border="1">
<tr><td colspan="2" style="vertical-align:bottom;">
<p><span class="font5">In [3]: analogy(model, 'riches', 'virtue',</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">'learning')</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">0ut[3]:</span></p></td><td>
<p></p></td><td>
<p></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">[(u'morality'</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">, 1.0672287940979004),</span></p></td><td>
<p></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">(u'piety*, ]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">L.0626451969146729),</span></p></td><td>
<p></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">(u'science',</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">. 1.0292117595672607),</span></p></td><td>
<p></p></td></tr>
<tr><td colspan="2" style="vertical-align:bottom;">
<p><span class="font5">(u'philosophy', 1.0257463455200195),</span></p></td><td>
<p></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">(u'prudence'</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">, 1.0140740871429443),</span></p></td><td>
<p></p></td></tr>
<tr><td>
<p><span class="font5">(u'genius',</span></p></td><td>
<p><span class="font5">0.9834112524986267), &nbsp;&nbsp;&nbsp;#</span></p></td><td>
<p><span class="font5">&lt;— 6th closest term</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">(u'wisdom',</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">0.9778728485107422),</span></p></td><td>
<p></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">(u'morals',</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">0.9766285419464111),</span></p></td><td>
<p></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">(u'modesty',</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">, 0.9748671650886536),</span></p></td><td>
<p></p></td></tr>
<tr><td>
<p><span class="font5">(u'humanity'</span></p></td><td>
<p><span class="font5">, 0.972758948802948)]</span></p></td><td>
<p></p></td></tr>
</table>
<p><span class="font0">Figure 1. “Riches” are to “Virtue” as “Learning” is to what?, asked of a word2vec model trained on 80 million words of</span></p>
<p><span class="font0">eighteenth-century literature (the ECCO-TCP corpus).</span></p>
<p><span class="font4">“Genius” is the sixth closest word vector, or the sixth most likely solution, to this analogy. How to test&nbsp;the significance of this result is not immediately clear,&nbsp;but, out of tens of thousands of possibilities, it's certainly provocative: it raises the possibility that word&nbsp;vectors might provide computational assistance to&nbsp;close readings. Indeed, the other words in this list amplify the semantic profile of this analogy in a way that&nbsp;might help to clarify its underlying implications. For&nbsp;instance, the contrast between the </span><span class="font4" style="font-style:italic;">intrinsic</span><span class="font4"> form of&nbsp;value in “Virtue” and the </span><span class="font4" style="font-style:italic;">extrinsic</span><span class="font4"> form of value in&nbsp;“Riches” seems underscored for me by the contrast&nbsp;here between the extrinsic writerly attribute of&nbsp;“Learning,” associated with an Oxbridge education,&nbsp;and the intrinsic attributes of morality, genius, and&nbsp;wisdom.</span></p>
<p><span class="font4">Ultimately, however, what does it mean to close-read word vectors? This is a question raised by Gabriel Recchia in a blogpost responding to my interpretation&nbsp;above as it first appeared on my blog (Recchia; Heuser,&nbsp;“Concepts”). Recchia's post explores other vector operations that even more reliably yield “genius,” namely&nbsp;</span><span class="font4" style="font-style:italic;">V(learning)+V(virtue)</span><span class="font4"> and </span><span class="font4" style="font-style:italic;">V(talents)+V(abili-ties)+V(erudition).</span><span class="font4"> To me, however, these alternative&nbsp;“paths” to genius do not exclude one another; instead,&nbsp;each contributes to our understanding of the semantics of genius in the period. My goal with this interpretation is not to “prove” Young's analogy, but rather to&nbsp;suggest that, by “amplifying” a particular analogy&nbsp;through its semantic associations across a corpus,&nbsp;word vectors help contextualize our interpretations of&nbsp;particular analogies in literature. As Recchia writes,&nbsp;“the computational exercise has helped us focus our&nbsp;search.”</span></p><h2><a name="bookmark4"></a><span class="font1" style="font-weight:bold;">Distant-reading Word Vectors</span></h2>
<p><span class="font4">If, then, vectors help us explore this </span><span class="font4" style="font-style:italic;">micro-</span><span class="font4">analytic scale of interpretation, they also help us scale those&nbsp;same interpretive models up to the level of macroanalysis. For instance, inspired by the foregoing closereading of Young's complex web of analogies (Table 1),&nbsp;we might continue Young's project of obsessive analo-gization by way of a distant reading. By defining vectors for a range of common eighteenth-century contrasts (Table 2), and then measuring the correlation&nbsp;between them, we can in fact construct </span><span class="font4" style="font-style:italic;">another</span><span class="font4"> complex web of analogies—this time gleaned computationally, from a large-scale archive of the period's discourse.</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font6" style="font-weight:bold;">Ancient(s) &lt;&gt; Modem(s)</span></p>
<p><span class="font6" style="font-weight:bold;">Beautiful &lt;&gt; Sublime</span></p>
<p><span class="font6" style="font-weight:bold;">Body &lt;&gt; Mind</span></p>
<p><span class="font6" style="font-weight:bold;">Comedy &lt;&gt; Tragedy</span></p>
<p><span class="font6" style="font-weight:bold;">Folly &lt;&gt; Wisdom</span></p>
<p><span class="font6" style="font-weight:bold;">Genius &lt;&gt; Learning</span></p>
<p><span class="font6" style="font-weight:bold;">Human &lt;&gt; Divine</span></p>
<p><span class="font6" style="font-weight:bold;">Judgment &lt;&gt; Invention</span></p>
<p><span class="font6" style="font-weight:bold;">Law &lt;&gt; Liberty</span></p>
<p><span class="font6" style="font-weight:bold;">Majxetal &lt;&gt; Common</span></p>
<p><span class="font6" style="font-weight:bold;">Parliament &lt;&gt; King</span></p>
<p><span class="font6" style="font-weight:bold;">Passion &lt;&gt; Reason</span></p></td><td>
<p><span class="font6" style="font-weight:bold;">Private &lt;&gt; Public</span></p>
<p><span class="font6" style="font-weight:bold;">Romances &lt;&gt; Novels</span></p>
<p><span class="font6" style="font-weight:bold;">Ruin &lt;&gt; Reputation</span></p>
<p><span class="font6" style="font-weight:bold;">Simplicity &lt;&gt; Refinement</span></p>
<p><span class="font6" style="font-weight:bold;">Tradition &lt;&gt; Revolution</span></p>
<p><span class="font6" style="font-weight:bold;">Tyranny &lt;&gt; Liberty</span></p>
<p><span class="font6" style="font-weight:bold;">Virtue &lt;&gt; Honour</span></p>
<p><span class="font6" style="font-weight:bold;">Virtue &lt;&gt; Riches</span></p>
<p><span class="font6" style="font-weight:bold;">Virtue &lt;&gt; Vice</span></p>
<p><span class="font6" style="font-weight:bold;">Whig &lt;&gt; Tory</span></p>
<p><span class="font6" style="font-weight:bold;">Woman &lt;&gt; Man</span></p></td></tr>
</table>
<p><span class="font0">Table 2: Common eighteenth-century contrasts, each expressed as a vector contrast. For instance, Virtue &lt;&gt; Vice&nbsp;denotes the vector V(Vice-Virtue). Contrasts were gleaned&nbsp;manually while reading Fielding's Tom Jones (1748), as well&nbsp;as a number of essays from the period; they are not meant</span></p>
<p><span class="font0">to be exhaustive. This is an admittedly unsatisfactory method; I am currently exploring ways to discover&nbsp;conceptual contrasts computationally.</span></p>
<p><span class="font4">Looking at a particularly strong correlation among</span></p>
<p><span class="font4">the contrasts in Table 2, between </span><span class="font4" style="font-style:italic;">V(Simplicity-Refine-</span></p>
<p><span class="font4" style="font-style:italic;">ment)</span><span class="font4"> and </span><span class="font4" style="font-style:italic;">V(Virtue-Vice),</span><span class="font4"> we can see how their correlation emerges from the way in which both contrasts carry similar semantic associations across the same&nbsp;set of words (Figure 3).</span></p><img src="582_files/582-1.jpg" style="width:220pt;height:218pt;"/>
<p><span class="font0">Figure 2. 1,000 most frequent nouns in the ECCO-TCP corpus. On the x-axis is their cosine similarity with the&nbsp;V(Simplicity-Refinement) vector: if above 0, then associated&nbsp;more with refinement; if below, more with simplicity.&nbsp;Conversely, on the y-axis, above 0 means associated more&nbsp;with Vice; below 0, more with Virtue.</span></p>
<p><span class="font4">In other words, this graph shows that there are more words for simple virtues (e.g. “graces”) than refined virtues (e.g. “science”), and more words for refined vices (e.g. “corruption”) than simple vices (e.g.&nbsp;“murder”). This correlation between their semantic&nbsp;associations (R<sup>A</sup>2 = 0.41) reveals, then, an analogy&nbsp;emerging from the period's broader discursive prac-tices—Simplicity is to Refinement as Virtue is to&nbsp;Vice</span><span class="font4" style="font-style:italic;">—</span><span class="font4">even as that analogy might appear only implicitly in particular essays, such as in Hume's “Of Simplicity and Refinement in Writing” (1742), when Hume&nbsp;loosely associates refinement with the moral decline&nbsp;of post-Augustan Rome.</span></p>
<p><span class="font4">This macro-analytic approach to discovering implicit discursive analogies allows us to visualize the ways in which the frequent conceptual contrasts in&nbsp;eighteenth-century literature are implicitly analogized&nbsp;in the discourse, and how those implicit analogical relationships may have helped to structure what Peter&nbsp;De Bolla has called the “conceptual architecture” of the&nbsp;period (Figure 4).</span></p><img src="582_files/582-2.jpg" style="width:230pt;height:178pt;"/>
<p><span class="font0">Figure 3. Semantic contrasts are connected in this network if the R<sup>A</sup>2 value of their correlation, across the 1,000 most&nbsp;frequent nouns (as in Figure 3), is greater than 0.1. Blue</span></p>
<p><span class="font0">lines read in the natural order (e.g. Simplicity is to</span></p>
<p><span class="font0">Refinement as Woman is to Man); red lines read in reverse order (e.g. Simplicity is to Refinement as the King is to&nbsp;Parliament). Nodes are sized by betweenness centrality,</span></p>
<p><span class="font0">and colored by network community. Edges are sized by the RA2 value.</span></p>
<p><span class="font4">From this network of correlated contrasts, we can see which of them, for instance, are implicitly gendered in the period's discourse. “Woman” is to “man,”&nbsp;for instance, as “queen” is to “king”—but also as the&nbsp;beautiful is to the sublime, as simplicity is to refinement, and as passion is to reason. Similarly, we can see&nbsp;which contrasts are moralized in the period: “virtue”&nbsp;is to “vice” as wisdom is to folly, as pity is to fear, as the&nbsp;mind is to the body. Moreover, the contrasts of virtue&nbsp;and vice, and simplicity and refinement, might actually&nbsp;play a central role in such a conceptual architecture of&nbsp;analogies, as seen from their centrality within the network.</span></p><h2><a name="bookmark5"></a><span class="font1" style="font-weight:bold;">Conclusion</span></h2>
<p><span class="font4">I hope to have demonstrated some of the ways in which word vectors might be useful for the digital humanities, and particularly for eighteenth-century literary studies, both by demonstrating how they might&nbsp;help us to close-read specific analogical maneuvers, as&nbsp;well as distant-read analogies as they emerge from&nbsp;patterns in their usage across a literary discourse.</span></p><h2><a name="bookmark6"></a><span class="font1" style="font-weight:bold;">Notes</span></h2>
<p><span class="font3">[1] According to statistics provided in the original paper for the Stanford NLP group's “GloVe,” a competing algorithm to word2vec, a word2vec model trained on a large English-language corpus can&nbsp;accurately solve 65% of analogies in a test dataset, and GloVe 75% (Pennington et al, Table 2).</span></p>
<p><span class="font3">As a rough comparison to the accuracy we would expect from human subjects, we might look to the&nbsp;Miller Analogy Test from Pearson—an admittedly unrelated analogy test, which is given to&nbsp;some graduate student applicants. In the MAT of&nbsp;2002-3, to accurately solve 65% or more of its&nbsp;100 analogies places a student above the 80th&nbsp;percentile (Pearson). Although not directly comparable, these statistics make more probable the&nbsp;assessment that word vectors are capable of capturing semantic relationships at a level competitive with human subjects.</span></p><h2><a name="bookmark7"></a><span class="font1" style="font-weight:bold;">Bibliography</span></h2>
<p><span class="font3" style="font-weight:bold;">Blei, D., Ng, A., and Jordan, M. </span><span class="font3">(2003). “Latent Dirichlet allocation.” </span><span class="font3" style="font-style:italic;">Journal of Machine Learning Research</span><span class="font3"> 3.4-5 (2003): 993-1022.</span></p>
<p><span class="font3" style="font-weight:bold;">Bolla, P. D. </span><span class="font3">(2013) </span><span class="font3" style="font-style:italic;">The Architecture of Concepts: The Historical Formation of Human Rights</span><span class="font3">. Fordham UP.</span></p>
<p><span class="font3" style="font-weight:bold;">Newman, D., and Block, S. </span><span class="font3">(2006). “Probabilistic topic decomposition of an eighteenth-century American newspaper.” </span><span class="font3" style="font-style:italic;">Journal of the American Society for Information</span></p>
<p><span class="font3" style="font-style:italic;">Science and Technology</span><span class="font3"> 57.6 (2006): 753-767.</span></p>
<p><span class="font3" style="font-weight:bold;">Gavin, M. </span><span class="font3">(2015) “The Arithmetic of Concepts: a response to Peter de Bolla.” </span><span class="font3" style="font-style:italic;">Modeling Literary History</span><span class="font3">. 19 Sep</span></p>
<p><span class="font3">2015. &nbsp;&nbsp;&nbsp;Web. Accessed 1 Nov 2016.</span></p>
<p><span class="font3" style="font-weight:bold;">Hamilton, W. L., Leskovec, J., and Jurafsky, D. </span><span class="font3">(2016). “Diachronic Word Embeddings Reveal Statistical Laws of Semantic Change.” arXiv preprint arXiv:1605.09096.&nbsp;Submitted 30 May 2016. Web. Accessed 1 Nov 2016.</span></p>
<p><span class="font3" style="font-weight:bold;">Heuser, R. </span><span class="font3">(2016a). “Word Vectors in the Eighteenth Century, Episode 1: Concepts.” </span><span class="font3" style="font-style:italic;">Adventures of the Virtual.</span><span class="font3"> 14 Apr 2016. Web. Accessed 7 Apr 2017. &lt;<a href="http://ryan-heuser.org/word-vectors-1">http://ryan-heuser.org/word-vectors-1</a>&gt;</span></p>
<p><span class="font3" style="font-weight:bold;">Heuser, R. </span><span class="font3">(2016b). “Word Vectors in the Eighteenth Century, Episode 2: Methods.” </span><span class="font3" style="font-style:italic;">Adventures of the Virtual.</span><span class="font3"> 1 Jun 2016. Web. Accessed 7 Apr 2017. &lt;<a href="http://ryan-heuser.org/word-vectors-2">http://ryan-heuser.org/word-vectors-2</a>&gt;</span></p>
<p><span class="font3" style="font-weight:bold;">Jockers, M. </span><span class="font3">(2013) </span><span class="font3" style="font-style:italic;">Macroanalysis: Digital Methods and Literary History</span><span class="font3">. U of Illinois P.</span></p>
<p><span class="font3" style="font-weight:bold;">Mikolov, T, et al. </span><span class="font3">(2013) “Distributed representations of words and phrases and their compositionality.” </span><span class="font3" style="font-style:italic;">Advances in neural information processing systems</span><span class="font3"> 26&nbsp;(2013).</span></p>
<p><span class="font3" style="font-weight:bold;">Pearson. </span><span class="font3">(2003) </span><span class="font3" style="font-style:italic;">“</span><span class="font3">Candidate Information Booklet.” </span><span class="font3" style="font-style:italic;">Miller Analogies Test.</span><span class="font3"> Web. Accessed 1 Nov 2016. &lt;<a href="http://im-ages.pearsonclinical.com/images/pdf/milleranalo-gies/matcib2002_03.pdf">http://im-ages.pearsonclinical.com/images/pdf/milleranalo-gies/matcib2002_03.pdf</a>&gt;</span></p>
<p><span class="font3" style="font-weight:bold;">Pennington, J., Socher, R., and Manning, C. </span><span class="font3">(2014). “Glove: Global Vectors for Word Representation.” </span><span class="font3" style="font-style:italic;">Proceedings of&nbsp;the 2014 Conference on Empirical Methods in Natural&nbsp;Language Processing</span><span class="font3"> (2014), 1532-1543.</span></p>
<p><span class="font3" style="font-weight:bold;">Recchia, G. </span><span class="font3">(2016) “‘Numberless Degrees Of Similitude': A</span></p>
<p><span class="font3">Response To Ryan Heuser's ‘Word Vectors In The Eighteenth Century, Part 1.'” </span><span class="font3" style="font-style:italic;">Gabriel Recchia's Blog</span><span class="font3">. 11 Jun</span></p>
<p><span class="font3">2016. &nbsp;&nbsp;&nbsp;Web. Accessed 7 Apr 2017.&nbsp;&lt;<a href="http://www.twonewthings.com/gabrielrec-chia/2016/06/11/numberless-degrees-of-similitude-word-vectors/">http://www.twonewthings.com/gabrielrec-chia/2016/06/11/numberless-degrees-of-similitude-word-vectors/</a>&gt;</span></p>
<p><span class="font3" style="font-weight:bold;">Rehurek, R. </span><span class="font3">(n.d.) “models.word2vec - Deep learning with word2vec.” </span><span class="font3" style="font-style:italic;">gensim</span><span class="font3">. Web. Accessed 1 Nov 2016.&nbsp;&lt;<a href="https://radimrehurek.com/gensim/mod-els/word2vec.html">https://radimrehurek.com/gensim/mod-els/word2vec.html</a>&gt;</span></p>
<p><span class="font3" style="font-weight:bold;">Salton, G. </span><span class="font3">(1971). </span><span class="font3" style="font-style:italic;">The SMART retrieval system: Experiments</span></p>
<p><span class="font3" style="font-style:italic;">in automatic document processing</span><span class="font3">. Prentice-Hall.</span></p>
<p><span class="font3" style="font-weight:bold;">Salton, G., Wong, A., and Yang, C. </span><span class="font3">(1975). “A vector space</span></p>
<p><span class="font3">model for automatic indexing.” </span><span class="font3" style="font-style:italic;">Communications of the</span></p>
<p><span class="font3" style="font-style:italic;">ACM</span><span class="font3"> 18.11, 613-620.</span></p>
<p><span class="font3" style="font-weight:bold;">Schmidt, B. </span><span class="font3">(2015a). “Vector Space Models for the Digital Humanities.” </span><span class="font3" style="font-style:italic;">Bookworm</span><span class="font3">. 25 Oct 2015. Web. Accessed 1&nbsp;Nov 2016.</span></p>
<p><span class="font3" style="font-weight:bold;">Schmidt, B. </span><span class="font3">(2015a).. “Rejecting the gender binary: a vector-space operation.” </span><span class="font3" style="font-style:italic;">Bookworm</span><span class="font3">. 30 Oct 2015. Web. Accessed 1 Nov 2016.</span></p>
<p><span class="font3" style="font-weight:bold;">Turney, P. D. and Pantel, P</span><span class="font3">. (2010)“From Frequency to Meaning: Vector Space Models of Semantics.” </span><span class="font3" style="font-style:italic;">Journal of&nbsp;Artificial Intelligence Research</span><span class="font3"> 37: 141-188.</span></p>
</body>
</html>