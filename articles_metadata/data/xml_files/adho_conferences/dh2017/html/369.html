<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
	"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head><meta http-equiv="content-type" content="text/html; charset=UTF-8"/><meta name="generator" content="ABBYY FineReader 14"/><title>Microsoft Word - 369. Song-Linking the Same Ukiyo-e Prints in Different Languages-369.docx</title><link rel="stylesheet" href="369_files/369.css" type="text/css"/>
</head>
<body>
<p><span class="font8">same Ukiyo-e prints that are exhibited in multiple databases with metadata values in different languages.</span></p>
<p><span class="font5" style="font-weight:bold;">Linking the Same Ukiyo-e Prints in Different&nbsp;Languages by Exploiting&nbsp;Word Semantic Relationships&nbsp;across Languages</span></p><h2><a name="caption1"></a><a name="bookmark0"></a><span class="font8" style="font-weight:bold;">Yuting Song</span></h2>
<p><span class="font8"><a href="mailto:gr0260ff@ed.ritsumei.ac.jp">gr0260ff@ed.ritsumei.ac.jp</a></span></p>
<p><span class="font8">Ritsumeikan University, Japan</span></p><h2><a name="bookmark1"></a><span class="font8" style="font-weight:bold;">Taisuke Kimura</span></h2>
<p><span class="font8"><a href="mailto:is0013hh@ed.ritsumei.ac.jp">is0013hh@ed.ritsumei.ac.jp</a></span></p>
<p><span class="font8">Ritsumeikan University, Japan</span></p><h2><a name="bookmark2"></a><span class="font8" style="font-weight:bold;">Biligsaikhan Batjargal</span></h2>
<p><span class="font8"><a href="mailto:biligsaikhan@gmail.com">biligsaikhan@gmail.com</a> Ritsumeikan University, Japan</span></p><h2><a name="bookmark3"></a><span class="font8" style="font-weight:bold;">Akira Maeda</span></h2>
<p><span class="font8"><a href="mailto:amaeda@is.ritsumei.ac.jp">amaeda@is.ritsumei.ac.jp</a> Ritsumeikan University, Japan</span></p>
<p><span class="font12" style="font-weight:bold;">Introduction</span></p>
<p><span class="font8">Many libraries and museums around the world have been releasing their digital collections and&nbsp;making them accessible online. They provide new&nbsp;opportunities for people to acquire information, but&nbsp;they also pose new challenges for accessing these large&nbsp;quantities of humanities resources. Language barriers&nbsp;are one of the main issues for accessing multiple&nbsp;databases in different languages. In this paper, we&nbsp;propose a method to link Ukiyo-e prints between&nbsp;databases in different languages by exploiting&nbsp;semantic similarity of metadata values across&nbsp;languages, in order to achieve our ultimate research&nbsp;goal that aims to provide multilingual access to&nbsp;multiple and diverse databases. We believe our&nbsp;proposed method could assist users in accessing&nbsp;Ukiyo-e databases regardless of languages.</span></p>
<p><span class="font8">Ukiyo-e, Japanese traditional woodblock print, is known as one of the popular arts of the Edo period&nbsp;(1603-1868). Many libraries, museums and galleries&nbsp;in Western countries have digitalized Ukiyo-e&nbsp;woodblock prints with the metadata values in&nbsp;different languages. Table 1 shows an example of the</span></p><div><img src="369_files/369-1.jpg" style="width:242pt;height:153pt;"/>
<p><span class="font2">Table 1. An example of the same Ukiyo-e prints that are exhibited in multiple databases with metadata values in&nbsp;different languages</span></p></div><br clear="all"/>
<p><span class="font8">For linking the same Ukiyo-e prints between databases in different languages, our previous&nbsp;methods (Batjargal et al., 2014; Kimura et al., 2015;&nbsp;Kimura et al., 2016) utilize the metadata values to&nbsp;calculate the similarity between Ukiyo-e prints, in&nbsp;which the metadata values are translated into the&nbsp;same language by using bilingual dictionaries or&nbsp;online machine translation services.</span></p>
<p><span class="font8">Resig (2013) has developed an image similarity based </span><span class="font8" style="text-decoration:underline;">Ukiyo-e print search system,</span><span class="font8"> which is able to&nbsp;search the same Ukiyo-e prints from multiple&nbsp;databases regardless of languages. However, this&nbsp;method cannot be applied to other humanities&nbsp;resources that have no images, such as texts, audio,&nbsp;video and so on.</span></p>
<p><span class="font8">In this paper, we use the metadata values to calculate the similarity between Ukiyo-e prints, which&nbsp;is the same as our previous methods (Batjargal et al.,&nbsp;2014; Kimura et al., 2015; Kimura et al., 2016). The&nbsp;difference is that we calculate similarity between&nbsp;metadata values of Ukiyo-e prints in different&nbsp;languages without translating.</span></p>
<p><span class="font12" style="font-weight:bold;">Methodology</span></p>
<p><span class="font8">Our method is based on word embeddings (Mikolov et al., 2013a), which are dense, lowdimensional and real-valued vectors for representing&nbsp;words. By using word embeddings, the words with a&nbsp;similar meaning have closer distances in a vector&nbsp;space, which means the semantic relationships&nbsp;between words can be captured. An example is shown&nbsp;in Fig. 1, in which two words “storm” and “hurricane”&nbsp;that express similar concepts are closer in a vector&nbsp;space (only two dimensions are shown for simplicity).&nbsp;Word embeddings can be learned by using the&nbsp;</span><span class="font8" style="text-decoration:underline;">Word2Vec toolkit,</span><span class="font8"> which employs a simple neural&nbsp;network model that can be trained on a large amount&nbsp;of unstructured text data in a short time (billions of&nbsp;words in hours).</span></p><h1><a name="caption2"></a><a name="bookmark4"></a><span class="font11">y | &nbsp;&nbsp;&nbsp;.&nbsp;&nbsp;&nbsp;&nbsp;0 rainfall</span></h1><h1><a name="bookmark5"></a><span class="font4" style="font-variant:small-caps;">q</span><span class="font11"> storm hurricane</span></h1><h1><a name="bookmark6"></a><span class="font11">0 evening O <sup>ni</sup>ê<sup>ht</sup></span></h1>
<p><span class="font2">Fig. 1 An example of capturing the sematic relationships between words by using word embeddings</span></p>
<p><span class="font8">Our proposed method is motivated by the idea of Mikolov et al., (2013b) that the same concepts have&nbsp;similar geometric arrangements across languages.&nbsp;Fig.2 illustrates the vector representations of Japanese&nbsp;words (“S” and “M”) and English words (“rainfall”&nbsp;and “storm”) that are used to describe weather&nbsp;phenomena. It can be seen that the same concepts (e.g.&nbsp;weather phenomena) in Japanese and English have&nbsp;similar geometric arrangements in a vector space.</span></p>
<p><span class="font8">What is more important is that the relationship between vector spaces that represent these two&nbsp;languages can possibly be captured by learning a&nbsp;mapping between them, e.g. a liner mapping (dotted&nbsp;arrows in Fig.2). If we know some word pairs in&nbsp;Japanese and English, e.g. “S” and “rainfall”, “M” and&nbsp;“storm”, we can learn a mapping that can help us to&nbsp;transform other words in the Japanese vector space to&nbsp;the English vector space.</span></p><img src="369_files/369-2.jpg" style="width:241pt;height:28pt;"/><img src="369_files/369-3.jpg" style="width:241pt;height:49pt;"/>
<p><span class="font2">Fig. 2 The vector representations of words that are used to describe weather phenomena (“storm” and “rainfall”) and&nbsp;time (“evening” and “night”) in Japanese (left) and English</span></p>
<p><span class="font2">(right)</span></p>
<p><span class="font8">Our goal is to measure the similarity between Ukiyo-e prints by using their metadata values in&nbsp;different languages. Motivated by the idea above, we&nbsp;represent textual metadata values as vectors in each&nbsp;language. Then, we learn a mapping between vector&nbsp;spaces that represent two languages in order to&nbsp;transform the vector representations of textual&nbsp;metadata values from source language space to target&nbsp;language space. Once we obtain the vector&nbsp;representations of textual metadata values in target&nbsp;language space, we can calculate the similarity&nbsp;between metadata values in different languages.</span></p>
<p><span class="font8">Fig. 3 illustrates how our method works. Firstly, we represent the titles of Ukiyo-e prints by additive&nbsp;combination of the vectors of words that compose the&nbsp;titles (Step 1 shown in Fig. 3). And then, we learn the&nbsp;mapping between vector spaces that represent&nbsp;different languages by using some title pairs in&nbsp;Japanese and English (Step 2 shown in Fig. 3), which&nbsp;can help us to transform metadata values from one&nbsp;language space to the other language space.</span></p><img src="369_files/369-4.jpg" style="width:241pt;height:137pt;"/>
<p><span class="font9">|li T È ¡W (Japanese title)</span></p>
<p><span class="font9">Storm below Mount Fuji (English title)</span></p>
<p><span class="font6">below</span></p>
<p><span class="font6">Storm</span></p>
<p><span class="font6">Mount</span></p>
<p><span class="font0">Word vectors</span></p>
<p><span class="font0">Word vectors</span></p>
<p><span class="font0">[——■■■■■] | Japanese title vector</span></p>
<p><span class="font0">English title vector</span></p>
<p><span class="font9">0 Storm below Mount Fuji .0 Clear Weather after Snow</span></p>
<p><span class="font9">.ib</span><span class="font9" style="text-decoration:underline;">T</span><span class="font9">SiUcst,</span></p>
<p><span class="font0" style="font-weight:bold;">Mapping</span></p>
<p><span class="font8">ÄUJ ®0#&lt;ck</span></p>
<p><span class="font0" style="font-weight:bold;">• Weather after Sr</span></p>
<p><span class="font0">The vector space that represents English</span></p>
<p><span class="font0" style="font-weight:bold;">(Tago Bay near Ejiri on the Tokaido) &nbsp;&nbsp;&nbsp;Manninr</span></p>
<p><span class="font0">0 .................—......'</span></p>
<p><span class="font0" style="font-weight:bold;">.............................Mapplnc</span></p>
<p><span class="font0" style="font-weight:bold;">(Noboto Bay) &nbsp;&nbsp;&nbsp;<sub>v</sub></span></p>
<p><span class="font8">-£ 0</span></p>
<p><span class="font0">The vector space that represents Japanese</span></p>
<p><span class="font9">Tago Bay near Ejiri on the Tökaidö</span></p>
<p><span class="font9">---------------&gt;0</span></p>
<p><span class="font3" style="font-variant:small-caps;">&gt; q</span><span class="font9"> Noboto Bay</span></p>
<p><span class="font1" style="font-weight:bold;">Step 1</span></p>
<p><span class="font1" style="font-weight:bold;">Step 1</span></p>
<p><span class="font1" style="font-weight:bold;">Step 2</span></p>
<p><span class="font2">Fig. 3 An example that illustrates the main tasks of the proposed method</span></p>
<p><span class="font12" style="font-weight:bold;">Experiments</span></p>
<p><span class="font8">We conducted experiments to evaluate our proposed method in linking the same Ukiyo-e prints in&nbsp;Japanese and English.</span></p>
<p><span class="font8">In the experiments, the titles are used to calculate similarities among Ukiyo-e prints. Based on our&nbsp;method, the Japanese and English titles are&nbsp;represented by additive combination of the vectors of&nbsp;words that compose the titles. We train the Japanese&nbsp;and English word vectors on Japanese and English&nbsp;Wikipedia articles using Word2Vec toolkit.</span></p>
<p><span class="font8">In the process of learning the mapping between two language spaces, we use 600 Japanese-English&nbsp;parallel short sentence pairs for pre-training the&nbsp;mapping between Japanese and English vector spaces.</span></p>
<p><span class="font8">In order to make this mapping more suitable to Ukiyo-e titles, we further use 74 pairs of Japanese and English Ukiyo-e titles to optimize this mapping, in which each&nbsp;pair of titles refers to the same Ukiyo-e prints. This&nbsp;optimized mapping are used to transform other&nbsp;vectors of the titles in Japanese space to English space.</span></p>
<p><span class="font8">We calculate the similarities between the titles of Ukiyo-e prints using cosine similarity. For each&nbsp;Japanese title, after we obtain the mapped vector in&nbsp;English space, our method outputs the most similar&nbsp;English title vector as its corresponding English title.</span></p>
<p><span class="font8">We use 173 pairs of Japanese and English Ukiyo-e titles as the test data to evaluate our method. The&nbsp;precision at top-n are used to measure the&nbsp;experimental results, which means the percentage of&nbsp;Japanese titles whose truly corresponding English title&nbsp;are ranked in top n. In order to verify the effectiveness&nbsp;of using Ukiyo-e titles to optimize the mapping, we&nbsp;show the results of both conditions of using Ukiyo-e&nbsp;titles and without using them in the pre-training. The&nbsp;experimental results are shown in Table 2.</span></p>
<table border="1">
<tr><td>
<p></p></td><td>
<p><span class="font10">Precision in top-1</span></p></td><td>
<p><span class="font10">Precision within top-5</span></p></td><td>
<p><span class="font10">Precision within top-10</span></p></td><td>
<p><span class="font10">Precision within top-15</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font10">Without using Ukiyo-e titles</span></p></td><td style="vertical-align:middle;">
<p><span class="font10">2.3%</span></p></td><td style="vertical-align:middle;">
<p><span class="font10">12.2%</span></p></td><td style="vertical-align:middle;">
<p><span class="font10">17.4%</span></p></td><td style="vertical-align:middle;">
<p><span class="font10">22.7%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font10">Using Ukiyo-e titles</span></p></td><td style="vertical-align:middle;">
<p><span class="font10">29.1%</span></p></td><td style="vertical-align:middle;">
<p><span class="font10">41.9%</span></p></td><td style="vertical-align:middle;">
<p><span class="font10">50.0%</span></p></td><td style="vertical-align:middle;">
<p><span class="font10">54.7%</span></p></td></tr>
</table>
<p><span class="font2">Table 2. The experimental results</span></p>
<p><span class="font7" style="font-weight:bold;">Batjargal, B., Kuyama, T., F. Kimura and Maeda, A.</span></p>
<p><span class="font7">(2014). “Identifying the same records across multiple Ukiyo-e image databases using textual data in different&nbsp;languages.” </span><span class="font7" style="font-style:italic;">Proceedings of the 14th ACM/IEEE-CS Joint&nbsp;Conference on Digital Libraries</span><span class="font7">. London, United Kingdom,&nbsp;pp. 193-96.</span></p>
<p><span class="font7" style="font-weight:bold;">Kimura, T., Batjargal, B., Kimura, F. and Maeda, A.</span></p>
<p><span class="font7">(2015). “Finding the Same Artworks from Multiple Databases in Different Languages.” </span><span class="font7" style="font-style:italic;">Digital Humanities 2015: Conference Abstracts</span><span class="font7">. Sydney, Australia.</span></p>
<p><span class="font7" style="font-weight:bold;">Kimura, T., Song, Y., Batjargal, B., Kimura, F. and Maeda, A. </span><span class="font7">(2016). “Identifying the Same Ukiyo-e Prints from Databases in Dutch and Japanese.” </span><span class="font7" style="font-style:italic;">In Digital Humanities</span></p>
<p><span class="font7" style="font-style:italic;">2016: Conference Abstracts.</span><span class="font7"> Krakow, Poland, pp. 822-24.</span></p>
<p><span class="font7" style="font-weight:bold;">Resig, J. </span><span class="font7">(2013). “Aggregating and analyzing digitized Japanese woodblock prints.” </span><span class="font7" style="font-style:italic;">In 3rd Annual Conference of the Japanese Association for Digital Humanities</span><span class="font7">. Kyoto, Japan.&nbsp;</span><span class="font7" style="text-decoration:underline;"><a href="https://ukiyo-e.org/about">https://ukiyo-e.org/about</span><span class="font7"></a>.</span></p>
<p><span class="font7" style="font-weight:bold;">Mikolov, T., Chen,K., Corrado, G. and Dean, J. </span><span class="font7">(2013a). “Efficient Estimation of Word Representations in Vector Space.” </span><span class="font7" style="font-style:italic;">arXiv preprint arXiv:1301.3781</span><span class="font7">.</span></p>
<p><span class="font7" style="font-weight:bold;">Mikolov, T., Le, Q.V. and Sutskever, I. </span><span class="font7">(2013b). “Exploiting</span></p>
<p><span class="font7">similarities among languages for machine translation.” </span><span class="font7" style="font-style:italic;">arXiv preprint arXiv:1309.4168</span><span class="font7">.</span></p>
<p><span class="font8">These results show that the precisions are further improved by using Japanese and English Ukiyo-e titles&nbsp;to optimize the mapping between Japanese and&nbsp;English vector spaces. The experimental results also&nbsp;confirm the usefulness of our proposed method for&nbsp;linking the same Ukiyo-e prints in Japanese and&nbsp;English.</span></p>
<p><span class="font12" style="font-weight:bold;">Conclusion</span></p>
<p><span class="font8">Our proposed method measures the similarity between metadata values without using any bilingual&nbsp;dictionary or online machine translation system.&nbsp;Moreover, our proposed method represents the&nbsp;metadata values using word embeddings, which can&nbsp;capture the semantic relationships between metadata&nbsp;values.</span></p>
<p><span class="font8">In the future, we will evaluate our method for linking Ukiyo-e prints in other languages.</span></p>
<p><span class="font12" style="font-weight:bold;">Bibliography</span></p>
</body>
</html>