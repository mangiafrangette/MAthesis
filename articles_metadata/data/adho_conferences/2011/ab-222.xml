
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8; charset=UTF-8" /><title>Supporting Scientific Discoveries to Answer Art Authorship Related Questions
					Across Diverse Disciplines and Geographically Distributed Resources </title><link rel="stylesheet" href="css/default/results.css" type="text/css" /><script src="script/yui/yahoo-dom-event.js" type="text/javascript"></script><script src="script/yui/connection-min.js" type="text/javascript"></script></head><body class="home blog"><div id="wrapper" class="hfeed"><div id="header"><div id="masthead"><div id="branding" role="banner"><h1 id="site-title"><span><a href="https://dh2011.stanford.edu/" title="Digital Humanities 2011: June 19 – 22" rel="home">Digital Humanities
                2011: June 19 – 22</a></span></h1><div id="site-description">Big Tent Digital Humanities</div><img src="https://www.stanford.edu/group/dh2011/cgi-bin/wordpress/wp-content/uploads/2010/09/tieDyeLarge.jpg" width="940" height="198" alt="" /></div><div id="access" role="navigation"><div class="menu"><ul><li><a href="https://dh2011.stanford.edu/" title="Home">Home</a></li><li><a href="https://dh2011.stanford.edu/?page_id=3" title="About">About</a></li><li><a href="https://dh2011.stanford.edu/?page_id=15" title="Accommodations &amp; Travel">Accommodations &amp; Travel</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=887" title="Accommodations">Accommodations</a></li><li><a href="https://dh2011.stanford.edu/?page_id=883" title="Travel">Travel</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=311" title="Registration">Registration</a></li><li><a href="https://dh2011.stanford.edu/?page_id=411" title="Schedule">Schedule</a></li><li><a href="https://dh2011.stanford.edu/?page_id=475" title="Workshops">Workshops</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=489" title="Tutorial 1: Introductory TEI ODD">Tutorial 1: Introductory TEI ODD</a></li><li><a href="https://dh2011.stanford.edu/?page_id=499" title="Tutorial 2 / Workshop: Integrating Digital Humanities Projects into the Undergraduate Curriculum">Tutorial 2 / Workshop: Integrating Digital Humanities Projects into the
                      Undergraduate Curriculum</a></li><li><a href="https://dh2011.stanford.edu/?page_id=507" title="Tutorial 3: An Introduction to XForms for Digital Humanists: How XForms Can Help Your Project">Tutorial 3: An Introduction to XForms for Digital Humanists: How XForms Can
                      Help Your Project</a></li><li><a href="https://dh2011.stanford.edu/?page_id=517" title="Tutorial 4: Introduction to Text Analysis With Voyeur Tools">Tutorial
                      4: Introduction to Text Analysis With Voyeur Tools</a></li><li><a href="https://dh2011.stanford.edu/?page_id=521" title="Tutorial 5: Gabmap: A Web Application for Analyzing Linguistic Variation">Tutorial 5: Gabmap: A Web Application for Analyzing Linguistic Variation</a></li><li><a href="https://dh2011.stanford.edu/?page_id=525" title="Tutorial 6: Natural Language Processing Tools for the Digital Humanities">Tutorial 6: Natural Language Processing Tools for the Digital Humanities</a></li><li><a href="https://dh2011.stanford.edu/?page_id=529" title="Tutorial 7: Network and Topical Analysis for the Humanities using NWB and Sci2">Tutorial 7: Network and Topical Analysis for the Humanities using NWB and
                      Sci2</a></li><li><a href="https://dh2011.stanford.edu/?page_id=493" title="Workshop: Visualization for Literary History">Workshop: Visualization
                      for Literary History</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=471" title="Social Program">Social
                  Program</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=541" title="Literary San Francisco (Full Day)">Literary San Francisco (Full
                      Day)</a></li><li><a href="https://dh2011.stanford.edu/?page_id=547" title="Silicon Valley History (Half-Day)">Silicon Valley History
                      (Half-Day)</a></li><li><a href="https://dh2011.stanford.edu/?page_id=537" title="Sonoma Wine Country (Full-Day)">Sonoma Wine Country (Full-Day)</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=181" title="CFPs">CFPs</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=97" title="General CFP">General
                      CFP</a></li><li><a href="https://dh2011.stanford.edu/?page_id=175" title="CFP en Español">CFP en
                      Español</a></li><li><a href="https://dh2011.stanford.edu/?page_id=287" title="CFP in German">CFP in
                      German</a></li><li><a href="https://dh2011.stanford.edu/?page_id=207" title="CFP in Greek">CFP in
                      Greek</a></li><li><a href="https://dh2011.stanford.edu/?page_id=229" title="CFP in Hungarian">CFP
                      in Hungarian</a></li><li><a href="https://dh2011.stanford.edu/?page_id=257" title="CFP in Italiano">CFP
                      in Italiano</a></li><li><a href="https://dh2011.stanford.edu/?page_id=157" title="Tutorial/Workshop CFP">Tutorial/Workshop CFP</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=19" title="Contacts">Contacts</a></li><li><a href="https://dh2011.stanford.edu/?page_id=801" title="Venue">Venue</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=829" title="Local Lunch Spots">Local Lunch Spots</a></li><li><a href="https://dh2011.stanford.edu/?page_id=845" title="Palo Alto Restaurants">Palo Alto Restaurants</a></li></ul></li></ul></div></div><br class="clear" /></div></div><div class="resultsHeader"><table><tr><td><a href="http://dh2011abstracts.stanford.edu/xtf/search" target="_top">New Search</a> | <span class="notActive">Return to Search Results</span> | <a href="http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-222.xml&amp;doc.view=print;chunk.id=0" target="_top">Print View</a></td><td align="right"><form action="http://dh2011abstracts.stanford.edu/xtf/view" target="_top" method="get"><input name="query" type="text" size="15" /><input type="hidden" name="docId" value="tei/ab-222.xml" /><input type="hidden" name="chunk.id" value="0" /><input type="submit" value="Search this Book" /></form></td></tr></table></div><hr /><div class="results"><h2>Paper: Supporting Scientific Discoveries to Answer Art Authorship Related Questions
					Across Diverse Disciplines and Geographically Distributed Resources </h2><h4>
					Bajcsy, Peter, 
					National Center for Supercomputing Applications, 
					<a href="mailto:pbajcsy@ncsa.uiuc.edu">pbajcsy@ncsa.uiuc.edu</a>
				</h4><h4>
					Kooper, Rob, National Center for Supercomputing
						Applications, <a href="mailto:kooper@ncsa.uiuc.edu">kooper@ncsa.uiuc.edu</a>
				</h4><h4>
					Marini, Luigi, National Center for Supercomputing
						Applications, <a href="mailto:lmarini@ncsa.uiuc.edu">lmarini@ncsa.uiuc.edu</a>
				</h4><h4>
					Shaw, Tenzing, National Center for Supercomputing
						Applications, <a href="mailto:twshaw3@ncsa.uiuc.edu">twshaw3@ncsa.uiuc.edu</a>
				</h4><h4>
					Hedeman, Anne D., University of
						Illinois, <a href="mailto:ahedeman@illinois.edu">ahedeman@illinois.edu</a>
				</h4><h4>
					Markley, Robert, University of
						Illinois, <a href="mailto:rmarkley@illinois.edu">rmarkley@illinois.edu</a>
				</h4><h4>
					Simeone, Michael, University of
						Illinois, <a href="mailto:mpsimeon@illinois.edu">mpsimeon@illinois.edu</a>
				</h4><h4>
					Hansen, Natalie, University of
						Illinois, <a href="mailto:nhansen2@illinois.edu">nhansen2@illinois.edu</a>
				</h4><h4>
					Appleford, Simon, University of
						Illinois, <a href="mailto:sapplefo@illinois.edu">sapplefo@illinois.edu</a>
				</h4><h4>Rehberger, Dean, MATRIX: The Center for Humane Arts,
						Letters, and Social Sciences Online, Michigan State
						University, <a href="mailto:dean.rehberger@matrix.msu.edu">dean.rehberger@matrix.msu.edu</a>
				</h4><h4>Richardson, Justine, MATRIX: The Center for Humane
						Arts, Letters, and Social Sciences Online, Michigan State
						University, <a href="mailto:justine.richardson@matrix.msu.edu">justine.richardson@matrix.msu.edu</a>
				</h4><h4>Geimer, Matthew, MATRIX: The Center for Humane Arts,
						Letters, and Social Sciences Online, Michigan State
						University, <a href="mailto:matt.geimer@matrix.msu.edu">matt.geimer@matrix.msu.edu</a>
				</h4><h4>Cohen, Steve M., MATRIX: The Center for Humane Arts,
						Letters, and Social Sciences Online, Michigan State
						University, <a href="mailto:steve.cohen@matrix.msu.edu">steve.cohen@matrix.msu.edu</a>
				</h4><h4>Ainsworth, Peter, University of
						Sheffield, <a href="mailto:p.f.ainsworth@sheffield.ac.uk">p.f.ainsworth@sheffield.ac.uk</a>
				</h4><h4>Meredith, Michael, University of
						Sheffield, <a href="mailto:M.Meredith@sheffield.ac.uk">M.Meredith@sheffield.ac.uk</a>
				</h4><h4>Guiliano, Jennifer, University of South
						Carolina, <a href="mailto:jenguiliano@gmail.com">jenguiliano@gmail.com</a>
				</h4><hr />
			
				<h2>Overview</h2>
				<p class="noindent">In the past, humanities scholars have primarily used text-based computational
					approaches to engage questions of authorship. In the area of visual arts,
					computational analysis of authorship is a growing field, but it is one that
					features diverse questions and requires complex algorithms, significant
					computational resources and a wide variety of experts from diverse disciplines
					to combine the results of visual inspections with computer generated results.
					Furthermore, when approaching the broad field of authorship-related questions in
					visual works, the variety of digital images representing cultural artifacts
					poses a formidable challenge on the robustness and accuracy of computer
					algorithms. The motivation of our work is to explore technologies that
					facilitate enquiry about authorship in visual art work and to address the
					challenges related to algorithm development, computational scalability of
					algorithms, distributed software development and data sharing, efficient
					communication tools across diverse disciplines, and robustness and general
					utility of algorithmic development when applied to a spectrum of authorship
					questions from historical images. In other words, we wanted to develop specific
					methods for new image-based research as well as build and model for future work
					in image processing and humanities research. We approached these challenges by
					selecting image subsets from the collections of 15th-century manuscripts, 17th
					and 18th-century maps, and 19th through 21st-century quilts that often have
					corporate and anonymous authors working in community groups, guilds, artisan
					shops, and scriptoriums, and report technologies designed to support authorship
					discoveries in these collections. Crucially, the questions our algorithms and
					experts address are concerned with using authorship as a trope for analysis and
					generating new data, not just verifying the heritage or identity of a given
					artifact.</p>
			

			
				<h2>Methodology</h2>


				<p class="noindent">The research being presented as part of this paper submission is derived from the
					Digging into Data to Answer Authorship Related Questions Grant awarded as part
					of the Digging into Data Challenge Competition (<a href="http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-222.xml&amp;chunk.id=&amp;toc.id=&amp;toc.depth=1&amp;brand=default&amp;anchor.id=http://www.diggingintodata.org#X" target="_top">www.diggingintodata.org</a>). An international, multi-disciplinary team
					of researchers from the University of Illinois (US), the National Center for
					Supercomputing Applications (US), Michigan State University (US), and the
					University of Sheffield (UK), the DID team works to formulate and address the
					problem of finding salient characteristics of artists from two-dimensional (2D)
					images of historical artifacts. Given a set of 2D images of historical artifacts
					with known authors, our project teams aim to discover what salient
					characteristics make an artist different from others, and then to enable
					statistical learning about individual and collective authorship. The objective
					of this effort is to learn what is unique about the style of each artist, and to
					provide the results at a much higher level of confidence than previously has
					been feasible by exploring a large search space in the semantic gap of image
					understanding. Team members are geographically distributed and have very
					different backgrounds and expertise. While the discoveries require involvements
					and interactions of experts in computer science and in humanities, we had to
					design a methodology for communicating, coordinating web design and public
					relationship interfaces, large size data sharing, collaborative software
					development, software sharing and testing, and hardware sharing. We approached
					this spectrum of collaborative project challenges by (a) establishing
					communication and coordination channels (ooVoo videoconference, mailing lists,
					legal point of contacts regarding licenses and intellectual properties), (b)
					designing and deploying a content repository called Medici, (c) designing and
					documenting a library of content based file comparisons with standard
					application programming interfaces (API) for software development called Versus,
					(d) deploying software source control and bug tracking systems accessible to all
					team members (SVN and JIRA), (e) designing web-based workflow systems that could
					give access to hardware resources at any site for execution of algorithms called
					Cyberintegrator, and (f) providing additional tools and user interfaces for
					humanity scholars to view large size images and contribute to the interpretation
					of the computer generated results.</p>
			

			
				<h2>Technical Approach and Initial Results</h2>
				<p class="noindent">Emphasizing the aspects of data-sharing, collaborative software development,
					distributed hardware resources, and interactions of experts from diverse domains
					in the Digging into Data project, we designed, developed and deployed
					technologies supporting a wide spectrum of team activities. The data, software
					and hardware sharing technologies include the Medici Content Management
					Repository (see Fig. 1), <p>
						<h2>Figure 1: User interface to the Medici management repository for data
							sharing, annotations and visualization of large size images.</h2>
						<img class="inline" src="http://dh2011abstracts.stanford.edu/xtf/data/tei/222/fig1.png" /><p><a href="javascript://" onclick="javascript:window.open('http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-222.xml&amp;doc.view=popup&amp;fig.ent=http://dh2011abstracts.stanford.edu/xtf/data/tei/222/fig1.png','popup','width=800,height=600,resizable=yes,scrollbars=yes')">Full Size Image </a></p>
					</p> the Im2Learn library of basic image processing and visualization
					algorithms that can be applied to various image analyses (see Fig. 2), <p>
						<h2>Figure 2: An example of a segmentation algorithm in Im2Learn library
							that was applied to historical map analyses (top) and manuscript
							illustration analyses (bottom).</h2>
						<img class="inline" src="http://dh2011abstracts.stanford.edu/xtf/data/tei/222/fig2a.png" /><p><a href="javascript://" onclick="javascript:window.open('http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-222.xml&amp;doc.view=popup&amp;fig.ent=http://dh2011abstracts.stanford.edu/xtf/data/tei/222/fig2a.png','popup','width=800,height=600,resizable=yes,scrollbars=yes')">Full Size Image </a></p>
						<img class="inline" src="http://dh2011abstracts.stanford.edu/xtf/data/tei/222/fig2b.png" /><p><a href="javascript://" onclick="javascript:window.open('http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-222.xml&amp;doc.view=popup&amp;fig.ent=http://dh2011abstracts.stanford.edu/xtf/data/tei/222/fig2b.png','popup','width=800,height=600,resizable=yes,scrollbars=yes')">Full Size Image </a></p>
					</p> the Versus library for content-based image comparison (see Fig.3),
						<p>
						<h2>Figure 3: Initial user interface to Versus in order to support image
							comparison based analyses.</h2>
						<img class="inline" src="http://dh2011abstracts.stanford.edu/xtf/data/tei/222/fig3.png" /><p><a href="javascript://" onclick="javascript:window.open('http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-222.xml&amp;doc.view=popup&amp;fig.ent=http://dh2011abstracts.stanford.edu/xtf/data/tei/222/fig3.png','popup','width=800,height=600,resizable=yes,scrollbars=yes')">Full Size Image </a></p>
					</p> and the Cyberintegrator workflow for managing computations on
					distributed computational resources. The Medici Content Repository System is a
					web and desktop-enabled content management system that allows users to upload,
					collate, annotate, and run analytics on a variety of files types allowing for
					portable and open representation of data with extensible analytical tools. The
					analytical capabilities come from the Im2learn library that provides a
					plug-and-play interface for adding new algorithms and tools. Due to the fact
					that the authorship questions are frequently based on a comparison operation, we
					have designed additional API called Versus which allows everyone to contribute
					with comparison methods. Once the algorithms for image analyses and comparisons
					have been developed, they can be integrated into workflows (a sequence of
					algorithmic operations to reach the analytical goal) in Cyberintegrator workflow
					environment. Cyberintegrator is a user friendly editor to several middleware
					software components that: 
						<li>enable users to easily include tools and data sets into a
							software/data unifying environment</li>
						<li>annotate data, tools and workflows with metadata</li>
						<li>visualize data and metadata</li>
						<li>share data and tools using local and remote context repository</li>
						<li>execute step-by-step workflows during scientific explorations</li>
						<li>gather provenance information about tool executions and data
							creations. </li>
					 In order to support visual explorations of large size images and
					contribute to the interpretation of the computer generated results by humanists
					and computer scientists, we have also integrated Microsoft Live Lab’s Seadragon
					library to build image pyramids and support fast zoom in and out operations.</p>
			
			
				<h2>Summary</h2>
				<p class="noindent">Our paper addressed each logistical and computational facet of a distributed,
					international collaboration. Based on our initial effort, all team members have
					responded positively to the technologies introduced and also helped in defining
					requirements for executing such complex projects involving collaborative
					humanities research. Based on our current observations, the web technologies for
					data, software and hardware sharing provided the foundation blocks for
					addressing the authorship discovery challenges. We have also concluded that the
					open nature of joint software development is necessary for overcoming
					intellectual property right and other legal hurdles.</p>
			
			
				<h2>Acknowledgment</h2>
				<p class="noindent">We would like to acknowledge the NSF ITS 09-10562 EAGER grant and the
					NSF/NEH/JISC Digging into Data (NSF grant ID: 1039385).</p>
			
		</div></div></body></html>