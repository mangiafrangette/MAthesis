
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8; charset=UTF-8" /><title>The Text-Image-Link-Editor: A tool for Linking Facsimiles &amp;
                    Transcriptions and Image Annotations</title><link rel="stylesheet" href="css/default/results.css" type="text/css" /><script src="script/yui/yahoo-dom-event.js" type="text/javascript"></script><script src="script/yui/connection-min.js" type="text/javascript"></script></head><body class="home blog"><div id="wrapper" class="hfeed"><div id="header"><div id="masthead"><div id="branding" role="banner"><h1 id="site-title"><span><a href="https://dh2011.stanford.edu/" title="Digital Humanities 2011: June 19 – 22" rel="home">Digital Humanities
                2011: June 19 – 22</a></span></h1><div id="site-description">Big Tent Digital Humanities</div><img src="https://www.stanford.edu/group/dh2011/cgi-bin/wordpress/wp-content/uploads/2010/09/tieDyeLarge.jpg" width="940" height="198" alt="" /></div><div id="access" role="navigation"><div class="menu"><ul><li><a href="https://dh2011.stanford.edu/" title="Home">Home</a></li><li><a href="https://dh2011.stanford.edu/?page_id=3" title="About">About</a></li><li><a href="https://dh2011.stanford.edu/?page_id=15" title="Accommodations &amp; Travel">Accommodations &amp; Travel</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=887" title="Accommodations">Accommodations</a></li><li><a href="https://dh2011.stanford.edu/?page_id=883" title="Travel">Travel</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=311" title="Registration">Registration</a></li><li><a href="https://dh2011.stanford.edu/?page_id=411" title="Schedule">Schedule</a></li><li><a href="https://dh2011.stanford.edu/?page_id=475" title="Workshops">Workshops</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=489" title="Tutorial 1: Introductory TEI ODD">Tutorial 1: Introductory TEI ODD</a></li><li><a href="https://dh2011.stanford.edu/?page_id=499" title="Tutorial 2 / Workshop: Integrating Digital Humanities Projects into the Undergraduate Curriculum">Tutorial 2 / Workshop: Integrating Digital Humanities Projects into the
                      Undergraduate Curriculum</a></li><li><a href="https://dh2011.stanford.edu/?page_id=507" title="Tutorial 3: An Introduction to XForms for Digital Humanists: How XForms Can Help Your Project">Tutorial 3: An Introduction to XForms for Digital Humanists: How XForms Can
                      Help Your Project</a></li><li><a href="https://dh2011.stanford.edu/?page_id=517" title="Tutorial 4: Introduction to Text Analysis With Voyeur Tools">Tutorial
                      4: Introduction to Text Analysis With Voyeur Tools</a></li><li><a href="https://dh2011.stanford.edu/?page_id=521" title="Tutorial 5: Gabmap: A Web Application for Analyzing Linguistic Variation">Tutorial 5: Gabmap: A Web Application for Analyzing Linguistic Variation</a></li><li><a href="https://dh2011.stanford.edu/?page_id=525" title="Tutorial 6: Natural Language Processing Tools for the Digital Humanities">Tutorial 6: Natural Language Processing Tools for the Digital Humanities</a></li><li><a href="https://dh2011.stanford.edu/?page_id=529" title="Tutorial 7: Network and Topical Analysis for the Humanities using NWB and Sci2">Tutorial 7: Network and Topical Analysis for the Humanities using NWB and
                      Sci2</a></li><li><a href="https://dh2011.stanford.edu/?page_id=493" title="Workshop: Visualization for Literary History">Workshop: Visualization
                      for Literary History</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=471" title="Social Program">Social
                  Program</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=541" title="Literary San Francisco (Full Day)">Literary San Francisco (Full
                      Day)</a></li><li><a href="https://dh2011.stanford.edu/?page_id=547" title="Silicon Valley History (Half-Day)">Silicon Valley History
                      (Half-Day)</a></li><li><a href="https://dh2011.stanford.edu/?page_id=537" title="Sonoma Wine Country (Full-Day)">Sonoma Wine Country (Full-Day)</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=181" title="CFPs">CFPs</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=97" title="General CFP">General
                      CFP</a></li><li><a href="https://dh2011.stanford.edu/?page_id=175" title="CFP en Español">CFP en
                      Español</a></li><li><a href="https://dh2011.stanford.edu/?page_id=287" title="CFP in German">CFP in
                      German</a></li><li><a href="https://dh2011.stanford.edu/?page_id=207" title="CFP in Greek">CFP in
                      Greek</a></li><li><a href="https://dh2011.stanford.edu/?page_id=229" title="CFP in Hungarian">CFP
                      in Hungarian</a></li><li><a href="https://dh2011.stanford.edu/?page_id=257" title="CFP in Italiano">CFP
                      in Italiano</a></li><li><a href="https://dh2011.stanford.edu/?page_id=157" title="Tutorial/Workshop CFP">Tutorial/Workshop CFP</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=19" title="Contacts">Contacts</a></li><li><a href="https://dh2011.stanford.edu/?page_id=801" title="Venue">Venue</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=829" title="Local Lunch Spots">Local Lunch Spots</a></li><li><a href="https://dh2011.stanford.edu/?page_id=845" title="Palo Alto Restaurants">Palo Alto Restaurants</a></li></ul></li></ul></div></div><br class="clear" /></div></div><div class="resultsHeader"><table><tr><td><a href="http://dh2011abstracts.stanford.edu/xtf/search" target="_top">New Search</a> | <span class="notActive">Return to Search Results</span> | <a href="http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-197.xml&amp;doc.view=print;chunk.id=0" target="_top">Print View</a></td><td align="right"><form action="http://dh2011abstracts.stanford.edu/xtf/view" target="_top" method="get"><input name="query" type="text" size="15" /><input type="hidden" name="docId" value="tei/ab-197.xml" /><input type="hidden" name="chunk.id" value="0" /><input type="submit" value="Search this Book" /></form></td></tr></table></div><hr /><div class="results"><h2>Paper: The Text-Image-Link-Editor: A tool for Linking Facsimiles &amp;
                    Transcriptions and Image Annotations</h2><h4>
                    Al-Hajj, Yahya Ahmed Ali, 
                    Worms University of Applied Sciences, Germany, 
                    <a href="mailto:alhajj@fh-worms.de">alhajj@fh-worms.de</a>
                </h4><h4>
                    Küster, Marc Wilhelm, 
                    Worms University of Applied Sciences, Germany, 
                    <a href="mailto:kuester@fh-worms.de">kuester@fh-worms.de</a>
                </h4><hr />
            
                <h2>Introduction</h2>
                <p class="noindent">TextGrid’s Text-Image-Link-Editor (TBLE “stands for for Text-Bild-Link-Editor,
                    German for Text-Image-Link-Editor”) is used to link segments of text with
                    sections on the corresponding image. A typical application is linking of scans
                    of facsimiles with their transcriptions, though these texts can also be created
                    during the linking process, which allows e.g. also for image annotations. The
                    information on the linking between manuscript fragments and the corresponding
                    transcription is itself stored in TEI. TextGrid is as a virtual research
                    environment (VRE) for the humanities disciplines dealing with texts in a wide
                    sense (philologies, epigraphy, linguistics, musicology, art history etc.). The
                    joint research project TextGrid is part of the D-Grid initiative, and is funded
                    by the German Federal Ministry of Education and Research (BMBF) for the period
                    starting June 1, 2009 to May 31, 2012 (reference number: 01UG0901A).</p>
                <p class="noindent">TextGrid consists of two principal building blocks, the grid-based backend
                    TextGridRep that hosts both infrastructure services and the repository layer for
                    access to research data and longterm archiving, and the user-facing TextGridLab.
                    The TextGrid Laboratory (TextGridLab), a single point of entry to the virtual
                    research environment, will provide integrated access to both new and existing
                    tools and services via a user friendly software [TG]. TBLE is a key component of
                    the TextGridLab that has been under continuous development since 2008 and is by
                    now in practical use.</p>
            
            
                <h2>State of the Art</h2>
                <p class="noindent">The integration of manuscript scans with their transcription and indeed the
                    critical edition itself is a desideratum of modern editions: “While some people
                    continue to think of electronic texts as exclusive of images, the fact is that
                    digital images of manuscripts are electronic texts, as well. The most compelling
                    scholarly editions of the future will make full use of markup schemes such as
                    XML [...], but not without extensive integration of images” [Kiernan2006]. In
                    this context TextGrid is not the only project that recognized the need for an
                    tool to facilitate this linking of image sections with transcriptions. The
                    Edition Production &amp; Presentation Technology's (EPPT's) [EPPT] tool box for
                    integrating images and text operates in much the same solution space.
                    [Parker2009] proposes the development of a web-based Text-Image Linking
                    Environment (TILE), and for much the same reasons as the TBLE, namely to
                    facilitate “the linking of images and textual information [which] remains a slow
                    and frustrating process for editors and curators”. [TILE] is currently under
                        development.For the current status of the project cf. also its
                        homepage 
         (<a href="http://tileproject.org" target="blank">link</a>)
    Consulted 2011-03-14
                    Unlike the Eclipse-based TBLE, TILE is Ajax-based, extending the Ajax XML
                    Encoder.</p>
                <p class="noindent">Similar in objective to TBLE and developed in much the same timeframe is Tapor’s
                    / the University of Victoria’s Image Markup Tool [Holmes2010]. Both
                    independently decided to use formats based on TEI P5 to store linking
                    information, though at this stage unfortunately not the same. Unlike TBLE, the
                    Image Markup Tool is a desktop program only for the MS Windows platform and
                    cannot be integrated into the TextGridLab.</p>
                <p class="noindent">[Cayless2008] reports on experiments to partially automate the linking between
                    manuscripts and their transcriptions. TBLE plans to integrate similar
                    functionality using OCR technology (cf. below).</p>
                <p class="noindent">As required in [Huitfeld2010], TBLE allows, in Peirce’s terminology, multiple
                    “types” to be associated with one “token”, or in other words to associate one
                    section in a manuscript with multiple, possibly contradictory interpretations /
                    transcriptions. Image sections can overlap, so that divergent segmentations are
                    possible.</p>
                <p class="noindent">As an aside, this type of linking is very different from the research field of
                    automated image analysis and image annotation which attempts to automatically
                    establish key metadata for an image, e.g. by identifying the objects or persons
                    shown on a photo.</p>

            
            
                <h2>Functionality</h2>
                <p class="noindent">The following use case is a typical example for working with the TBLE: A scholar
                    wants to publish manuscripts as collection of images, which offer a digital
                    representation of the original work, but also wants to publish his take on its
                    correct transcription in view of establishing a critical edition. The solution
                    is to write the content of these hand written documents as text in a
                    human/machine readable format e.g. XML and this text can be divided into logical
                    related segments for example: verses, lines and then these text segments can be
                    easily linked with the corresponding sections on the images using the TBLE.</p>
                <p class="noindent">The TBLE can be used for:</p>
                
                    <h2>Linking Existing Texts and Digitized Manuscripts</h2>
                    <p class="noindent">Text and image are opened, then the corresponding components (text segment
                        and selected image section) are marked by pairs and the linkage is
                        confirmed. The results can be saved as a new file (local or in the
                        TextGridRepository), which contains the linking information (image
                        coordinates, text segment identifiers, URIs of the used text and image
                        files). Sections can be rectangles or arbitrary polygons.</p>
                    <p class="noindent">The content of the new created file represents the saved information as a TEI
                        document with an embedded [SVG] section (see section 4 “The TEI-Model” for
                        more details). Once a file is saved, double clicking it reloads used images,
                        texts and links to continue editing. Changing or adding new links as well as
                        modifying the linked text is possible at any time.</p>
                    <p class="noindent">Instead of starting out with an existing transcription and linking it with
                        the image data, the scholar can also decide to start from scratch with an
                        empty text file. The new text segments can be inserted stepwise or at
                        once.</p>
                    <p class="noindent">Any number of different and possibly conflicting transcriptions and
                        segmentations can be linked against one set of digitized manuscripts.</p>
                
                
                    <h2>Annotation of Image Sections and Existing Links</h2>
                    <p class="noindent">The Text-Image-Link-Editor offers many other useful features, that help
                        annotating specific links or image sections. For example:</p>
                    <p class="noindent">
                            <li>It's possible to build logical groups of links (e.g. verses,
                                comments, etc.) using the layers-tool.</li>
                            <li>A text-direction (e.g. left-to-right &amp; top-to-bottom) can be
                                assigned to the links.</li>
                        </p>
                
            
            
                <h2>The TEI-Model</h2>
                <p class="noindent">The output file of the Text-Image-Link-Editor follows the TEI model with embedded
                    svg description elements. The following is a list, which crudely describes the
                    structure of the TEI document:</p>
                <p class="noindent">
                        <li>&lt;teiHeader&gt; this element could be used to save the metadata of
                            the document.</li>
                        <li>&lt;facsimile&gt; in this element is the svg element embedded, which
                            keeps the topographic descriptions of images and links.</li>
                        <li>&lt;body&gt; in the body element are the link groups, that contain the
                            link elements. These link elements represent the relationship between
                            the image sections and the corresponding text segments. The relationship
                            between images and texts and links is represented in the following
                            figure:</li>
                    </p>
                <p class="noindent"><p>
                        <h2>The TEI output file of the Text-Image-Link-Editor to describe the
                            relationship between images and texts and links [Maynooth2010]</h2>
                        <img class="inline" src="http://dh2011abstracts.stanford.edu/xtf/data/tei//197/197-1.jpg" /><p><a href="javascript://" onclick="javascript:window.open('http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-197.xml&amp;doc.view=popup&amp;fig.ent=http://dh2011abstracts.stanford.edu/xtf/data/tei//197/197-1.jpg','popup','width=800,height=600,resizable=yes,scrollbars=yes')">Full Size Image </a></p>
                    </p></p>
            
            
                <h2>Structure and Components</h2>
                <p class="noindent">The Text-image-Link-Editor is a part of the TextGridLab and is implemented as a
                    group of Eclipse plugins following the [MVC] patternThe
                        Model-View-Controller (MVC) pattern separates the modeling of the domain,
                        the presentation, and the actions based on user input into three separate
                        classes.</p>
                <p class="noindent">This tool consists of a Toolkit and two views in addition to the XML Editor and
                    the generic Navigator:</p>
                <p class="noindent">
                        <li><b>Image View:</b> shows the images and enables you to
                            select individual image sections to be linked.</li>
                        <li><b>Thumb View:</b> is used for navigation. It displays a
                            reduced version of the entire image and the active image detail (which
                            is enlarged in the Image View) which can easily be moved and
                            zoomed.</li>
                        <li><b>Toolkit:</b> provides different functions for working
                            on the Image View.</li>
                        <li><b>XML Editor:</b> allows you to open or create texts as
                            well as to select individual text elements.</li>
                    </p>
                <p>
                    <h2>TBLE in action</h2>
                    <img class="inline" src="http://dh2011abstracts.stanford.edu/xtf/data/tei//197/197-2.jpg" /><p><a href="javascript://" onclick="javascript:window.open('http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-197.xml&amp;doc.view=popup&amp;fig.ent=http://dh2011abstracts.stanford.edu/xtf/data/tei//197/197-2.jpg','popup','width=800,height=600,resizable=yes,scrollbars=yes')">Full Size Image </a></p>
                </p>
            
            
                <h2>Further Enhancement</h2>
                <p class="noindent">TBLE is already actively used in a number of projects, but continues to be
                    enhanced, taking into account new user requirements coming up in the field. In
                    particular, we plan to implement a new feature in the Text-Image-Link-Editor to
                    enable an automated segmentation of facsimiles using the [OCRopus] OCR-system,
                    which offers a possibility to partially automate the linkage
                        process.OCRopus (tm) is a state-of-the-art document analysis and OCR
                        system, featuring pluggable layout analysis, pluggable character
                        recognition, statistical natural language modeling, and multi-lingual
                        capabilities. http://code.google.com/p/ocropus/ . Consulted
                        2011-03-14</p>
            
        <h2>References:</h2>
            
                
                    <p>
                        Cayless, Hugh
                        2008
                         “Experiments in Automated Linking of TEI Transcripts to
                            Manuscript Images, ” 
                        <i>TEI Members Meeting</i>, 
                        2008
                        
         (<a href="http://www.cch.kcl.ac.uk/cocoon/tei2008/programme/abstracts/abstract-166.html" target="blank">link</a>)
   
                    </p>
                    <p>
                        Kiernan, Kevin et al.
                        <i>Edition Production &amp; Presentation Technology
                            (EPPT)</i>, 
                        2011-03-12
                        
         (<a href="http://www.eppt.org/eppt/" target="blank">link</a>)
   
                    </p>
                    <p>
                        Holmes, Martin
                        <i>The UvC Image Markup Tool Project. Project homepage</i>, 
                        2010-10-31
                        
         (<a href="http://tapor.uvic.ca/~mholmes/image_markup/index.php" target="blank">link</a>)
   
                    </p>
                    <p>
                        Huitfeldt, Claus; Yves Marcoux and C. M. Sperberg-McQueen
                        2010
                         “Extension of the type/token distinction to document
                            structure, ” 
                        <i>Proceedings of Balisage: The Markup Conference 2010</i>, 
                        Balisage Series on Markup Technologies
                        5
                        doi:10.4242/BalisageVol5.Huitfeldt01.
                    </p>
                    <p>
                        [Kiernan2006]
                        Kiernan, Kevin
                        2006
                         “Electronic Textual Editing: Digital Facsimiles in
                            Editing, ” 
                        <i>Electronic Textual Editing</i>, 
                        Burnard, Lou; O'Brien O'Keeffe, Katherine and Unsworth, John
                            (Eds)
                        MLA
                        2011-03-14
                        
         (<a href="http://www.tei-c.org/About/Archive_new/ETE/Preview/kiernan.xml" target="blank">link</a>)
   
                    </p>
                    <p>
                        [Maynooth2010]
                        Maynooth - Michael Leuk, Dr. Simon Rettelbach
                        2010
                        <i>Cost Workshop</i>, 
                    </p>
                    <p>
                        [Parker2009]
                        Porter, Dorothy Carr; Reside, Duke andWalsh, John
                        2009
                         “Text-Image Linking Environment (TILE), ” 
                        <i>Digital Humanities, 2009</i>, 
                        2009
                        p. 388ff
                    </p>

                    <p>
                        [SVG]
                        <i>W3C, Scalable Vector Graphics (SVG)</i>, 
                        2011-03-14
                        
         (<a href="http://www.w3.org/Graphics/SVG/" target="blank">link</a>)
   
                    </p>
                    <p>
                        [TEI]
                        <i>The Text Encoding Initiative</i>, 
                        2011-03-14
                        
         (<a href="http://www.tei-c.org" target="blank">link</a>)
   
                    </p>
                    <p>
                        [TG]
                        <i>About TextGrid</i>, 
                        2011-03-14
                        
         (<a href="http://www.textgrid.de/en/ueber-textgrid.html" target="blank">link</a>)
   
                    </p>
                
            
        </div></div></body></html>