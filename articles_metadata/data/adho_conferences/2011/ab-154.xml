
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8; charset=UTF-8" /><title>CloudPad – A Cloud-based Documentation and Archiving Tool for Mixed Reality
                    Artworks</title><link rel="stylesheet" href="css/default/results.css" type="text/css" /><script src="script/yui/yahoo-dom-event.js" type="text/javascript"></script><script src="script/yui/connection-min.js" type="text/javascript"></script></head><body class="home blog"><div id="wrapper" class="hfeed"><div id="header"><div id="masthead"><div id="branding" role="banner"><h1 id="site-title"><span><a href="https://dh2011.stanford.edu/" title="Digital Humanities 2011: June 19 – 22" rel="home">Digital Humanities
                2011: June 19 – 22</a></span></h1><div id="site-description">Big Tent Digital Humanities</div><img src="https://www.stanford.edu/group/dh2011/cgi-bin/wordpress/wp-content/uploads/2010/09/tieDyeLarge.jpg" width="940" height="198" alt="" /></div><div id="access" role="navigation"><div class="menu"><ul><li><a href="https://dh2011.stanford.edu/" title="Home">Home</a></li><li><a href="https://dh2011.stanford.edu/?page_id=3" title="About">About</a></li><li><a href="https://dh2011.stanford.edu/?page_id=15" title="Accommodations &amp; Travel">Accommodations &amp; Travel</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=887" title="Accommodations">Accommodations</a></li><li><a href="https://dh2011.stanford.edu/?page_id=883" title="Travel">Travel</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=311" title="Registration">Registration</a></li><li><a href="https://dh2011.stanford.edu/?page_id=411" title="Schedule">Schedule</a></li><li><a href="https://dh2011.stanford.edu/?page_id=475" title="Workshops">Workshops</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=489" title="Tutorial 1: Introductory TEI ODD">Tutorial 1: Introductory TEI ODD</a></li><li><a href="https://dh2011.stanford.edu/?page_id=499" title="Tutorial 2 / Workshop: Integrating Digital Humanities Projects into the Undergraduate Curriculum">Tutorial 2 / Workshop: Integrating Digital Humanities Projects into the
                      Undergraduate Curriculum</a></li><li><a href="https://dh2011.stanford.edu/?page_id=507" title="Tutorial 3: An Introduction to XForms for Digital Humanists: How XForms Can Help Your Project">Tutorial 3: An Introduction to XForms for Digital Humanists: How XForms Can
                      Help Your Project</a></li><li><a href="https://dh2011.stanford.edu/?page_id=517" title="Tutorial 4: Introduction to Text Analysis With Voyeur Tools">Tutorial
                      4: Introduction to Text Analysis With Voyeur Tools</a></li><li><a href="https://dh2011.stanford.edu/?page_id=521" title="Tutorial 5: Gabmap: A Web Application for Analyzing Linguistic Variation">Tutorial 5: Gabmap: A Web Application for Analyzing Linguistic Variation</a></li><li><a href="https://dh2011.stanford.edu/?page_id=525" title="Tutorial 6: Natural Language Processing Tools for the Digital Humanities">Tutorial 6: Natural Language Processing Tools for the Digital Humanities</a></li><li><a href="https://dh2011.stanford.edu/?page_id=529" title="Tutorial 7: Network and Topical Analysis for the Humanities using NWB and Sci2">Tutorial 7: Network and Topical Analysis for the Humanities using NWB and
                      Sci2</a></li><li><a href="https://dh2011.stanford.edu/?page_id=493" title="Workshop: Visualization for Literary History">Workshop: Visualization
                      for Literary History</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=471" title="Social Program">Social
                  Program</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=541" title="Literary San Francisco (Full Day)">Literary San Francisco (Full
                      Day)</a></li><li><a href="https://dh2011.stanford.edu/?page_id=547" title="Silicon Valley History (Half-Day)">Silicon Valley History
                      (Half-Day)</a></li><li><a href="https://dh2011.stanford.edu/?page_id=537" title="Sonoma Wine Country (Full-Day)">Sonoma Wine Country (Full-Day)</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=181" title="CFPs">CFPs</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=97" title="General CFP">General
                      CFP</a></li><li><a href="https://dh2011.stanford.edu/?page_id=175" title="CFP en Español">CFP en
                      Español</a></li><li><a href="https://dh2011.stanford.edu/?page_id=287" title="CFP in German">CFP in
                      German</a></li><li><a href="https://dh2011.stanford.edu/?page_id=207" title="CFP in Greek">CFP in
                      Greek</a></li><li><a href="https://dh2011.stanford.edu/?page_id=229" title="CFP in Hungarian">CFP
                      in Hungarian</a></li><li><a href="https://dh2011.stanford.edu/?page_id=257" title="CFP in Italiano">CFP
                      in Italiano</a></li><li><a href="https://dh2011.stanford.edu/?page_id=157" title="Tutorial/Workshop CFP">Tutorial/Workshop CFP</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=19" title="Contacts">Contacts</a></li><li><a href="https://dh2011.stanford.edu/?page_id=801" title="Venue">Venue</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=829" title="Local Lunch Spots">Local Lunch Spots</a></li><li><a href="https://dh2011.stanford.edu/?page_id=845" title="Palo Alto Restaurants">Palo Alto Restaurants</a></li></ul></li></ul></div></div><br class="clear" /></div></div><div class="resultsHeader"><table><tr><td><a href="http://dh2011abstracts.stanford.edu/xtf/search" target="_top">New Search</a> | <span class="notActive">Return to Search Results</span> | <a href="http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-154.xml&amp;doc.view=print;chunk.id=0" target="_top">Print View</a></td><td align="right"><form action="http://dh2011abstracts.stanford.edu/xtf/view" target="_top" method="get"><input name="query" type="text" size="15" /><input type="hidden" name="docId" value="tei/ab-154.xml" /><input type="hidden" name="chunk.id" value="0" /><input type="submit" value="Search this Book" /></form></td></tr></table></div><hr /><div class="results"><h2>Paper: CloudPad – A Cloud-based Documentation and Archiving Tool for Mixed Reality
                    Artworks</h2><h4>
                    Giannachi, Gabriella, 
                    Centre for Intermedia, University of Exeter, 
                    <a href="mailto:g.giannachi@exeter.ac.uk">g.giannachi@exeter.ac.uk</a>
                </h4><h4>
                    Lowood, Henry, 
                    Stanford Libraries, Stanford University, 
                    <a href="mailto:lowood@stanford.edu">lowood@stanford.edu</a>
                </h4><h4>
                    Rowland, Duncan, 
                    Mixed Reality Lab, University of Nottingham, 
                    <a href="mailto:dar@cs.nott.ac.uk">dar@cs.nott.ac.uk</a>
                </h4><h4>
                    Benford, Steve, 
                    Mixed Reality Lab, University of Nottingham, 
                    <a href="mailto:sdb@cs.nott.ac.uk">sdb@cs.nott.ac.uk</a>
                </h4><h4>
                    Price, Dominic, 
                    Mixed Reality Lab, University of Nottingham, 
                    <a href="mailto:djp@cs.nott.ac.uk">djp@cs.nott.ac.uk</a>
                </h4><hr />
            

                <p class="noindent">This paper reflects on the process of designing and building a documentation and
                    archiving tool named CloudPad on the basis of its first evaluation at Stanford
                    Libraries and the San Francisco Art Institute in September 2010. The paper
                    explores the value of CloudPad and its ability to document individual users’
                    replay of an artwork within the context of performance documentation and new
                    media archiving, speculating on its possible use within a number of curatorial,
                    educational and creative contexts that are relevant to digital humanities.</p>
                <p class="noindent">The CloudPad was developed in 2010 by a team in Horizon RCUK-funded digital
                    economy research and involved staff in performance studies and computer science
                    from the Universities of Exeter and Nottingham, with partners from Stanford
                    Libraries, the Ludwig Boltzman Institute Media.Art.Research, The San Francisco
                    Art Institute, British Library, Blast Theory, and the University of Sheffield.
                    The work developed out of the team’s intention to research novel theoretical and
                    practical approaches for the documentation and archiving of mixed reality
                    performances and artworks that span both digital and physical entities (Benford
                    and Giannachi 2011), allowing users to engage with the materials creatively over
                    time and from different locations. The project benefitted from previous research
                    conducted by members of the team through the AHRC-funded Presence project
                    (2004-9), which used second life and a wiki to document practices spanning from
                    performance art, to video art and new media, including work in virtual reality
                    CAVE, and the EPSRC-funded Creator project (2008-9) which used an e-science
                    tool, the digital replay system, to generate synchronised annotations about a
                    mixed reality performance (DRS). The project also benefitted from the findings
                    of the e-dance project (2007- 9), which was jointly funded by AHRC, JISC and
                    EPSRC, and conducted by colleagues from the Universities of Bedfordshire, Leeds,
                    Manchester and Open University. This adopted access grid technologies for
                    developing new approaches to choreographic composition, involving the use of the
                    Memetic toolkit for recording, replaying and annotating sessions in access grid.
                    Finally, the project was developed in dialogue with artworks such as Lynn
                    Hershman Leeson’s RAW/WAR feminist film archives (2010), sosolimited’s
                    interactive archival performances, and current thinking in new media
                    documentation (e.g. Costello 2005, Depocas et al 2003, Jones and Muller 2008 and
                    Dekker 2011, among others).</p>
                <p class="noindent">Technically the CloudPad was designed as a customisable web-based platform aiming
                    to facilitate the synchronised playback and mash-up of cloud-based media
                    entities such as video or audio files, as well as webpages and photographic
                    materials, together with layers of user annotations. It took a novel approach to
                    the archiving and replay of pervasive media experiences by making use of Web 2.0
                    technologies (DiNucci 1999) rather than grid technologies. CloudPad users were
                    empowered to view the repository as a living document in which they could leave
                    their own impression of an experience (both of the original event recordings as
                    well as any thematic connections or annotations provided by other visitors and
                    subject experts). Previous interactive systems designed for the replay of events
                    for analysis lack this level of emergent reflection (see Brundell 2008),
                    treating the corpus of recorded material as essentially immutable. To enable
                    this, the CloudPad made use of internet-based storage, which means that media
                    from a wide variety of different sources could be included in a presentation
                    (for example YouTube videos can be included and synchronised with images from
                    Flickr). This was accomplished by the use of HTML5 (see w3.org), an emerging web
                    standard that enables collaborative interactive applications to be developed
                    which run inside a web browser (Murray 2005).</p>
                <p class="noindent">As an initial form of content to assess the operation of the CloudPad we utilised
                    a ‘bespoke’ documentation of Blast Theory’s Rider Spoke that was recorded by our
                    team when the work occurred at the ars electronica festival in Linz in 2009.
                    Rider Spoke is a location-based game for cyclists developed by Blast Theory in
                    collaboration with Mixed Reality Laboratory at the University of Nottingham as
                    part of the European research project IPerG. The work encouraged participants to
                    cycle around a city in order to record personal memories and make statements
                    about their past, present and future that were associated with particular
                    locations (see figure 1). 
                    <p>
                        <h2>Blast Theory, Rider Spoke. Participant listening to recordings.
                            Copyright Blast Theory.</h2>
                        <img class="inline" src="http://dh2011abstracts.stanford.edu/xtf/data/tei//154/154-1.jpg" /><p><a href="javascript://" onclick="javascript:window.open('http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-154.xml&amp;doc.view=popup&amp;fig.ent=http://dh2011abstracts.stanford.edu/xtf/data/tei//154/154-1.jpg','popup','width=800,height=600,resizable=yes,scrollbars=yes')">Full Size Image </a></p>
                    </p>
                    To collect a documentation that addressed the
                    complexity of this work, we developed a hybrid approach. This included the
                    collection of documentations pertaining to the artists and technologists’
                    descriptions of the works (in terms of original aims, interim analyses and final
                    evaluations), as well as documentations of the user experience (see Jones and
                    Muller 2008 and Depocas et al 2003), the latter recorded from a variety of
                    points of view (e.g. first person, third person) and through a number of
                    technologies (e.g., video, GPS, Wi-Fi) and perspectives (see figures 2, 3 and
                    4). 
                    <p>
                        <h2>Linz documentation. Participant captured via first person point of
                            view.</h2>
                        <img class="inline" src="http://dh2011abstracts.stanford.edu/xtf/data/tei//154/154-2.jpg" /><p><a href="javascript://" onclick="javascript:window.open('http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-154.xml&amp;doc.view=popup&amp;fig.ent=http://dh2011abstracts.stanford.edu/xtf/data/tei//154/154-2.jpg','popup','width=800,height=600,resizable=yes,scrollbars=yes')">Full Size Image </a></p>
                    </p>
                    
                    <p>
                        <h2>Linz documentation. Participant captured via third person point of
                            view.</h2>
                        <img class="inline" src="http://dh2011abstracts.stanford.edu/xtf/data/tei//154/154-3.jpg" /><p><a href="javascript://" onclick="javascript:window.open('http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-154.xml&amp;doc.view=popup&amp;fig.ent=http://dh2011abstracts.stanford.edu/xtf/data/tei//154/154-3.jpg','popup','width=800,height=600,resizable=yes,scrollbars=yes')">Full Size Image </a></p>
                    </p>
                    
                    <p>
                        <h2>Linz documentation. Participants journey through the city captured on
                            googlemaps.</h2>
                        <img class="inline" src="http://dh2011abstracts.stanford.edu/xtf/data/tei//154-4.jpg" /><p><a href="javascript://" onclick="javascript:window.open('http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-154.xml&amp;doc.view=popup&amp;fig.ent=http://dh2011abstracts.stanford.edu/xtf/data/tei//154-4.jpg','popup','width=800,height=600,resizable=yes,scrollbars=yes')">Full Size Image </a></p>
                    </p>
                    
                    The overall analytical approach was interdisciplinary, thus including
                    different and potentially even contrasting accounts of the event (see
                    Chamberlain et al 2010). These accounts were presented through a number of
                    historic, canonic and participant ‘trajectories’ (see figure 5). 
                    
                    <p>
                        <h2>Matt Adams’ annotation about a participant linking first and third person
                            perspectives in a canonic trajectory.</h2>
                        <img class="inline" src="http://dh2011abstracts.stanford.edu/xtf/data/tei//154/154-5.jpg" /><p><a href="javascript://" onclick="javascript:window.open('http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-154.xml&amp;doc.view=popup&amp;fig.ent=http://dh2011abstracts.stanford.edu/xtf/data/tei//154/154-5.jpg','popup','width=800,height=600,resizable=yes,scrollbars=yes')">Full Size Image </a></p>
                    </p>
                    
                    By historic
                    trajectories we defined a historic event, i.e. a participant’s experience as
                    documented in a video; by canonic trajectories we defined an expert user’s set
                    of annotations through these materials; and by participant trajectories we
                    defined the CloudPad user’s own annotations (Giannachi et al 2010). This
                    architecture does not privilege a single viewpoint and encourages creative use
                    of both the historic materials and their canonic annotations. Arguably, every
                    replay, producing participant trajectories, re-constitutes the work.</p>
                <p class="noindent">The CloudPad evaluation showed that users did not only envisage adopting the
                    CloudPad for purposes of documentation and archiving, but also wanted to use it
                    curatorially, to present work to others and engage users in annotating
                    materials, for example in an online exhibition, academically, to write ‘visual
                    essays’, and creatively, to make artwork. We have seen that the CloudPad offers
                    scholars, artists and students the possibility to document, archive, curate and
                    create synchronised variable media mash-ups from existing digital resources.
                    These mash-ups, which show how users have engaged with the original
                    documentation stored on CloudPad, build an invaluable resource for those who may
                    be interested in how a core documentation or archive is navigated and
                    interpreted over time. In other words, the CloudPad is not only a documentation
                    and archiving tool, it also documents and archives itself, generating contextual
                    footprints or traces and possibly even re-enactments of every replay of the
                    original materials. This paper reflects on the advances generated by this
                    particular functionality in terms of performance documentation, preservation,
                    and re-enactment.</p>
            
            
                <h2>Acknowledgements</h2>
                <p class="noindent">We gracefully acknowledge the RCUK funded Horizon digital economy research and
                    the AHRC funded Riders Have Spoken project. We would like to thank Blast Theory
                    and staff at the Ludwig Boltzman Institute Media.Art.Research, Katja Kwastek,
                    Dieter Daniels and Ingrid Spoerl in particular, who facilitated the
                    documentation of <i>Rider Spoke</i> in Linz, and our
                    participants and volunteers who gave their time to make this documentation
                    possible. We would also like to thank the staff and students at the San
                    Francisco Art Institute, Stanford Libraries and St Jose State University for
                    providing crucial feedback that informed the writing of this paper.</p>

            
        <h2>References:</h2>
            
                
                    <p>
                        Benford, S. and Giannachi, G.
                        2011
                        <i>Performing Mixed Reality</i>, 
                        the MIT Press
                        Cambridge, Mass.
                    </p>
                    <p>
                        Brundell, P., Tennent, P., Greenhalgh, C., Knight, D., Crabtree, A.,
                            O’Malley, C., Ainsworth, S., Clarke, D., Carter, R. and Adolphs,
                            S.
                        2008
                         “Digital Replay System (DRS) - a tool for interaction
                            analysis, ” 
                        <i>Proceedings of the 2008 International
                            Conference on Learning Sciences</i>, 
                        Utrecht: ICSL, 
                        June 23-24, 2008
                    </p>
                    <p>
                        Chamberlain, A., Rowland, D., Foster, J., Giannachi, G.
                        2010
                         “Riders Have Spoken: Replaying and Archiving Pervasive
                            Performances, ” 
                        <i>Leonardo Transactions</i>, 
                        43.1
                        90-1
                    </p>
                    <p>
                        Costello, B., Muller, L., Amitani, S., and Edmonds, E.
                        2005
                         “Understanding the Experience of Interactive Art: Iamascope
                            in beta_space, ” 
                        <i>ACM 2005</i>, 
                        vol. 123
                        49-56
                    </p>
                    <p>
                        Dekker, Cosetta Saba, Julia Noordegraaf, Barbara Le Maître and
                            Vinzenz Hediger (eds.)
                        forthcoming 2011
                        <i>Preserving and Exhibiting Media Art: Challenges and
                            Perspectives</i>, 
                        University Press
                        Amsterdam
                    </p>
                    <p>
                        Depocas, A., Ippolito, J., Jones, C.
                        2003
                        <i>Permanence through Change: The Variable Media
                            Approach</i>, 
                        Guggenheim Museum Publications
                        New York
                    </p>
                    <p>
                        DiNucci, D.
                        1999
                        <i>History Fragmented Future Recovered</i>, 
                        October 2010
                        
         (<a href="http://www.cole20.com/web-20-history-fragmented-future-recovered/" target="blank">link</a>)
   
                    </p>
                    <p>
                        Giannachi, G., Rowland, D., Benford, S., Price, D.
                        2010
                         “The Documentation and Archiving of Mixed Media Experiences:
                            the Case of Rider Spoke, ” 
                        <i>Digital Futures</i>, 
                        Nottingham, 
                        11-12 October 2010
                    </p>
                    <p>
                        <i>Horizon</i>, 
                        October 2010
                        
         (<a href="https://www.horizon.ac.uk/" target="blank">link</a>)
   
                    </p>
                    <p>
                        <i>IPerG</i>, 
                        October 2010
                        
         (<a href="http://iperg.sics.se/index.php" target="blank">link</a>)
   
                    </p>
                    <p>
                        Jones, J. and Muller, L.
                        2008
                         “Between Real and Ideal: Documenting Media Art, ” 
                        <i>Leonardo</i>, 
                        41.4
                        418-41
                    </p>
                    <p>
                        Murray, G.
                        2005
                        <i>Asynchronous JavaScript Technology and XML (Ajax) With the
                            Java Platform</i>, 
                        October 2010
                        
         (<a href="http://www.oracle.com/technetwork/articles/javaee/ajax-135201.html" target="blank">link</a>)
   
                    </p>

                
            
        </div></div></body></html>