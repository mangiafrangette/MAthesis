
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8; charset=UTF-8" /><title>Interactive Layout Analysis, Content Extraction and Transcription of
                    Historical Printed Books using Agora and Retro</title><link rel="stylesheet" href="css/default/results.css" type="text/css" /><script src="script/yui/yahoo-dom-event.js" type="text/javascript"></script><script src="script/yui/connection-min.js" type="text/javascript"></script></head><body class="home blog"><div id="wrapper" class="hfeed"><div id="header"><div id="masthead"><div id="branding" role="banner"><h1 id="site-title"><span><a href="https://dh2011.stanford.edu/" title="Digital Humanities 2011: June 19 – 22" rel="home">Digital Humanities
                2011: June 19 – 22</a></span></h1><div id="site-description">Big Tent Digital Humanities</div><img src="https://www.stanford.edu/group/dh2011/cgi-bin/wordpress/wp-content/uploads/2010/09/tieDyeLarge.jpg" width="940" height="198" alt="" /></div><div id="access" role="navigation"><div class="menu"><ul><li><a href="https://dh2011.stanford.edu/" title="Home">Home</a></li><li><a href="https://dh2011.stanford.edu/?page_id=3" title="About">About</a></li><li><a href="https://dh2011.stanford.edu/?page_id=15" title="Accommodations &amp; Travel">Accommodations &amp; Travel</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=887" title="Accommodations">Accommodations</a></li><li><a href="https://dh2011.stanford.edu/?page_id=883" title="Travel">Travel</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=311" title="Registration">Registration</a></li><li><a href="https://dh2011.stanford.edu/?page_id=411" title="Schedule">Schedule</a></li><li><a href="https://dh2011.stanford.edu/?page_id=475" title="Workshops">Workshops</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=489" title="Tutorial 1: Introductory TEI ODD">Tutorial 1: Introductory TEI ODD</a></li><li><a href="https://dh2011.stanford.edu/?page_id=499" title="Tutorial 2 / Workshop: Integrating Digital Humanities Projects into the Undergraduate Curriculum">Tutorial 2 / Workshop: Integrating Digital Humanities Projects into the
                      Undergraduate Curriculum</a></li><li><a href="https://dh2011.stanford.edu/?page_id=507" title="Tutorial 3: An Introduction to XForms for Digital Humanists: How XForms Can Help Your Project">Tutorial 3: An Introduction to XForms for Digital Humanists: How XForms Can
                      Help Your Project</a></li><li><a href="https://dh2011.stanford.edu/?page_id=517" title="Tutorial 4: Introduction to Text Analysis With Voyeur Tools">Tutorial
                      4: Introduction to Text Analysis With Voyeur Tools</a></li><li><a href="https://dh2011.stanford.edu/?page_id=521" title="Tutorial 5: Gabmap: A Web Application for Analyzing Linguistic Variation">Tutorial 5: Gabmap: A Web Application for Analyzing Linguistic Variation</a></li><li><a href="https://dh2011.stanford.edu/?page_id=525" title="Tutorial 6: Natural Language Processing Tools for the Digital Humanities">Tutorial 6: Natural Language Processing Tools for the Digital Humanities</a></li><li><a href="https://dh2011.stanford.edu/?page_id=529" title="Tutorial 7: Network and Topical Analysis for the Humanities using NWB and Sci2">Tutorial 7: Network and Topical Analysis for the Humanities using NWB and
                      Sci2</a></li><li><a href="https://dh2011.stanford.edu/?page_id=493" title="Workshop: Visualization for Literary History">Workshop: Visualization
                      for Literary History</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=471" title="Social Program">Social
                  Program</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=541" title="Literary San Francisco (Full Day)">Literary San Francisco (Full
                      Day)</a></li><li><a href="https://dh2011.stanford.edu/?page_id=547" title="Silicon Valley History (Half-Day)">Silicon Valley History
                      (Half-Day)</a></li><li><a href="https://dh2011.stanford.edu/?page_id=537" title="Sonoma Wine Country (Full-Day)">Sonoma Wine Country (Full-Day)</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=181" title="CFPs">CFPs</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=97" title="General CFP">General
                      CFP</a></li><li><a href="https://dh2011.stanford.edu/?page_id=175" title="CFP en Español">CFP en
                      Español</a></li><li><a href="https://dh2011.stanford.edu/?page_id=287" title="CFP in German">CFP in
                      German</a></li><li><a href="https://dh2011.stanford.edu/?page_id=207" title="CFP in Greek">CFP in
                      Greek</a></li><li><a href="https://dh2011.stanford.edu/?page_id=229" title="CFP in Hungarian">CFP
                      in Hungarian</a></li><li><a href="https://dh2011.stanford.edu/?page_id=257" title="CFP in Italiano">CFP
                      in Italiano</a></li><li><a href="https://dh2011.stanford.edu/?page_id=157" title="Tutorial/Workshop CFP">Tutorial/Workshop CFP</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=19" title="Contacts">Contacts</a></li><li><a href="https://dh2011.stanford.edu/?page_id=801" title="Venue">Venue</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=829" title="Local Lunch Spots">Local Lunch Spots</a></li><li><a href="https://dh2011.stanford.edu/?page_id=845" title="Palo Alto Restaurants">Palo Alto Restaurants</a></li></ul></li></ul></div></div><br class="clear" /></div></div><div class="resultsHeader"><table><tr><td><a href="http://dh2011abstracts.stanford.edu/xtf/search" target="_top">New Search</a> | <span class="notActive">Return to Search Results</span> | <a href="http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-184.xml&amp;doc.view=print;chunk.id=0" target="_top">Print View</a></td><td align="right"><form action="http://dh2011abstracts.stanford.edu/xtf/view" target="_top" method="get"><input name="query" type="text" size="15" /><input type="hidden" name="docId" value="tei/ab-184.xml" /><input type="hidden" name="chunk.id" value="0" /><input type="submit" value="Search this Book" /></form></td></tr></table></div><hr /><div class="results"><h2>Poster: Interactive Layout Analysis, Content Extraction and Transcription of
                    Historical Printed Books using Agora and Retro</h2><h4>
                    Ramel, Jean-Yves, 
                    Lab d'Informatique, Ecole Polytechnique de l’Université de
                        Tours, 
                    <a href="mailto:ramel@univ-tours.fr">ramel@univ-tours.fr</a>
                </h4><h4>
                    Sidère, Nicholas, 
                    Lab. d'Informatique, Ecole Polytechnique de l’Université de
                        Tours, 
                    <a href="mailto:nicolas.sidere@univ-tours.fr">nicolas.sidere@univ-tours.fr</a>
                </h4><hr />
            
                <p class="noindent">High level analyses of document images are mainly based on the output of a page
                    segmentation process. For example, the extracted text regions can be the input
                    to an OCR system to retrieve the ASCII characters printed on the pages. The
                    spatial relationships between segmented blocks along with other features can be
                    used in logical page organization analysis to group the extracted components
                    appropriately and recover the correct reading order. Many techniques for page
                    segmentation have been proposed in the literature but most of them are based on
                    the assumption that an input document image consists of a set of rectangular
                    blocks. Furthermore, the classification step is generally domain specific and
                    uses static rules to automatically determine, for each block, the coherent label
                    selected from a predefined list (title, paragraph, graphic, table,...). These
                    limitations appear too restrictive with respect to some noisy and distorted
                    documents and new approaches need to be developed. </p>
                <p class="noindent">In this context, we present a work achieved in collaboration with the “Centre
                    d’Etude Superieur de la Renaissance” of Tours (CESR /
                    http://www.cesr.univ-tours.fr). The CESR is a training and research centre which
                    receives students and researchers who wish to work on various domains of the
                    Renaissance using a rich library of historical books. The CESR wants to create a
                    Humanistic Virtual Library; however, until now, only bitmap versions of several
                    books that have been scanned or photographed are accessible. The initial
                    objective of the CESR was to obtain an ASCII version of the text contained in
                    the pages of these historical books. The centre first tried to use the
                    commercial OCR software to index their books but they quickly realized that,
                    applied to historical documents, this procedure would had been vowed to failure.
                    So, the CESR asked our Pattern Recognition and Image Analysis research team to
                    help them to define a new system adapted to their needs. They have appreciated
                    our efforts as our collaboration will lead to a system able to bring a better
                    description and indexation of the content of their books and would also make the
                    search and the reading of these precious historical books easier. </p>
                <p class="noindent">The poster will first describe the new hybrid method we have developed for the
                    extraction of layout information and of specific elements like graphical parts
                    or ornaments based on the construction of two representations of the contents of
                    the images. A mapping of the shapes and a mapping of the background are
                    computed. By exploiting this information, our algorithm produces and sends back
                    a list of blocks constituting a first segmentation result. Then, this initial
                    representation of the image is used during a more sophisticated analysis. Having
                    an aim of genericity, the architecture of the system that we carried out
                    authorizes an interactive installation of scenarios for analysis of the image
                    contents. Scenarios work on the initial representation provided by the first
                    step of the segmentation. According to its needs (localization of the ornamental
                    letters, the notes at margins, titles,…) and using user-friendly interfaces, the
                    user (not expert in image processing) builds scenarios allowing to label, to
                    merge, to remove the blocks contained in the intermediate representation. One
                    can thus locates the desired entities without taking care of the other areas of
                    the image. The elaborated scenarios can then be stored, modified and applied to
                    various sets of images during batch processing. The results obtained with this
                    method are very interesting; the adjustment of the necessary parameters is
                    straightfoward and not sensitive to variations. The originality of our approach
                    lies in the opportunity which we offer to the users to be able to build, in an
                    interactive way, scenarios of incremental analysis. We propose to call this new
                    method “user-driven analysis” in opposition to data-driven or model-driven
                    methods. The goal is, on the basis of the initial segmentation, to be able to
                    make the representation of the images evolve in a progressive way to lead to the
                    finest possible characterization of its contents according to the user
                    objectives and to the type of images to be analyzed. The CESR has processed
                    several complete books using AGORA prototype and their own scenarios of block
                    classification. Thus, the CESR has increased the number of books offered to the
                    users in its Virtual Library (see http://www.bvh.univ-tours.fr). Even if the
                    system produced some errors, the processing and time saved as compared to manual
                    processing is considerable (for exemple, the manual indexation of the page
                    layout of an historical book of 300 pages last approximately two days instead of
                    only two hours when using Agora), this providing to the specialists of
                    historical books, a useful tool which they had never imagine (see Figure 1).</p>
                <p class="noindent">Concerning text transcription, the originality of our work relies upon the
                    analysis and exploitation of pattern redundancy in documents to allow efficient
                    and quick transcription of books as well as identification of typographic
                    materials. This pattern redundancy is mainly obtained via clustering methods.
                    Like this, the traditional OCR problem could be reformulated into a text
                    transcription one. A text, be it ancient or not, is made up of sequences of
                    symbols. The scanning process produces pictures where symbols are represented as
                    thumbnails of patterns (a pattern could be a single character, a part of a
                    character or a set of joined characters), which may be more or less distinct.
                    Without prior knowledge about the meaning of these symbols, the application of a
                    clustering approach assigns thumbnails of a similar shape to the same cluster.
                    As an example, one cluster containing thumbnails of the lowercase letter “a,”
                    another one the uppercase letter “A,” yet another one the letter “b” in a
                    specific font, and so on. Once the clustering is done, a user could assign a
                    label to each cluster using a other Graphics User Interface (software called
                    RETRO). These labels are then automatically assigned to each pattern, thus
                    achieving the text transcription of the whole book. In this way, if 90% of
                    patterns are detected as redundant, only one character in ten will be labeled by
                    the user in order to transcribe the book. This part of the work is still in
                    progress and is corresponding to a Google Digital Award obtained by our team in
                    December 2010.</p>
            
            
                <p>
                    <h2>Figure 1 : A view of the proposed processing framework with Agora and
                        Retro</h2>
                    <img class="inline" src="http://dh2011abstracts.stanford.edu/xtf/data/tei//184/figure1.png" /><p><a href="javascript://" onclick="javascript:window.open('http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-184.xml&amp;doc.view=popup&amp;fig.ent=http://dh2011abstracts.stanford.edu/xtf/data/tei//184/figure1.png','popup','width=800,height=600,resizable=yes,scrollbars=yes')">Full Size Image </a></p>
                </p>
            


        </div></div></body></html>