
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8; charset=UTF-8" /><title>CLAROS—Collaborating on Delivering the Future of the Past</title><link rel="stylesheet" href="css/default/results.css" type="text/css" /><script src="script/yui/yahoo-dom-event.js" type="text/javascript"></script><script src="script/yui/connection-min.js" type="text/javascript"></script></head><body class="home blog"><div id="wrapper" class="hfeed"><div id="header"><div id="masthead"><div id="branding" role="banner"><h1 id="site-title"><span><a href="https://dh2011.stanford.edu/" title="Digital Humanities 2011: June 19 – 22" rel="home">Digital Humanities
                2011: June 19 – 22</a></span></h1><div id="site-description">Big Tent Digital Humanities</div><img src="https://www.stanford.edu/group/dh2011/cgi-bin/wordpress/wp-content/uploads/2010/09/tieDyeLarge.jpg" width="940" height="198" alt="" /></div><div id="access" role="navigation"><div class="menu"><ul><li><a href="https://dh2011.stanford.edu/" title="Home">Home</a></li><li><a href="https://dh2011.stanford.edu/?page_id=3" title="About">About</a></li><li><a href="https://dh2011.stanford.edu/?page_id=15" title="Accommodations &amp; Travel">Accommodations &amp; Travel</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=887" title="Accommodations">Accommodations</a></li><li><a href="https://dh2011.stanford.edu/?page_id=883" title="Travel">Travel</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=311" title="Registration">Registration</a></li><li><a href="https://dh2011.stanford.edu/?page_id=411" title="Schedule">Schedule</a></li><li><a href="https://dh2011.stanford.edu/?page_id=475" title="Workshops">Workshops</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=489" title="Tutorial 1: Introductory TEI ODD">Tutorial 1: Introductory TEI ODD</a></li><li><a href="https://dh2011.stanford.edu/?page_id=499" title="Tutorial 2 / Workshop: Integrating Digital Humanities Projects into the Undergraduate Curriculum">Tutorial 2 / Workshop: Integrating Digital Humanities Projects into the
                      Undergraduate Curriculum</a></li><li><a href="https://dh2011.stanford.edu/?page_id=507" title="Tutorial 3: An Introduction to XForms for Digital Humanists: How XForms Can Help Your Project">Tutorial 3: An Introduction to XForms for Digital Humanists: How XForms Can
                      Help Your Project</a></li><li><a href="https://dh2011.stanford.edu/?page_id=517" title="Tutorial 4: Introduction to Text Analysis With Voyeur Tools">Tutorial
                      4: Introduction to Text Analysis With Voyeur Tools</a></li><li><a href="https://dh2011.stanford.edu/?page_id=521" title="Tutorial 5: Gabmap: A Web Application for Analyzing Linguistic Variation">Tutorial 5: Gabmap: A Web Application for Analyzing Linguistic Variation</a></li><li><a href="https://dh2011.stanford.edu/?page_id=525" title="Tutorial 6: Natural Language Processing Tools for the Digital Humanities">Tutorial 6: Natural Language Processing Tools for the Digital Humanities</a></li><li><a href="https://dh2011.stanford.edu/?page_id=529" title="Tutorial 7: Network and Topical Analysis for the Humanities using NWB and Sci2">Tutorial 7: Network and Topical Analysis for the Humanities using NWB and
                      Sci2</a></li><li><a href="https://dh2011.stanford.edu/?page_id=493" title="Workshop: Visualization for Literary History">Workshop: Visualization
                      for Literary History</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=471" title="Social Program">Social
                  Program</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=541" title="Literary San Francisco (Full Day)">Literary San Francisco (Full
                      Day)</a></li><li><a href="https://dh2011.stanford.edu/?page_id=547" title="Silicon Valley History (Half-Day)">Silicon Valley History
                      (Half-Day)</a></li><li><a href="https://dh2011.stanford.edu/?page_id=537" title="Sonoma Wine Country (Full-Day)">Sonoma Wine Country (Full-Day)</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=181" title="CFPs">CFPs</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=97" title="General CFP">General
                      CFP</a></li><li><a href="https://dh2011.stanford.edu/?page_id=175" title="CFP en Español">CFP en
                      Español</a></li><li><a href="https://dh2011.stanford.edu/?page_id=287" title="CFP in German">CFP in
                      German</a></li><li><a href="https://dh2011.stanford.edu/?page_id=207" title="CFP in Greek">CFP in
                      Greek</a></li><li><a href="https://dh2011.stanford.edu/?page_id=229" title="CFP in Hungarian">CFP
                      in Hungarian</a></li><li><a href="https://dh2011.stanford.edu/?page_id=257" title="CFP in Italiano">CFP
                      in Italiano</a></li><li><a href="https://dh2011.stanford.edu/?page_id=157" title="Tutorial/Workshop CFP">Tutorial/Workshop CFP</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=19" title="Contacts">Contacts</a></li><li><a href="https://dh2011.stanford.edu/?page_id=801" title="Venue">Venue</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=829" title="Local Lunch Spots">Local Lunch Spots</a></li><li><a href="https://dh2011.stanford.edu/?page_id=845" title="Palo Alto Restaurants">Palo Alto Restaurants</a></li></ul></li></ul></div></div><br class="clear" /></div></div><div class="resultsHeader"><table><tr><td><a href="http://dh2011abstracts.stanford.edu/xtf/search" target="_top">New Search</a> | <span class="notActive">Return to Search Results</span> | <a href="http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-224.xml&amp;doc.view=print;chunk.id=0" target="_top">Print View</a></td><td align="right"><form action="http://dh2011abstracts.stanford.edu/xtf/view" target="_top" method="get"><input name="query" type="text" size="15" /><input type="hidden" name="docId" value="tei/ab-224.xml" /><input type="hidden" name="chunk.id" value="0" /><input type="submit" value="Search this Book" /></form></td></tr></table></div><hr /><div class="results"><h2>Poster: CLAROS—Collaborating on Delivering the Future of the Past</h2><h4>
                    Rahtz, Sebastian, 
                    University of Oxford Computing Services, 
                    <a href="mailto:sebastian.rahtz@oucs.ox.ac.uk">sebastian.rahtz@oucs.ox.ac.uk</a>
                </h4><h4>
                    Dutton, Alexander, 
                    University of Oxford Computing Services, 
                    <a href="mailto:alexander.dutton@oucs.ox.ac.uk">alexander.dutton@oucs.ox.ac.uk</a>
                </h4><h4>
                    Kurtz, Donna, 
                    Beazley Archive, University of Oxford, 
                    <a href="mailto:donna.kurtz@beazley.ox.ac.uk">donna.kurtz@beazley.ox.ac.uk</a>
                </h4><h4>
                    Klyne, Graham, 
                    Department of Zoology, University of Oxford, 
                    <a href="mailto:graham.klyne@zoology.ox.ac.uk">graham.klyne@zoology.ox.ac.uk</a>
                </h4><h4>
                    Zisserman, Andrew, 
                    Department of Engineering Science, University of
                        Oxford, 
                    <a href="mailto:andrew.zisserman@eng.ox.ac.uk">andrew.zisserman@eng.ox.ac.uk</a>
                </h4><h4>
                    Arandjelović, Relja, 
                    Department of Engineering Science, University of
                        Oxford, 
                    <a href="mailto:relja.arandjelovic@chch.ox.ac.uk">relja.arandjelovic@chch.ox.ac.uk</a>
                </h4><hr />
            <p class="noindent">CLAROS (Classical Art Research Online Services) is a technology and data
                collaboration between classical art and archaeology research projects, museums and
                semantic web researchers. Documenting objects from the museums of the world, CLAROS
                aims to engage with the public across the widest possible spectrum. It builds on the
                success of the Beazley Archive which has provided programmes for the public as well
                as the scholar and an illustrated linked dictionary for more than fifteen years.
                CLAROS (<a href="http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-224.xml&amp;chunk.id=&amp;toc.id=&amp;toc.depth=1&amp;brand=default&amp;anchor.id=http://www.clarosnet.org/#X" target="_top">http://www.clarosnet.org/</a>) is
                based at the University of Oxford, with partners in the UK, France, Germany,
                Switzerland and Greece. The portfolio includes an aggregating RDF database, web
                discovery interfaces for different types of audience, visual search using image
                analysis of shapes and images, semantic information extraction from digitized text,
                place and name gazetteers, and investigation of avatars for resource discovery.
                CLAROS aims to be an effective and powerful partner in the realm of semantic web and
                linked data about the past. </p>

            
                <h2>Data Modelling</h2>
                <p class="noindent">The CLAROS aggregating data cache pulls information from its partners, limiting
                    itself to those interchange components which can be mapped to the CIDOC
                    Conceptual Reference Model (CRM) ontology, with a few extensions relating to dates
                    and geolocations. The majority of records so far use CRM concepts <i>E22_Man-Made_Object</i>, <i>E53_Place</i>,
                        <i>E52_Time-Span</i> and <i>E21_Person</i>.
                    The data contributions, using XML RDF as the ingest form, include the Beazley
                    Archive (pottery and gems)
                    and the Lexicon of Greek Personal Names (onomastic
                        data)http://www.lgpn.ox.ac.uk/ at the University of Oxford, the
                        <i>Arachne</i> Sculpture Archive, the <i>Lexicon Iconographicum Mythologiae Classicae</i> in Paris and Basel, and
                    the German Archaeological Institute, producing an RDF triple store of over 20
                    million assertions. The federating and subsidiarity principle of CLAROS is that
                    it acts simply as a resource discovery system, with search results linking back
                    to the host database for more information, preserving the IPR and intellectual
                    integrity of each partner. A SPARQL interface and RESTful APIs are provided for
                    expert use, but CLAROS itself provides an exemplar query and visualisation
                    interface (the Explorer) with an emphasis on textual search, timeline display
                    and mapping of results. It is expected that the user will start with broad
                    search terms, receive back information from a wide variety of sources, and then
                    gradually refine and explore the results, perhaps ending in unexpected
                    places.</p>

                <p class="noindent">
                    <img class="inline" src="http://dh2011abstracts.stanford.edu/xtf/data/tei/224/image1.png" /><p><a href="javascript://" onclick="javascript:window.open('http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-224.xml&amp;doc.view=popup&amp;fig.ent=http://dh2011abstracts.stanford.edu/xtf/data/tei/224/image1.png','popup','width=800,height=600,resizable=yes,scrollbars=yes')">Full Size Image </a></p>
                </p>
            

            
                <h2>Metamorphoses</h2>
                <p class="noindent">One of the research subprojects of CLAROS is <i>Metamorphoses</i>, whose aim is to establish a working co-reference system for
                    name, place and date information in classical art and archaeology and ancient
                    history projects at Oxford. This will provide geo-naming and geo-locating
                    services to both CLAROS partners in their normal research, and to the CLAROS
                    Explorer in performing searches. One output is an aggregating Ancient Place
                    Server with web services to answer queries about locations of places, names of
                    places, and types of places within a chosen area. We work on a social model of
                    places as objects which come into existence as a result of naming by one or more
                    groups of people at a particular time. We expect places to have multiple names,
                    to have different geographical limits over time, and to have relationships with
                    other places. </p>
            

            
                <h2>Visual Search</h2>
                <p class="noindent">A novel aspect of CLAROS is that visual queries can be used to access and search
                    the archives that are linked to within CLAROS. Suppose, for example, that a
                    novice takes a photograph of a Greek vase in a museum on their iPhone, or finds
                    an image of a Greek vase on the web, that they would like to know more about.
                    This image can be use as a visual query to retrieve that vase from the archive,
                    in much the same way as the text phrase “Greek vase” can be used as a query in
                    Google to retrieve web pages which contain that phrase. The method is
                    illustrated in Figure 1: the image is uploaded to a web server, and the server
                    returns the matches in the archive together with meta-information – for instance
                    identifying the type of the vase, its date, its material, its decorations etc.
                        <p>
                        <img class="inline" src="http://dh2011abstracts.stanford.edu/xtf/data/tei/224/image2.jpeg" /><p><a href="javascript://" onclick="javascript:window.open('http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-224.xml&amp;doc.view=popup&amp;fig.ent=http://dh2011abstracts.stanford.edu/xtf/data/tei/224/image2.jpeg','popup','width=800,height=600,resizable=yes,scrollbars=yes')">Full Size Image </a></p>
                        <img class="inline" src="http://dh2011abstracts.stanford.edu/xtf/data/tei/224/image3.png" /><p><a href="javascript://" onclick="javascript:window.open('http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-224.xml&amp;doc.view=popup&amp;fig.ent=http://dh2011abstracts.stanford.edu/xtf/data/tei/224/image3.png','popup','width=800,height=600,resizable=yes,scrollbars=yes')">Full Size Image </a></p>
                        <img class="inline" src="http://dh2011abstracts.stanford.edu/xtf/data/tei/224/image4.png" /><p><a href="javascript://" onclick="javascript:window.open('http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-224.xml&amp;doc.view=popup&amp;fig.ent=http://dh2011abstracts.stanford.edu/xtf/data/tei/224/image4.png','popup','width=800,height=600,resizable=yes,scrollbars=yes')">Full Size Image </a></p>
                        <h2>Figure 1: Identifying a vase from a web photo: an image of a vase is uploaded
                            from a web link (top), and is matched to one in the Beazley vase
                            collection (middle) in real time (a search through over 100,000 images).
                            This identifies the type of vase, its material, date and decorations
                            from the meta-information (bottom) associated with this data in the
                            Beazley archive.</h2>
                        </p> 
                    Figure 2 gives another example, this time for a visual search of the
                        <i>Arachne</i> classical sculpture archive. <p>
                        <img class="inline" src="http://dh2011abstracts.stanford.edu/xtf/data/tei/224/image5.png" /><p><a href="javascript://" onclick="javascript:window.open('http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-224.xml&amp;doc.view=popup&amp;fig.ent=http://dh2011abstracts.stanford.edu/xtf/data/tei/224/image5.png','popup','width=800,height=600,resizable=yes,scrollbars=yes')">Full Size Image </a></p>
                        <img class="inline" src="http://dh2011abstracts.stanford.edu/xtf/data/tei/224/image6.png" /><p><a href="javascript://" onclick="javascript:window.open('http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-224.xml&amp;doc.view=popup&amp;fig.ent=http://dh2011abstracts.stanford.edu/xtf/data/tei/224/image6.png','popup','width=800,height=600,resizable=yes,scrollbars=yes')">Full Size Image </a></p>
                        <h2>Figure 2: Identifying a sculpture from a web photo: an image of a sculpture is
                            uploaded from a web link (top), and is matched to one in the Arachne
                            sculpture collection. In turn, this provides links to other images of
                            the sculpture in the collection and also to associated meta-information
                            (bottom).</h2>
                    </p>
                </p>

                <p class="noindent">That this visual search is possible, and indeed can be carried out with results
                    being returned immediately, is due to recent methods developed in the computer
                    vision community on visually searching for objects in large scale image datasets
                    (see [1] for details).</p>
            
        <h2>References:</h2>
            
                
                    <p>
                        J. Philbin, O. Chum, M. Isard, J. Sivic, and A. Zisserman
                        2007
                         “Object Retrieval with Large Vocabularies and Fast Spatial
                            Matching, ” 
                        <i>IEEE Conference on Computer Vision and Pattern
                            Recognition</i>, 
                    </p>
                
            
        </div></div></body></html>