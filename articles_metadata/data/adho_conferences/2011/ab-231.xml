
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8; charset=UTF-8" /><title>When to Ask for Help: Evaluating Projects for Crowdsourcing</title><link rel="stylesheet" href="css/default/results.css" type="text/css" /><script src="script/yui/yahoo-dom-event.js" type="text/javascript"></script><script src="script/yui/connection-min.js" type="text/javascript"></script></head><body class="home blog"><div id="wrapper" class="hfeed"><div id="header"><div id="masthead"><div id="branding" role="banner"><h1 id="site-title"><span><a href="https://dh2011.stanford.edu/" title="Digital Humanities 2011: June 19 – 22" rel="home">Digital Humanities
                2011: June 19 – 22</a></span></h1><div id="site-description">Big Tent Digital Humanities</div><img src="https://www.stanford.edu/group/dh2011/cgi-bin/wordpress/wp-content/uploads/2010/09/tieDyeLarge.jpg" width="940" height="198" alt="" /></div><div id="access" role="navigation"><div class="menu"><ul><li><a href="https://dh2011.stanford.edu/" title="Home">Home</a></li><li><a href="https://dh2011.stanford.edu/?page_id=3" title="About">About</a></li><li><a href="https://dh2011.stanford.edu/?page_id=15" title="Accommodations &amp; Travel">Accommodations &amp; Travel</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=887" title="Accommodations">Accommodations</a></li><li><a href="https://dh2011.stanford.edu/?page_id=883" title="Travel">Travel</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=311" title="Registration">Registration</a></li><li><a href="https://dh2011.stanford.edu/?page_id=411" title="Schedule">Schedule</a></li><li><a href="https://dh2011.stanford.edu/?page_id=475" title="Workshops">Workshops</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=489" title="Tutorial 1: Introductory TEI ODD">Tutorial 1: Introductory TEI ODD</a></li><li><a href="https://dh2011.stanford.edu/?page_id=499" title="Tutorial 2 / Workshop: Integrating Digital Humanities Projects into the Undergraduate Curriculum">Tutorial 2 / Workshop: Integrating Digital Humanities Projects into the
                      Undergraduate Curriculum</a></li><li><a href="https://dh2011.stanford.edu/?page_id=507" title="Tutorial 3: An Introduction to XForms for Digital Humanists: How XForms Can Help Your Project">Tutorial 3: An Introduction to XForms for Digital Humanists: How XForms Can
                      Help Your Project</a></li><li><a href="https://dh2011.stanford.edu/?page_id=517" title="Tutorial 4: Introduction to Text Analysis With Voyeur Tools">Tutorial
                      4: Introduction to Text Analysis With Voyeur Tools</a></li><li><a href="https://dh2011.stanford.edu/?page_id=521" title="Tutorial 5: Gabmap: A Web Application for Analyzing Linguistic Variation">Tutorial 5: Gabmap: A Web Application for Analyzing Linguistic Variation</a></li><li><a href="https://dh2011.stanford.edu/?page_id=525" title="Tutorial 6: Natural Language Processing Tools for the Digital Humanities">Tutorial 6: Natural Language Processing Tools for the Digital Humanities</a></li><li><a href="https://dh2011.stanford.edu/?page_id=529" title="Tutorial 7: Network and Topical Analysis for the Humanities using NWB and Sci2">Tutorial 7: Network and Topical Analysis for the Humanities using NWB and
                      Sci2</a></li><li><a href="https://dh2011.stanford.edu/?page_id=493" title="Workshop: Visualization for Literary History">Workshop: Visualization
                      for Literary History</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=471" title="Social Program">Social
                  Program</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=541" title="Literary San Francisco (Full Day)">Literary San Francisco (Full
                      Day)</a></li><li><a href="https://dh2011.stanford.edu/?page_id=547" title="Silicon Valley History (Half-Day)">Silicon Valley History
                      (Half-Day)</a></li><li><a href="https://dh2011.stanford.edu/?page_id=537" title="Sonoma Wine Country (Full-Day)">Sonoma Wine Country (Full-Day)</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=181" title="CFPs">CFPs</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=97" title="General CFP">General
                      CFP</a></li><li><a href="https://dh2011.stanford.edu/?page_id=175" title="CFP en Español">CFP en
                      Español</a></li><li><a href="https://dh2011.stanford.edu/?page_id=287" title="CFP in German">CFP in
                      German</a></li><li><a href="https://dh2011.stanford.edu/?page_id=207" title="CFP in Greek">CFP in
                      Greek</a></li><li><a href="https://dh2011.stanford.edu/?page_id=229" title="CFP in Hungarian">CFP
                      in Hungarian</a></li><li><a href="https://dh2011.stanford.edu/?page_id=257" title="CFP in Italiano">CFP
                      in Italiano</a></li><li><a href="https://dh2011.stanford.edu/?page_id=157" title="Tutorial/Workshop CFP">Tutorial/Workshop CFP</a></li></ul></li><li><a href="https://dh2011.stanford.edu/?page_id=19" title="Contacts">Contacts</a></li><li><a href="https://dh2011.stanford.edu/?page_id=801" title="Venue">Venue</a><ul class="children"><li><a href="https://dh2011.stanford.edu/?page_id=829" title="Local Lunch Spots">Local Lunch Spots</a></li><li><a href="https://dh2011.stanford.edu/?page_id=845" title="Palo Alto Restaurants">Palo Alto Restaurants</a></li></ul></li></ul></div></div><br class="clear" /></div></div><div class="resultsHeader"><table><tr><td><a href="http://dh2011abstracts.stanford.edu/xtf/search" target="_top">New Search</a> | <span class="notActive">Return to Search Results</span> | <a href="http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-231.xml&amp;doc.view=print;chunk.id=0" target="_top">Print View</a></td><td align="right"><form action="http://dh2011abstracts.stanford.edu/xtf/view" target="_top" method="get"><input name="query" type="text" size="15" /><input type="hidden" name="docId" value="tei/ab-231.xml" /><input type="hidden" name="chunk.id" value="0" /><input type="submit" value="Search this Book" /></form></td></tr></table></div><hr /><div class="results"><h2>Paper: When to Ask for Help: Evaluating Projects for Crowdsourcing</h2><h4>
                    Organisciak, Peter, 
                    University of Illinois, United States of America, 
                    <a href="mailto:organis2@illinois.edu">organis2@illinois.edu</a>
                </h4><hr />
            
                <p class="noindent">A growing online phenomenon is that of crowdsourcing, where groups of disparate
                    people, connected through technology, contribute to a common product. It refers
                    to the collaborative possibilities of a communications medium as flexible and as
                    populated as the Internet. If many hands make light work, crowdsourcing websites
                    show how light the work can be, breaking tasks into hundreds of pieces for
                    hundreds of hands. Building from the growing body of research in the area
                    including the author’s work on crowd motivations, this paper outlines the
                    necessary steps and considerations in enriching projects through
                    crowdsourcing.</p>
                <p class="noindent">Though not new, crowdsourcing as it exists online has been enabled by emerging
                    technologies. It has grown out of increasingly efficient – and affordable –
                    forms of communication. Since such collaboration has expanded so quickly, there
                    have been few investigations into the design of crowdsourcing. At the same time,
                    the most successful projects have emerged in an organic nature that many
                    deliberate attempts have failed to replicate, suggesting the need for more
                    investigation in the area. Jeff Howe, who first defined the term and popularized
                    the trend, has explained that “we know crowdsourcing exists because we've
                    observed it in the wild. However, it's proven difficult to breed in captivity”
                    (2008).</p>
                <p class="noindent">The gaps in knowledge of online crowds are quickly being filled however, allowing
                    projects to move away from reliance on serendipity. This presentation derives
                    from recently completed thesis work on the motivations of crowds within
                    crowdsourcing (Organisciak 2010). While it will reflect that study’s findings on
                    how, its primary focus is on the equally important questions of why and when in
                    light of those findings. For which tasks is crowdsourcing an appealing option
                    and what resources should be present for a project to adequately motivate the
                    users? A bottom-up classification of crowdsourcing categories is proposed,
                    followed by a checklist of needs that an institution must consider before
                    attempting their own crowdsourcing.</p>
                <p class="noindent">In this study, a sample of 300 crowdsourcing sites was examined and classified.
                    Synthesizing these classifications resulted in a proposed list of eleven
                    non-exclusive categories for crowdsourcing, six describing method and five
                    describing structure. Methods include encoding, creation, idea exchange, skills
                    aggregation, knowledge aggregation, and opinion aggregation. Additionally, there
                    are financial, platform, gaming, group empowerment, and ludic structures
                    observed within these systems. Derived from existing systems, these categories
                    and their variants offer unique design patterns and best practice cases that can
                    assist in assessing the types of tasks at which they excel.</p>
                <p class="noindent">Appropriateness of the task is just one facet of running a crowdsourcing project.
                    The other consideration is whether a project offers a return that potential
                    participants would find rewarding. In addressing this, a content analysis was
                    used to identify site design mechanics related to user experience in thirteen
                    cases spanning the breadth of the identified categories. These mechanics were
                    then discussed in a series of user interviews to determine what users truly care
                    about. In this study, a collection of primary and secondary motivators are
                    proposed as foundational considerations in running a project. The primary
                    motivators seen in the user interviews were interest in the topic, ease of entry
                    and of participation, altruism and meaningful contribution, sincerity, and
                    appeal to knowledge. A final one, financial incentive, is perhaps the most
                    blunt. Secondary motivators include indicators of progress and reputation (i.e.
                    “cred”), utility, fun, system feedback, social networking, and fixed windows
                    (i.e. well-groomed quality).</p>
                <p class="noindent">An understanding of the nature of crowdsourcing holds notable benefits to
                    scholarship in the humanities and social sciences. Most significantly, this is
                    because it allows large-scale insights into the qualitative and the abstract,
                    those areas inextricably linked to the limits of manpower, unable to be
                    delegated to computing power. “What is the sentiment of this sentence”, is the
                    type of question a crowdsourcing site may ask (<a href="http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-231.xml&amp;chunk.id=&amp;toc.id=&amp;toc.depth=1&amp;brand=default&amp;anchor.id=http://mturk.com/#X" target="_top">Mechanical Turk</a>, May 2nd 2010), if not always as directly.  Since much
                    work in the arts cannot easily be quantified, logistics and resources often
                    limit humanities research to a balance between breadth and depth; crowdsourcing
                    offers an escape from this issue.</p>
                <p class="noindent">Consider one task that is often seen in existing crowdsourcing sites:
                    crowd-encoded classification. Classification tasks are dependent on the
                    person-hours available, because person-hours are the only dependable way to
                    approach these tasks. Whether directly or incidentally, online crowds can
                    effectively encode or classify content. Though the reliability of the end
                    product is often far below that of a professional encoder, large-scale crowd
                    projects can often account for this through multiple independent
                    classifications, measuring consistency and reliability through agreement.  <a href="http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-231.xml&amp;chunk.id=&amp;toc.id=&amp;toc.depth=1&amp;brand=default&amp;anchor.id=http://www.galaxyzoo.org#X" target="_top">Galaxy Zoo</a>, an effort from Oxford to
                    classify galaxies, found crowdsourced data to be within 10% agreement with the
                    same data classified professionally (Lintott et al. 2009). The high quality of
                    work is especially notable because the experiment and its follow-ups received
                    their 60 millionth classification in April 2010.</p>
                <p class="noindent"><a href="http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-231.xml&amp;chunk.id=&amp;toc.id=&amp;toc.depth=1&amp;brand=default&amp;anchor.id=http://www.flickr.com/commons#X" target="_top">Flickr Commons</a>, an initiative to put
                    photo archives on a photo-sharing community, is a similar project that – by way
                    of community-based research, information and tagging – has enriched the metadata
                    of hundreds of Library of Congress photographs in the United States of America
                    (Springer, et al. 2008). Another <a href="http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-231.xml&amp;chunk.id=&amp;toc.id=&amp;toc.depth=1&amp;brand=default&amp;anchor.id=http://newspapers.nla.gov.au/#X" target="_top">pilot
                        project involving public tagging</a>, by the National Library of Australia,
                    concluded that “tagging is a good thing, users want it, and it adds more
                    information to data. It costs little to nothing and is relatively easy to
                    implement; therefore, more libraries and archives should just implement it
                    across their entire collections” (Holley 2010). The National Library of
                    Australia followed through on this recommendation.</p>
                <p class="noindent">Such projects are often greeted with suspicion in professional or scholarly
                    communities. The National Library of Australia report notes that "institutions
                    who have not implemented user tagging generally perceive many potential problems
                    that institutions who have implemented user tagging do not report" (Clayton et
                    al. 2008 qtd. in Holley 2010). The Library of Congress report similarly notes
                    many concerns that critics provided, such as: “Would fan mail, false memories,
                    fake facts, and uncivil discourse obscure knowledge? … Would the Library lose
                    control of its collections? Would library catalogs and catalogers become
                    obsolete?...Would history be dumbed-down? Would photographs be disrespected or
                    exploited?” (Springer et al. 2008). In both cases, the reports state that the
                    concerns, within the respective project’s experiences, have not manifested.</p>
                <p class="noindent">Encoding is a notable use of crowdsourcing in academia, but not the only one.
                    Some projects, such as the <a href="http://dh2011abstracts.stanford.edu/xtf/view?docId=tei/ab-231.xml&amp;chunk.id=&amp;toc.id=&amp;toc.depth=1&amp;brand=default&amp;anchor.id=http://www.stoa.org/sol/#X" target="_top">Suda On Line</a>,
                    benefit from collected contributions of expertise and knowledge. Suda On Line is
                    a project to translate a Byzantine encyclopedia, Suda, into English for the
                    first time. It has been steadily progressing since 1998, producing a
                    comprehensive resource while staying at a manageable participation scale
                    (Mahoney 2009). In other cases, crowdsourcing allows public and volunteer
                    projects to compete with the scale and quality of commercial projects, as has
                    been seen in OpenStreetMap, Project Gutenberg, and many open source
                    projects.</p>
                <p class="noindent">As crowdsourcing continues to be tested – and if it continues to be successful –
                    in public institutions, understanding how to undertake such projects will become
                    more important. The benefits are being stated, and the scale and openness on
                    which public institutions operate makes them a compatible beneficiary of
                    crowdsourcing activities. Users appear especially altruistic toward public
                    projects, emphasizing in this study their preference for meaningful engagement
                    with institutional workings over symbolic outreach.</p>
                <p class="noindent">The study informing this work is large, and my hope is to provide a digestible
                    account of its results. The reason for this goal is straightforward: there is
                    still much work to be done in understanding the mechanics of crowdsourcing, but
                    the potential is great. I hope that the sharing of this foundational work will
                    encourage others to explore further.</p>
            
            
                <h2>Acknowledgements</h2>
                <p class="noindent">This study owes a great debt to Lisa M Given, my thesis advisor, as well as
                    additional committee members Geoffrey Rockwell and Stan Ruecker.</p>
            
        <h2>References:</h2>
            
                
                    <p>
                        Holly, Rosé
                         “Tagging Full Text Searchable Articles: An Overview of Social Tagging
                            Activity in Historic Australian Newspapers August 2008 — August
                            2009, ” 
                        <i>D-Lib</i>, 
                        12(1/2)
                        2010
                        
         (<a href="http://www.dlib.org/dlib/january10/holley/01holley.html#4" target="blank">link</a>)
   
                        January 31, 2010
                    </p>
                    <p>
                        Howe, Jeff
                        Crowdsourcing
                        2008
                    </p>
                    <p>
                        Lintott, Chris, et al
                         “Galaxy Zoo : Morphologies derived from visual inspection of galaxies
                            from the Sloan Digital Sky Survey, ” 
                        <i>arXiv</i>, 
                        0804.4483
                        2010
                        
         (<a href="http://uk.arxiv.org/abs/0804.4483" target="blank">link</a>)
   
                    </p>
                    <p>
                        Organisciak, Piotr
                        <i>Why bother? Examining the motivations of users in large-scale
                            crowd-powered online initiatives</i>, 
                        2010
                        
         (<a href="http://repository.library.ualberta.ca/dspace/handle/10048/1370" target="blank">link</a>)
   
                    </p>
                    <p>
                        Springer, Michelle, et. al.
                        <i>For the Common Good: The Library of Congress Flickr Pilot Project</i>, 
                        2008
                    </p>
                    <p>
                        Mahoney, Anne
                         “Tachypaedia Byzantina: The Suda On Line as Collaborative
                            Encyclopedia, ” 
                        <i>Digital Humanities Quarterly</i>, 
                        3.1
                        2009
                    </p>
                
            
        </div></div></body></html>