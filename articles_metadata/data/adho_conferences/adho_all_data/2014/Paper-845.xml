<?xml version="1.0" encoding="utf-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:x="http://www.w3.org/1999/xhtml" xmlns:exsl="http://exslt.org/common" xml:id="Paper-845">
	<teiHeader>
		<fileDesc>
			<titleStmt>
				<title>Marrying the Benefits of Print and Digital: Algorithmically Selecting Context for a Key Word</title>
				<author>
					<name>
						<surname>Benner</surname>, <forename>Drayton Callen</forename>
					</name>
					<affiliation>University of Chicago, United States of America </affiliation>
					<email></email>
				</author>
			</titleStmt>
			<publicationStmt>
				<authority/>
				<publisher>EPFL, Switzerland</publisher>
				<distributor>
					<name>EPFL Digital Humanities Laboratory</name>
					<address>
						<addrLine>GC D2 386</addrLine>
						<addrLine>Station 18</addrLine>
						<addrLine>CH-1015 Lausanne</addrLine>
						<addrLine>frederic.kaplan@epfl.ch</addrLine>
					</address>
				</distributor>
				<pubPlace>Lausanne, Switzerland</pubPlace>
				<address>
					<addrLine>EPFL</addrLine>
					<addrLine>CH-1015 Lausanne</addrLine>
				</address>
				<availability>
					<p/>
					</availability>
				</publicationStmt>
				<notesStmt>
					<note type="abstract">Software systems for presenting and analyzing texts have proliferated in recent decades as humanists have digitized more texts, and search is one of the core functionalities of these software systems. However, in displaying search results, digital tools have lacked one of characteristics of older print concordances, which typically present the key word in its context on one line of text with the context carefully chosen so as to maximize the reader’s understanding of the key word’s context given the space limitations. In this paper, I present an algorithmic approach to mimic a human’s activity in choosing the context for a given line length and font. This results in a presentation of search results almost as good as a human would choose without the tens or even hundreds of person-years required for traditional print concordances. Moreover, unlike print concordances, this algorithmic approach is flexible, accommodating changes in line length and font.</note>
				</notesStmt>
				<sourceDesc>
					<p>No source: created in electronic format.</p>
					<p>
					  <date when="20140710"/>
					  <time when="11:00:00"/>
					</p>
					<p n="session">5</p>
					<p n="room">319 - Amphipôle</p>
				</sourceDesc>
			</fileDesc>
			<profileDesc>
				<textClass>
					<keywords scheme="original" n="category">
						<term>Paper</term>
					</keywords>
					<keywords scheme="original" n="subcategory">
						<term>Long Paper</term>
					</keywords>
					<keywords scheme="original" n="keywords">
						<term>key word in context</term>
						<term>KWIC</term>
						<term>concordance</term>
						<term>search results</term>
						<term></term>
					</keywords>
					<keywords scheme="original" n="topic">
						<term>corpora and corpus activities</term>
						<term>information retrieval</term>
						<term>natural language processing</term>
						<term>text analysis</term>
						<term>concording and indexing</term>
						<term></term>
					</keywords>
				</textClass>
			</profileDesc>
		</teiHeader>
		<text type="paper">
			<front>
				<div>
					<p></p>
				</div>
			</front>
			<body>
				<div>
					<head>1. Introduction</head>
					<p>Over the last few decades as more texts have been digitized, numerous software systems have arisen to display the texts and allow scholars to analyze them. These software systems have varied in their delivery (web-based, desktop software, mobile app, etc.) and their functionality, yet nearly all of them have included full-text search capabilities. Search is a central tool for scholars researching a corpus, and it is a task for which computers are perfectly suited. Despite the ubiquity of searching capabilities, there is no single method for displaying search results. When a user has requested to see a key word in its context, how much context should be presented to the user?</p>
					<p>In choosing the context to present, there is no single solution that will always be best. At times, users will want to see detailed context requiring several lines. At other times, users will want to see as many search results as possible in a small visual space. Thus, providing multiple ways of viewing search results is desirable. When each search result is contained in a single line, perhaps the most attractive presentation currently in common use contains the key word in the middle, showing whatever context that fits on each side, a presentation style also found in some print concordances (Clarke, 1984; The Computer Bible, 1970-).</p>
					<figure>
						<graphic url="DH2014_2_275-1"/>
						<p>Fig. 1: . Results from a KWIC (Key Word in Context) search using Perseus under Philologic at perseus.uchicago.edu.</p>
					</figure>
					<p>However, there is another method of displaying search results on a single line that is found in some print concordances that antedate digital tools. In this tradition, the context surrounding the key word is chosen manually so as to provide the reader as much information as possible about the key word’s context.</p>
					<figure>
						<graphic url="DH2014_2_275-2"/>
						<p>Fig. 2: The entry “strengthen” in (Strong, 1890).</p>
					</figure>
					<p>Unfortunately, this method requires a tremendous amount of manual effort; it has only been practical in concordances of the Bible and other heavily-studied texts. The following concordances that antedate the maturation of the digital age take this approach: <hi rend="bold">Bible</hi>: Cruden (1737); Young (1882); Strong (1890); Mandelkern (1896); Hazard (1922); Gant (1950); Lisowsky (1958); Even-Shoshan (1977); <hi rend="bold">Homer</hi>: Prendergast (1875: Iliad); Dunbar (1880: Odyssey); <hi rend="bold">Shakespeare</hi>: Clarke (1846). Since the full flowering of the digital age, it has been abandoned in most concordances and even in commercial Bible software, as shown in the following figures.</p>
					<figure>
						<graphic url="DH2014_2_275-3"/>
						<p>Fig. 3: Search results from Logos Bible Software (logos.com) on a PC.</p>
					</figure>
					<figure>
						<graphic url="DH2014_2_275-4"/>
						<p>Fig. 4: . Search results from BibleWorks (BibleWorks.com) on a PC.</p>
					</figure>
					<figure>
						<graphic url="DH2014_2_275-5"/>
						<p>Fig. 5: Search results from Olive Tree Bible Software (OliveTree.com) on a Samsung Galaxy S3 smartphone. As a disclaimer, I wrote the search engine—but not the code to display the search results—for Olive Tree Bible Software as an independent contractor.</p>
					</figure>
					<p>There have been some print concordances in the digital age for which the single-line context has been produced algorithmically, at least in part (e.g. Ellison, 1957; Spevack, 1968-1975; Goodrick and Kohlenberger, 1990; Kohlenberger, 1991; Dixon and Dawson, 1992; Mounce, 2012). Where algorithmic details have been published in part (Soule, 1956; Dixon, 1974; Dawson, 1977; Burton, 1982), they have often been primarily dependent on punctuation and/or manual annotation as a pre-processing step. While pioneering in their day, computing resources are more plentiful today, and the field of natural language processing has advanced greatly.</p>
					<p>I propose an algorithm that seeks to mimic a human reader’s choice of context for a search term. The goal is to produce the most relevant context for a key word on a line that is of arbitrary width using an arbitrary font. This provides the benefits of traditional print concordances without the tens or hundreds of person-years required to produce them for even a single line width and font size.</p>
				</div>
				<div>
					<head>2. Algorithm</head>
					<head>2.1 Preprocessing</head>
					<p>The text must, of course, be available in electronic form, but a syntactic parsing is also necessary. There are some electronic texts that have been parsed syntactically by hand (e.g. Andersen and Forbes, 2012), but the recent development of general-purpose parsers has made this work possible on a broader scale. As these parsers are developed for more languages and dialects and as they improve, the approach outlined here will become more and more useful. For this work, I generated phrase structure trees and dependency trees using StanfordCoreNLP (version 1.3.5, <ref type="url" target="http://nlp.stanford.edu/software/index.shtml">nlp.stanford.edu/software/index.shtml</ref>) on three texts (cf. Toutanova et al., 2003; de Marneffe et al., 2006). In keeping with the traditional use of concordances with Bible translations, I chose two Bible translations along with one novel: the <hi rend="italic">King James Version (KJV)</hi> of the Bible (1769 text edition), the <hi rend="italic">English Standard Version (ESV)</hi> of the Bible (2011 text edition, Old Testament/Hebrew Bible portion only), and Henry James’ novel <hi rend="italic">What Maisie Knew (Maisie)</hi>. A small amount of preprocessing was done before and after StanfordCoreNLP’s parsing, both to fix some repetitive errors in StanfordCoreNLP’s analysis and also to remove, and then reinstate, the main archaisms in the KJV.</p>
				</div>
				<div>
					<head>2.2 Algorithm</head>
					<p>In order to develop an algorithm for mimicking a human’s choice of context, I developed training data by randomly choosing key words from the <hi rend="italic">ESV</hi> and line lengths, ranging from what might fit legibly on a typical smartphone to a line three times as long. I then displayed all possible contexts that fit on the line but make maximum use of the space on the line. That is, no more words could fit on either side. In addition, sensible rules concerning which types of punctuation were appropriate at the beginning or end were employed (e.g. a possible context could not begin with a comma or end with an open quotation mark), and possible contexts could not cross verse boundaries. In the rare case that there was only one option, that key word was discarded. A user selected his preferred context for 500 such key words, occasionally choosing two or three different contexts if they seemed equally desirable<ref target="n01">1</ref>. After analyzing his choices, I produced the following metric <hi rend="italic">w(k,n)</hi> to give a value (weight) to each nearby word <hi rend="italic">n</hi> for the key word <hi rend="italic">k</hi>:</p>
					<figure>
						<graphic url="DH2014_2_275-6"/>
					</figure>
					<p>Let <hi rend="italic">a<hi rend="sub">p</hi></hi> be the nearest common ancestor of <hi rend="italic">k</hi> and <hi rend="italic">n</hi> in the phrase structure tree and <hi rend="italic">a<hi rend="sub">d</hi></hi> be the nearest common ancestor of <hi rend="italic">k</hi> and <hi rend="italic">n</hi> in the dependency tree. Then <hi rend="italic">d<hi rend="sub">pk</hi></hi> is the distance between <hi rend="italic">a<hi rend="sub">p</hi></hi> and <hi rend="italic">k</hi> in the phrase structure tree, <hi rend="italic">d<hi rend="sub">pn</hi></hi> is the distance between <hi rend="italic">a<hi rend="sub">p</hi></hi> and <hi rend="italic">n</hi> in the phrase structure tree, <hi rend="italic">d<hi rend="sub">dk</hi></hi> is the distance between <hi rend="italic">a<hi rend="sub">d</hi></hi> and <hi rend="italic">k</hi> in the dependency tree, and <hi rend="italic">d<hi rend="sub">dn</hi></hi> is the distance between <hi rend="italic">a<hi rend="sub">d</hi></hi> and <hi rend="italic">n</hi> in the dependency tree.</p>
					<p>Each possible context is evaluated as the sum of <hi rend="italic">w(k,n)</hi> for each <hi rend="italic">n</hi> in the possible context; the context with the highest value is chosen. If multiple possible contexts have identical values, any can be chosen; I picked the one that had the most context before the key word.</p>
					<p>The constants were optimized to the following values using a Monte Carlo particle filter on the training data:<lb/>
					<figure>
						<graphic url="DH2014_2_275-7"/>
					</figure>
					These constants reveal that the dependency tree was more important than the phrase structure tree.</p>
				</div>
				<div>
					<head>3. Results</head>
					<p>In addition to the above-mentioned training set, test sets were then generated from the <hi rend="italic">ESV</hi> and <hi rend="italic">Maisie</hi> with 100 key words each, and four human annotators made selections for each. The results are listed in Table 1. Since human annotators occasionally selected two or three contexts as equally good, a match for a given key word is calculated as:</p>
					<figure>
						<graphic url="DH2014_2_275-8"/>
					</figure>
					<table>
						<row>
							<cell role="label"> </cell>
							<cell role="label"><hi rend="italic">ESV</hi> training set</cell>
							<cell role="label"><hi rend="italic">ESV</hi> test set</cell>
							<cell role="label"><hi rend="italic">Maisie</hi> test set</cell>
						</row>
						<row>
							<cell role="data">Algorithm matches user selection</cell>
							<cell role="data">67.8%</cell>
							<cell role="data">62.5%</cell>
							<cell role="data">47.8%</cell>
						</row>
						<row>
							<cell role="data">Expected algorithm matches if selections were random from a uniform distribution</cell>
							<cell role="data">27.4%</cell>
							<cell role="data">25.5%</cell>
							<cell role="data">21.9%</cell>
						</row>
						<row>
							<cell role="data">Inter-annotator agreement</cell>
							<cell role="data">N/A</cell>
							<cell role="data">65.8%</cell>
							<cell role="data">53.0%</cell>
						</row>
						<row>
							<cell role="data">Expected inter-annotator agreement if selections were random from a uniform distribution</cell>
							<cell role="data">N/A</cell>
							<cell role="data">27.0%</cell>
							<cell role="data">23.5%</cell>
						</row>
					</table>
					<p>These results indicate that on average, the algorithm matches a given human annotator slightly less often than another human annotator does. Assuming that human intuition presents the gold standard for this task, this means that the algorithm is doing only slightly worse than humans at picking the best context for the key word.</p>
					<p>Some screenshots of algorithmically-generated key words in context are shown below.</p>
					<figure>
						<graphic url="DH2014_2_275-9"/>
						<p>Fig. 6: KWIC search for “Aaron” in <hi rend="italic">ESV</hi>, <hi rend="italic">KJV</hi>; “Maisie” in <hi rend="italic">Maisie</hi> (from left to right).</p>
					</figure>
					<figure>
						<graphic url="DH2014_2_275-10"/>
						<p>Fig. 7: Randomly Selected Key Words from <hi rend="italic">ESV</hi>, <hi rend="italic">KJV</hi> and <hi rend="italic">Maisie</hi> (from left to right).</p>
					</figure>
				</div>
				<div>
					<head>4. Conclusion</head>
					<p>Searching for key words is one of the core functions of text analysis software. The work presented here holds promise as a way of improving the way in which search results are displayed by automating a time-consuming manual technique traditionally used in print concordances. In addition, future work could deal with more complex displays, including possibly not using all the space available, possibly using ellipses, and dealing with displaying results of searches involving multiple key words.</p>
				</div>
			</body>
			<back>
				<div type="Notes">
					<note xml:id="n01" n="1">I would like to thank James Covington for his annotation of the training set and both test sets, Rodelle Williams and D. Chris Benner for their annotation of both test sets, Humphrey H. Hardy for his annotation of the <hi rend="italic">ESV</hi> test set, and Samuel L. Boyd for his annotation of the <hi rend="italic">Maisie</hi> test set.</note>
				</div>
				<div type="References">
					<listBibl>
						<bibl>
							<bibl><hi rend="bold">Andersen, F. I. &amp; Forbes, A. D.</hi> (2012). Biblical Hebrew Grammar Visualized. Winona Lake: Eisenbrauns.</bibl>
							<bibl><hi rend="bold">Burton, D. M.</hi> (1982). Automated Concordances and Word-indexes: Machine Decisions and Editorial Revisions. Computers and the Humanities 16, 195-218.</bibl>
							<bibl><hi rend="bold">Clarke, E. G.</hi> (1984). Targum Pseudo-Jonathan of the Pentateuch: Text and Concordance. Hoboken: Ktav.</bibl>
							<bibl><hi rend="bold">Clarke, M. C.</hi> (1846). The Complete Concordance to Shakespeare: Being a Verbal Index to all the Passages in the Dramatic Works of the Poet. New York: Wiley and Putnam.</bibl>
							<bibl><hi rend="bold">Cruden, A.</hi> (1737). A Complete Concordance to the Old and New Testament; or a Dictionary and Alphabetical Index to the Bible with a Concordance to the Apocrypha, and a Compendium of the Holy Scriptures. London: Frederick Warne &amp; Co.</bibl>
							<bibl><hi rend="bold">Dawson, J. L.</hi> (1977). Textual Bracketing. ALLC Bulletin 5, 148-157.</bibl>
							<bibl><hi rend="bold">de Marneffe, M.-C., MacCartney, B. &amp; Manning, C. D.</hi> (2006). Generating Typed Dependency Parses from Phrase Structure Parses. Language Resources and Evaluation Conference. Genoa, Italy.</bibl>
							<bibl><hi rend="bold">Dixon, J. E. G.</hi> (1974). A Prose Concordance: Rabelais. ALLC Bulletin 2, 47-54.</bibl>
							<bibl><hi rend="bold">Dixon, J. E. G. &amp; Dawson, J. L.</hi> (1992). Concordance des Œuvres de François Rabelais. Genève: Droz.</bibl>
							<bibl><hi rend="bold">Dunbar, H.</hi> (1880). A Complete Concordance to the Odyssey and Hymns of Homer. To which is added A Concordance to the Parallel Passages in the Iliad, Odyssey and Hymns. Oxford: Clarendon.</bibl>
							<bibl><hi rend="bold">Ellison, J. W.</hi> (1957). Nelson's Complete Concordance of the Revised Standard Version of the Bible. New York: Nelson.</bibl>
							<bibl><hi rend="bold">Even-Shoshan, A.</hi> (1977). Ḳonḳordantsyah ḥadashah le-Torah, Nevʼim, u-Khetuvim: botsar leshon ha-Miḳra - ʻIvrit ṿa-Aramit: shorashim, milim, shemot peratiyim, tserufim ṿe-nirdafim. Jerusalem: Ḳiryat sefer.</bibl>
							<bibl><hi rend="bold">Gant, W. J.</hi> (1950). Concordance of the Bible in the Moffatt Translation. London: Hodder and Stoughton.</bibl>
							<bibl><hi rend="bold">Goodrick, E. W. &amp; Kohlenberger, J. R., III</hi> (1990). The NIV Exhaustive Concordance. Grand Rapids: Zondervan.</bibl>
							<bibl><hi rend="bold">Hazard, M. C.</hi> (1922). A Complete Concordance to the American Standard Version of the Holy Bible. New York: Nelson.</bibl>
							<bibl><hi rend="bold">Kohlenberger, J. R., III</hi> (1991). The NRSV Concordance Unabridged: Including the Apocryphal/Deuterocanonical Books. Grand Rapids: Zondervan.</bibl>
							<bibl><hi rend="bold">Lisowsky, G.</hi> (1958). Konkordanz zum hebräischen Alten Testament, nach dem von Paul Kahle in der Biblia Hebraica edidit R. Kittel besorgten masoretischen Text. Stuttgart: Privileg. Württ. Bibelanstalt.</bibl>
							<bibl><hi rend="bold">Mandelkern, S.</hi> (1896). Veteris Testamenti concordantiae hebraicae atque chaldaicae, quibus continentur cuncta quae in prioribus concordantiis reperiuntur vocabula, lacunis omnibus expletis, emendatis cuiusquemodi vitiis, locis ubique denuo excerptis atque in meliorem formam redactis, vocalibus interdum adscriptis, particulae omnes adhuc nondum collatae, pronomina omnia hic primum congesta atque enarrata, nomina propria omnia separatim commemorata. Lipsiae: Veit et comp.</bibl>
							<bibl><hi rend="bold">Mounce, W. D.</hi> (2012). ESV Comprehensive Concordance of the Bible. Wheaton: Crossway.</bibl>
							<bibl><hi rend="bold">Prendergast, G. L.</hi> (1875). A Complete Concordance to the Iliad of Homer. London: Longmans, Green &amp; Co.</bibl>
							<bibl><hi rend="bold">Soule, G.</hi> (1956). Machine that Indexed the Bible. Popular Science 169, 173-175, 242, 246.</bibl>
							<bibl><hi rend="bold">Spevack, M.</hi> (1968-1975). A Complete and Systematic Concordance to the Works of Shakespeare. Hildesheim: Georg Olms.</bibl>
							<bibl><hi rend="bold">Strong, J.</hi> (1890). The Exhaustive Concordance of the Bible: Showing every Word of the Text of the Common English Version of the Canonical Books, and every Occurrence of each Word in Regular Order: together with A Comparative Concordance of the Authorized and Revised Versions, Including the American Variations: Also Brief Dictionaries of the Hebrew and Greek Words of the Original, with References to the English Words. Cincinnati: Jennings &amp; Graham.</bibl>
							<bibl><hi rend="bold">The Computer Bible</hi>. (1970-). Missoula: Scholars Press.</bibl>
							<bibl><hi rend="bold">Toutanova, K., Klein, D., Manning, C. D. &amp; Singer, Y.</hi> (2003). Feature-rich Part-of-speech Tagging with a Cyclic Dependency Network. Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Volume 1. Edmonton, Canada: Association for Computational Linguistics.</bibl>
							<bibl><hi rend="bold">Young, R.</hi> (1882). Analytical Concordance to the Bible on an Entirely New Plan: Containing every word in Alphabetical Order, Arranged under its Hebrew or Greek Original, with the Literal Meaning of each, and its Pronunciation; Exhibiting about Three Hundred and Eleven Thousand References, Marking 30,000 Various Readings in the New Testament, with the Latest Information on Biblical Geography and Antiquities, etc. etc. etc. Philadelphia: Lippincott &amp; Co.</bibl>
						</bibl>
					</listBibl>
				</div>
			</back>
		</text>
	</TEI>
