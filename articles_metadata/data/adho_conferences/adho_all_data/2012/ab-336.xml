<?xml version="1.0" encoding="UTF-8"?>
<?oxygen RNGSchema="../schema/xmod_web.rnc" type="compact"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0"
     xmlns:xmt="http://www.cch.kcl.ac.uk/xmod/tei/1.0" 
     xml:id="ab-336">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title>Automatic recognition of speech, thought and writing representation in German narrative texts</title>
                <author>
                    <name>Brunner, Annelen</name>
                    <affiliation>Institut für deutsche Sprache, Mannheim, Germany</affiliation>
                    <email>annelen_brunner@gmx.de</email>
                </author>
            </titleStmt>
            <publicationStmt>
                <publisher>Jan Christoph Meister, Universität Hamburg</publisher>
                <address>
                   <addrLine>Von-Melle-Park 6, 20146 Hamburg, Tel. +4940 428 38 2972</addrLine>
                   <addrLine>www.dh2012.uni-hamburg.de</addrLine>
              </address>
            </publicationStmt>
            <sourceDesc>
                <p>No source: created in electronic format.</p>
            </sourceDesc>
        </fileDesc>
        <revisionDesc>
            <change>
                <date>2012-04-15</date>
                <name>DH</name>
                <desc>generate TEI-template with data from ConfTool-Export</desc>
            </change>
            <change>
                <date>2012-04-13</date>
                <name>LS</name>
                <desc>provide metadata for publicationStmt</desc>
            </change>
        </revisionDesc>
    </teiHeader>
    <text type="paper">
        <body>
            <p>This paper presents a subset of the results of a larger project which explores ways
                to recognize and classify a narrative feature – speech, thought and writing
                representation (ST&amp;WR) – automatically, using surface information and methods of
                computational linguistics. </p>
                <p>Speech, thought and writing can be represented in various ways. Common categories
                in narratology are direct representation (<hi rend="italic">He</hi><hi rend="italic"
                    > thought:</hi><hi rend="italic"> ‘I</hi><hi rend="italic"> am</hi><hi
                    rend="italic"> hungry.</hi><hi rend="italic">’</hi>), free indirect
                representation, which takes characteristics of the character’s voice as well as the
                narrator’s (<hi rend="italic">Well,</hi><hi rend="italic"> where</hi><hi
                    rend="italic"> would</hi><hi rend="italic"> he</hi><hi rend="italic">
                    get</hi><hi rend="italic"> something</hi><hi rend="italic"> to</hi><hi
                    rend="italic"> eat</hi><hi rend="italic"> now?</hi>), indirect representation
                    (<hi rend="italic">He</hi><hi rend="italic"> said</hi><hi rend="italic">
                    that</hi><hi rend="italic"> he</hi><hi rend="italic"> was</hi><hi rend="italic"
                    >hungry.</hi>) and reported representation, which can be a mere mentioning of a
                speech, thought or writing act (<hi rend="italic">They</hi><hi rend="italic">
                    talked</hi><hi rend="italic"> about</hi><hi rend="italic"> lunch.</hi>).
                ST&amp;WR is a feature central to narrative theory, as it is important for
                constructing a fictional character and sheds light on the narrator-character
                relationship and the narrator’s stance. The favored techniques not only vary between
                authors and genres, but have changed and developed over the course of literary
                history. Therefore, an automated annotation of this phenomenon would be valuable, as
                it could quickly deal with a large number of texts and allow a narratologist to
                study regularities and differences between different time periods, genres or
                authors.</p>
                <p>The approach presented here specifically aims at applying digital methods to the
                    recognition of features conceptualized in narrative theory. This sets it apart
                    from other digital approaches to literary texts which often operate purely on a
                    vocabulary level and are more focussed on thematic issues or on author or group
                    specific stylistics. Recent approaches to the goal of automatically identifying
                    ST&amp;WR are either not concerned with narrativity at all, like Krestel et al.
                    who developed a recognizer of direct and indirect speech representation in
                    newspaper texts to identify second hand information, or not interested in the
                    techniques themselves, like Elson et al. who use recognition of direct speech
                    representation to extract a network of interrelations of fictional characters.
                    Also, both approaches are for the English language and can therefore not be used
                    in this project.</p>
                <p>Basis for the research is a corpus containing 13 short narratives in German
                    written between 1786 and 1917 (about 57 000 tokens). The corpus has been
                    manually annotated with a set of ST&amp;WR categories adapted from
                    narratological theory. This step is comparable to the annotation project
                    conducted by Semino and Short for a corpus of English literary, autobiographical
                    and newspaper texts, but is something that has never been done for German
                    literary texts before. The manual annotation gives empirical insight into the
                    surface structures and the complex nature of ST&amp;WR, but also serves as
                    training material for machine learning approaches and, most importantly, as
                    reference for evaluation of the automatic recognizer. </p>
                <p>The main focus of this paper is the automatic recognition. Rule-based as well as
                    machine learning approaches have been tested for the task of detecting instances
                    of the narratological categories. In the scope of this paper, a subset of these
                    strategies is presented and compared.</p>
                <p>For the rule-based approach, simple and robust methods are favored, which do not
                require advanced syntactic or semantic preprocessing, automatic reasoning or complex
                knowledge bases. The modules make use of conventions like punctuation, as well as
                lexical and structural characteristics for different types of ST&amp;WR. A central
                feature is a list of words that signal ST&amp;WR, e.g. <hi rend="italic">to say</hi>
                    (<hi rend="italic">sagen</hi>), <hi rend="italic">to whisper</hi> (<hi
                    rend="italic">flüstern</hi>). For the recognition of indirect ST&amp;WR
                specifically, patterns of surfaces and morphological categories are used to match
                the dependent propositions (e.g. <hi rend="italic">E</hi><hi rend="italic">r sagte,
                    dass er hungrig sei.</hi> [<hi rend="italic">He said that he was hungry.</hi>]:
                signal word – followed by comma – followed by a conjunction – followed by a verb in
                subjunctive mode). This methods achieves F1 scores of up to 0.71 in a sentence-based
                evaluation. Direct representation can be detected with an F1 score of 0.84 by
                searching for quotation patterns and framing phrases (e.g. <hi rend="italic">he
                    said</hi>). Annotating reported representation, which is quite diverse, achieves
                an F1 score of up to 0.57.</p>
                <p>The machine learning approach uses a random forest learning algorithm trained on
                    the manually annotated corpus. Features like sentence length, number of certain
                    word types and types of punctuation are used as attributes. The advantage of
                    this approach lies in the fact that it can also be used to handle types of
                    ST&amp;WR which do have less obvious structural or lexical characteristics, like
                    free indirect representation, for which an F1 score of 0.43 can be achieved when
                    performing sentence-based cross validation on the corpus. The F1 score for
                    detecting direct representation is 0.81, for indirect representation 0.57 and
                    for reported representation 0.51.  </p>
                <p>The components of the automatic recognizer are modular and realized as working
                    prototypes in the framework GATE (General Architecture for Text Engineering)
                    (http://gate.ac.uk). When the project is finished, it is intended to publish
                    these components as GATE plugins and make them available as a free download.</p>
                <p>In the paper, the advantages and disadvantages of rule-based and machine learning
                    approaches as well as possibilities for combination are discussed. For example,
                    rules can be used for ST&amp;WR strategies with clear patterns and conventions,
                    like direct and – to an extent – indirect representation, but machine learning
                    for the more elusive types like free indirect representation. It is also
                    possible to get results for the same ST&amp;WR category from different modules
                    and use those to calculate scores. E.g. merging the results of rule-based and ML
                    methods improves the overall F1 score for recognizing direct representation in
                    the corpus. </p>
                <p>Though the figures above give a rough idea of expected success rates, evaluation
                    is in fact an analytic task itself: Results are not only quite different for
                    different types of ST&amp;WR and dependent on the exact configuration of the
                    recognizer modules. There is also the question of what kind of results should be
                    prioritized for narratological research and how to deal with cases which are
                    problematic even for a human annotator. However, the modular structure of the
                    recognizer is designed to allow for customization and the main goal of the
                    project is to shed light on the relationship between the manual annotation,
                    generated with narratological concepts in mind, and the possibilities and
                    limitations of ultimately surface-based automatic annotation. 
            </p>
        </body>
        <back>
            <div>
               
                    <head>References</head>
                <p>
                    <hi rend="bold">Cunningham,</hi><hi rend="bold"> H., et</hi><hi rend="bold">
                            al. </hi>(2011). Text Processing with GATE (Version 6): <ref
                            target="http://www.tinyurl/gatebook" type="external">http://www.tinyurl/gatebook</ref>
                        (accessed 14 March 2012).</p>
                    <p><hi rend="bold">Elson,</hi><hi rend="bold"> D.</hi><hi rend="bold"> K., N.
                            Dames,</hi><hi rend="bold"> and K. R. McKeown</hi> (2010). Extracting
                        Social Networks from Literary Fiction.<hi rend="italic"> Proceedings</hi><hi
                            rend="italic"> of</hi><hi rend="italic"> the</hi><hi rend="italic">
                            48th</hi><hi rend="italic"> Annual</hi><hi rend="italic">
                            Meeting</hi><hi rend="italic"> of</hi><hi rend="italic"> the</hi><hi
                            rend="italic"> Association</hi><hi rend="italic"> for</hi><hi
                            rend="italic"> Computational</hi><hi rend="italic"> Linguistics</hi><hi
                            rend="italic"> 2010, </hi>pp. 138-147. </p>
                    <p><hi rend="bold">Krestel, R., S. Bergler,  and R. Witte</hi> (2008). Minding
                        the Source: Automatic Tagging of Reported Speech in Newspaper Articles.<hi
                            rend="italic"> Proceedings of the Sixth International Language Resources
                            and Evaluation Conference</hi>
                        <hi rend="italic">(LREC 2008),</hi> Marrakech, Morocco, May 28-30 2008.</p>
                    <p><hi rend="bold">Semino,</hi><hi rend="bold"> E., and M. Short</hi> (2004).
                            <hi rend="italic">Corpus</hi><hi rend="italic"> stylistics.</hi><hi
                            rend="italic"> Speech,</hi><hi rend="italic"> writing</hi><hi
                            rend="italic"> and</hi><hi rend="italic"> thought</hi><hi rend="italic">
                            presentation</hi><hi rend="italic"> in</hi><hi rend="italic"> a</hi><hi
                            rend="italic"> corpus</hi><hi rend="italic"> of</hi><hi rend="italic">
                            English</hi><hi rend="italic"> writing. </hi>London, New York:<hi
                            rend="italic"> </hi>Routledge.
                </p>
            </div>
        </back>
    </text>
</TEI>