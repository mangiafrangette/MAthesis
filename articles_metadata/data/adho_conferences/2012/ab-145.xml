<?xml version="1.0" encoding="UTF-8"?>
<?oxygen RNGSchema="../schema/xmod_web.rnc" type="compact"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0"
     xmlns:xmt="http://www.cch.kcl.ac.uk/xmod/tei/1.0" 
     xml:id="ab-145">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title>Formal Semantic Modeling for Human and Machine-based Decoding of Medieval Manuscripts</title>
                <author>
                    <name>Ritsema van Eck, Marianne Petra</name>
                    <affiliation>Rijksuniversiteit Groningen, The Netherlands</affiliation>
                    <email>nanne.rve@gmail.com</email>
                </author>
                <author>
                    <name>Schomaker, Lambert</name>
                    <affiliation>Rijksuniversiteit Groningen, The Netherlands</affiliation>
                    <email>schomaker@ai.rug.nl</email>
                </author>
            </titleStmt>
            <publicationStmt>
                <publisher>Jan Christoph Meister, Universität Hamburg</publisher>
                <address>
                   <addrLine>Von-Melle-Park 6, 20146 Hamburg, Tel. +4940 428 38 2972</addrLine>
                   <addrLine>www.dh2012.uni-hamburg.de</addrLine>
              </address>
            </publicationStmt>
            <sourceDesc>
                <p>No source: created in electronic format.</p>
            </sourceDesc>
        </fileDesc>
        <revisionDesc>
            <change>
                <date>2012-04-15</date>
                <name>DH</name>
                <desc>generate TEI-template with data from ConfTool-Export</desc>
            </change>
            <change>
                <date>2012-04-13</date>
                <name>LS</name>
                <desc>provide metadata for publicationStmt</desc>
            </change>
        </revisionDesc>
    </teiHeader>
    <text type="paper">
        <body>
            <div>
            <p>In recent years, archival institutions storing historic handwritten document
                collections have been somewhat reluctant to invest in digitization (scanning). The
                reasons for this are threefold. Firstly, early, rigorous digitization campaigns of
                the past (1985-2000) were costly and sometimes disappointing. Secondly, the quality
                of Optical Character Recognition (OCR) techniques is very low for <hi rend="italic">handwritten</hi> manuscripts. Thirdly, the digitization of historical documents
                and the permanent storage of the resulting digital images is costly. Such
                investments are generally only considered worthwhile if it is possible to access and
                browse the digitized material quickly and easily, in a manner which satisfies a
                large user base.</p>
            
            <p>The <hi rend="italic">Monk</hi> system was developed in answer to the afore-mentioned
                problem: the aim of this project is build an interactive search engine for browsing
                handwritten historical documents, using machine-learning and pattern classification.
                Ultimately, it should become possible to ‘google’ for a search-term in large
                collections of digitized handwritten document images. Traditional OCR fails in
                handwriting, because patterns are largely connected, noisy and difficult to read,
                even for humans. In addition, historical script types vary tremendously according
                spatio-temporal origins. Furthermore, traditional Automatic Handwriting Recognition
                (AHM) techniques require many examples of a single word or letter class from a
                single writer to be considered feasible in this case, and training occurs off line,
                in a lab or company. Therefore, an innovative new bootstrapping method based on
                user-based word labeling was developed to train a computer system, <hi rend="italic"
                    >Monk, </hi>to read historical scripts (Zant, van der et al. 2009). This system
                has been used successfully in the first massive processing of early twentieth
                century handwriting in the Dutch ‘Cabinet of the Queen.’ The success of this
                endeavor stimulated the research in the direction of older, more difficult
                material.</p></div>
            
            <div>
            <head>A Difficult Case: the Leuven Alderman’s Rolls</head>
            <p>The Leuven city archive is currently in the process of digitizing its collection of
                the Leuven Alderman’s rolls, early fifteenth century. This text is the urban record
                of voluntary jurisdiction and disputes settled by the Aldermen; individual cases are
                described in short legal acts. As a pilot study, the book of the year 1421 (MS SAL
                7316, Leuven City Archive, Belgium) was ingested by the <hi rend="italic">Monk</hi>
                system, with the aim of achieving handwriting recognition on the current Gothic
                minuscule these hundreds of pages are written in. Indeed, this is no easy feat,
                considering that contemporary humans need special training to be able to read this
                script. However, even if one – as a human – can decipher series of individual
                characters (letters, abbreviations, glyphs) in the text, this does not directly lead
                to understanding. Firstly, there is a linguistic barrier: the rolls are written
                mostly in Latin and occasionally in Middle Dutch. Secondly, in order to understand
                what the text means one needs much background knowledge about the type of text and
                the administration of justice in medieval Leuven. As the <hi rend="italic">Monk
                </hi>system still makes many mistakes in its attempts to read the script of the
                Leuven alderman’s rolls, it seems that additional modeling is needed to improve
                results of computer-based reading.</p></div>
            
            <div>
            <head>Contextual Modeling: Language and Semantics</head>
            <p>The idea of top-down linguistic support for bottom-up word hypotheses generated by a
                script classifier such as <hi rend="italic">Monk</hi> – is not entirely new. The use
                of a statistical language model to improve offline handwriting recognition has been
                proposed (Zimmerman &amp; Bunke 2004). However, the use of a general language model
                or syntax will not do in case of the Leuven Alderman’s rolls. Firstly, the text
                employs a register of highly artificial legal language. Secondly, no formal language
                models are existent for the Middle Dutch and Medieval Latin it employs and no
                encoded text corpus exists for the automatic generation of a ‘stochastic grammar’
                (Manning &amp; Schütze 1999).</p>
            <p>Therefore, a semantic model was developed to support recognition by <hi rend="italic"
                    >Monk </hi>in the rolls. While syntactic modeling may fail due to input
                variation and variability, semantics are invariably present in any utterance of
                language. A semantic framework can support both the human- and machine-based
                decoding. In the case of the Leuven Alderman’s rolls, meaning, i.e. higher knowledge
                levels, supports the recognition of words and letter forms at the lexical and
                orthographical level. Human readers, as opposed to digital document processors,
                sample text opportunistically and take into account contextual information
                eclectically (Schomaker 2007). To distinguish the /v/ from the /b/ in current gothic
                minuscule the human reader may rely on contextual information where an uninformed
                computer program cannot. More specifically, the interpretation of the ink patterns
                on a page is determined by an expectancy on what to find in the text. In case of an
                ‘IOU’, for instance, the reader expects to find, somewhere, the names of two
                persons, a sum of money, and possibly a date of payment. The more difficult the
                deciphering of patterns at the small scale, the more important is the role of such
                additional high-level information and expectation at a larger scale of observation:
                the semantics expressed by a text block of about a paragraph or administrative entry
                (‘item’) in the case of an administrative archive.</p></div>
                
                <div>
            <head>Semantic Support</head>
            <p>During the present project a framework for disclosing the semantics contained in the
                digital image of the manuscript page was attempted. First, the accomplishments of
                historical philological method and manuscript studies were put into practice to
                create a ‘world model’ as introduced in the field of artificial intelligence (Schank
                1975), specifying objects, their attributes and their mutual (abstract)
                relationships. Such a model is the necessary ‘historical backdrop’ for understanding
                the text. It includes vital information elements, such as the specific type of legal
                text and its place in the process of administering voluntary justice (Synghel G. v.
                2007; Smulders 1967).</p>
            <p>Secondly, a typology of types of acts was formulated, with the help of scholarship on
                    the comparable alderman’s rolls of Den Bosch (van Synghel 1993; Spierings 1984).
                    This typology of acts functions as a fundamental part of the interpretative
                    apparatus. Exhaustive knowledge about which key phrases encode for a certain
                    type of act, immensely help in identifying the real-life legal transaction an
                    act refers to. However, the gap between high level meaning and the 2-dimensional
                    format of the document still needs to be bridged.</p></div>
            
            <div>
            <head>Towards a Formal Semantic Modeling of the Act</head>
            <p>In the research field of document structure and lay-out analysis a distinction is
                commonly made between ‘geometrical layout’ and ‘logical content’; referring to
                specific visual regions on the page, and their content and/or functional label, and
                reading order. The logical structure can then be mapped to the relevant geometrical
                regions on the page, to achieve optimal analysis of the document image (Haralick
                1994; Namboodiri &amp; Jain 2007).</p>
            <p>During the second phase of the project ‘The Legal transactions’ a formal
                semantic model was constructed based on the basic distinction between geometrical
                and logical representation, viz. digital image and semantic content respectively.
                The geometrical branch is subdivided in polygonal <hi rend="italic">regions of
                    interest</hi> (ROIs), which again break down into smaller nodes such a ‘ink’ and
                ‘background’. The logical branch describes the structure of semantic content in
                legal acts. By interlinking the relevant nodes the two branches using unique
                identifiers (idROIs), it becomes possible to cross-refer between manuscript page and
                content.</p>
            <p>Several XML schemes for layout and content modeling exist; however, to date none of
                    these standards is designed for handwritten text (Stehno, Egger, &amp; Retti
                    2003; Bulacu,  van Koert &amp; Schomaker 2007). These formalisms are suitable
                    for regular, printed text and rectangular elements. Due to the erratic nature of
                    the page layout and line formation in medieval handwritten manuscripts a system
                    of polygonal visual regions connected to the semantic model by unique identifier
                    codes needs to be used for <hi rend="italic">Monk</hi>, comparable to layout
                    modeling tools such as TrueViz and GEDI.</p>
            <p>None  of these formalisms provide an easy solution for linkage between layout and the
                semantic level: such a connective layer needs to be developed for each particular
                document type. If it is elaborated in Web Ontology Language (OWL) or Resource
                Description Framework (RDF), the ‘aldermen’ semantic model can be used to train <hi rend="italic">Monk </hi>to recognize the structural elements of acts and
                formulate hypotheses about their meaning. Conversely, the same model may assist in
                interactive teaching of humans as to where to locate the desired information in an
                act. The most exciting finding of this study was that superficial low-level ink
                patterns and glyphs can be used to infer clues about the semantic content, which in
                turn constrains the large number of possible text interpretations.</p>
            </div>
            <div>
            <p>As an example, a selection of the most basic logical components in
                the legal acts was made:</p>            
            <xmt:uList>
                <item>the start of a new act is signaled by ‘<hi rend="italic">Item</hi>’
                    (X<hi rend="sub">0</hi>,Y<hi rend="sub">0</hi>)</item>
                <item>the <hi rend="italic">semantic anchor</hi> reveals the type of legal
                    transaction (X<hi rend="sub">1</hi>,Y<hi rend="sub">1</hi>)</item>
                <item>names of presiding aldermen and (X<hi rend="sub">2</hi>, Y<hi rend="sub">2</hi>)</item>
                <item>the date give the act legal force (X<hi rend="sub">3</hi>,Y<hi rend="sub">3</hi>)</item>
                <item>the ‘solvit’ glyph signals that a charter was issued and seal-money paid (X<hi rend="sub">4</hi>,Y<hi rend="sub">4</hi>)</item>
            </xmt:uList></div>
            
            <div>
                <p>From a number of pages, 22 acts were manually analyzed in terms of the geometric distribution of element in the horizontal plane. Based on the relative geographical location of these semantic elements and their probability of occurrence in the plane, Monk may weigh his bottom-up hypotheses using a Bayesian model (see fig. 1). The small sample includes only the most basic semantic elements on the page; many more may be added to improve recognition accuracy.</p>
            
                <p><figure><graphic url="img145-1.jpg" rend="left" height="256px" width="341px" mimeType="image/jpeg"/><head>Figure 1</head></figure></p>
            </div>
            
            
                </body>
        <back><div>
                <head>References</head>
           <p><hi rend="bold">Balacu, M., R. van Koert, and L. Schomaker</hi> (2007). <hi
                        rend="italic">Layout Analysis of Handwritten Historical Documents for
                        Searching the Archive of the Cabinet of the Dutch Queen: Proceedings of the
                        9th International Conference on Document Analysis and Recognition.</hi>
                    Curitiba, Brazil, September 2007.</p>
            <p><hi rend="bold">Haralick, R. M.</hi> (1994). <hi rend="italic">Document Image
                        Understanding: Geometric and Logical Layout: Proceedings of the Computer
                        Vision and Pattern Recognition Conference.</hi> Seattle, June 1994.</p>
            <p><hi rend="bold">Manning, C. D., and H. Schütze</hi> (1999). <hi rend="italic"
                        >Foundations of Statistical Language Processing.</hi> Cambridge, Mass.: MIT
                    Press.</p>
            <p><hi rend="bold">Namboodiri, A., and A. Jain</hi> (2007). Document Structure and
                    Layout Analysis. B. B. Chaudhuri (ed), <hi rend="italic">Digital Document
                        Processing</hi>. London: Springer, pp. 29-48.</p>
            <p><hi rend="bold">Schank, R. C.</hi> (1975).<hi rend="italic"> Conceptual Information
                        Processing</hi>. Amsterdam: North-Holland Publishing Company.</p>
            <p><hi rend="bold">Schomaker, L.</hi> (2007). Reading Systems: An Introduction to
                    Digital Document Processing. In B. B. Chaudhuri (ed), <hi rend="italic">Digital
                        Document Processing</hi>. London: Springer, pp 1-26.</p>
            <p><hi rend="bold">Smulders, F. W.</hi> (1967). Over het Schepenprotocol. <hi
                        rend="italic">Brabants Heem</hi> 19: 159-65.</p>
            <p><hi rend="bold">Spierings, M.</hi> (1984). <hi rend="italic">Het Schepenprotocol
                        van’s-Hertogenbosch, 1368-1400</hi>. Tilburg: Stichting Zuidelijk Historisch
                    Contact.</p>
            <p><hi rend="bold">Stehno, B., A. Egger, and G. Retti</hi> (2003) METAe – Automated
                    Encoding of Digitized Texts.<hi rend="italic"> </hi><hi rend="italic">Literary
                        and Linguistic Computing</hi>, 18: 77-88.</p>
            <p><hi rend="bold">Synghel, G. van</hi> (1993). <hi rend="italic">Het Bosc’’ Protocol:
                        een Praktische Handleiding.</hi> ’s-Hertogenbosch: Werken met Brabantse
                    bronnen 2.</p>
            <p><hi rend="bold">Synghel, G. van</hi> (2007). <hi rend="italic">“Actum in camera
                        scriptorum oppidi de Buscoducis”: De stedelijke secretarie
                        van’s-Hertogenbosch to ca. 1450.</hi> Hilversum: Verloren.</p>
            <p><hi rend="bold">Zant, T. van der, et al.</hi> (2009). Where are the Search Engines
                    for Handwritten Documents. <hi rend="italic">Interdisciplinary Science
                        Reviews</hi> 34: 228-39.</p>
            <p><hi rend="bold">Zimmerman, M., and H. Bunke</hi> (2004). <hi rend="italic">Optimizing
                        the Integration of a Statistical Language Model in HMM based Offline
                        Handwriting Text Recognition: Proceedings of the 17th International
                        Conference on Pattern Recognition</hi>. Cambridge, UK, August 2004.</p>
        </div>
        </back>
    </text>
</TEI>