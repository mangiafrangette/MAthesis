Textometry is a methodology of text corpora analysis combining qualitative and quantitative techniques (kwic concordances, word frequency lists, collocations, factorial analysis, etc.). A new generation of textometric open-source software called TXM is currently developped since 2007. This article presents the design of the import environment being developed to allow the platform to analyze various kind of TEI encoded sources. The TXM platform “translates” the TEI source document structure into the terms relevant for textometric analysis: “text units”, “text metadata”, “lexical units”, “word properties”, “text divisions”, primary and secondary “text surface”, “out-of-text”, “pagination”, etc. We will describe how that approach has been validated on a comprehensive set of completely unrelated TEI encoded corpora: “Bibliothèques Virtuelles Humanistes” corpus (16th century books), Flaubert’s “Bouvard et Pécuchet” 19th century novel, corpus of the “DISCOURS” linguistic journal and the TEI version of the Brown 1 million words corpus from the NLTK project.