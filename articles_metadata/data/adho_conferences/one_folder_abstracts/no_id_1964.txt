 The Visionary Cross Project is medium-sized international digital scholarly edition and archive of texts and objects from Anglo-Saxon England (O’Donnell et al., 2012; Rosselli Del Turco, 2014). The objects it studies include two stone crosses, an altar cross/reliquary, and several poems from the Vercelli Book, one of the four main manuscripts of Old English verse. The objects range in size from approximately 5 m to little more than 30 cm. They date from the 8th through the 11th centuries. They include several of the best known and most studied artifacts from the period (see among many others Ó Carragáin, 2005; Orton, 2004). The Visionary Cross Project is both a Digital Library and an edition (O’Donnell, 2013; Leoni et al., 2015; O’Donnell, 2016; Anderson, 2017). Its goals include providing a navigable library of digital replicas of these unique and important artifacts, and a scholarly mediation and assessment of their importance, key features, and relationships. This means that each object must be represented in an appropriate digital format: 3D models, 2D photography, and XML transcriptions. At the same time, the collection as a whole must be overseeable and navigable: users must be able to find their way from 3D object to XML transcription to 2D photograph and back, understanding the relationship of the parts to the whole. Finally, a design goal since the very beginning has been that the project must be easily extensible without negotiation. That is to say that other projects, researchers, and users must be able to discover, access, and reuse independently individual elements of our edition in their own projects without requiring either write-access to our infrastructure or additional permissions beyond the standard licences. In several cases, capturing our data required interventions with the environment that the owners of these objects are unlikely to allow again soon. In such circumstances, others need to be able to discover and access all our material and be able to reuse it for their own purposes. In this paper, we discuss the approach we are taking to the publication of this collection. In particular, we show how Zenodo and Github can be used together in an interrelated set of workflows to disseminate content as both a (machine and human-readable) Linked Open Data Digital Library and a (human readable) Digital Scholarly Edition.  GitHub is a free commercial software development platform, recently purchased by Microsoft, that is widely used by developers to host and review code, manage projects, and build software; it provides a free integrated Jekyll-based web-server that can be used to serve out webpages built within the repository (Wikipedia contributors, 2018; see Spiro, 2016 for a discussion of the use of GitHub in DH). Zenodo is the data repository of the European Community OpenAIRE project. It is hosted by CERN and provides ready and free access to and storage and tools more commonly used for “Big Science” projects (Wikipedia contributors, 2017; Zenodo). In addition to allowing uploads of data from scientific projects, Zenodo can also be used to archive snapshots of projects built in Github, providing long-term preservation and discovery aides such as DOIs to individual GitHub releases (Potter and Smith, 2015; GitHub, 2016). Taken together, these services provide researchers with a complete, free, and archivally responsible way of storing and disseminating data and longer form analyses in formats that work well for both machines and human readers. We are aware that GitHub is a commercial repository (now owned by Microsoft) that does not guarantee long-term preservation. As we demonstrate in the paper, however, the use of GitHub in conjunction with Zenodo does provide archival quality protection for the codebase, each snapshot of which is preserved as a Zenodo record. Zenodo guarantees preservation for the life of CERN + 20 years.  Although we discuss these issues and our solution in the context of the Visionary Cross project, our paper is very much not a project report. The approach we present in this paper simply and easily addresses a number of long-standing issues surrounding the longevity, extensibility, and reusability of data and results in the Digital Humanities:  It ensures the easy discovery and long-term survival of published data and results with no requirement for future maintenance (Publish-and-Forget); It conforms to archival standards and principles for longevity, machine-readability, and linking and is easily scaled (up or down); It is fully available for future extension, addition, excerption, reuse, repurposing, or reanalysis by others without negotiation; It ensures that data and contextual analysis are linked bi-directionally, meaning that users are always able to access the discrete data points from which a Humanities-focused analysis and commentary is built and understand each data point in the context of these larger synthetic research products.   Just as importantly, the techniques we exemplify using objects and analyses from our collection are easily generalised and extended to any small or medium-sized scholarly edition or cultural heritage collection, especially if these objects and analysis are processed by hand or partial automation. These are projects that, in particular, may otherwise find it difficult to justify devoting resources to developing or implementing the workflows and infrastructure necessary to publish datasets or individual pieces of data in a linkable fashion, especially if synthetic, humanities-focussed research and results are the project’s main interest. Although our focus in this paper is on small and medium-sized humanities and cultural heritage projects, the systems we are discussing were developed originally to support “big” science, which commonly works with data on a scale far beyond even the largest Digital Humanities or Cultural Heritage project. In our discussion, we indicate how our approach can be adjusted for use with fully or largely automated processing and publication systems typical of larger Humanities and Cultural Heritage projects. In conclusion, the main value of this work is that it shows how Linked Open Data standards and techniques more typically thought of in the context of large corpora and libraries can be used productively in small and medium scale projects, especially those in which more traditional, synthetic humanities commentary and research are understood to represent a major or even predominant part of the intellectual value of the edition or collection.  At the same time, our paper also shows how data (including collections containing heterogeneous and “unusual” types such as 3D) and analysis can be published in an easily discoverable, archivally sound fashion that requires little to no subsequent maintenance while remaining open to non-negotiated reused and extension.  And finally it demonstrates how data publication can complement rather than compete with traditional longer-form humanities research, ensuring that users can access bidirectionally the discrete data upon which an argument is built and the traditionally more synthetic humanities analysis and commentary that typically provides an essential context in small and medium sized collections and editions.  